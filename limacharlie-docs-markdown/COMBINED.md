# LimaCharlie Complete Documentation

Generated: 2025-10-11 17:39:38

---

# Getting Started

## Quickstart

# Quickstart
LimaCharlie is infrastructure to connect sources of security data, automate activity based on what's being observed, and forward data to where you need it. There's no *correct* way to use it - every environment is different.

That said, the majority of LimaCharlie users require basic endpoint detection and response (EDR) capabilities. This guide will cover:

1. Creating a new [**Organization**](/v2/docs/quickstart#creating-an-organization)
2. Deploying a [**Sensor**](/v2/docs/quickstart#deploying-a-sensor) to the Organization
3. Adding [**Sigma rules**](/v2/docs/quickstart#adding-sigma-rules) to detect suspicious activity
4. Forwarding detections to an external destination as an [**Output**](/v2/docs/quickstart#output)

All of this can be done within our free tier, which offers full platform functionality for up to two (2) sensors. If you haven't already signed up for a free account, please do so at [app.limacharlie.io](https://app.limacharlie.io).

Let's get started!

## Creating an Organization

LimaCharlie organizations are isolated tenants in the cloud, conceptually equivalent to "projects". They can be configured to suit the needs of each deployment.

After accepting the initial Terms of Service, you'll be offered a prompt to create an organization in a selected `Region` with a globally unique `Name`.

Region Selection

The region that you select for an organization is permanent. Please also consider regulatory requirements for you and/or your customers' data.

Once the organization is created, you'll be forwarded to our initial dashboard and Sensor list, which will be empty and ready for the next step.

## Deploying a Sensor

From the Sensors page in your new organization, click `Add Sensor` to open the setup flow for new sensors. Generally speaking, Sensors are executables that install on hosts and connect them to the LimaCharlie cloud to send telemetry, receive commands, and other capabilities.

Sensors Overview

For a full overview of types of sensors and their capabilities, check out [Sensors](/v2/docs/sensors).

The setup flow should make this process straightforward. For example's sake, let's say we're installing a sensor on a Windows 10 (64 bit) machine we have in front of us.

* Choose the Windows sensor type
* Create an Installation Key - this registers the executable to communicate securely with your organization
* Choose the `64 bit (.exe)` installer
* Follow the on-screen instructions to execute the installer properly
* See immediate feedback when the sensor registers successfully with the cloud

Potential Issues

Since sensors are executables that talk to the cloud, antivirus software and networking layers may interfere with installation. If you run into an issue, take a look at troubleshooting.

With a Windows sensor connected to the cloud, you should gain a lot of visibility into the endpoint. If we view the new sensor inside the web application, we'll have access to views such as:

* `Timeline`: the viewer for telemetry events being collected from the endpoint
* `Processes`: the list of processes running on the endpoint, their level of network activity, and commands to manipulate processes (i.e. kill / pause / resume process, or view modules)
* `File System`: an explorer for the endpoint's file system, right in the browser
* `Console`: a safe shell-like environment for issuing commands
* `Live Feed`: a running view of the live output of all the sensor's events

With telemetry coming in from the cloud, let's add rules to detect potentially malicious activity.

## Adding Sigma Rules

Writing security rules and automations from scratch is a huge effort. To set an open, baseline standard of coverage, LimaCharlie maintains a `sigma` add-on which can be enabled for free, and is kept up to date with the [openly maintained threat signatures](https://github.com/SigmaHQ/sigma).

Enabling the Sigma add-on will automatically apply rules to your organization to match these threat signatures so we can begin to see Detections on incoming endpoint telemetry.

Writing Detection and Response rules

Writing your own rules is outside the scope of this guide, but we do encourage checking out [Detection & Response](/v2/docs/detection-and-response) when you're finished.

## Output

Security data generated from sensors is yours to do with as you wish. For example's sake, let's say we want to forward detections to an [Amazon S3 bucket](https://aws.amazon.com/s3/) for longer-lived storage of detections.

From the Outputs page in your organization, click `Add Output` to open the setup flow for new outputs. Again, the setup flow should make this process straightforward.

* Choose the Detections stream
* Choose the Amazon S3 destination
* Configure the Output and ensure it connects securely to the correct bucket:

  + Output Name
  + Bucket Name
  + Key ID
  + Secret Key
  + Region
* Optionally, you can view samples of the detection stream's data (assuming recent detections have occurred)

With this output in place you can extend the life of your detections beyond the 1 year LimaCharlie retains them, and stage them for any tool that can pull from S3.

Endpoint Detection & Response

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

### Related articles

* [Managed Rulesets](/docs/managed-rulesets)
* [Sigma Rules](/docs/sigma-rules)

---

#### What's Next

* [LimaCharlie Core Concepts](/docs/limacharlie-core-concepts)

Table of contents

+ [Creating an Organization](#creating-an-organization)
+ [Deploying a Sensor](#deploying-a-sensor)
+ [Adding Sigma Rules](#adding-sigma-rules)
+ [Output](#output)

---

## Use Cases

# Use Cases
* 1 Minute to read

## Related articles

* [Billing Options](/docs/billing-options)

---

### What's Next

* [Sleeper Mode](/docs/sleeper-mode)

Table of contents

+ [Common LimaCharlie Use Cases](#common-limacharlie-use-cases)

Tags

* [LimaCharlie](/docs/en/tags/LimaCharlie)
* [use cases](/docs/en/tags/use%20cases)

---

## What is LimaCharlie?

# What is LimaCharlie?
* 1 Minute to read

## What's Next

* [Use Cases](/docs/use-cases)

---

# Sensors

## AI Agent Engine [LABS]

# AI Agent Engine [LABS]
> LimaCharlie LABS

The AI Agent Engine Extension allows you to easily codify and execute AI Agents within the context of your Organization with access to the LimaCharlie APIs for investigation, remediation and automation.

The AI Agent definition themselves are managed in the `ai_agent` [Hive](/v2/docs/config-hive) Configurations and can be managed across tenants using the Infrastructure as Code extension. This hive requires the `ai_agent.*` permissions.

The execution of an AI Agent can be triggered through the following means:

1. Interactively in the web app by going to the Extensions section for the AI Agent Engine extension.
2. By issuing an `extension request` action through a [D&R rule](/v2/docs/detection-and-response-examples).
3. By issuing an extension request on the API directly: <https://api.limacharlie.io/static/swagger/#/Extensions/createExtensionRequest>
4. By issuing an extension request through the Python CLI/SDK or Golang SDK, which means they’re also available to [Playbooks](/v2/docs/playbook).

This means agents can be invoked in a fully automated fashion based on events, detections, audit messages or any other [target](/v2/docs/detection-on-alternate-targets) of  rules. But it can also be used in an ad-hoc fashion triggered manually.

## Usage

When invoking an AI Agent, all you need is the playbook name as defined in Hive and an initial message. Optionally, an AI Agent can also receive a JSON dictionary object as parameters, this is useful when passing the AI Agent additional context like a detection or event from a D&R rule.

Interactions with the agent are associated with a given (Interactive) Session ID (ISID). A Session ID is like a ChatGPT session where all the context is available to the agent. Starting a new session returns an `isid` and the `get_session` action requires an `isid`.

Common tips:

* Specify only the subset of tools you want your AI to use, otherwise it may do things you didn’t expect or take initiative in ways you don’t intend.
* Make the AI as specialized as possible, tell it exactly what you want it to do, processes and how you want to get the response (markdown, JSON etc).
* Give the AI examples, adding more details and examples to the `instructions` help greatly.

The credentials provided to the engine are simply a LimaCharlie API key, we recommend storing it in a [secret](/v2/docs/config-hive-secrets) and referencing as `hive://secret/my-lc-creds`.

### Actions

#### start\_session

Start a new AI Agent session, specifying all the detailed parameters (see AI Agent Structure below that are both the Agent Definition parameters and the `start_session` parameters).

#### list\_tools

List all the tools available to be called by the agent along with their categories that can be used to customize agents.

### D&R rule example

Here is an example D&R rule starting a new invocation of a playbook.

```
- action: extension request
  extension name: ext-ai-agent-engine
  extension action: start_session
  extension request:
    agent_definition: '{{ "my-agent-name" }}'
    message: You're a cyber security expert, summarize this detection: {...}
```

### Python example

```
# Import LC SDK
import limacharlie
import json
# Instantiate the SDK with default creds.
lc = limacharlie.Manager()
# Instantiate the Extension manager object.
ext = limacharlie.Extension(lc)

# Issue a request to the "ext-ai-agent-engine" extension for the "my-agent-name" agent.
response = ext.request("ext-ai-agent-engine", "start_session", {
    "agent_definition": "my-agent-name",
    "message": "You're a cyber security expert, summarize this detection: {...}"
})

for msg in response['data']['responses']:
  print(f"AI says: {json.dumps(msg, indent=2)}")
```

## AI Agent structure

### Example AI Agent Definition

The following is a sample AI Agent definition that simply aims at summarizing detections.

```json
{
  "name": "my-agent",
  "description": "Some agent that does something...",
  "credentials": "hive://secret/ai-creds", // These credentials will be used when accessing LimaCharlie APIs.
  // Instructions are the core system behavior for the AI
  "instructions": "You are a cybersecurity expert system who's job it is to summarize detections/alerts for SOC analysts. Output as markdown. Include detailed technical context about the alert and if MITRE techniques are mentioned, summarize them. Also include what next steps of the investigation should be. The audience of the report is a cyber security team at a medium sized enterprise.",
  "max_iterations": 10, // If the AI makes tool calls to the LC API or LC Sensors, this limits the number of iterations the AI is called.
  "allowed_tools": [
    "get_sensor_info" // List of tool categories (see list_tools or the Available Tools section below).
  ]
}
```

### Available Tools

The tools available to the AI Agents are the same ones available from the official [LimaCharlie MCP Server](/v2/docs/mcp-server).

## Infrastructure as Code

Not currently available, coming up.

## Billing

The AI Agent Engine is billed per token processed, including initial messages, prompt and response.

## Privacy

Currently, the model in use is the commercial Gemini models.

Although the models may change (and eventually Bring-Your-Own-Model), these models will never use your data to train more models and LimaCharlie never uses the data to train models.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Command-line Interface

---

### What's Next

* [Playbook [LABS]](/docs/playbook)

Table of contents

+ [Usage](#usage)
+ [AI Agent structure](#ai-agent-structure)
+ [Infrastructure as Code](#infrastructure-as-code)
+ [Billing](#billing)
+ [Privacy](#privacy)

---

## Agent Deployment via Microsoft Intune

# Agent Deployment via Microsoft Intune
* 1 Minute to read

## Related articles

* [Windows Agent Installation](/docs/windows-agent-installation)
* [Building a custom MSI installer for Windows](/docs/building-a-custom-msi-installer-for-windows)

---

### What's Next

* [ChromeOS with Google Chrome Enterprise](/docs/chrome-enterprise)

Table of contents

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## Chrome Agent Installation

# Chrome Agent Installation
* 1 Minute to read

## Related articles

* [ChromeOS with Google Chrome Enterprise](/docs/chrome-enterprise)
* [Edge Agent Installation](/docs/edge-agent-installation)

---

### What's Next

* [Container Clusters](/docs/container-clusters)

Table of contents

+ [Installation Instructions](#installation-instructions)
+ [Troubleshooting the Chrome Sensor](#troubleshooting-the-chrome-sensor)

Tags

* [browser agent](/docs/en/tags/browser%20agent)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)

---

## Config Hive: Cloud Sensors

# Config Hive: Cloud Sensors
* 1 Minute to read

## Related articles

* [Config Hive: Yara](/docs/config-hive-yara)
* [Config Hive: Detection & Response Rules](/docs/config-hive-dr-rules)
* [Config Hive: Secrets](/docs/config-hive-secrets)
* [Config Hive](/docs/config-hive)
* [Config Hive: Lookups](/docs/config-hive-lookups)

---

### What's Next

* [Config Hive: Detection & Response Rules](/docs/config-hive-dr-rules)

Table of contents

+ [Format](#format)
+ [Permissions](#permissions)
+ [Command-Line Usage](#command-line-usage)
+ [Usage](#usage)
+ [Example](#example)

Tags

* [api](/docs/en/tags/api)
* [platform](/docs/en/tags/platform)

---

## Detecting Sensors No Longer Sending Data

# Detecting Sensors No Longer Sending Data
## **Overview**

A common request is to alert an administrator if a Sensor that normally forwards data, stops or fails to send data. This LimaCharlie Playbook is meant to be triggered on a schedule by  rule. It checks for data sent, via the LimaCharlie Python SDK, within a given time window. If no data is sent during the time period, then an alert is generated, one per sensor.

### Example Playbook Code

```python
import limacharlie
import time

# LimaCharlie D&R Rule to trigger this playbook
# every 30 minutes.
# detection:
#   target: schedule
#   event: 30m_per_org
#   op: exists
#   path: /
# response:
# - action: extension request
#   extension name: ext-playbook
#   extension action: run_playbook
#   extension request:
#     name: check-missing-data
#     credentials: hive://secret/playbook-missing-data-creds

SENSOR_SELECTOR = "plat == windows and `server` in tags"
DATA_WITHIN = 10 * 60 * 1000 # 10 minutes

def notify_missing_data(sdk: limacharlie.Limacharlie, sensor: limacharlie.Sensor):
    # TODO: Implement this, but it's optional if all you want is a detection
    # since those will be generated automatically.
    pass

def get_relevant_sensors(sdk: limacharlie.Limacharlie) -> list[limacharlie.Sensor]:
    sensors = sdk.sensors(selector=SENSOR_SELECTOR)
    relevant_sensors = []
    for sensor in sensors:
        relevant_sensors.append(sensor)
    return relevant_sensors

def playbook(sdk: limacharlie.Limacharlie, data: dict) -> dict | None:
    # Get the sensors we care about.
    relevant_sensors = get_relevant_sensors(sdk)

    stopped_sensors = []

    # For each sensor, check if we've received data within that time period.
    for sensor in relevant_sensors:
        # To do that we will get the data overview and see if a recent time stamp is present.
        data_overview = sensor.getHistoricOverview(int(time.time() - DATA_WITHIN), int(time.time()))
        after = int(time.time() * 1000) - DATA_WITHIN
        for timestamp in data_overview:
            if timestamp > after:
                print(f"Data received for sensor {sensor.sid} at {timestamp}")
                break
        else:
            print(f"No data received for sensor {sensor.sid} in the last {DATA_WITHIN} seconds")
            notify_missing_data(sdk, sensor)
            stopped_sensors.append(sensor)

    # Report a detection for stopped sensors.
    if stopped_sensors:
        return {"detection":{
            "stopped_sensors": [sensor.sid for sensor in stopped_sensors]
        }}
    return None
```

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

#### What's Next

* [Ingesting Defender Event Logs](/docs/ingesting-defender-event-logs)

Table of contents

---

## Docker Agent Installation

# Docker Agent Installation
## Docker

The LimaCharlie agent is designed to run within a Docker container, providing seamless integration with containerized environments. Running the agent in a container allows for efficient deployment and management while ensuring security monitoring and telemetry collection.

Additionally, the agent can also be deployed on various container cluster technologies, such as Kubernetes. For Kubernetes deployment details, refer to [Container Clusters](https://docs.limacharlie.io/docs/container-clusters).

### Host Visibility Requirements

For the LimaCharlie agent to have full visibility into activities on the host system, the following configurations are required:

* The container must run in **privileged mode** to access host-level resources.
* The container must use **host networking** to observe network activity.
* The container must use **host PID mode** to track running processes.
* Various **host-level directories** must be mounted into the container, including:

  + The root filesystem (`rootfs`)
  + Docker network namespaces (`netns`)
  + The directory containing kernel modules and debug symbols

Additionally, on newer Linux kernel versions (5.7+), the agent leverages **eBPF** for enhanced visibility and telemetry collection.

#### Agent Docker Image

A publicly available Docker image for the LimaCharlie agent is hosted on [Docker Hub](https://hub.docker.com/r/refractionpoint/limacharlie_sensor):

```
docker pull refractionpoint/limacharlie_sensor:latest
```

##### Image Flavors

Docker image is available in different flavors based on specific distributions:

* `latest` - Default version based on CentOS Linux.
* `alpine` - Based on Alpine Linux (smaller image size).
* `centos` - Based on CentOS Linux.

#### Available Environment Variables

The agent supports several environment variables to control its behavior:

* `LC_INSTALLATION_KEY` - Specifies the installation key required to authenticate the agent.
* `HOST_FS` - Defines the path where the host's root filesystem is mounted within the container. Example: `/rootfs`.
* `NET_NS` - Specifies the path to the host's network namespace directory. Example: `/netns`.

These variables must be configured appropriately to ensure the agent functions as expected.

#### Running the Agent Using Docker CLI

To run the LimaCharlie agent in a Docker container, use the following command:

```
docker run --privileged --net=host \
  -v /:/rootfs:ro \
  -v /var/run/docker/netns:/netns:ro \
  -v /sys/kernel/debug:/sys/kernel/debug:ro \
  -v /sys/kernel/btf:/sys/kernel/btf:ro \
  -v /lib/modules:/lib/modules:ro \
  --env LC_INSTALLATION_KEY=<your_key> \
  --env HOST_FS=/rootfs \
  --env NET_NS=/netns \
  refractionpoint/limacharlie_sensor:latest
```

Ensure that you replace `<your_key>` with your actual LimaCharlie installation key.

#### Running the Agent Using Docker Compose

You can also manage the LimaCharlie agent using Docker Compose. Below is a sample `docker-compose.yml` file:

```
services:
  lc-sensor:
    image: refractionpoint/limacharlie_sensor:latest
    restart: unless-stopped
    network_mode: "host"
    pid: "host"
    privileged: true
    environment:
      - HOST_FS=/rootfs
      - NET_NS=/netns
      - LC_INSTALLATION_KEY=<your key>
    deploy:
      resources:
        limits:
          cpus: "0.9"
          memory: "256M"
        reservations:
          cpus: "0.01"
          memory: "128M"
    cap_add:
      - SYS_ADMIN
    volumes:
      - /:/rootfs
      - /var/run/docker/netns:/netns
      - /sys/kernel/debug:/sys/kernel/debug
      - /sys/kernel/btf:/sys/kernel/btf
      - /lib/modules:/lib/modules
```

To start the container, run:

```
docker-compose up -d
```

This setup ensures the agent runs as a privileged container, enabling full visibility into the host system while being managed through Docker Compose.

#### Building a Custom Docker Image

If you need to create a custom Docker image incorporating the LimaCharlie agent, you can use the following Dockerfile as a base:

```
FROM alpine

RUN mkdir /lc
WORKDIR /lc

RUN wget https://downloads.limacharlie.io/sensor/linux/alpine64 -O lc_sensor
RUN chmod 500 ./lc_sensor

CMD ["./lc_sensor", "-d", "-"]
```

Build the image using:

```
docker build -t my-lc-agent .
```

---

##### Related articles

* [Kubernetes Pods Logs](/docs/adapter-types-kubernetes-pods-logs)
* [Container Clusters](/docs/container-clusters)

---

###### What's Next

* [Edge Agent Installation](/docs/edge-agent-installation)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [linux](/docs/en/tags/linux)
* [sensors](/docs/en/tags/sensors)

---

## Edge Agent Installation

# Edge Agent Installation
* 1 Minute to read

## Related articles

* [ChromeOS with Google Chrome Enterprise](/docs/chrome-enterprise)
* [Chrome Agent Installation](/docs/chrome-agent-installation)

---

### What's Next

* [Linux Agent Installation](/docs/linux-agent-installation)

Table of contents

+ [Edge Installation Instructions](#edge-installation-instructions)

Tags

* [browser agent](/docs/en/tags/browser%20agent)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)

---

## Endpoint Agent

# Endpoint Agent
* 1 Minute to read

## Related articles

* [Sensors](/docs/sensors)
* [Windows Agent Installation](/docs/windows-agent-installation)
* [Endpoint Agent Uninstallation](/docs/endpoint-agent-uninstallation)
* [Endpoint Agent Versioning and Upgrades](/docs/endpoint-agent-versioning-and-upgrades)
* [Installation Keys](/docs/installation-keys)
* [Sensor Connectivity](/docs/sensor-connectivity)

---

### What's Next

* [Endpoint Agent Commands](/docs/endpoint-agent-commands)

Table of contents

+ [Endpoint Agent Types](#endpoint-agent-types)
+ [Quota](#quota)
+ [Events](#events)
+ [Commands](#commands)
+ [Installation Keys](#installation-keys)
+ [Sensor Versions &amp; Upgrades](#sensor-versions-amp-upgrades)

Tags

* [browser agent](/docs/en/tags/browser%20agent)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [linux](/docs/en/tags/linux)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## Endpoint Agent Commands

# Endpoint Agent Commands
Endpoint Agent commands offer a safe way to interact with a Sensor's host either for investigation, management, or threat mitigation purposes.

## Sending Commands

Commands can be sent to Sensors via:

* Manually using the Console of a sensor in the [web application](https://app.limacharlie.io).
* Manually using the [CLI](https://github.com/refractionPOINT/python-limacharlie)
* Programmatically in the response action of a [Detection & Response](/v2/docs/detection-and-response) rule, via the `task` action.
* Programmatically using the [REST API](https://doc.limacharlie.io/docs/api/b3A6MTk2NDI0OQ-task-sensor)

Sensor REPort/REPly Events

Regardless of which you choose, sent commands will be acknowledged immediately with an empty response, followed by a `CLOUD_NOTIFICATION` event being sent by the sensor. The content of command outputs are delivered as sensor [events](/v2/docs/endpoint-agent-events-overview) suffixed with `_REP`, depending on the command.

**Please ensure that you have enabled the appropriate response event(s) in** [**Event Collection**](/v2/docs/ext-exfil) **to ensure that you will receive the Sensor response.**

This non-blocking approach makes responses accessible via the [event streams](/v2/docs/sensors) passing through Detection & Response rules and Outputs.

## Structure

Commands follow typical CLI conventions using a mix of positional arguments and named optional arguments.

Here's `dir_list` as an example:

```
dir_list [-h] [-d DEPTH] rootDir fileExp

positional arguments:
    rootDir     the root directory where to begin the listing from
    fileExp     a file name expression supporting basic wildcards like * and ?

optional arguments:
    -h, --help      show this help message and exit
    -d DEPTH, --depth DEPTH     optional maximum depth of the listing, defaults to a single level
```

The Console in the web application will provide autocompletion hints of possible commands for a sensor and their parameters. For API users, commands and their usage details may be retrieved via the `/tasks` and `/task` REST API endpoints.

## Investigation IDs

To assist in finding the responses more easily, you may specify an arbitrary `investigation_id` string with a command. The response will then include that value under `routing/investigation_id`. Under the hood, this is exactly how the Console view in the web application works.

If an `investigation_id` is prefixed with `__` (double underscore) it will omit the resulting events from being forwarded to Outputs. This is primarily to allow Services to interact with sensors without spamming.

## Command Line Format

When issuing commands to sensors as a command line (versus a list of tokens), the quoting and escaping of arguments can be confusing. This is a short explanation:

The command line tasks are parsed as if they were issued to a shell like `sh` or `cmd.exe` with a few tweaks to make it easier and more intuitive to use.

Arguments are parsed as separated by spaces, like: `dir_list /home/user *` is equal to 2 arguments: `/home/user` and `*`.

If an argument contains spaces, for example a single directory like `/file/my files`, you must use either single (`'`) or double (`"`) quotes around the argument, like: `dir_list "/files/my files"`.

A backslash (`\`), like in Windows file paths does not need to be escaped. It is only interpreted as an escape character when it is followed by a single or double quote.

The difference between single quotes and double quotes is that double quotes support escaping characters within using `\`, while single quotes never interpret `\` as an escape character. For example:

* `log_get --file "c:\\temp\\my dir\\" --type json` becomes `log_get`, `--file`, `c:\temp\my dir\`, `--type`, `json`
* `log_get --file 'c:\\temp\\my dir\\' --type json` becomes `log_get`, `--file`, `c:\\temp\\my dir\\`, `--type`, `json`
* `log_get --file 'c:\temp\my dir\' --type json` becomes `log_get`, `--file`, `c:\temp\my dir\`, `--type`, `json`
* `log_get --file "c:\temp\my dir\\" --type json` becomes `log_get`, `--file`, `c:\temp\my dir\`, `--type`, `json`

This means that as a general statement, unless you want to embed quoted strings within specific arguments, it is easier to use single quotes around arguments and not worry about escaping `\`.

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Command-line Interface

---

### Related articles

* [Reference: EDR Events](/docs/reference-edr-events)
* [Endpoint Agent Events Overview](/docs/endpoint-agent-events-overview)
* [Detection and Response](/docs/detection-and-response)
* [Response Actions](/docs/response-actions)
* [Payloads](/docs/payloads)
* [Installation Keys](/docs/installation-keys)
* [Reference: Error Codes](/docs/reference-error-codes)
* [Exfil (Event Collection)](/docs/ext-exfil)

---

#### What's Next

* [Reference: Endpoint Agent Commands](/docs/reference-endpoint-agent-commands)

Table of contents

+ [Sending Commands](#sending-commands)
+ [Structure](#structure)
+ [Investigation IDs](#investigation-ids)
+ [Command Line Format](#command-line-format)

Tags

* [browser agent](/docs/en/tags/browser%20agent)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [linux](/docs/en/tags/linux)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## Endpoint Agent Events Overview

# Endpoint Agent Events Overview
## Overview

This category describes and provides samples for the various events emitted by the LimaCharlie Endpoint Agent Sensor. These events can be leveraged in [D&R rules](/v2/docs/detection-and-response) and queried with [LCQL](/v2/docs/lcql).

Important note about Event Collection

Only events enabled in the Exfil configuration will be shipped by the endpoint agent. If you're not seeing a specific event you expect, make sure that the desired event type is enabled in the [Exfil extension](/v2/docs/ext-exfil) configuration. Ensure your Exfil settings are properly configured to capture all required event types for your use case.

## Atoms

Atoms are Globally Unique Identifiers (GUIDs). An example might be: `1e9e242a512d9a9b16d326ac30229e7b`. You can treat them as opaque values. These unique values are used to relate events together rather than using Process IDs, which are themselves unreliable.

### Relationships

Atoms can be found in up to 3 spots in an event:

* `routing/this`: current event
* `routing/parent`: parent of the current event
* `routing/target`: target of the current event

Using atom references from a single event, the chain of ancestor events can be constructed. Here's a simplified example of an event and its parent event:

**Child event:**

```json
{
  "event": {...},
  "routing": {
    "this": "abcdef",
    "parent": "zxcv"
    ...
  }
}
```

**Parent event:**

```json
{
  "event": {...},
  "routing": {
    "this": "zxcv",
    "parent": "poiuy"
    ...
  }
}
```

API users may construct a tree from a single atom using these 2 endpoints:

* `/insight/{oid}/{sid}/{atom}` - get event by atom
* `/insight/{oid}/{sid}/{atom}/children` - get children of an atom

These can be called recursively on each event's `routing/parent` and/or child events to complete a full tree if required - this is how the tree view works in the Timeline of a sensor in the web application.

The parent-child relationship serves to describe parent and child processes via the `NEW_PROCESS` or `EXISTING_PROCESS` events, but other types of events may also have parents. For example, on `NETWORK_SUMMARY` events, the `parent` will be the process that generated the network connections.

Tip: when using custom storage and/or searching solutions it's helpful to index the values of `routing/this` and `routing/parent` for each event. Doing so will speed up searching during threat hunting and investigations.

Finally, the `routing/target` is only sometimes found in an event, and it represents an event that interacts with another event without having a parent-child relationship. For example, in the `NEW_REMOTE_THREAD` event, this `target` represents a process where a remote thread was created.

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, Exfil (Event Collection) is a configuration extension that determines which types of events are collected and sent from endpoint agents to the cloud. It controls the data flow, ensuring only specified events are transmitted for monitoring and analysis. To capture specific events, they must be enabled within the Exfil or Event Collection settings.

In LimaCharlie, Exfil (Event Collection) is a configuration extension that determines which types of events are collected and sent from endpoint agents to the cloud. It controls the data flow, ensuring only specified events are transmitted for monitoring and analysis. To capture specific events, they must be enabled within the Exfil or Event Collection settings.

---

#### Related articles

* [Reference: EDR Events](/docs/reference-edr-events)
* [Exfil (Event Collection)](/docs/ext-exfil)
* [Event Schemas](/docs/event-schemas)
* [Reference: Platform Events](/docs/reference-platform-events)
* [Events](/docs/events)

---

##### What's Next

* [Sysmon Comparison](/docs/sysmon-comparison)

Table of contents

+ [Overview](#overview)
+ [Atoms](#atoms)

Tags

* [browser agent](/docs/en/tags/browser%20agent)
* [detection and response](/docs/en/tags/detection%20and%20response)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [events](/docs/en/tags/events)
* [linux](/docs/en/tags/linux)
* [macos](/docs/en/tags/macos)
* [windows](/docs/en/tags/windows)

---

## Endpoint Agent Installation

# Endpoint Agent Installation
The Endpoint Agent is signed, and the same for everyone. The endpoint agent's customization, which indicates the owner, is done at installation based on the [installation key](/v2/docs/installation-keys) used. The Installation Key specifies where the Sensor should connect to enroll, as well as the encryption key used to start the enrollment process.

Enterprise-wide deployment

Looking to deploy many endpoint agents at once? Check out Enterprise Sensor Deployment.

Installing the endpoint agent does not require a reboot.

## Installing the Endpoint Agent

The sensors are designed to be simple to use and re-package for any deployment methodology you use in your Organization.

The sensor requires administrative privileges to install. On Windows this means an Administrator or System account, on macOS and Linux it means the root account.

Before installing, you will need the [installation key](/v2/docs/installation-keys) you want to use.

For OS-specific installation instructions, choose your OS in the nav bar on the left.

## Required Permissions

**Windows**

* Administrative privileges - Must run as LocalSystem service
* SeDebugPrivilege - Debug programs privilege
* SeBackupPrivilege - Back up files and directories privilege
* SeRestorePrivilege - Restore files and directories privilege

**Linux**

* Root privileges (UID 0) - Required for system monitoring
* RLIMIT\_MEMLOCK set to RLIM\_INFINITY - For eBPF program loading
* Mount capabilities - For filesystem mounting
* CAP\_BPF or CAP\_SYS\_ADMIN - For eBPF kernel module operation
* CAP\_NET\_ADMIN - For network monitoring

**macOS**

* Root privileges (UID 0) - Required for system monitoring
* Kernel extension entitlements - Including com.apple.security.cs.debugger
* Apple KPI dependencies - bsd, libkern, dsep, mach kernel programming interfaces

**Cross-Platform Requirements**

* File system read/write access to system directories
* Process monitoring capabilities
* Network monitoring and outbound HTTPS access
* Registry access (Windows) for system configuration

> Note: The sensors require these elevated privileges for legitimate security monitoring including process detection, file system monitoring, network analysis, and kernel-level telemetry collection.

## Downloading the Agents

To download the single installers relevant for your deployment, access the `/download/[platform]/[architecture]` control plane.
 The `platform` component is one of `win`, `linux` or `osx` while the `architecture` component is either `32` or `64`.

For example:

* <https://downloads.limacharlie.io/sensor/windows/32> for the Windows 32 bit executable installer
* <https://downloads.limacharlie.io/sensor/windows/64> for the Windows 64 bit executable installer
* <https://downloads.limacharlie.io/sensor/windows/msi32> for the Windows 32 bit MSI installer
* <https://downloads.limacharlie.io/sensor/windows/msi64> for the Windows 64 bit MSI installer
* <https://downloads.limacharlie.io/sensor/linux/64> for the Linux 64 bit installer
* <https://downloads.limacharlie.io/sensor/linux/alpine64> for the Linux Alpine 64 bit installer
* <https://downloads.limacharlie.io/sensor/linux/deb32> for the Linux 32 bit Debian package
* <https://downloads.limacharlie.io/sensor/linux/deb64> for the Linux 64 bit Debian package
* <https://downloads.limacharlie.io/sensor/linux/debarm64> for the Linux ARM 64 bit Debian package
* <https://downloads.limacharlie.io/sensor/mac/64> for the macOS 64 bit installer
* <https://downloads.limacharlie.io/sensor/mac/arm64> for the macOS ARM 64 bit (Apple Silicon) installer
* h[ttps://downloads.limacharlie.io/sensor/chrome](https://downloads.limacharlie.io/sensor/chrome) for the Chrome extension
* <https://downloads.limacharlie.io/sensor/edge> for the MS Edge extension

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

### Related articles

* [Endpoint Agent Uninstallation](/docs/endpoint-agent-uninstallation)
* [Endpoint Agent Events Overview](/docs/endpoint-agent-events-overview)
* [Endpoint Agent Versioning and Upgrades](/docs/endpoint-agent-versioning-and-upgrades)
* [Installation Keys](/docs/installation-keys)
* [FAQ - Sensor Installation](/docs/faq-sensor-installation)

---

#### What's Next

* [Chrome Agent Installation](/docs/chrome-agent-installation)

Table of contents

+ [Installing the Endpoint Agent](#installing-the-endpoint-agent)
+ [Required Permissions](#required-permissions)
+ [Downloading the Agents](#downloading-the-agents)

Tags

* [browser agent](/docs/en/tags/browser%20agent)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [linux](/docs/en/tags/linux)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## Endpoint Agent Uninstallation

# Endpoint Agent Uninstallation
* 1 Minute to read

## Related articles

* [Endpoint Agent](/docs/endpoint-agent)
* [Docker Agent Installation](/docs/docker-agent-installation)
* [macOS Agent Installation](/docs/macos-agent-installation)
* [Endpoint Agent Events Overview](/docs/endpoint-agent-events-overview)
* [Chrome Agent Installation](/docs/chrome-agent-installation)
* [Windows Agent Installation](/docs/windows-agent-installation)
* [macOS Agent Installation via Jamf Now](/docs/installing-macos-agents-via-jamf-now)
* [Linux Agent Installation](/docs/linux-agent-installation)
* [Endpoint Agent Installation](/docs/endpoint-agent-installation)
* [Edge Agent Installation](/docs/edge-agent-installation)
* [macOS Agent Installation - Older Versions (macOS 10.15 Catalina to macOS 14 Sonoma)](/docs/macos-agent-installation-latest-os-versions)
* [macOS Agent Installation - Older Versions (macOS 10.14 and prior)](/docs/macos-agent-installation-older-versions)

---

### What's Next

* [Endpoint Agent Versioning and Upgrades](/docs/endpoint-agent-versioning-and-upgrades)

Table of contents

+ [Manually Uninstalling the {{glossary.Endpoint Agent}}](#manually-uninstalling-the-{{glossary-endpoint-agent}})
+ [Uninstalling Endpoint Agents from the Platform](#uninstalling-endpoint-agents-from-the-platform)
+ [Package Management Tools](#package-management-tools)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [linux](/docs/en/tags/linux)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## Endpoint Agent Versioning and Upgrades

# Endpoint Agent Versioning and Upgrades
## Endpoint Agent Versioning and Upgrades

LimaCharlie frequently releases new versions of the endpoint agent (typically every few weeks), giving you full control over which version runs in your Organization. Sensors are not updated by default, allowing you to manage versioning and deployment as needed.

### Endpoint Agent Components

The LimaCharlie endpoint agent consists of two main components, each versioned independently:

1. **On-disk agent**: Implements core identity, cryptography, and transport mechanisms. This component rarely requires updates and typically remains static.
2. **Over-the-air core**: The main component that receives frequent updates and delivers advanced functionality. It can be easily updated via the LimaCharlie cloud.

When updates occur, they impact the over-the-air component, as it's the easiest to modify, with the update size generally being around 3-5 MB.

### Version Labels

LimaCharlie provides three version labels to simplify version management:

1. **Latest**: The most recent release with new fixes and features.
2. **Stable**: A less frequently updated version, ideal for maintaining slower update cadences.
3. **Experimental**: The beta version of the next "Latest" release.

You can upgrade to any of these versions for your organization by using the LimaCharlie web interface or the [API](https://api.limacharlie.io/static/swagger/#/Modules/upgradeOrg).

### Managing Versioning for Sensors

To manage the versioning of sensors, you can leverage LimaCharlie’s **System** Tags:

* `lc:latest`: Tags the Sensor to receive the most recent version.

  + This tag is primarily intended for testing `latest` sensor version against a small set of representative sensors before org-wide upgrades to `latest`.
* `lc:stable`: Tags the sensor to receive a stable version.
* `lc:experimental`: Tags the sensor to receive the experimental version.

These tags can be applied to individual sensors to alter version behavior, and updates take effect within 10 minutes. This method also enables staging deployments to test updates on a small group of sensors before organization-wide rollouts.

### Updating Endpoint Agents

#### Best Practices

When deploying new sensor versions, follow a controlled testing approach by first applying the `lc:latest` tag to a small subset of representative systems across different operating systems and workloads. Monitor these test systems for a period of time, evaluating stability, performance, and telemetry quality. If testing is successful, update the organization-level sensor version and remove the `lc:latest` tag from test systems, while maintaining a rollback plan and monitoring system health during the deployment. Note that the `lc:latest` sensor tag should primarily be used for upgrade testing purposes, as it automatically updates sensors to new versions as they are released.

#### Manual Update

You can manually trigger an update for all endpoint agents in your organization by simply clicking a button in the web interface. This action updates the over-the-air component of the sensors within 20 minutes, with no need to re-download installers, as the installer remains unchanged.

#### Auto-Update

To automate updates, apply the `lc:stable` tag to your sensors. This will ensure that sensors automatically update to the latest stable version upon release.

#### Staged Deployment

For testing new versions, tag specific sensors with `lc:latest` to run the latest version without affecting the rest of your organization. This allows you to test new releases on selected hosts before proceeding with a full rollout.

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

##### Related articles

* [Endpoint Agent](/docs/endpoint-agent)
* [Endpoint Agent Events Overview](/docs/endpoint-agent-events-overview)
* [Installation Keys](/docs/installation-keys)
* [Sensor Tags](/docs/sensor-tags)

---

###### What's Next

* [Payloads](/docs/payloads)

Table of contents

+ [{{glossary.Endpoint Agent}} Versioning and Upgrades](#{{glossary-endpoint-agent}}-versioning-and-upgrades)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)

---

## Endpoint Detection and Response (EDR)

# Endpoint Detection and Response (EDR)
* 1 Minute to read

## What's Next

* [Enterprise SOC](/docs/enerprises)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)
* [EDR](/docs/en/tags/EDR)
* [use case](/docs/en/tags/use%20case)

---

## Enterprise-Wide Agent Deployment

# Enterprise-Wide Agent Deployment
* 1 Minute to read

## Related articles

* [Agent Deployment via Microsoft Intune](/docs/agent-deployment-microsoft-intune)
* [ChromeOS with Google Chrome Enterprise](/docs/chrome-enterprise)

---

### What's Next

* [Agent Deployment via Microsoft Intune](/docs/agent-deployment-microsoft-intune)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)

---

## FAQ - Sensor Installation

# FAQ - Sensor Installation
## How can I add LimaCharlie traffic to an allow list?

The tables below show the hostnames and IPs used to connect to LimaCharlie. All connections use TCP port 443 and TLS 1.2+

## What Hostnames and IPs does LimaCharlie use for each region?

### Canada (Quebec)

| Hostname | IP | Use |
| --- | --- | --- |
| aae67d7e76570ec1.lc.limacharlie.io | 35.203.33.203 | Windows, Mac, & Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) |
| aae67d7e76570ec1.edr.limacharlie.io | 35.201.82.57 | Windows, Mac, & Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) |
| aae67d7e76570ec1.wss.limacharlie.io | 35.201.96.199 | Chrome, Edge and Adapters |
| aae67d7e76570ec1.ingest.limacharlie.io | 34.149.216.238 | Logs and Artifacts |
| aae67d7e76570ec1.replay.limacharlie.io | 142.250.115.121 | Replay |
| aae67d7e76570ec1.live.limacharlie.io | 34.120.175.14 | Live feed |
| aae67d7e76570ec1.hook.limacharlie.io | 142.250.115.121 | Webhooks |

### US (Iowa)

| Hostname | IP | Use |
| --- | --- | --- |
| 9157798c50af372c.lc.limacharlie.io | 35.194.62.236 | Windows, Mac, & Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) |
| 9157798c50af372c.edr.limacharlie.io | 34.149.165.165 | Windows, Mac, & Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) |
| 9157798c50af372c.wss.limacharlie.io | 34.102.223.182 | Chrome, Edge and Adapters |
| 9157798c50af372c.ingest.limacharlie.io | 34.120.157.194 | Logs and Artifacts |
| 9157798c50af372c.replay.limacharlie.io | 142.250.115.121 | Replay |
| 9157798c50af372c.live.limacharlie.io | 34.120.123.4 | Live feed |
| 9157798c50af372c.hook.limacharlie.io | 142.250.115.121 | Webhooks |

### India (Mumbai)

| Hostname | IP | Use |
| --- | --- | --- |
| 4d897015b0815621.lc.limacharlie.io | 35.200.151.24 | Windows, Mac, & Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) |
| 4d897015b0815621.edr.limacharlie.io | 34.102.207.18 | Windows, Mac, & Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) |
| 4d897015b0815621.wss.limacharlie.io | 34.98.108.101 | Chrome, Edge and Adapters |
| 4d897015b0815621.ingest.limacharlie.io | 34.149.161.19 | Logs and Artifacts |
| 4d897015b0815621.replay.limacharlie.io | 142.250.115.121 | Replay |
| 4d897015b0815621.live.limacharlie.io | 35.244.221.119 | Live feed |
| 4d897015b0815621.hook.limacharlie.io | 142.250.115.121 | Webhooks |

### UK (London)

| Hostname | IP | Use |
| --- | --- | --- |
| 70182cf634c346bd.lc.limacharlie.io | 35.242.152.114 | Windows, Mac, & Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) |
| 70182cf634c346bd.edr.limacharlie.io | 34.107.134.233 | Windows, Mac, & Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) |
| 70182cf634c346bd.wss.limacharlie.io | 35.244.147.201 | Chrome, Edge and Adapters |
| 70182cf634c346bd.ingest.limacharlie.io | 34.149.56.238 | Logs and Artifacts |
| 70182cf634c346bd.replay.limacharlie.io | 142.250.115.121 | Replay |
| 70182cf634c346bd.live.limacharlie.io | 35.244.146.102 | Live feed |
| 70182cf634c346bd.hook.limacharlie.io | 142.250.115.121 | Webhooks |

### Europe (Emshaven)

| Hostname | IP | Use |
| --- | --- | --- |
| b76093c3662d5b4f.lc.limacharlie.io | 35.204.142.125 | Windows, Mac, & Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) |
| b76093c3662d5b4f.edr.limacharlie.io | 34.111.194.87 | Windows, Mac, & Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) |
| b76093c3662d5b4f.wss.limacharlie.io | 130.211.22.248 | Chrome, Edge and Adapters |
| b76093c3662d5b4f.ingest.limacharlie.io | 34.120.5.160 | Logs and Artifacts |
| b76093c3662d5b4f.replay.limacharlie.io | 142.250.115.121 | Replay |
| b76093c3662d5b4f.live.limacharlie.io | 34.120.64.23 | Live feed |
| b76093c3662d5b4f.hook.limacharlie.io | 142.250.115.121 | Webhooks |

### Australia (Sydney)

| Hostname | IP | Use |
| --- | --- | --- |
| abc32764762fce67.lc.limacharlie.io | 34.151.84.52 | Windows, Mac, & Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) |
| abc32764762fce67.edr.limacharlie.io | 34.54.253.51 | Windows, Mac, & Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) |
| abc32764762fce67.wss.limacharlie.io | 34.96.104.54 | Chrome, Edge and Adapters |
| abc32764762fce67.ingest.limacharlie.io | 35.241.63.128 | Logs and Artifacts |
| abc32764762fce67.replay.limacharlie.io | 34.49.249.16 | Replay |
| abc32764762fce67.live.limacharlie.io | 34.8.102.215 | Live feed |
| abc32764762fce67.hook.limacharlie.io | 34.49.185.177 | Webhooks |

## How much data does the LimaCharlie Sensor produce per day?

The amount of data that is produced by the sensor is dependent on how much, and what kind of activity is taking place on the endpoint. That being said, the average data produced per endpoint across thousands of deployments is approximately 1MB per day.

## What resources does the LimaCharlie agent consume?

The total footprint of the agent on disk combined with what is in memory is approximately 50MB. The agent typically runs under 1% CPU.

Depending on what actions you may be performing it may increase (e.g. if you’re doing a full YARA scan it’s expected that the CPU usage will increase). When you use our YARA trickle scan, that also keeps CPU usage within reasonable bounds. You’ll only see YARA scans spike CPU when you do a full manual scan.

Depending on the configuration of the agent (it’s fully customizable), the network bandwidth will vary, but we typically see approximately 2MB per day on Windows hosts.

## Why does my sensor initially connect successfully but then disappear?

Sometimes we see the agent connect to the LimaCharlie cloud, enrolls, then disconnects (which is normal the first time after enrollment) and never connects again, or it doesn't show that kernel has been acquired.

This behavior is typical with SSL interception. Sometimes it's a network device, but at other times some security products on the host can do that without being very obvious.

You can confirm if there is SSL interception by performing the following steps to check the SSL fingerprint of the LimaCharlie cloud from the host.

**Confirm the region of your** Organization

If you already know where your organization's region is located, you can move to the next step. To verify the organization's region where the data is processed and stored, click `Add Sensor` from the `Sensors` view. You will then see the region listed under `Sensor Connectivity`.
![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/installation(1).png)

**Open the test URL**
Via web browser, navigate to one of the below test URLs that corresponds to the correct region:

[Test URL - US Region](https://9157798c50af372c.lc.limacharlie.io/)
[Test URL - UK Region](https://70182cf634c346bd.lc.limacharlie.io/)
[Test URL - India Region](https://4d897015b0815621.lc.limacharlie.io/)
[Test URL - Europe Region](https://b76093c3662d5b4f.lc.limacharlie.io/)
[Test URL - Canada Region](https://aae67d7e76570ec1.lc.limacharlie.io/)

No website will open; you should get a "Your connection is not private" type of message instead.

**Display the SSL Certificate**

By clicking near the URL bar on the exclamation mark, you will open a small menu and you can click "Certificate status"/"Certificate validity"/"Certificate is not valid" which will display the certificate information.

![certifricate](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/certifricate.png)

![certificate-1](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/certificate-1.png)

**Confirm the SHA-1 and SHA-256 fingerprints**

The SHA-1 and SHA-256 fingerprints should match the values below that correspond to the region your organization is in.

If the SHA-1 and SHA-256 fingerprints you are seeing do not match what's listed below, that's an indicator of the SSL interception.

| Region | SHA-256 Fingerprint | SHA-1 Fingerprint |
| --- | --- | --- |
| US | 14 44 8C B6 A1 19 A5 BE 18 AE 28 07 E3 D6 BD 55 B8 7A 5E 0C 3F 2D 78 03 6E 7C 6A 2A AA 45 8F 60 | 1A 72 67 08 D0 83 7D A9 62 85 39 55 A1 12 1B 10 B0 F4 56 1A |
| UK | 49 49 B0 41 D6 14 F3 3B 86 BF DF 14 24 F8 BD 2F E1 98 39 41 5A 99 E6 F1 C7 A2 C8 AB 34 0C FE 1D | 2E 49 00 DB F8 3A 2A 88 E0 15 76 D5 C5 4F 8F F3 7D 27 77 DD |
| India | 68 6F 08 3D 53 3F 08 E0 22 EB F6 67 0C 3C 41 08 75 D6 0E 67 03 88 D9 B6 E1 F8 19 6B DA 54 5A A3 | 37 57 DD 4E CF 2B 25 0B CA EA E2 E6 E3 B2 98 48 29 19 F3 6B |
| Europe | EF B3 FA A7 78 AB F0 B0 41 00 CF A3 5F 44 3F 9A 4D 16 28 B9 83 22 85 E3 36 44 D5 DC F9 5C 78 5B | 07 72 B3 31 1A 89 D6 54 1D 71 C3 07 AD B5 8A 26 FD 30 7E 5D |
| Canada | D3 40 8B 59 AE 5A 28 75 D1 65 71 50 52 2E 6F 45 26 EE E8 19 3A 9A 74 39 C1 64 60 B8 6A 92 15 47 | E3 EF AE 6A 0E 7F 18 83 15 FE F2 02 6C F3 2D 4E 59 95 4D 0A |

## What happens if a host is offline?

When the host is offline, the Sensor will keep collecting telemetry and store it locally in a "ring buffer" (which limits the total possible size). The buffer is ~60mb, so the amount of time it will cover will vary based on how much telemetry the individual endpoint generates. e.g. A domain controller will likely be generating many more events than a regular end user workstation.

When the host is back online, the content of this buffer will be flushed to the cloud where [detection and response](/v2/docs/detection-and-response) () rules will apply as usual.

The same ring buffer is used when the Sensor runs normally, even if data is not sent to the cloud in real-time. The cloud can then retroactively request the full or partial content of the ring buffer, bringing your telemetry current.

## How can I tell which Installation Key was used to enroll a sensor?

On occasion you may need to check which installation key was used to enroll a sensor. You can do so by comparing the sensors `Installer ID` with the Installation Key's `Adapter Key` value.

1. Go to the Sensors section and click into the sensor in question to view its details page. Take note of the `Installer ID`.
2. Go to the Install Sensors section.  Click the copy icon under the `Adapter Key`.
3. Compare these two values; the Installer ID on a sensor should be the same as the Adapter Key of the installation key used.

If you need to check a large list of sensors, you can perform an export of all sensors from the main sensors list page, or use the LimaCharlie API.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

---

### Related articles

* [Endpoint Agent Installation](/docs/endpoint-agent-installation)
* [Installation Keys](/docs/installation-keys)

---

#### What's Next

* [FAQ - Sensor Removal](/docs/sensor-removal)

Table of contents

+ [How can I add LimaCharlie traffic to an allow list?](#how-can-i-add-limacharlie-traffic-to-an-allow-list-)
+ [What Hostnames and IPs does LimaCharlie use for each region?](#what-hostnames-and-ips-does-limacharlie-use-for-each-region-)
+ [How much data does the LimaCharlie {{glossary.Sensor}} produce per day?](#how-much-data-does-the-limacharlie-{{glossary-sensor}}-produce-per-day-)
+ [What resources does the LimaCharlie agent consume?](#what-resources-does-the-limacharlie-agent-consume-)
+ [Why does my sensor initially connect successfully but then disappear?](#why-does-my-sensor-initially-connect-successfully-but-then-disappear-)
+ [What happens if a host is offline?](#what-happens-if-a-host-is-offline-)
+ [How can I tell which {{glossary.Installation Key}} was used to enroll a sensor?](#how-can-i-tell-which-{{glossary-installation-key}}-was-used-to-enroll-a-sensor-)

Tags

* [faq](/docs/en/tags/faq)
* [sensors](/docs/en/tags/sensors)

---

## FAQ - Sensor Removal

# FAQ - Sensor Removal
* 1 Minute to read

## What's Next

* [FAQ - Sensor Troubleshooting](/docs/faq-troubleshooting)

Table of contents

+ [How do I verify the LimaCharlie agent was uninstalled from macOS systems?](#how-do-i-verify-the-limacharlie-agent-was-uninstalled-from-macos-systems-)
+ [Verify the LimaCharlie processes are not running](#verify-the-limacharlie-processes-are-not-running)
+ [Verify all files on disk were removed](#verify-all-files-on-disk-were-removed)
+ [Verify LimaCharlie Network Extension was removed](#verify-limacharlie-network-extension-was-removed)
+ [Verify LimaCharlie Security Extension was removed](#verify-limacharlie-security-extension-was-removed)

---

## Installation Keys

# Installation Keys
Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

There are four components of an Installation Key:

* Organization ID **(**OID**)**: The Organization ID that this key should enroll into.
* **Installer ID (IID)**: Installer ID that is generated and associated with every Installation Key.
* **Tags**: A list of Tags automatically applied to sensors enrolling with the key.
* **Description**: The description used to help you differentiate uses of various keys.

## Management

Installation keys can be managed on the **Sensors > Installation Keys** page in the web app.

On this page, under the `Connectivity` section, you will see the various URLs associated with Sensor and Adapter connectivity.

### Pinned Certificates

Typically, Sensors require access over port 443 and use pinned SSL certificates. This is the default deployment option, and does not support traffic interception.

If you need to install sensors without pinned certificates, an installation key must be created with a specific flag. This must be done via the REST API, by setting the `use_public_root_ca` flag to `true`.

More details can be found [here](https://github.com/refractionPOINT/python-limacharlie/blob/master/limacharlie/Manager.py#L1386).

## Use of Tags

Generally speaking, we use at least one Installation Key per organization. Then we use different keys to help differentiate parts of our infrastructure. For example, you may create a key with Tag "server" that you will use to install on your servers, a key with "vip" for executives in your organization, or a key with "sales" for the sales department, etc. This way you can use the tags on various sensors to figure out different detection and response rules for different types of hosts on your infrastructure.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

In LimaCharlie, an Organization ID (OID) is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

---

### Related articles

* [macOS Agent Installation via Jamf Now](/docs/installing-macos-agents-via-jamf-now)
* [Docker Agent Installation](/docs/docker-agent-installation)
* [macOS Agent Installation](/docs/macos-agent-installation)
* [FAQ - Sensor Installation](/docs/faq-sensor-installation)
* [Chrome Agent Installation](/docs/chrome-agent-installation)
* [Windows Agent Installation](/docs/windows-agent-installation)
* [Linux Agent Installation](/docs/linux-agent-installation)
* [Endpoint Agent Installation](/docs/endpoint-agent-installation)
* [macOS Agent Installation - MDM Configuration Profiles](/docs/macos-agent-installation-mdm-configuration-profiles)
* [Agent Deployment via Microsoft Intune](/docs/agent-deployment-microsoft-intune)
* [Endpoint Agent](/docs/endpoint-agent)
* [Endpoint Agent Commands](/docs/endpoint-agent-commands)
* [Adapter Deployment](/docs/adapter-deployment)
* [Adapters](/docs/adapters)
* [Adapter Usage](/docs/adapter-usage)

---

#### What's Next

* [Adapters](/docs/adapters)

Table of contents

+ [Management](#management)
+ [Use of Tags](#use-of-tags)

Tags

* [sensors](/docs/en/tags/sensors)

---

## Linux Agent Installation

# Linux Agent Installation
The LimaCharlie Linux Sensor interfaces with the kernel to acquire deep visibility into the host's activity while taking measures to preserve the host's performance. We make full use of eBPF, which **requires Linux 4.4 or above**.

The Sensor current supports all Linux distributions (including ARM and MIPS).

Linux Distribution Support

Our Linux Sensor fully utilizes eBPF, which requires at least Linux 4.4 or above. Use the command `uname -r` to check your kernel version to determine support.

## Installation Instructions

### System Requirements

All versions of Debian and CentOS starting around Debian 5 should be supported. Due to the high diversity of the ecosystem it's also likely to be working on other distributions. If you need a specific platform, contact us.

### Deb Package

If you are deploying on a Debian Linux system, we recommend using the `.deb` package. You can find a link to the Debian package for various architectures at [Downloading the Agent](https://docs.limacharlie.io/docs/endpoint-agent-installation#downloading-the-agents).

The deb package will install the LimaCharlie sensor using a `systemd` service, or if unavailable a `system V` service.

The Installation Key is required by the installer via the `debconf` configuration mechanism. By default, installing the package interactively will request the installation key via a local command/GUI interface. To perform large scale installations, we recommend setting the installation key programmatically.

**Installating interactively:**

```
sudo dpkg -i limacharlie.deb
```

or

```
sudo apt install ./limacharlie.deb
```

**Uninstalling interactively:**

```
sudo dpkg -r limacharlie
```

or

```
sudo apt remove limacharlie
```

**Installing and setting the installation key programmatically with dpkg:**

```
echo "limacharlie limacharlie/installation_key string INSTALLATION_KEY_HERE" | sudo debconf-set-selections && sudo dpkg -i limacharlie.deb
```

**Installing and setting the installation key programmatically with apt:**

```
echo "limacharlie limacharlie/installation_key string INSTALLATION_KEY_HERE" | sudo debconf-set-selections && sudo apt install ./limacharlie.deb -y
```

Debian packages are offered for the various architectures the Linux sensor suppports, like:

```
https://downloads.limacharlie.io/sensor/linux/64  https://downloads.limacharlie.io/sensor/linux/deb64
```

### Custom Installation

Executing the installer via the command line, pass the `-d INSTALLATION_KEY` argument where `INSTALLATION_KEY` is the key
 mentioned above.

Because Linux supports a plethora of service management frameworks, by default the LC sensor does not install itself onto the system. Rather it assumes the "current working directory" is the installation directory and  immediately begins enrollment from there.

This means you can wrap the executable using the specific service management technology used within your Organization by simply specifying the location of the installer, the `-d INSTALLATION_KEY` parameter and making sure the current working directory is the directory where you want the few sensor-related files written to disk to reside.

A common methodology for Linux is to use `init.d`, if this is sufficient for your needs, see this [sample install script](https://github.com/refractionPOINT/lce_doc/blob/master/docs/lc_linux_installer.sh).
 You can invoke it like this:

```
sudo chmod +x ./lc_linux_installer.sh
sudo ./lc_linux_installer.sh <PATH_TO_LC_SENSOR> <YOUR_INSTALLATION_KEY>
```

You may also pass the value `-` instead of the `INSTALLATION_KEY` like: `-d -`. This will make the installer look for the installation key in an alternate place in the following order:

* Environment variable `LC_INSTALLATION_KEY`
* Text file in current working directory: `lc_installation_key.txt`

### Disabling Netlink

By default, the Linux sensor makes use of Netlink if available. In some rare configurations this auto-detection may be unwanted and Netlink usage can be disabled by setting the environment variable `DISABLE_NETLINK` to any value on the sensor process.

## Uninstalling the Agent

For additional agent uninstall options, see [Endpoint Agent Uninstallation](/v2/docs/endpoint-agent-uninstallation)

Linux agent uninstallation depends on how the sensor was installed. For example, if installed via a Debian package (`dpkg` file), you should uninstall via the same mechanism. If you installed via the SystemV installation method, please utilize the bottom of [this script](https://github.com/refractionPOINT/lce_doc/blob/master/docs/lc_linux_installer.sh#L97).

### Sensor Command

The `uninstall` command does not work for Linux systems. However, there is a chained command that can be run from the Sensor Console:

```
 run --shell-command "service limacharlie stop; rm /bin/rphcp; update-rc.d limacharlie remove -f; rm -rf /etc/init.d/limacharlie; rm /etc/hcp ; rm /etc/hcp_conf; rm /etc/hcp_hbs"
```

The above command removes LimaCharlie and associated files from the system when run remotely. Note that the above command could also be coupled with a  rule for automated sensor uninstallation, if necessary.

### Debian Systems

If the sensor was originally installed with the .deb file, this option is the cleanest uninstall method.

```
apt remove limacharlie
```

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

#### Related articles

* [Ingesting Linux Audit Logs](/docs/ingesting-linux-audit-logs)
* [Container Clusters](/docs/container-clusters)
* [Endpoint Agent Uninstallation](/docs/endpoint-agent-uninstallation)

---

##### What's Next

* [macOS Agent Installation](/docs/macos-agent-installation)

Table of contents

+ [Installation Instructions](#installation-instructions)
+ [Uninstalling the Agent](#uninstalling-the-agent)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [linux](/docs/en/tags/linux)
* [sensors](/docs/en/tags/sensors)

---

## Reference

# Reference
3 Articles  in this category

---

## Reference: Endpoint Agent Commands

# Reference: Endpoint Agent Commands
## Supported Commands by OS

For commands which emit a report/reply event type from the agent, the corresponding event type is provided.

| Command | Report/Reply Event | macOS | Windows | Linux | Chrome | Edge |
| --- | --- | --- | --- | --- | --- | --- |
| [artifact\_get](/v2/docs/reference-endpoint-agent-commands#artifactget) | N/A | ☑️ | ☑️ | ☑️ |  |  |
| [deny\_tree](/v2/docs/reference-endpoint-agent-commands#denytree) | N/A | ☑️ | ☑️ | ☑️ |  |  |
| [dir\_find\_hash](/v2/docs/reference-endpoint-agent-commands#dirfindhash) | [DIR\_FINDHASH\_REP](/v2/docs/edr-events#dirfindhashrep) | ☑️ | ☑️ | ☑️ |  |  |
| [dir\_list](/v2/docs/reference-endpoint-agent-commands#dirlist) | [DIR\_LIST\_REP](/v2/docs/edr-events#dirlistrep) | ☑️ | ☑️ | ☑️ |  |  |
| [dns\_resolve](/v2/docs/reference-endpoint-agent-commands#dnsresolve) | [DNS\_REQUEST](/v2/docs/edr-events#dnsrequest) | ☑️ | ☑️ | ☑️ | ☑️ | ☑️ |
| [doc\_cache\_get](/v2/docs/reference-endpoint-agent-commands#doccacheget) | [GET\_DOCUMENT\_REP](/v2/docs/edr-events#getdocumentrep) | ☑️ | ☑️ |  |  |  |
| [get\_debug\_data](/v2/docs/reference-endpoint-agent-commands#getdebugdata) | [DEBUG\_DATA\_REP](/v2/docs/edr-events#debugdatarep) | ☑️ | ☑️ | ☑️ |  |  |
| [exfil\_add](/v2/docs/reference-endpoint-agent-commands#exfiladd) | [CLOUD\_NOTIFICATION](/v2/docs/edr-events#cloudnotification) | ☑️ | ☑️ | ☑️ |  |  |
| [exfil\_del](/v2/docs/reference-endpoint-agent-commands#exfildel) | [CLOUD\_NOTIFICATION](/v2/docs/edr-events#cloudnotification) | ☑️ | ☑️ | ☑️ |  |  |
| [exfil\_get](/v2/docs/reference-endpoint-agent-commands#exfilget) | [GET\_EXFIL\_EVENT\_REP](/v2/docs/edr-events#getexfileventrep) | ☑️ | ☑️ | ☑️ |  |  |
| [file\_del](/v2/docs/reference-endpoint-agent-commands#filedel) | [FILE\_DEL\_REP](/v2/docs/edr-events#filedelrep) | ☑️ | ☑️ | ☑️ |  |  |
| [file\_get](/v2/docs/reference-endpoint-agent-commands#fileget) | [FILE\_GET\_REP](/v2/docs/edr-events#filegetrep) | ☑️ | ☑️ | ☑️ |  |  |
| [file\_hash](/v2/docs/reference-endpoint-agent-commands#filehash) | [FILE\_HASH\_REP](/v2/docs/edr-events#filehashrep) | ☑️ | ☑️ | ☑️ |  |  |
| [file\_info](/v2/docs/reference-endpoint-agent-commands#fileinfo) | [FILE\_INFO\_REP](/v2/docs/edr-events#fileinforep) | ☑️ | ☑️ | ☑️ |  |  |
| [file\_mov](/v2/docs/reference-endpoint-agent-commands#filemov) | [FILE\_MOV\_REP](/v2/docs/edr-events#filemovrep) | ☑️ | ☑️ | ☑️ |  |  |
| [fim\_add](/v2/docs/reference-endpoint-agent-commands#fimadd) | [FIM\_ADD](/v2/docs/edr-events#fimadd) | ☑️ | ☑️ | ☑️ |  |  |
| [fim\_del](/v2/docs/reference-endpoint-agent-commands#fimdel) | [FIM\_DEL](/v2/docs/edr-events#fimdel) | ☑️ | ☑️ | ☑️ |  |  |
| [fim\_get](/v2/docs/reference-endpoint-agent-commands#fimget) | [FIM\_LIST\_REP](/v2/docs/edr-events#fimlistrep) | ☑️ | ☑️ | ☑️ |  |  |
| [hidden\_module\_scan](/v2/docs/reference-endpoint-agent-commands#hiddenmodulescan) | [HIDDEN\_MODULE\_DETECTED](/v2/docs/edr-events#hiddenmoduledetected) |  | ☑️ | ☑️ |  |  |
| [history\_dump](/v2/docs/reference-endpoint-agent-commands#historydump) | [HISTORY\_DUMP\_REP](/v2/docs/edr-events#historydumprep) | ☑️ | ☑️ | ☑️ | ☑️ | ☑️ |
| [log\_get](/v2/docs/reference-endpoint-agent-commands#logget) | N/A |  | ☑️ |  |  |  |
| [logoff](/v2/docs/reference-endpoint-agent-commands#logoff) | N/A | ☑️ | ☑️ | ☑️ |  |  |
| [mem\_find\_handle](/v2/docs/reference-endpoint-agent-commands#memfindhandle) | [MEM\_FIND\_HANDLES\_REP](/v2/docs/edr-events#memfindhandlesrep) |  | ☑️ |  |  |  |
| [mem\_find\_string](/v2/docs/reference-endpoint-agent-commands#memfindstring) | [MEM\_FIND\_STRING\_REP](/v2/docs/edr-events#memfindstringrep) | ☑️ | ☑️ | ☑️ |  |  |
| [mem\_handles](/v2/docs/reference-endpoint-agent-commands#memhandles) | [MEM\_HANDLES\_REP](/v2/docs/edr-events#memhandlesrep) |  | ☑️ |  |  |  |
| [mem\_map](/v2/docs/reference-endpoint-agent-commands#memmap) | [MEM\_MAP\_REP](/v2/docs/edr-events#memmaprep) | ☑️ | ☑️ | ☑️ |  |  |
| [mem\_read](/v2/docs/reference-endpoint-agent-commands#memread) | [MEM\_READ\_REP](/v2/docs/edr-events#memreadrep) | ☑️ | ☑️ | ☑️ |  |  |
| [mem\_strings](/v2/docs/reference-endpoint-agent-commands#memstrings) | [MEM\_STRINGS\_REP](/v2/docs/edr-events#memstringsrep) | ☑️ | ☑️ | ☑️ |  |  |
| [netstat](/v2/docs/reference-endpoint-agent-commands#netstat) | [NETSTAT\_REP](/v2/docs/edr-events#netstatrep) | ☑️ | ☑️ | ☑️ |  |  |
| [os\_autoruns](/v2/docs/reference-endpoint-agent-commands#osautoruns) | [OS\_AUTORUNS\_REP](/v2/docs/edr-events#osautorunsrep) | ☑️ | ☑️ |  |  |  |
| [os\_drivers](/v2/docs/reference-endpoint-agent-commands#osdrivers) | N/A |  | ☑️ |  |  |  |
| [os\_kill\_process](/v2/docs/reference-endpoint-agent-commands#oskillprocess) | [OS\_KILL\_PROCESS\_REP](/v2/docs/edr-events#oskillprocessrep) | ☑️ | ☑️ | ☑️ |  |  |
| [os\_packages](/v2/docs/reference-endpoint-agent-commands#ospackages) | [OS\_PACKAGES\_REP](/v2/docs/edr-events#ospackagesrep) |  | ☑️ | ☑️ | ☑️ | ☑️ |
| [os\_processes](/v2/docs/reference-endpoint-agent-commands#osprocesses) | [OS\_PROCESSES\_REP](/v2/docs/edr-events#osprocessesrep) | ☑️ | ☑️ | ☑️ |  |  |
| [os\_resume](/v2/docs/reference-endpoint-agent-commands#osresume) | [OS\_RESUME\_REP](/v2/docs/edr-events#osresumerep) | ☑️ | ☑️ | ☑️ |  |  |
| [os\_services](/v2/docs/reference-endpoint-agent-commands#osservices) | [OS\_SERVICES\_REP](/v2/docs/edr-events#osservicesrep) | ☑️ | ☑️ | ☑️ |  |  |
| [os\_suspend](/v2/docs/reference-endpoint-agent-commands#ossuspend) | [OS\_SUSPEND\_REP](/v2/docs/edr-events#ossuspendrep) | ☑️ | ☑️ | ☑️ |  |  |
| [os\_users](/v2/docs/reference-endpoint-agent-commands#osusers) | [OS\_USERS\_REP](/v2/docs/edr-events#osusersrep) |  | ☑️ |  |  |  |
| [os\_version](/v2/docs/reference-endpoint-agent-commands#osversion) | [OS\_VERSION\_REP](/v2/docs/edr-events#osversionrep) | ☑️ | ☑️ | ☑️ |  |  |
| [put](/v2/docs/reference-endpoint-agent-commands#put) | [RECEIPT](/v2/docs/edr-events#receipt) | ☑️ | ☑️ | ☑️ |  |  |
| [rejoin\_network](/v2/docs/reference-endpoint-agent-commands#rejoinnetwork) | [REJOIN\_NETWORK](/v2/docs/edr-events#rejoinnetwork) | ☑️ | ☑️ | ☑️ | ☑️ | ☑️ |
| [restart](/v2/docs/reference-endpoint-agent-commands#restart) | N/A | ☑️ | ☑️ | ☑️ |  |  |
| [run](/v2/docs/reference-endpoint-agent-commands#run) | N/A | ☑️ | ☑️ | ☑️ |  |  |
| [seal](/v2/docs/reference-endpoint-agent-commands#seal) |  |  | ☑️ |  |  |  |
| [segregate\_network](/v2/docs/reference-endpoint-agent-commands#segregatenetwork) | [SEGREGATE\_NETWORK](/v2/docs/edr-events#segregatenetwork) | ☑️ | ☑️ | ☑️ | ☑️ | ☑️ |
| [set\_performance\_mode](/v2/docs/reference-endpoint-agent-commands#setperformancemode) | N/A | ☑️ | ☑️ | ☑️ |  |  |
| [shutdown](/v2/docs/reference-endpoint-agent-commands#shutdown) |  | ☑️ | ☑️ | ☑️ |  |  |
| [uninstall](/v2/docs/reference-endpoint-agent-commands#uninstall) | N/A | ☑️ | ☑️ | ☑️ |  |  |
| [yara\_scan](/v2/docs/reference-endpoint-agent-commands#yarascan) | [YARA\_DETECTION](/v2/docs/edr-events#yaradetection) | ☑️ | ☑️ | ☑️ |  |  |
| [yara\_update](/v2/docs/reference-endpoint-agent-commands#yaraupdate) | N/A | ☑️ | ☑️ | ☑️ |  |  |
| [epp\_status](/v2/docs/reference-endpoint-agent-commands#eppstatus) | [EPP\_STATUS\_REP] | ☑️ |  |  |  |  |
| [epp\_scan](/v2/docs/reference-endpoint-agent-commands#eppscan) | [EPP\_SCAN\_REP] | ☑️ |  |  |  |  |
| [epp\_list\_exclusions](/v2/docs/reference-endpoint-agent-commands#epplistexclusions) | [EPP\_LIST\_EXCLUSIONS\_REP] | ☑️ |  |  |  |  |
| [epp\_add\_exclusion](/v2/docs/reference-endpoint-agent-commands#eppaddexclusion) | [EPP\_ADD\_EXCLUSION\_REP] | ☑️ |  |  |  |  |
| [epp\_rem\_exclusion](/v2/docs/reference-endpoint-agent-commands#eppremexclusion) | [EPP\_REM\_EXCLUSION\_REP] | ☑️ |  |  |  |  |
| [epp\_list\_quarantine](/v2/docs/reference-endpoint-agent-commands#epplistquarantine) | [EPP\_LIST\_QUARANTINE\_REP] | ☑️ |  |  |  |  |

---

## Command Descriptions

### artifact\_get

Retrieve an artifact from a Sensor.

The artifact collection command allows you to retrieve files directly from an EDR Sensor. This command is useful for collecting a single or multiple files from a Sensor in response to a detection or for incident triage purposes.

Artifacts can be collected via the automated Artifact Collection in the web UI, initiated via API calls, or pulled via the `artifact_get` command. Each approach provides value, depending on your use case. Utilizing the Artifact Collection capability can automate artifact collection across a fleet, whereas sensor commands can help collect files from a single Sensor under investigation.

**Platforms:**

**Report/Reply Event:**
 N/A

**Usage:**

```
usage: artifact_get [-h] [--file FILE] [--source SOURCE] [--type TYPE]
                    [--payload-id PAYLOADID] [--days-retention RETENTION]
                    [--is-ignore-cert]

optional arguments:
  --file FILE           file path to get
  --source SOURCE       optional os specific artifact source (not currently supported)
  --type TYPE           optional artifact type
  --payload-id PAYLOADID
                        optional specifies an idempotent payload ID to use
  --days-retention RETENTION
                        number of days the data should be retained, default 30
  --is-ignore-cert      if specified, the sensor will ignore SSL cert mismatch
                        while upload the artifact
```

Note on usage scenarios for the `--is-ignore-cert` flag: If the sensor is deployed on a host where built-in root CAs are not up to date or present at all, it may be necessary to use the `--is-ignore-cert` flag to allow the logs to be pushed to the cloud.

Unlike the main sensor transport (which uses a pinned certificate), the Artifact Collection feature uses Google infrastructure and their public SSL certificates. This may sometimes come up in unexpected ways. For example fresh Windows Server installations do not have the root CAs for `google.com` enabled by default.

---

### deny\_tree

Tells the sensor that all activity starting at a specific process (and its children) should be denied and killed. This particular command is excellent for ransomware mitigation.

**Platforms:**

**Usage:**

```
usage: deny_tree [-h] atom [atom ...]

positional arguments:
  atom        atoms to deny from
```

---

### dir\_find\_hash

Find files matching hashes starting at a root directory.

**Platforms:**

**Reply/Report Event:**
[DIR\_FINDHASH\_REP](/v2/docs/reference-edr-events#dirfindhashrep)

**Usage:**

```
usage: dir_find_hash [-h] [-d DEPTH] --hash HASHES rootDir fileExp

positional arguments:
  rootDir               the root directory where to begin the search from
  fileExp               a file name expression supporting basic wildcards like
                        * and ?

optional arguments:
  -d DEPTH, --depth DEPTH
                        optional maximum depth of the listing, defaults to a
                        single level
  --hash HASHES         sha256 to search for, can be specified multiple times
```

---

### dir\_list

List the contents of a directory.

> Windows Directories
>
> When using dir\_list on Windows systems, ensure the rootDir value is contained within double quotes AND backslashes are escaped. To list all files in a directory, a wildcard (e.g., \*) must be used for the fileExp value.
>
> For example, this will list all files in C:\
>
> * dir\_list “c:\\” \*
>
> These examples will **NOT** work correctly and will not show any files, but will not give an error since they are properly formatted:
>
> * dir\_list c:\\ \* (Missing double quotes)
> * dir\_list “c:\\” (Missing fileExp value)

**Platforms:**

**Report/Reply Event:**
[DIR\_LIST\_REP](/v2/docs/reference-edr-events#dirlistrep)

**Usage:**

```
usage: dir_list [-h] [-d DEPTH] rootDir fileExp

positional arguments:
  rootDir               the root directory where to begin the listing from
  fileExp               a file name expression supporting basic wildcards like
                        * and ?

optional arguments:
  -d DEPTH, --depth DEPTH
                        optional maximum depth of the listing, defaults to a
                        single level
```

---

### dns\_resolve

Cause the sensor to do a network resolution. Mainly used for internal purposes. An error code of 0 indicates a successful command.

**Platforms:**

**Usage:**

```
dns_resolve [-h] domain

positional arguments:
  domain      domain name to resolve
```

**Sample Output:**

```json
{
   "ERROR" : 0
}
```

You wll also see a corresponding `DNS_REQUEST` event in the Sensor timeline.

**Sample** `DNS_REQUEST` **Event:**

```json
{
  "DNS_TYPE": 1,
  "DOMAIN_NAME": "www.google.com",
  "IP_ADDRESS": "142.251.116.105",
  "MESSAGE_ID": 30183
}
```

---

### doc\_cache\_get

Retrieve a document / file that was cached on the sensor.

**Platforms:**

**Report/Reply Event:**
[GET\_DOCUMENT\_REP](/v2/docs/reference-edr-events#getdocumentrep)

This command is currently listed to the following document types:

* .bat
* .js
* .ps1
* .sh
* .py
* .exe
* .scr
* .pdf
* .doc
* .docm
* .docx
* .ppt
* .pptm
* .pptx
* .xlt
* .xlsm
* .xlsx
* .vbs
* .rtf
* .hta
* .lnk
* Any files created in `system32` on Windows.

**Usage:**

```
usage: doc_cache_get [-h] [-f FILE_PATTERN] [-s HASHSTR]

optional arguments:
  -f FILE_PATTERN, --file_pattern FILE_PATTERN
                        a pattern to match on the file path and name of the
                        document, simple wildcards ? and * are supported
  -s HASHSTR, --hash HASHSTR
                        hash of the document to get
```

---

### exfil\_add

Add an LC event to the list of events sent back to the backend by default.

Exfil Service

Rather than using the `exfil_add` and `exfil_del` commands exclusively, it is recommended to use the [Exfil extension](/v2/docs/ext-exfil) available through the web UI and REST interface.

**Platforms:**

**Usage:**

```
usage: exfil_add [-h] -e EXPIRE event

positional arguments:
  event                 name of event to start exfiling

optional arguments:
  -e EXPIRE, --expire EXPIRE
                        number of seconds before stopping exfil of event
```

---

### exfil\_del

Remove an LC event from the list of events always sent back to the backend.

Exfil Service

Rather than using the `exfil_add` and `exfil_del` commands exclusively, it is recommended to use the [Exfil extension](/v2/docs/ext-exfil) available through the web UI and REST interface.

**Platforms:**

**Usage:**

```
usage: exfil_del [-h] event

positional arguments:
  event       name of event to stop exfiling
```

---

### exfil\_get

List all LC events sent back to the backend by default.

**Platforms:**

**Report/Reply Event:**
[GET\_EXFIL\_EVENT\_REP](/v2/docs/reference-edr-events#getexfileventrep)

**Usage:**

```
usage: exfil_get [-h]
```

---

### file\_del

Delete a file from the endpoint.

**Platforms:**

**Report/Reply Event:**
[FILE\_DEL\_REP](/v2/docs/reference-edr-events#filedelrep)

\*\*Usage: \*\*

```
usage: file_del [-h] file

positional arguments:
  file        file path to delete
```

---

### file\_get

Retrieve a file from the endpoint.

*Note: The* `file_get` *command is limited to 10MB in size. For files larger than 10MB, please utilize the* `artifact_get` *command.*

**Platforms:**

**Report/Reply Event:**
[FILE\_GET\_REP](/v2/docs/reference-edr-events#filegetrep)

**Usage:**

```
usage: file_get [-h] [-o OFFSET] [-s MAXSIZE] file

positional arguments:
  file                  file path to file to get

optional arguments:
  -o OFFSET, --offset OFFSET
                        offset bytes to begin reading the file at, in base 10
  -s MAXSIZE, --size MAXSIZE
                        maximum number of bytes to read, in base 10, max of
                        10MB
```

---

### file\_hash

Compute the hash of a file.

**Platforms:**

**Report/Reply Event:**
[FILE\_HASH\_REP](/v2/docs/reference-edr-events#filehashrep)

**Usage:**

```
usage: file_hash [-h] file

positional arguments:
  file        file path to hash
```

---

### file\_info

Get file information, timestamps, sizes, etc.

**Platforms:**

**Report/Reply Event:**
[FILE\_INFO\_REP](/v2/docs/reference-edr-events#fileinforep)

**Usage:**

```
usage: file_info [-h] file

positional arguments:
  file        file path to file to get info on
```

---

### file\_mov

Move / rename a file on the endpoint.

**Platforms:**

**Report/Reply Event:**
[FILE\_MOV\_REP](/v2/docs/reference-edr-events#filemovrep)

**Usage:**

```
usage: file_mov [-h] srcFile dstFile

positional arguments:
  srcFile     source file path
  dstFile     destination file path
```

---

### fim\_add

Add a file or registry path pattern to monitor for modifications.

FIM rules are not persistent. This means that once an asset restarts, the rules will be gone. The recommended way of managing rule application is to use [Detection & Response rules](/v2/docs/detection-and-response) in a similar way to managing events sent to the cloud.

A sample  rule is available [here](/v2/docs/detection-and-response-examples).

Note that instead of using the `fim_add` and `fim_del` commands directly it is recommended to use [the Integrity extension](/v2/docs/ext-integrity) available through the web UI and REST interface.

**Platforms:**
   (see [this](/v2/docs/linux-agent-installation) for notes on Linux support)

**Report/Reply Event:**
[FIM\_ADD](/v2/docs/reference-edr-events#fimadd)

Patterns include basic wildcards:

* for one character: `?`
* for at least one character: `+`
* for any number of characters: `*`
* escape character: `\`

Note that the pattern is not a string literal, therefore "" needs to be escaped by one more level than usual.

So for example, you could do:

* `?:\*\Programs\Startup\*`
* `\REGISTRY\*\Microsoft\Windows\CurrentVersion\Run*`

Which would result in: `fim_add --pattern "?:\*\Programs\Startup\*" --pattern "\REGISTRY\*\Microsoft\Windows\CurrentVersion\Run*"`

**Usage:**

```
usage: fim_add [-h] --pattern PATTERNS

optional arguments:
  --pattern PATTERNS  file path or registry path pattern to monitor
```

---

### fim\_del

Remove a pattern from monitoring.

**Platforms:**
   (see [this](/v2/docs/linux-agent-installation) for notes on Linux support)

**Report/Reply Event:**
[FIM\_DEL](/v2/docs/reference-edr-events#fimdel)

```
usage: fim_del [-h] --pattern PATTERNS

optional arguments:
  --pattern PATTERNS  file path or registry path pattern to stop monitoring
```

---

### fim\_get

Get the list of the current monitored pattern(s).

**Platforms:**
   (see [this](/v2/docs/linux-agent-installation) for notes on Linux support)

**Report/Reply Event:**
[FIM\_LIST\_REP](/v2/docs/reference-edr-events#fimlistrep)

```
usage: fim_get [-h]
```

---

### get\_debug\_data

Retrieve debug data from the EDR sensor.

**Platforms:**

**Report/Reply Event:**
[DEBUG\_DATA\_REP](/v2/docs/reference-edr-events#debugdatarep)

---

### hidden\_module\_scan

Look for hidden modules in a process's (or all) memory. Hidden modules are DLLs or dylibs loaded manually (not by the OS).

**Platforms:**

**Report/Reply Event:**
[HIDDEN\_MODULE\_DETECTED](/v2/docs/reference-edr-events#hiddenmoduledetected)

**Usage:**

```
usage: hidden_module_scan [-h] pid

positional arguments:
  pid         pid of the process to scan, or "-1" for ALL processes
```

---

### history\_dump

Send to the backend the entire contents of the sensor event cache, i.e. detailed events of everything that happened recently.

**Platforms:**

**Report/Reply Event:**
[HISTORY\_DUMP\_REP](/v2/docs/reference-edr-events#historydumprep)

**Usage:**

```
usage: history_dump [-h] [-r ROOT] [-a ATOM] [-e EVENT]

optional arguments:
  -r ROOT, --rootatom ROOT
                        dump events present in the tree rooted at this atom
  -a ATOM, --atom ATOM  dump the event with this specific atom
  -e EVENT, --event EVENT
                        dump events of this type only
```

---

### log\_get

`log_get` is a legacy command that has been replaced with `artifact_get`. You can still issue a `log_get` command from the Sensor, however the parameters and output are the same as `artifact_get`.

### logoff

Execute a logoff for all the users

**Platforms:**

```
usage: logoff --is-confirmed
```

---

### mem\_find\_handle

Find specific open handles in memory on Windows.

**Platforms:**

**Report/Reply Event:**
[MEM\_FIND\_HANDLES\_REP](/v2/docs/reference-edr-events#memfindhandlesrep)

**Usage:**

```
mem_find_handle [-h] needle

positional arguments:
  needle      substring of the handle names to get
```

---

### mem\_find\_string

Find specific strings in memory.

**Platforms:**

**Report/Reply Event:**
[MEM\_FIND\_STRING\_REP](/v2/docs/reference-edr-events#memfindstringrep)

**Due to recent changes in MacOS, this may be less reliable on that platform.**

**Usage:**

```
mem_find_string [-h] -s STRING [STRING ...] pid

positional arguments:
  pid                   pid of the process to search in, 0 for all processes

optional arguments:
  -s STRING [STRING ...], --strings STRING [STRING ...]
                        list of strings to look for
```

---

### mem\_handles

List all open handles from a process (or all) on Windows.

**Platforms:**

**Report/Reply Event:**
[MEM\_HANDLES\_REP](/v2/docs/reference-edr-events#memhandlesrep)

**Usage:**

```
mem_handles [-h] [-p PID] [-a PROCESSATOM]

optional arguments:
  -p PID, --pid PID     pid of the process to get the handles from, 0 for all
                        processes
  -a PROCESSATOM, --processatom PROCESSATOM
                        the atom of the target process
```

---

### mem\_map

Display the map of memory pages from a process including size, access rights, etc.

**Platforms:**

**Report/Reply Event:**
[MEM\_MAP\_REP](/v2/docs/reference-edr-events#memmaprep)

**Due to recent changes in MacOS, this may be less reliable on that platform.**

**Usage:**

```
mem_map [-h] [-p PID] [-a PROCESSATOM]

optional arguments:
  -p PID, --pid PID     pid of the process to get the map from
  -a PROCESSATOM, --processatom PROCESSATOM
                        the atom of the target proces
```

---

### mem\_read

Retrieve a chunk of memory from a process given a base address and size.

**Platforms:**

**Report/Reply Event:**
[MEM\_READ\_REP](/v2/docs/reference-edr-events#memreadrep)

**Due to recent changes in MacOS, this may be less reliable on that platform.**

**Usage:**

```
mem_read [-h] [-p PID] [-a PROCESSATOM] baseAddr memSize

positional arguments:
  baseAddr              base address to read from, in HEX FORMAT
  memSize               number of bytes to read, in HEX FORMAT

optional arguments:
  -p PID, --pid PID     pid of the process to get the map from
  -a PROCESSATOM, --processatom PROCESSATOM
                        the atom of the target process
```

---

### mem\_strings

List strings from a process's memory.

**Platforms:**

**Report/Reply Event:**
[MEM\_STRINGS\_REP](/v2/docs/reference-edr-events#memstringsrep)

**Due to recent changes in MacOS, this may be less reliable on that platform.**

**Usage:**

```
mem_strings [-h] [-p PID] [-a PROCESSATOM]

optional arguments:
  -p PID, --pid PID     pid of the process to get the strings from
  -a PROCESSATOM, --processatom PROCESSATOM
                        the atom of the target process
```

---

### netstat

List network connections and sockets listening.

**Platforms:**

**Usage:**

```
netstat [-h]
```

**Sample Output:**

```json
{
  "FRIENDLY": 0,
  "NETWORK_ACTIVITY": [
    {
      "DESTINATION": {
        "IP_ADDRESS": "0.0.0.0",
        "PORT": 0
      },
      "PROCESS_ID": 716,
      "PROTOCOL": "tcp4",
      "SOURCE": {
        "IP_ADDRESS": "0.0.0.0",
        "PORT": 135
      },
      "STATE": 2
    },
    {
      ...
    }
  ]
}
```

Netstat `STATE` fields can be mapped via the Windows `MIB_TCP_STATE` table, found [here](https://learn.microsoft.com/en-us/windows/win32/api/tcpmib/ns-tcpmib-mib_tcprow_lh).

| State | Value |
| --- | --- |
| 1 | CLOSED |
| 2 | LISTEN |
| 3 | SYN-SENT |
| 4 | SYN-RECEIVED |
| 5 | ESTABLISHED |
| 6 | FIN-WAIT-1 |
| 7 | FIN-WAIT-2 |
| 8 | CLOSE-WAIT |
| 9 | CLOSING |
| 10 | LAST-ACK |
| 11 | TIME-WAIT |
| 12 | DELETE TCB |

---

### os\_autoruns

List pieces of code executing at startup, similar to SysInternals autoruns.

**Platforms:**

```
usage: os_autoruns [-h]
```

---

### os\_drivers

List all drivers on Windows.

**Platforms:**

```
usage: os_drivers [-h]
```

---

### os\_kill\_process

Kill a process running on the endpoint.

**Platforms:**

```
usage: os_kill_process [-h] [-p PID] [-a PROCESSATOM]

optional arguments:
  -p PID, --pid PID     pid of the process to kill
  -a PROCESSATOM, --processatom PROCESSATOM
                        the atom of the target process
```

---

### os\_packages

List installed software packages.

**Platforms:**

```
usage: os_packages [-h]
```

---

### os\_processes

List all running processes on the endpoint.

For a faster response time, we recommend running `os_processes --is-no-modules`.

**Platforms:**

```
usage: os_processes [-h] [-p PID] [--is-no-modules]

optional arguments:
  -p PID, --pid PID  only get information on process id
  --is-no-modules    do not report modules in processes
```

---

### os\_resume

Resume execution of a process on the endpoint.

**Platforms:**

```
usage: os_resume [-h] [-p PID] [-a PROCESSATOM] [-t TID]

optional arguments:
  -p PID, --pid PID     process id
  -a PROCESSATOM, --processatom PROCESSATOM
                        the atom of the target process
  -t TID, --tid TID     thread id
```

---

### os\_services

List all services (Windows, launchctl on MacOS and initd on Linux).

**Platforms:**

```
usage: os_services [-h]
```

---

### os\_suspend

Suspend a process running on the endpoint.

**Platforms:**

```
usage: os_suspend [-h] [-p PID] [-a PROCESSATOM] [-t TID]

optional arguments:
  -p PID, --pid PID     process id
  -a PROCESSATOM, --processatom PROCESSATOM
                        the atom of the target process
  -t TID, --tid TID     thread id
```

---

### os\_users

List system users.

**Platforms:**

```
usage: os_users [-h]
```

---

### os\_version

Get detailed OS information on the endpoint.

**Platforms:**

```
usage: os_version [-h]
```

---

### put

Upload a payload to an endpoint without executing it.

**Platforms:**

```
usage: put [-h] --payload-name NAME [--payload-path PATH] [--is-ignore-cert]

optional arguments:
  --payload-name NAME  name of the payload to run
  --payload-path PATH  full path where to put the payload (including file name)
  --is-ignore-cert     if specified, the sensor will ignore SSL cert mismatch
```

**Report/Reply Event(s):**
`RECEIPT`
`CLOUD_NOTIFICATION`

Error Codes

A 200 `ERROR` code implies a successful `put` command, and will include the resulting file path. Any other error codes can be investigated [here](/v2/docs/reference-error-codes).

**Command Notes:**

Note on usage scenarios for the `--is-ignore-cert` flag: If the sensor is deployed on a host where built-in root CAs are not up to date or present at all, it may be necessary to use the `--is-ignore-cert` flag to allow the sensor to pull the payload to execute from the cloud.

Unlike the main sensor transport (which uses a pinned certificate), the Payloads feature uses Google infrastructure and their public SSL certificates.

This may sometimes come up in unexpected ways. For example fresh Windows Server installations do not have the root CAs for `google.com` enabled by default.

**Example:**

Assume you have a payload named `sample-script.sh`, and you wanted to upload it to the `/tmp` folder on a remote system, keeping the same name:

```
put --payload-name "sample_script.sh" --payload-path "/tmp/sample_script.sh"
```

If successful, this action will yield the following `RECEIPT` event:

```
"details":{
    "event":{
        "ERROR":200
        "FILE_PATH":"/tmp/sample-script.sh"
    }
"routing" : {...}
```

---

### pcap\_ifaces

List the network interfaces available for capture on a host.

**Platforms:**

**Usage:**

```
pcap_ifaces [-h]
```

**Sample Output:**

```json
{
  "INTERFACE": [
    {
      "IPV4": [
        "10.128.15.198"
      ],
      "IPV6": [
        "fe80::4001:aff:fe80:fc6"
      ],
      "NAME": "ens4"
    },
    {
      "IPV4": [
        "127.0.0.1"
      ],
      "IPV6": [
        "::1"
      ],
      "NAME": "lo"
    },
    {
      "IPV4": [],
      "IPV6": [],
      "NAME": "any"
    },
    {
      "IPV4": [],
      "IPV6": [],
      "NAME": "nflog"
    },
    {
      "IPV4": [],
      "IPV6": [],
      "NAME": "nfqueue"
    }
  ]
}
```

---

### reboot

Execute an immediate system reboot (no warnings and zero delay time)

**Platforms:**

```
usage: reboot --is-confirmed
```

---

### reg\_list

List the keys and values in a Windows registry key.

**Platforms:**

```
usage: reg_list [-h] reg

positional arguments:
  reg         registry path to list, must start with one of "hkcr", "hkcc", "hkcu", "hklm", "hku", e.g. "hklm\software"...
```

---

### rejoin\_network

Tells the sensor to allow network connectivity again (after it was segregated).

**Platforms:**

**Report/Reply Event:**
[REJOIN\_NETWORK](/v2/docs/reference-edr-events#rejoinnetwork)

**Usage:**

```
usage: rejoin_network [-h]
```

---

### restart

Forces the LimaCharlie agent to re-initialize. This is typically only useful when dealing with cloned sensor IDs in combination with the remote deletion of the identity file on disk.

**Platforms:**

---

### run

Execute a payload or a shell command on the sensor.

**Platforms:**

```
usage: run [-h] [--payload-name NAME] [--arguments ARGUMENTS]
           [--shell-command SHELLCMD] [--timeout TIMEOUT] [--is-ignore-cert][--interpreter INTERPRETER]

optional arguments:
  --payload-name NAME   name of the payload to run
  --arguments ARGUMENTS
                        arguments to run the payload with
  --shell-command SHELLCMD
                        shell command to run
  --timeout TIMEOUT     number of seconds to wait for payload termination
  --is-ignore-cert      if specified, the sensor will ignore SSL cert mismatch
                        while upload the log
  --interpreter INTERPRETER
specifies that the named payload should be executed with
a specific interpreter like "powershell"
```

Note on usage scenarios for the `--is-ignore-cert` flag: If the sensor is deployed on a host where built-in root CAs are not up to date or present at all, it may be necessary to use the `--is-ignore-cert` flag to allow the sensor to pull the payload to execute from the cloud.

Using Arguments

In some cases, using the `--arguments` parameter may result in an error. If so, insert a leading space into the provided arguments.

For example `--arguments ' -ano'`

Unlike the main sensor transport (which uses a pinned certificate), the Payloads feature uses Google infrastructure and their public SSL certificates.

This may sometimes come up in unexpected ways. For example fresh Windows Server installations do not have the root CAs for `google.com` enabled by default.

Some shell execution requires embedding quotes within the command, for example when executing powershell. Here’s an example:

```
run --shell-command "powershell.exe -command \"Get-MpComputerStatus | Select-Object AMRunningMode\""
```

The above starts `powershell.exe` and passes it the `-command` argument and the value of the `-command` is `"Get-MpComputerStatus | Select-Object AMRunningMode”`.

---

###

### seal

Instruct the sensor to harden itself from tampering. This capability protects against use cases such as local admin users attempting to uninstall the LimaCharlie service. Please note that sealed status is currently only reflected in `CONNECTED` and `SYNC` events.

Seal Availability

Supported on sensor version 4.29.0 or newer and currently only supported on Windows.

Important note: the `seal` direct sensor command is stateless, meaning it will not survive a reboot. For this reason, in almost all cases, you want to automate the change of status in D&R rules using the `seal` and `unseal` [response actions](/v2/docs/response-actions) instead of this task. Alternatively you can also use the REST API endpoint `{`SID`}/seal` to change the status in a way that survives reboots.

The `should_seal` Boolean parameter indicates whether a Sensor has yet to complete the `seal` command.

**Platforms:**

**Usage:**

```
usage: seal [--enable] [--disable]
```

**Sample Event:**
 On Sensors version 4.29.0 or newer, you will see the following metadata within `SYNC` or `CONNECTED` events:

```json
{
 ... ,
 "SEAL_STATUS" : {
    "ERROR": 0,
    "IS_DISABLED": 1
    }
}
```

---

### segregate\_network

Tells the sensor to stop all network connectivity on the host except LC comms to the backend. So it's network isolation, great to stop lateral movement.

Note that you should never upgrade a sensor version while the network is isolated through this mechanism. Doing so may result in the agent not regaining connectivity to the cloud, requiring a reboot to undo.

This command primitive is NOT persistent, meaning a sensor you segregate from the network using this command alone, upon reboot will rejoin the network. To achieve isolation from the network in a persistent way, see the `isolate network` and `rejoin network` [Detection & Response rule actions](/v2/docs/response-actions).

**Platforms:**

**Report/Reply Event:**
[SEGREGATE\_NETWORK](/v2/docs/reference-edr-events#segregatenetwork)

**Usage:**

```
usage: segregate_network [-h]
```

---

### set\_performance\_mode

Turn on or off the high performance mode on a sensor. This mode is designed for very high performance servers requiring high IO throughout. This mode reduces the accuracy of certain events which in turn reduces impact on the system, and is not useful for the vast majority of hosts. You can read more about Performance Mode and its caveats [here](/v2/docs/ext-exfil#performance-rules).

**Platforms:**

**Usage:**

```
usage: set_performance_mode [-h] [--is-enabled]

optional arguments:
  --is-enabled  if specified, the high performance mode is enabled, otherwise
                disabled
```

---

### shutdown

Execute an immediate system shut down (no warnings and zero delay time)

**Platforms:**

```
usage: shutdown --is-confirmed
```

---

### uninstall

Uninstall the sensor from that host.

*For more information on Sensor uninstallation, including Linux systems, check* [*here*](/v2/docs/endpoint-agent-uninstallation)*.*

**Platforms:**

**Usage:**

```
usage: uninstall [-h] [--is-confirmed]

optional arguments:
  --is-confirmed  must be specified as a confirmation you want to uninstall
                  the sensor
```

---

### yara\_scan

Scan for a specific yara signature in memory and files on the endpoint.

**Platforms:**

**The memory component of the scan on MacOS may be less reliable due to recent limitations imposed by Apple.**

```
yara_scan [--pid PID] [--filePath FILEPATH] [--processExpr PROCESSEXPR] [--is-memory-only] [--is-no-validation] [--root-dir ROOT-DIR] [--file-exp FILE-EXP] [--depth DEPTH] RULE

Positional arguments:
  RULE                   rule to compile and run on sensor, Yara resource reference like "hive://yara/my-source,other-source", literal rule or "https://" URL or base64 encoded rule

Options:
  --pid PID, -p PID      pid of the process to scan [default: -1]
  --filePath FILEPATH, -f FILEPATH
                         path to the file scan
  --processExpr PROCESSEXPR, -e PROCESSEXPR
                         expression to match on to scan (matches on full process path)
  --is-memory-only       only scan the memory, ignore files on disk. [default: true]
  --is-no-validation     if specified, do not validate the rule before sending. [default: false]
  --root-dir ROOT-DIR, -r ROOT-DIR
                         the root directory where to begin the search for files to scan
  --file-exp FILE-EXP, -x FILE-EXP
                         a file name expression supporting basic wildcards like * and ? to match against files in the --root-dir [default: *]
  --depth DEPTH, -d DEPTH
                         optional maximum depth of the search for files to scan, defaults to a single level
```

---

### yara\_update

Update the compiled yara signature bundle that is being used for constant memory and file scanning on the sensor.

Note

Instead of using the `yara_update` command directly it is recommended to use [the YARA extension](/v2/docs/ext-yara) available through the web UI and REST interface.

**Platforms:**

```
usage: yara_update [-h] rule

positional arguments:
  rule        rule to compile and set on sensor for constant scanning, literal rule or "https://" URL or base64 encoded rule
```

---

### epp\_status

Get the current status of EPP on a sensor.

**Platforms:**

```
usage: epp_status [-h]
```

---

### epp\_scan

Scan a directory or file using the EPP on the sensor.

**Platforms:**

```
usage: epp_scan [-h] path

positional arguments:
  path        File or directory to scan
```

---

### epp\_list\_exclusions

List all the exclusions for EPP on a sensor.

**Platforms:**

```
usage: epp_list_exclusions [-h]
```

---

### epp\_add\_exclusion

Add a new exclusion to EPP on a sensor.

**Platforms:**

```
usage: epp_add_exclusion [-h] value [--type]

positional arguments:
  value        Value of the exclusion to add
optional arguments:
  --type  Type of exclusion. Options are: extension, path, process
```

---

### epp\_rem\_exclusion

Remove an exclusion for EPP on a sensor.

**Platforms:**

```
usage: epp_rem_exclusion [-h] value [--type]

positional arguments:
  value        Value of the exclusion to remove
optional arguments:
  --type  Type of exclusion. Options are: extension, path, process
```

---

### epp\_list\_quarantine

List quarantined EPP on a sensor.

**Platforms:**

```
usage: epp_list_quarantine [-h]
```

---

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Endpoint Detection & Response

In LimaCharlie, Exfil (Event Collection) is a configuration extension that determines which types of events are collected and sent from endpoint agents to the cloud. It controls the data flow, ensuring only specified events are transmitted for monitoring and analysis. To capture specific events, they must be enabled within the Exfil or Event Collection settings.

In LimaCharlie, a Sensor ID (SID) is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

---

#### Related articles

* [Reference: EDR Events](/docs/reference-edr-events)
* [Detection and Response](/docs/detection-and-response)
* [Exfil (Event Collection)](/docs/ext-exfil)
* [Payloads](/docs/payloads)
* [Reference: Error Codes](/docs/reference-error-codes)
* [Integrity](/docs/ext-integrity)
* [Payload Manager](/docs/payload-manager)
* [YARA Manager](/docs/ext-yara-manager)

---

##### What's Next

* [Endpoint Agent Installation](/docs/endpoint-agent-installation)

Table of contents

+ [Supported Commands by OS](#supported-commands-by-os)
+ [Command Descriptions](#command-descriptions)

Tags

* [browser agent](/docs/en/tags/browser%20agent)
* [detection and response](/docs/en/tags/detection%20and%20response)
* [dfir](/docs/en/tags/dfir)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [linux](/docs/en/tags/linux)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## Reference: Sensor Selector Expressions

# Reference: Sensor Selector Expressions
Many components in LimaCharlie require selecting a set of Sensors based on some characteristics. The selector expression is a text field that describe what matching characteristics the selector is looking for.

The following fields are available in this evaluation:

* `sid`: the Sensor ID
* `oid`: the Organization ID
* `iid`: the Installation Key ID
* `plat`: the Platform name (see [platforms](/v2/docs/reference-id-schema#platforms))
* `ext_plat`: the Extended Platform name (see [platforms](/v2/docs/reference-id-schema#platforms))
* `arch`: the Architecture name (see [architectures](/v2/docs/reference-id-schema#architecture))
* `enroll`: the Enrollment as a second epoch timestamp
* `hostname`: the hostname
* `mac_addr`: the latest MAC address
* `alive`: second epoch timestamp of the last time the Sensor connected to the cloud
* `ext_ip`: the last external IP
* `int_ip` the last internal IP
* `isolated`: a boolean True if the sensor's network is isolated
* `should_isolate`: a boolean True if the sensor is marked to be isolated
* `kernel`: a boolean True if the sensor has some sort of "kernel" enhanced visibility
* `did`: the Device ID the sensor belongs to
* `tags`: the list of tags the sensor currently has

The following are the available operators:

* `==`: equals
* `!=`: not equal
* `in`: element in list, or substring in string
* `not in`: element not in list, or substring not in string
* `matches`: element matches regular expression
* `not matches`: element does not match regular expression

Here are some examples:

* all sensors with the test tag: `test in tags`
* all windows boxes with an internal IP starting in 10.3.x.x: `` plat == windows and int_ip matches `^10\.3\..*` ``
* all 1password sensors, strings starting with a number need to be quoted with a backtick: `` plat == `1password` ``
* all linux with network isolation or evil tag: `plat == linux or (isolated == true or evil in tags)`

In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

## Related articles

* [LimaCharlie Query Language](/docs/lcql)
* [LCQL Examples](/docs/lcql-examples)
* [Velociraptor](/docs/ext-velociraptor)

---

### What's Next

* [Events](/docs/events)

Tags

* [platform](/docs/en/tags/platform)
* [reference](/docs/en/tags/reference)
* [sensors](/docs/en/tags/sensors)

---

## Sensor Connectivity

# Sensor Connectivity
* 1 Minute to read

## Related articles

* [Endpoint Agent](/docs/endpoint-agent)
* [macOS Agent Installation via Jamf Now](/docs/installing-macos-agents-via-jamf-now)
* [Chrome Agent Installation](/docs/chrome-agent-installation)
* [Windows Agent Installation](/docs/windows-agent-installation)
* [Linux Agent Installation](/docs/linux-agent-installation)
* [Endpoint Agent Installation](/docs/endpoint-agent-installation)
* [Edge Agent Installation](/docs/edge-agent-installation)
* [macOS Agent Installation - Older Versions (macOS 10.15 Catalina to macOS 14 Sonoma)](/docs/macos-agent-installation-latest-os-versions)
* [macOS Agent Installation - Older Versions (macOS 10.14 and prior)](/docs/macos-agent-installation-older-versions)
* [Docker Agent Installation](/docs/docker-agent-installation)
* [macOS Agent Installation](/docs/macos-agent-installation)

---

### What's Next

* [Endpoint Agent](/docs/endpoint-agent)

Table of contents

+ [Proxy Tunneling](#proxy-tunneling)

Tags

* [adapters](/docs/en/tags/adapters)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)

---

## Sensor Cull

# Sensor Cull
The Sensor Cull Extension performs continuous cleaning of "old" sensors that have not connected to an Organization within a set period of time. This is useful for environments with cloud deployments or VM/template-based deployments that may enroll sensors repeatedly, and for a short period of time.

The extension works by creating rules that describe when specified sensors should be cleaned up.

## Enabling the Sensor Cull Extension

To enable the Sensor Cull extension, navigate to the [Sensor Cull extension page](https://app.limacharlie.io/add-ons/extension-detail/ext-sensor-cull) in the LimaCharlie marketplace.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-cull-1.png)

After clicking **Subscribe**, the Sensor Cull extension should be available almost immediately.

## Using the Sensor Cull Extension

Once enabled, you will see a **Sensor Cull** option under **Sensors** within the LimaCharlie web UI. You can also interact with the extension via REST API.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-cull-2.png)

Within the Sensor Cull module, you have the ability to create rules. Sensor Cull rules are run automatically once a day, and can be edited as needed.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-cull-3.png)

Each rule specifies a single sensor `tag` used as a selector for the sensors the rule applies to. A rule also has a `name` (simply used for your bookkeeping), and a `ttl` which is the number of days a sensor can remain unconnected to LimaCharlie before it becomes eligible for cleanup.

## Actions via REST API

The following REST API actions can be sent to interact with the Sensor Cull extension:

### get\_rules

Get the list of existing rules

```json
{
  "action": "get_rules"
}
```

### run

Perform an ad-hoc cleanup.

```json
{
  "action": "run"
}
```

### add\_rule

The following example creates a rule name `my new rule` that applies to all sensors with the `vip` Tag, and cleans them up when they have not connected in 30 days.

```json
{
  "action": "add_rule",
  "name": "my new rule",
  "tag": "vip",
  "ttl": 30
}
```

### del\_rule

Delete an existing rule by name.

```json
{
  "action": "del_rule",
  "name": "my new rule"
}
```

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

---

#### Related articles

* [VDI & Virtual Machine Templates](/docs/vdi-virtual-machine-templates)

---

##### What's Next

* [Usage Alerts](/docs/ext-usage-alerts)

Table of contents

+ [Enabling the Sensor Cull Extension](#enabling-the-sensor-cull-extension)
+ [Using the Sensor Cull Extension](#using-the-sensor-cull-extension)
+ [Actions via REST API](#actions-via-rest-api)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Sensor Tags

# Sensor Tags
Tags in LimaCharlie are simple strings that can be associated with any number of sensors. A Sensor can also have an arbitrary number of tags associated with it.

Tags appear in every event coming from a sensor under the `routing` component of the event. This greatly simplifies the writing of detection and response rules based on the presence of specific tags, at the cost of including more non-unique data per event.
 Tags can be used for a variety of purposes, including:

* to classify endpoints
* automate detection and response
* create powerful workflows
* trigger automations

## Use Cases for Sensor Tags

### Classification

You can use tags to classify an endpoint in a number of different ways based on what is important to you.  Some examples of classifications are shown below for inspiration.

**Departments**

Create tags to classify endpoints based on what business department they belong to.  e.g. sales, finance, operations, development, support, legal, executives.

**Usage Type**

You may wish to tag endpoints based on their type of usage.  e.g. workstation, server, production, staging.

By having endpoints tagged in this manner you can easily identify endpoints and decide what actions you may wish to take while considering the tag.  For example, if you see an endpoint is tagged with `workstation` and `executives`, and you happen to see suspicious activity on the endpoint, it may be worthwhile for you to prioritize response.

### Automating detection and response

You can use tags to automate detection and response.

For example, you can create a detection & response rule so that when a specific user logs in on a device, the box is tagged as `VIP-sales` and the sensor starts collecting an extended list of events from that box.

### Creating workflows

You can use tags to create workflows and automations. For instance, you can configure an output (forwarder) to send all detections containing `VIP-sales` tag to Slack so that you can review them asap, while detections tagged as `sales` can be sent to an email address.

### Trigger Automations

Create a Yara scanning rule so that endpoints tagged as 'sales' are continuously scanned against the specific sets of Yara signatures.

## Adding Tags

Tags can be added to a sensor a few different ways:

1. Enrollment: the installation keys can optionally have a list of Tags that will get applied to sensors that use them.
2. Manually: using the API as described below, either manually by a human or through some other integration.
3. Detection & Response: automated detection and response rules can programatically add a tag (and check for tags).

### Manual API

Issue a `POST` to `/{sid}/tags` REST endpoint

### Detection & Response

In detection and response rules. To achieve this, in the response part of the detection & response rule, specify the add tag action. For example, to tag a device as DESKTOP, you would say:

```
- action: add tag
tag: DESKTOP
```

## Removing Tags

### Manual API

Issue a `DELETE` to `/{sid}/tags` REST endpoint

### Detection & Response

In detection and response rules

### Manual in the web app

In the web app, click on the sensor in question to expand it. You will see the list of tags you can add/edit/remove.

## Checking Tags

### Manual API

Issue a `GET` to `/{sid}/tags` REST endpoint

### Detection & Response

In detection and response rules

## System Tags

We provide system level functionality with a few system tags.  Those tags are listed below for reference:

### lc:latest

When you tag a sensor with `lc:latest`, the sensor version currently assigned to the Organization will be ignored for that specific sensor, and the latest version of the sensor will be used instead. This means you can tag a representative set of computers in the Organization with the `lc:latest` tag in order to test-deploy the latest version and confirm no negative effects.

### lc:stable

When you tag a sensor with `lc:stable`, the sensor version currently assigned to the Organization will be ignored for that specific sensor, and the *stable* version of the sensor will be used instead. This means you can upgrade an organization as a whole, but leave a few specific sensors behind by assigning the lc:stable tag to them.

### lc:experimental

When you tag a sensor with `lc:experimental`, the sensor version currently assigned to the Organization will be ignored for that specific sensor. An experimental version of the sensor will be used instead. This tag is typically used when working with the LimaCharlie team to troubleshoot sensor-specific issues.

### lc:no\_kernel

When you tag a sensor with `lc:no_kernel`, the kernel component will not be loaded on the host.

### lc:debug

When you tag a sensor with `lc:debug`, the debug version of the sensor currently assigned to the Organization will be used.

### lc:limit-update

When you tag a sensor with lc:limit-update, the sensor will not update the version it's running at run-time. The version will only be loaded when the sensor starts from scratch like after a reboot.

### lc:sleeper

When you tag a sensor with *lc:sleeper*, the sensor will keep its connection to the LimaCharlie Cloud, but will disable all other functionality to avoid any impact on the system.

### lc:usage

When you tag a sensor with *lc:usage*, the sensor will work as usual, but its connection will not count against the normal sensor quota. Instead, the time the sensor spends connected will be billed separately per second, and so will events received by the sensor. For more details, see [Sleeper Deployments](/v2/docs/sleeper).

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

#### Related articles

* [Response Actions](/docs/response-actions)
* [Installation Keys](/docs/installation-keys)
* [Template Strings and Transforms](/docs/template-strings-and-transforms)
* [Endpoint Agent Versioning and Upgrades](/docs/endpoint-agent-versioning-and-upgrades)
* [Updating Sensors to the Newest Version](/docs/updating-sensors-to-the-newest-version)
* [Test a New Sensor Version](/docs/test-a-new-sensor-version)

---

##### What's Next

* [Artifacts](/docs/artifacts)

Table of contents

+ [Use Cases for Sensor Tags](#use-cases-for-sensor-tags)
+ [Adding Tags](#adding-tags)
+ [Removing Tags](#removing-tags)
+ [Checking Tags](#checking-tags)
+ [System Tags](#system-tags)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)
* [platform](/docs/en/tags/platform)
* [sensors](/docs/en/tags/sensors)

---

## Sensors

# Sensors
* 1 Minute to read

## Related articles

* [Endpoint Agent Events Overview](/docs/endpoint-agent-events-overview)
* [Endpoint Agent Installation](/docs/endpoint-agent-installation)
* [Endpoint Agent](/docs/endpoint-agent)

---

### What's Next

* [Installation Keys](/docs/installation-keys)

Table of contents

+ [Overview](#overview)

Tags

* [sensors](/docs/en/tags/sensors)

---

## Test a New Sensor Version

# Test a New Sensor Version
* 1 Minute to read

## Related articles

* [Endpoint Agent Versioning and Upgrades](/docs/endpoint-agent-versioning-and-upgrades)
* [Updating Sensors to the Newest Version](/docs/updating-sensors-to-the-newest-version)

---

### What's Next

* [Updating Sensors to the Newest Version](/docs/updating-sensors-to-the-newest-version)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## Updating Sensors to the Newest Version

# Updating Sensors to the Newest Version
* 1 Minute to read

## Related articles

* [Endpoint Agent Versioning and Upgrades](/docs/endpoint-agent-versioning-and-upgrades)
* [Test a New Sensor Version](/docs/test-a-new-sensor-version)
* [Endpoint Agent Installation](/docs/endpoint-agent-installation)

---

### What's Next

* [Ingesting Sysmon Event Logs](/docs/ingesting-sysmon-event-logs)

Table of contents

+ [Manual Update](#manual-update)
+ [Automated Update](#automated-update)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## Windows Agent Installation

# Windows Agent Installation
## Windows Agent Installation Instructions

Windows MSI Installation Versioning

Our MSI packages are created programmatically, and thus will have a version of `1.0.0.0` upon compilation and download. Note Sensor versions will reflect the latest version as of the MSI download, and sensor version control is managed via the LimaCharlie application, not the MSI package.

### System Requirements

The LimaCharlie.io agent supports Windows XP 32 bit and up (32 and 64 bit). However, Windows XP and 2003 support is for the more limited capabilities of the agent that do not require kernel support.

### Installing via MSI

[Windows Installer](https://learn.microsoft.com/en-us/windows/win32/msi/windows-installer-portal) is an installation and configuration service provided with Windows. Microsoft Software Installer, or MSI, files allow for an easy and portable installation format on Windows systems.

LimaCharlie makes portable MSI files available with each new sensor release. They are available at a static URL for easy downloading:

* [32-bit MSI installer](https://downloads.limacharlie.io/sensor/windows/msi32)
* [64-bit MSI installer](https://downloads.limacharlie.io/sensor/windows/msi64)

Similar to executable installation, when installing with an MSI, you will need to provide the desired Installation Key, passed through as the `InstallationKey` variable.

**32-bit MSI installation command:**

`hcp_win_x86_release_<sensor_version>.msi InstallationKey=<installation_key>`

**64-bit MSI installation command:**

`hcp_win_x64_release_<sensor_version>.msi InstallationKey=<installation_key>`

Executing the installer via the command line, pass the `-i INSTALLATION_KEY` argument where `INSTALLATION_KEY` is the key mentioned above. This will install the sensor as a Windows service and trigger its enrollment.

You may also install the Windows sensor using the MSI version. With the MSI, install using:

```
installer.msi InstallationKey="INSTALLATION_KEY"
```

You may also pass the value `-` instead of the `INSTALLATION_KEY` like: `-i -`. This will make the installer look for the installation key in an alternate place in the following order:

* Environment variable `LC_INSTALLATION_KEY`
* Text file in current working directory: `lc_installation_key.txt`

#### Verify the service is running

In an administrative command prompt issue the command `sc query rphcpsvc` and confirm the `STATE` displayed is `RUNNING`.

## Uninstalling the Agent

For additional agent uninstall options, see [Endpoint Agent Uninstallation](/v2/docs/endpoint-agent-uninstallation)

### Manual Uninstallation

#### Windows EXE

On Windows, the LimaCharlie sensor can be uninstalled on individual endpoints by running the installer EXE with the `-c` argument, which will remove the Sensor and its service entirely.

Example:

```
C:\Windows\System32\rphcp.exe -c
del C:\Windows\System32\rphcp.exe
```

#### Windows MSI

If uninstalling via the Windows MSI installer, the `/x` switch can be used to uninstall.

Example:

```
msiexec /x lc_sensor.msi /qn
```

If you run into issues where the service is still present (`sc.exe query rphcpsvc`) or the exe is still left behind (`C:\Windows\System32\rphcp.exe`), you can remove them with the following:

```
C:\Windows\System32\rphcp.exe -c       # If this throws an error about the service, it's safe to ignore
del C:\Windows\System32\rphcp.exe
```

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

##### Related articles

* [Endpoint Agent](/docs/endpoint-agent)
* [Endpoint Agent Uninstallation](/docs/endpoint-agent-uninstallation)
* [Building a custom MSI installer for Windows](/docs/building-a-custom-msi-installer-for-windows)

---

###### What's Next

* [Building a custom MSI installer for Windows](/docs/building-a-custom-msi-installer-for-windows)

Table of contents

+ [Windows Agent Installation Instructions](#windows-agent-installation-instructions)
+ [Uninstalling the Agent](#uninstalling-the-agent)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## macOS Agent Installation

# macOS Agent Installation
* 1 Minute to read

## Related articles

* [macOS Agent Installation - MDM Configuration Profiles](/docs/macos-agent-installation-mdm-configuration-profiles)
* [macOS Agent Installation - Older Versions (macOS 10.14 and prior)](/docs/macos-agent-installation-older-versions)
* [macOS Agent Installation - Older Versions (macOS 10.15 Catalina to macOS 14 Sonoma)](/docs/macos-agent-installation-latest-os-versions)
* [Ingesting MacOS Unified Logs](/docs/ingesting-macos-unified-logs)
* [macOS Agent Installation via Jamf Now](/docs/installing-macos-agents-via-jamf-now)
* [Mac Unified Logging](/docs/adapter-types-mac-unified-logging)
* [Endpoint Agent Events Overview](/docs/endpoint-agent-events-overview)

---

### What's Next

* [macOS Agent Installation - Latest Versions (macOS 15 Sequoia and newer)](/docs/clone-macos-agent-installation-latest-versions-macos-15-sequoia-and-newer)

Table of contents

+ [Installation Instructions](#installation-instructions)
+ [Uninstalling the Agent](#uninstalling-the-agent)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)

---

## macOS Agent Installation - Latest Versions (macOS 15 Sequoia and newer)

# macOS Agent Installation - Latest Versions (macOS 15 Sequoia and newer)
## macOS Sensor (macOS 15 Sequoia)

This document provides details of how to install, verify, and uninstall the LimaCharlie Endpoint Agent on macOS (versions 15 Sonoma). We also offer separate documentation for older versions.

### Installer Options

When running the installer from the command line, you can pass the following arguments:

```
-v: display build version.
-q: quiet; do not display banner.
-d <INSTALLATION_KEY>: the installation key to use to enroll, no permanent installation.
-i <INSTALLATION_KEY>: install executable as a service with deployment key.
-r: uninstall executable as a service.
-c: uninstall executable as a service and delete identity files.
-w: executable is running as a macOS service.
-h: displays the list of accepted arguments.
```

### Installation Flow

1. Download the Sensor installer file.  Installer for: [Intel Mac](https://downloads.limacharlie.io/sensor/mac/64) -or- [Apple Silicon Mac](https://downloads.limacharlie.io/sensor/mac/arm64).
2. Add execute permission to the installer file via the command line

> chmod +x lc\_sensor

3. Run the installer via the command line.  You'll pass the argument -i and your Installation Key.

> sudo ./lc\_sensor -i YOUR\_INSTALLATION\_KEY\_GOES\_HERE

You can obtain the installation key from the [Installation Keys](/v2/docs/installation-keys) section of the LimaCharlie web application.

The sensor will be installed as a launchctl service. Installation will trigger the sensors enrollment with the LimaCharlie cloud

![macOS Terminal application showing LimaCharlie installation](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/1-Terminal_install.png)

4. An application (`RPHCP.app`) will be installed in the /Applications folder and will automatically launch.  Note that it may take a few minutes before you see this happened after installation.

   You will be prompted to grant permissions for system extensions to be installed. Click the "**Open System Settings**" button

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/2-Endpoint_Extension_Installation_Dialog.png)

6. Ensure the toggle for “Allow in the Background” next to “Refraction Point, Inc.” is toggled On.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/2.5-Login_Items_and_Extensions.png)

7. Click the “i” info icon next to “Endpoint Security Extensions”, then ensure the toggle next to “RPHCP” is on.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/3-Endpoint_Extension_Enablement.png)

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/EndpointSecurityExtension-Enabled.png)

8. After enabling that toggle you’ll need to click the “Allow” button to allow RPHCP to filter network content.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/4-Network_Filter_Enablement.png)

8. You'll be prompted to grant Full Disk Access.  Check the checkbox next to the RPHCP app in System Preferences -> Privacy -> Full Disk Access

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/5-Full_Disk_Access_Permission_Dialog.png)

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/6-Full_Disk-Access_Enablement.png)

The installation is now complete and you should see a message indicating that the installation was successful.

![Success](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/09-Success.png)

### Verifying Installation

To verify that the sensor was installed successfully, you can log into the LimaCharlie web application and see if the device has appeared in the Sensors section. Additionally, you can check the following on the device itself:

In a Terminal, run the command:

> sudo launchctl list | grep com.refractionpoint.rphcp

![Successful installation verification](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Verification/Verification-installation-successful.png)

If the agent is running, this command should return records as shown above.

You can also check the /Applications folder and launch the RPHCP.app.

![Applications folder](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/10-Applications.png)

You can confirm the network filter was properly installed and enabled by going to System Settings → Network → VPN & Filters. You should expect to see “RPHCP” in the list with the status showing as Enabled.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/7-Network_Filter_Confirmation(1).png)

The application will show a message to indicate if the required permissions have been granted.

![App installed correctly](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/11-App_Installed_Correctly.png)

As described in the dialog, the RPHCP.app application must be left in the /Applications folder in order for it to continue operating properly.

#### A note on permissions

Apple has purposely made installing extensions (like the ones used by LimaCharlie) a process that requires several clicks on macOS. The net effect of this is that the first time the sensor is installed on a macOS system, permissions will need to be granted via System Preferences

Currently, the only way to automate the installation is to use an Apple-approved MDM solution. These solutions are often used by large organizations to manage their Mac fleet. If you are using such a solution, see your vendor's documentation on how to add extensions to the allow list which can be applied to your entire fleet.

We're aware this is an inconvenience and hope Apple will provide better solutions for security vendors in future.

### Uninstallation Flow

To uninstall the sensor:

1. Run the installer via the command line.  You'll pass the argument -c

> sudo ./hcp\_osx\_x64\_release\_4.23.0 -c

![Uninstall progress](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Uninstallation/1-Uninstall_Progress.png)

2. You will be prompted for credentials to modify system extensions.  Enteryour password and press OK.

![Uninstall permissions](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Uninstallation/2-Uninstaller_Permissions.png)

The related system extension will be removed and the `RPHCP.app` will be removed from the /Applications folder.

3. You should see a message indicating that the uninstallation was successful.

![Uninstall success](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Uninstallation/3-Uninstall_Success.png)

Note: After uninstallation the LimaCharlie sensor along with the related extensions will be removed. macOS requires a reboot to fully unload and remove extensions.

### Install Using MDM Solutions

See our document [macOS Agent Installation with MDM Solutions](/docs/macos-agent-installation-mdm-configuration-profiles) for the Mobile Device Management (MDM) Configuration Profile that can be used to deploy the LimaCharlie agent to an enterprise fleet.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

#### What's Next

* [macOS Agent Installation via Microsoft Intune](/docs/macos-agent-installation-via-microsoft-intune)

Table of contents

+ [macOS {{glossary.Sensor}} (macOS 15 Sequoia)](#macos-{{glossary-sensor}}-macos-15-sequoia-)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)

---

## macOS Agent Installation - MDM Configuration Profiles

# macOS Agent Installation - MDM Configuration Profiles
This document provides details of the Mobile Device Management (MDM) Configuration Profile that can be used to deploy the LimaCharlie agent to your enterprise fleet on macOS (versions 10.15 and newer).

## Affected Dialogs

Once the configuration profile is deployed using an approved MDM server, users will not need to provide approval to complete the agent installation. In particular, the following three system approval dialogs will no longer be presented:

System Extension
![System Extensions Required](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/04-System_Extension_Required.png)

Network Filter
![Network filter](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/07--Network_Filter.png)

Full Disk Access
![Full disk access](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/08-Full_Disk_Access.png)

Application Installation
![RPHCP application install](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/03-Permissions_Required.png)

## Configuration Profile Details

We have provided a sample configuration profile for reference: [![MobileConfig icon](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/mobileconfig-icon.png)](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/LimaCharlie.mobileconfig.zip)

 [Download LimaCharlie.mobileconfig sample configuration profile](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/LimaCharlie.mobileconfig.zip)

This profile includes the following permissions:

* System Extension
* Full Disk Access
* Network Content Filter

## Silent Installation Preference

In addition to the MDM profile, you will also want to place the following preference file in the /Library/Preferences folder on the endpoint prior to installation. With this preference file in place the application will provide for a silent installation.

The required preference file can be downloaded here: [![Preference file icon](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/preference-icon.png)](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/com.refractionpoint.rphcp.client.plist.zip)

 [Download com.refractionpoint.rphcp.client.plist preference file (to be placed in the /Library/Preferences folder on the endpoint)](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/com.refractionpoint.rphcp.client.plist.zip)

## Installation Scripts

We have made a sample installation and uninstallation script available. You can use these with MDM providers to mass install/remove LimaCharlie. Note that the installation script should be edited prior to use as it requires your unique Installation Key to be entered.

These scripts will determine the machine architecture (Intel or Apple Silicon), download the appropriate installer, and then perform the installation or uninstallation. They also will automatically add (or remove, for uninstallations) the Silent Installation Preference File.

[Sample Installation Script](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/sample-install-limacharlie.sh)

[Sample Uninstallation Script](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/sample-uninstall-limacharlie.sh)

## Example Jamf Pro Setup

While any Apple / user approved MDM provider may be used, we have provided specific instructions for Jamf Pro as a matter of convenience.

1. Log into Jamf Pro and go to Computers -> Configuration Profiles
2. Add a new profile
3. In the General section choose a name for the profile and set Level to "Computer Level"

![System Extensions Required](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/JamfPro-1-General.png)

4. Add a Privacy Preferences Policy Control configuration and set the parameters as follows:

Identifier:
com.refractionpoint.rphcp.extension

Identifier Type:
Bundle ID

Code Requirement:
anchor apple generic and identifier "com.refractionpoint.rphcp.extension" and (certificate leaf[field.1.2.840.113635.100.6.1.9] /\* exists \*/ or certificate 1[field.1.2.840.113635.100.6.2.6] /\* exists \*/ and certificate leaf[field.1.2.840.113635.100.6.1.13] /\* exists \*/ and certificate leaf[subject.OU] = N7N82884NH)

App or Service:
SystemPolicyAllFiles

Access:
Allow

![System Extensions Required](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/JamfPro-2-PPPC.png)

5. Add a System Extensions configuration and set the parameters as follows:

Enter your desired display name

System Extension Types: Allowed System Extensions

Team Identifier: N7N82884NH

Allowed System Extensions: com.refractionpoint.rphcp.extension

![System Extensions Required](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/JamfPro-2-SystemExtensions.png)

6. Add a Content Filter configuration and set the parameters as follows:

Enter your desired filter name

Identifier: com.refractionpoint.rphcp.client

Filter Order: Firewall

Add a Socket Filter with the following details:
Socket Filter Bundle Identifier:
com.refractionpoint.rphcp.client

Socket Filter Designated Requirement
anchor apple generic and identifier "com.refractionpoint.rphcp.client" and (certificate leaf[field.1.2.840.113635.100.6.1.9] /\* exists \*/ or certificate 1[field.1.2.840.113635.100.6.2.6] /\* exists \*/ and certificate leaf[field.1.2.840.113635.100.6.1.13] /\* exists \*/ and certificate leaf[subject.OU] = N7N82884NH)

Add a Network Filter with the following details:

Network Filter Bundle Identifier:
com.refractionpoint.rphcp.client

Network Filter Designated Requirement:
anchor apple generic and identifier "com.refractionpoint.rphcp.client" and (certificate leaf[field.1.2.840.113635.100.6.1.9] /\* exists \*/ or certificate 1[field.1.2.840.113635.100.6.2.6] /\* exists \*/ and certificate leaf[field.1.2.840.113635.100.6.1.13] /\* exists \*/ and certificate leaf[subject.OU] = N7N82884NH)

![System Extensions Required](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/JamfPro-4-ContentFilter.png)

7. Deploy the configuration profile to your devices.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

### Related articles

* [macOS Agent Installation via Jamf Now](/docs/installing-macos-agents-via-jamf-now)
* [Enterprise-Wide Agent Deployment](/docs/enterprise-wide-agent-deployment)
* [macOS Agent Installation](/docs/macos-agent-installation)
* [macOS Agent Installation - Older Versions (macOS 10.14 and prior)](/docs/macos-agent-installation-older-versions)
* [macOS Agent Installation - Older Versions (macOS 10.15 Catalina to macOS 14 Sonoma)](/docs/macos-agent-installation-latest-os-versions)

---

#### What's Next

* [macOS Agent Installation via Jamf Now](/docs/installing-macos-agents-via-jamf-now)

Table of contents

+ [Affected Dialogs](#affected-dialogs)
+ [Configuration Profile Details](#configuration-profile-details)
+ [Silent Installation Preference](#silent-installation-preference)
+ [Installation Scripts](#installation-scripts)
+ [Example Jamf Pro Setup](#example-jamf-pro-setup)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)

---

## macOS Agent Installation - Older Versions (macOS 10.14 and prior)

# macOS Agent Installation - Older Versions (macOS 10.14 and prior)
## macOS Sensor (macOS 10.14 and prior)

This document provides details of how to install, verify, and uninstall the LimaCharlie sensor on macOS (versions 10.14 and prior).  We also offer [documentation for macOS 10.15 and newer](/v2/docs/macos-agent-installation-latest-os-versions).

### Installer Options

When running the installer from the command line, you can pass the following arguments:

```
-v: display build version.
-q: quiet; do not display banner.
-d <INSTALLATION_KEY>: the installation key to use to enroll, no permanent installation.
-i <INSTALLATION_KEY>: install executable as a service with deployment key.
-r: uninstall executable as a service.
-c: uninstall executable as a service and delete identity files.
-w: executable is running as a macOS service.
-h: displays the list of accepted arguments.
```

### Installation Flow

1. Download the [Sensor installer file](https://downloads.limacharlie.io/sensor/mac/64)
2. Add execute permission to the installer file via the command line

> chmod +x hcp\_osx\_x64\_release\_4.23.0

3. Run the installer via the command line.  You'll pass the argument -i and your Installation Key.

> sudo ./hcp\_osx\_x64\_release\_4.23.0 -i YOUR\_INSTALLATION\_KEY\_GOES\_HERE

![Basic installation](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/01-Basic_installation.png)

You can obtain the installation key from the Installation Keys section of the LimaCharlie web application.  [More information about installation keys](https://doc.limacharlie.io/docs/documentation/docs/manage_keys.md).

The sensor will be installed as a launchctl service.  Installation will trigger the sensors enrollment with the LimaCharlie cloud.

![Installation success](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/02-Installation_success.png)

4. You will be prompted to grant permissions for system extensions to be installed.

![Permissions required](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/macOS_10.14/03_Older_Systems-System_Extension_Notice.png)

5. Click the "Open System Preferences" button
6. Unlock the preference pane using the padlock in the bottom left corner, then click the Allow button next to `System software from developer "Refraction Point, Inc" was blocked from loading.`

![Unlocked](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/macOS_10.14/04-Older_Systems-System_Software_Approval.png)

The installation is now complete and you should see a message indicating that the installation was successful.

## Verifying Installation

To verify that the sensor was installed successfully, you can log into the LimaCharlie web application and see if the device has appeared in the Sensors section.  Additionally, you can check the following on the device itself:

**Ensure the process is running**

In a Terminal, run the command:

> sudo launchctl list | grep com.refractionpoint.rphcp

![Successful installation verification](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/macOS_10.14/Installed_correctly.png)

If the agent is running, this command should return a record as shown above.

**Ensure the Kernel Extension is loaded**

You can confirm that the kernel extension is loaded by running the command:

> kextstat | grep com.refractionpoint.

![Successful installation verification](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/macOS_10.14/verifying-extension.png)

If the extension is loaded, this command should return a record as shown above.

### A note on permissions

Apple has purposely made installing extensions (like the ones used by LimaCharlie) a process that requires several clicks on macOS.  The net effect of this is that the first time the sensor is installed on a macOS system, permissions will need to be granted via System Preferences

Currently, the only way to automate the installation is to use an Apple-approved MDM solution. These solutions are often used by large organizations to manage their Mac fleet. If you are using such a solution, see your vendor's documentation on how to add extensions to the allow list which can be applied to your entire fleet.

We're aware this is an inconvenience and hope Apple will provide better solutions for security vendors in future.

## Uninstallation Flow

To uninstall the sensor:

1. Run the installer via the command line.

You'll pass the argument -c

> sudo ./hcp\_osx\_x64\_release\_4.23.0 -c

![Uninstall progress](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/macOS_10.14/Installed_correctly.png)

2. You should see a message indicating that the uninstallation was successful.

![Uninstall success](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Uninstallation/3-Uninstall_Success.png)

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

### Related articles

* [macOS Agent Installation](/docs/macos-agent-installation)
* [macOS Agent Installation - MDM Configuration Profiles](/docs/macos-agent-installation-mdm-configuration-profiles)
* [macOS Agent Installation - Older Versions (macOS 10.15 Catalina to macOS 14 Sonoma)](/docs/macos-agent-installation-latest-os-versions)
* [Ingesting MacOS Unified Logs](/docs/ingesting-macos-unified-logs)
* [macOS Agent Installation via Jamf Now](/docs/installing-macos-agents-via-jamf-now)
* [Mac Unified Logging](/docs/adapter-types-mac-unified-logging)

---

#### What's Next

* [macOS Agent Installation - MDM Configuration Profiles](/docs/macos-agent-installation-mdm-configuration-profiles)

Table of contents

+ [macOS {{glossary.Sensor}} (macOS 10.14 and prior)](#macos-{{glossary-sensor}}-macos-10-14-and-prior-)
+ [Verifying Installation](#verifying-installation)
+ [Uninstallation Flow](#uninstallation-flow)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)

---

## macOS Agent Installation - Older Versions (macOS 10.15 Catalina to macOS 14 Sonoma)

# macOS Agent Installation - Older Versions (macOS 10.15 Catalina to macOS 14 Sonoma)
## macOS Sensor (macOS 10.15 Catalina to macOS 14 Sonoma)

This document provides details of how to install, verify, and uninstall the LimaCharlie Endpoint Agent on macOS (versions 10.15 Catalina though to macOS 14 Sonoma). We also offer documentation for [macOS 10.14 and prior](/v2/docs/macos-agent-installation-older-versions), and [macOS 10.15 and newer](/v2/docs/clone-macos-agent-installation-latest-versions-macos-15-sequoia-and-newer).

### Installer Options

When running the installer from the command line, you can pass the following arguments:

```
-v: display build version.
-q: quiet; do not display banner.
-d <INSTALLATION_KEY>: the installation key to use to enroll, no permanent installation.
-i <INSTALLATION_KEY>: install executable as a service with deployment key.
-r: uninstall executable as a service.
-c: uninstall executable as a service and delete identity files.
-w: executable is running as a macOS service.
-h: displays the list of accepted arguments.
```

### Installation Flow

1. Download the Sensor installer file.  Installer for: [Intel Mac](https://downloads.limacharlie.io/sensor/mac/64) -or- [Apple Silicon Mac](https://downloads.limacharlie.io/sensor/mac/arm64).
2. Add execute permission to the installer file via the command line

> chmod +x lc\_sensor

3. Run the installer via the command line.  You'll pass the argument -i and your Installation Key.

> sudo ./lc\_sensor -i YOUR\_INSTALLATION\_KEY\_GOES\_HERE

![Basic installation](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/01-Basic_installation.png)

You can obtain the installation key from the [Installation Keys](/v2/docs/installation-keys) section of the LimaCharlie web application.

The sensor will be installed as a launchctl service. Installation will trigger the sensors enrollment with the LimaCharlie cloud.

![Installation success](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/02-Installation_success.png)

4. An application (`RPHCP.app`) will be installed in the /Applications folder and will automatically launch.  You will be prompted to grant permissions for system extensions to be installed.

![Permissions required](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/03-Permissions_Required.png)

5. Click the "Open System Preferences" button

![System Extensions Required](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/04-System_Extension_Required.png)

6. Unlock the preference pane using the padlock in the bottom left corner, then click the Allow button next to `System software from application "RPHCP" was blocked from loading.`

![Unlocked](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/06-Allow_System_Software_Unlocked.png)

7. You'll be prompted to allow the application to Filter Network Content.  Click the Allow button.

![Network filter](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/07--Network_Filter.png)

8. You'll be prompted to grant Full Disk Access.  Check the checkbox next to the RPHCP app in System Preferences -> Privacy -> Full Disk Access

![Full disk access](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/08-Full_Disk_Access.png)

The installation is now complete and you should see a message indicating that the installation was successful.

![Success](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/09-Success.png)

### Verifying Installation

To verify that the sensor was installed successfully, you can log into the LimaCharlie web application and see if the device has appeared in the Sensors section. Additionally, you can check the following on the device itself:

In a Terminal, run the command:

> sudo launchctl list | grep com.refractionpoint.rphcp

![Successful installation verification](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Verification/Verification-installation-successful.png)

If the agent is running, this command should return records as shown above.

You can also check the /Applications folder and launch the RPHCP.app.

![Applications folder](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/10-Applications.png)

The application will show a message to indicate if the required permissions have been granted.

![App installed correctly](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Installation/11-App_Installed_Correctly.png)

As described in the dialog, the RPHCP.app application must be left in the /Applications folder in order for it to continue operating properly.

#### A note on permissions

Apple has purposely made installing extensions (like the ones used by LimaCharlie) a process that requires several clicks on macOS. The net effect of this is that the first time the sensor is installed on a macOS system, permissions will need to be granted via System Preferences

Currently, the only way to automate the installation is to use an Apple-approved MDM solution. These solutions are often used by large organizations to manage their Mac fleet. If you are using such a solution, see your vendor's documentation on how to add extensions to the allow list which can be applied to your entire fleet.

We're aware this is an inconvenience and hope Apple will provide better solutions for security vendors in future.

### Uninstallation Flow

To uninstall the sensor:

1. Run the installer via the command line.  You'll pass the argument -c

> sudo ./hcp\_osx\_x64\_release\_4.23.0 -c

![Uninstall progress](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Uninstallation/1-Uninstall_Progress.png)

2. You will be prompted for credentials to modify system extensions.  Enteryour password and press OK.

![Uninstall permissions](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Uninstallation/2-Uninstaller_Permissions.png)

The related system extension will be removed and the `RPHCP.app` will be removed from the /Applications folder.

3. You should see a message indicating that the uninstallation was successful.

![Uninstall success](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/images/Uninstallation/3-Uninstall_Success.png)

### Install Using MDM Solutions

See our document [macOS Agent Installation with MDM Solutions](/docs/macos-agent-installation-mdm-configuration-profiles) for the Mobile Device Management (MDM) Configuration Profile that can be used to deploy the LimaCharlie agent to an enterprise fleet.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

#### Related articles

* [macOS Agent Installation](/docs/macos-agent-installation)
* [macOS Agent Installation - MDM Configuration Profiles](/docs/macos-agent-installation-mdm-configuration-profiles)
* [macOS Agent Installation - Older Versions (macOS 10.14 and prior)](/docs/macos-agent-installation-older-versions)
* [Ingesting MacOS Unified Logs](/docs/ingesting-macos-unified-logs)
* [macOS Agent Installation via Jamf Now](/docs/installing-macos-agents-via-jamf-now)
* [Mac Unified Logging](/docs/adapter-types-mac-unified-logging)

---

##### What's Next

* [macOS Agent Installation - Older Versions (macOS 10.14 and prior)](/docs/macos-agent-installation-older-versions)

Table of contents

+ [macOS {{glossary.Sensor}} (macOS 10.15 Catalina to macOS 14 Sonoma)](#macos-{{glossary-sensor}}-macos-10-15-catalina-to-macos-14-sonoma-)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)

---

## macOS Agent Installation via Jamf Now

# macOS Agent Installation via Jamf Now
[Jamf Now](https://www.jamf.com/products/jamf-now/) is an MDM solution that provides an easy way to manage Apple devices for small and medium-sized businesses. LimaCharlie sensors can be deployed via Jamf Now for easy app distribution and inventory capabilities.

## Prerequisites

* a Jamf Now account;
* a provisioning profile that grants the necessary pre-authorizations (such as is [available here](/v2/docs/macos-agent-installation-latest-os-versions)) for deployment on the clients;
* a LimaCharlie Mac Sensor installer package (`.pkg`) that’s configured as desired for deployment on the clients.

## Set up your account on Jamf Now

1. Create a Jamf Now account at [https://signup.jamfnow.com](https://signup.jamfnow.com/), and log in.
2. Choose the “APNs” tab in the sidebar, and click “Get Started”.
3. Click “Download Certificate Signing Request.plist” and save the plist.
4. Click Next in the lower right.
5. As per the “Create an Apple Push Certificate” checklist shown, click “Open the Apple Push Certificates Portal”.
6. Log in with your Apple ID.
7. On the “Apple Push Certificates Portal” page to which you are redirected, click the green “Create Certificate” button.
8. Accept the Terms of Use, and click Continue.
9. On the “Create a New Push Certificate” page to which you’re redirected, specify the plist you downloaded in step 2 and click Upload.
10. On the “Confirmation” page, click Download and save the new PEM certificate file.
11. Navigate back to the Jamf Now page as at step 5, and click Next in the lower right.
12. On the “Upload Push Certificate” page, specify the PEM you downloaded in step 10.
13. Under “Save Your Apple ID”, annotate same as Jamf invites to do so, and click Save.

## Prepare the LimaCharlie sensor installer package on Jamf

As a prerequisite you must have on hand a LimaCharlie Sensor installer package (.pkg) that’s configured as desired.

1. Choose the “Apps” tab in the Jamf Now sidebar. It will show “No apps yet, let’s fix that.”
2. Click “Add an App”.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28117%29.png)

3. On the “Add an App” page, click “Upload Your App” in the top menu.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28118%29.png)

4. Drag your LC Sensor package installer onto the page (or click “browse” to locate it) to upload it to Jamf.
5. Give the package an appropriate name, and click Done.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28119%29.png)

## Prepare the LimaCharlie sensor provisioning on Jamf

1. Choose the “Blueprints” tab in the Jamf Now sidebar.
2. Click “Create New Blueprint” at the top.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28120%29.png)

3. Enter a meaningful Name and Description as prompted, and click Save Blueprint.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28121%29.png)

4. Click on the entry for your new Blueprint.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28122%29.png)

5. On the inner tab bar that appears, click “Custom Profiles”, and then “Add a Custom Profile”.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28123%29.png)

6. Drag your LimaCharlie mobileconfig file onto the page (or click “browse” to locate it) to upload it to Jamf.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28124%29.png)

7. Click “Add Custom Profile” in the lower right.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28125%29.png)

8. On the inner tab bar, click “Apps”, and then click “Add App”.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28126%29.png)

9. In the list, enable the “Install Automatically” checkbox for with the installer package that you uploaded earlier.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28127%29.png)

10. Click “Save Changes” in the lower right.

## Prepare Jamf Now to enroll devices

1. Choose the “Devices” tab in the Jamf Now sidebar. It will show “No devices yet, let’s fix that.”
2. Click “Enable Open Enrollment”.
3. On the “Open Enrollment” page, activate the “Enable Open Enrollment” checkbox, enter an Access Code as prompted, and click Save Settings.
4. Take note of the indicated enrollment link.

## Enroll a Mac for management in Jamf

The following recipe presumes the use of MacOS 13 (Ventura).

1. On a subject Mac, visit the enrollment link from step 4 in the section above.
2. Enter the appropriate Access Code and user name, and click Start Enrollment.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28128%29.png)

3. Save the “enroll.mobileconfig” file that begins to download, and then open it in the Finder by double-clicking.
4. Open the System Settings app and navigate to the newly-installed profile.

   1. Choose “Privacy & Security”.
   2. Scroll to the bottom, and under the “Others” heading, click “Profiles”.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28129%29.png)

5. Double-click on the “ Profile”.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28130%29.png)

6. Click “Install…” in the lower left.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28131%29.png)

7. Authenticate with the appropriate password when prompted with “Profiles is trying to enroll you in a remote management (MDM) service”.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28132%29.png)

8. Observe that System Settings declares “This Mac is supervised and managed by ”.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28133%29.png)

## Provision a Mac with the LimaCharlie sensor

1. Choose the “Blueprints” tab in the Jamf Now sidebar.
2. Click the entry for the custom Blueprint you created from Step 6 onward in the “Prepare the LC sensor package on Jamf” section above.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28134%29.png)

3. On the inner tab bar that appears, click “Devices”, and then “Add a Device”.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28135%29.png)

4. Click on a device you want to provision, and then click “Add Devices” in the lower right corner.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28136%29.png)

5. Observe after a few moments that both the provisioning profile and the LimaCharlie sensor have been installed on the subject Mac.

   1. The Mac appear in the Jamf Devices list on the Blueprints tab with the label “Settings applied”. (It may initially appear as “Settings not applied”; simply refresh the page.)

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28137%29.png)

2. On the Mac itself, an additional profile appears in System Settings > Privacy & Security > Profiles.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28138%29.png)

3. A “Background Items Added” notification is displayed.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28139%29.png)

4. The RPHCP.app appears in the Mac’s Applications folder, and the rphcp daemon is running.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

### Related articles

* [macOS Agent Installation](/docs/macos-agent-installation)
* [macOS Agent Installation - Older Versions (macOS 10.15 Catalina to macOS 14 Sonoma)](/docs/macos-agent-installation-latest-os-versions)
* [macOS Agent Installation - Older Versions (macOS 10.14 and prior)](/docs/macos-agent-installation-older-versions)
* [macOS Agent Installation - MDM Configuration Profiles](/docs/macos-agent-installation-mdm-configuration-profiles)
* [Ingesting MacOS Unified Logs](/docs/ingesting-macos-unified-logs)
* [Mac Unified Logging](/docs/adapter-types-mac-unified-logging)

---

#### What's Next

* [VDI & Virtual Machine Templates](/docs/vdi-virtual-machine-templates)

Table of contents

+ [Prerequisites](#prerequisites)
+ [Set up your account on Jamf Now](#set-up-your-account-on-jamf-now)
+ [Prepare the LimaCharlie sensor installer package on Jamf](#prepare-the-limacharlie-sensor-installer-package-on-jamf)
+ [Prepare the LimaCharlie sensor provisioning on Jamf](#prepare-the-limacharlie-sensor-provisioning-on-jamf)
+ [Prepare Jamf Now to enroll devices](#prepare-jamf-now-to-enroll-devices)
+ [Enroll a Mac for management in Jamf](#enroll-a-mac-for-management-in-jamf)
+ [Provision a Mac with the LimaCharlie sensor](#provision-a-mac-with-the-limacharlie-sensor)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)

---

## macOS Agent Installation via Microsoft Intune

# macOS Agent Installation via Microsoft Intune
You can deploy the LimaCharlie Sensor for macOS using the MDM provider of your choice. Below are instructions for deploying the LimaCharlie Sensor for macOS using Microsoft Intune.

## **MDM Profile**

Set up the installation script by following these steps:

1. In the [Microsoft Intune admin center](https://intune.microsoft.com/), go to Devices → Manage Devices → Configuration.

![Screenshot of MS Intune -> Devices | Configuration](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/Configurations.png)

2. Choose [Policies](https://intune.microsoft.com/?ref=AdminCenter#view/Microsoft_Intune_DeviceSettings/DevicesMenu/~/configuration), click the Create button and choose New Policy

   1. Set the Platform to be macOS

   2. Set the Profile Type to be Templates, then choose the template name “Custom”

   3. Click Create

3. Enter the custom policy details as follows:

   1. Name:  LimaCharlie

   2. Custom configuration profile name:  LimaCharlie

   3. Deployment channel: Device channel

   4. Configuration profile file: Download and use the [LimaCharlie MDM profile](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/LimaCharlie.mobileconfig.zip).

Set the Assignments to include all users who need the profile installed.

![Screenshot of MS Intune -> Devices | Configuration | Details](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/Configuration-details.png)

## Installation Script

Set up the installation script by following these steps:

1. In the [Microsoft Intune admin center](https://intune.microsoft.com/), go to Devices → Manage Devices → Scripts and remediations.

![Screenshot of MS Intune -> Devices | Scripts](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/Scripts.png)

2. Choose [Platform scripts](https://intune.microsoft.com/?ref=AdminCenter#view/Microsoft_Intune_DeviceSettings/DevicesMenu/~/scripts), click the Add button and choose macOS

3. Set up the script with the following parameters:

Name: Install LimaCharlie

Shell script:  [Download this template shell script](https://storage.googleapis.com/limacharlie-io/doc/sensor-installation/macOS/MDM_profiles/sample-install-limacharlie.sh); be sure to edit it to include your Installation Key before uploading it in MS Intune.

Run script as signed-in user:  No

Hide script notifications on devices:  Yes

Script frequency:  Not configured

Max number of times to retry if script fails:  3

Assignments:  Set the `Included groups` to be `All Users` if you wish all users to get the application to be installed, or simply select the correct group to whom you wish to have LimaCharlie be installed for.

![Screenshot of MS Intune -> Devices | Scripts | Details](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/Script-details.png)

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

### What's Next

* [macOS Agent Installation - Older Versions (macOS 10.15 Catalina to macOS 14 Sonoma)](/docs/macos-agent-installation-latest-os-versions)

Table of contents

+ [MDM Profile](#mdm-profile)
+ [Installation Script](#installation-script)

---

# Events

## Azure Event Hub

# Azure Event Hub
* 1 Minute to read

## Related articles

* [Azure Kubernetes Service (AKS)](/docs/azure-kubernetes-service)
* [Azure Monitor](/docs/azure-monitor)
* [Azure Network Security Group](/docs/azure-network-security-group)
* [Azure SQL Audit Logs](/docs/azure-sql-audit-logs)
* [Azure Event Hub](/docs/adapter-types-azure-event-hub)
* [Microsoft Entra ID](/docs/adapter-types-microsoft-entra-id)
* [Azure](/docs/ext-cloud-cli-azure)

---

### What's Next

* [Azure Storage Blob](/docs/outputs-destinations-azure-storage-blob)

Tags

* [azure](/docs/en/tags/azure)
* [outputs](/docs/en/tags/outputs)

---

## Azure Event Hub

# Azure Event Hub
## Overview

This Adapter allows you to connect to an Azure Event Hub to fetch structured data stored there.

[Azure Event Hubs](https://azure.microsoft.com/en-us/products/event-hubs) are fully managed, real-time data ingestion services that allow for event streaming from various Microsoft Azure services. LimaCharlie can ingest either structured known data (such as JSON or XML) *or* known Microsoft data types, including:

* Azure Monitor (Platform: `azure_monitor`)
* Entra ID [formerly Azure AD] (Platform: `azure_ad`)
* Microsoft Defender (Platform: `msdefender`)

Documentation for creating an event hub can be found here [here](https://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-create).

## Deployment Configurations

All adapters support the same `client_options`, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.

* `client_options.identity.oid`: the LimaCharlie Organization ID (OID) this adapter is used with.
* `client_options.identity.installation_key`: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.
* `client_options.platform`: the type of data ingested through this adapter, like `text`, `json`, `gcp`, `carbon_black`, etc.
* `client_options.sensor_seed_key`: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.

### Adapter-specific Options

* If using a binary Adapter, `azure_event_hub` will be the ingestion type.
* `connection_string` - The connection string provided in Azure for connecting to the Azure Event Hub, including the `EntityPath=...` at the end which identifies the Hub Name (this component is sometimes now shown in the connection string provided by Azure).

## Guided Deployment

Azure Event Hub data can be pulled via either a cloud or binary Adapter.

### Cloud-to-Cloud

LimaCharlie offers several helpers within the webapp that allow you to ingest Microsoft data, such as Entra ID or Microsoft Defender, from Azure Event Hubs.

### CLI Deployment

The following example configures a binary Adapter to collect Microsoft Defender data from an Azure Event Hub:

```
./lc_adapter azure_event_hub client_options.identity.installation_key=<INSTALLATION_KEY> \
client_options.identity.oid=<OID> \
client_options.platform=msdefender \
client_options.sensor_seed_key=<SENSOR_SEED_KEY> \
client_options.hostname=<HOSTNAME> \
"connection_string=Endpoint=sb://mynamespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=fnaaaaaaaaaaaaaaak0g54alYbbbbbbbbbbbbbbbALQ=;EntityPath=lc-stream"
```

### Infrastructure as Code Deployment

```
# Azure Event Hub Specific Docs: https://docs.limacharlie.io/docs/adapter-types-azure-event-hub

sensor_type: "azure_event_hub"
  azure_event_hub:
    connection_string: "Endpoint=sb://your-eventhub-namespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=YOUR_EVENT_HUB_SHARED_ACCESS_K
  EY_HERE;EntityPath=your-actual-event-hub-name"
    client_options:
      identity:
        oid: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
        installation_key: "YOUR_LC_INSTALLATION_KEY_FOR_AZURE"
      hostname: "azure-eventhub-adapter"
      platform: "json"
      sensor_seed_key: "azure-eventhub-prod-sensor"
      indexing: []
```

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Command-line Interface

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

#### Related articles

* [Azure Network Security Group](/docs/azure-network-security-group)
* [Azure Storage Blob](/docs/outputs-destinations-azure-storage-blob)
* [Azure Monitor](/docs/azure-monitor)
* [Azure](/docs/ext-cloud-cli-azure)
* [Azure SQL Audit Logs](/docs/azure-sql-audit-logs)
* [Azure Kubernetes Service (AKS)](/docs/azure-kubernetes-service)
* [Azure Key Vault](/docs/azure-logs-key-vault)
* [Azure Event Hub](/docs/outputs-destinations-azure-event-hub)
* [Microsoft Defender](/docs/adapter-types-microsoft-defender)
* [Microsoft Entra ID](/docs/adapter-types-microsoft-entra-id)

---

##### What's Next

* [Canarytokens](/docs/adapter-types-canarytokens)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [Guided Deployment](#guided-deployment)

Tags

* [adapters](/docs/en/tags/adapters)
* [azure](/docs/en/tags/azure)
* [sensors](/docs/en/tags/sensors)

---

## Azure Logs

# Azure Logs
5 Articles  in this category

---

## Event Schemas

# Event Schemas
Since LimaCharlie standardizes on JSON, including arbitrary sources of data, it means that Schema in LimaCharlie is generally dynamic.

To enable users to create schemas in external systems that expect more strictly typed data, LimaCharlie makes a Schema API available.

This Schema API exposes the "learned" schema from specific event types. As data comes into LimaCharlie, the Schema API will accumulate the list of fields and types observed for those specific events. In turn, the API allows you to retrieve this learned schema.

## API

### Listing Schemas

The list of all available schemas can get retrieved by doing a `GET` to `api.limacharlie.io/v1/orgs/YOUR-OID/schema`.

The returned data looks like:

```json
{
  "event_types": [
    "evt:New-ExchangeAssistanceConfig",
    "det:00285-WIN-RDP_Connection_From_Non-RFC-1918_Address",
    "det:VirusTotal hit on DNS request",
    "evt:WEL",
    "evt:SHUTTING_DOWN",
    "evt:NETSTAT_REP",
    "evt:AdvancedHunting-DeviceEvents",
    "evt:NEW_DOCUMENT",
    "sched:12h_per_cloud_adapter",
    "sched:1h_per_sensor",
    "sched:3h_per_sensor",
    ...
}
```

Each element in the list of schema is composed of a prefix and a value.

Prefixes can be:

* `evt` for an Event.
* `dep` for a Deployment Event.
* `det` for a Detection.
* `art` for an Artifact Event.
* `sched` for Scheduling Events.

The value is generally the Event Type except for Detections where it is the `cat` (detection name).

### Retrieveing Schema Definition

Retrieving a specific schema definition can be done by doing a `GET` on `api.limacharlie.io/v1/orgs/YOUR-OID/schema/EVENT-TYPE`, where the `EVENT-TYPE` is one of the exact keys returned by the listing API above.

The returned data looks like:

```json
{
  "schema": {
    "elements": [
      "i:routing/event_time",
      "s:routing/sid",
      "i:routing/moduleid",
      "i:event/PROCESS_ID",
      "s:routing/this",
      "i:event/DNS_TYPE",
      "s:routing/iid",
      "s:routing/did",
      "i:event/DNS_FLAGS",
      "i:routing/tags",
      "s:event/IP_ADDRESS",
      "s:routing/event_type",
      "i:event/MESSAGE_ID",
      "s:event/CNAME",
      "s:event/DOMAIN_NAME",
      "s:routing/ext_ip",
      "s:routing/parent",
      "s:routing/hostname",
      "s:routing/int_ip",
      "i:routing/plat",
      "s:routing/oid",
      "i:routing/arch",
      "s:routing/event_id"
    ],
    "event_type": "evt:DNS_REQUEST"
  }
}
```

The `schema.elements` data returned is composed of a prefix and a value.

The prefix is one of:

* `i` indicating the element is an Integer.
* `s` indicating the element is a String.
* `b` indicating the element is a Boolean.

The value is a path within the JSON. For example, the schema above would represent the following event:

```json
{
  "event": {
    "CNAME": "cs9.wac.phicdn.net",
    "DNS_TYPE": 5,
    "DOMAIN_NAME": "ocsp.digicert.com",
    "MESSAGE_ID": 19099,
    "PROCESS_ID": 1224
  },
  "routing": {
    "arch": 2,
    "did": "b97e9d00-aaaa-aaaa-aaaa-27c3468d5901",
    "event_id": "8cec565d-14bd-4639-a1af-4fc8d5420b0c",
    "event_time": 1656959942437,
    "event_type": "DNS_REQUEST",
    "ext_ip": "35.1.1.1",
    "hostname": "demo-win-2016.c.lc-demo-infra.internal",
    "iid": "7d23bee6-aaaa-aaaa-aaaa-c8e8cca132a1",
    "int_ip": "10.1.1.1",
    "moduleid": 2,
    "oid": "8cbe27f4-aaaa-aaaa-aaaa-138cd51389cd",
    "parent": "42217cb0326ca254999554a862c3298e",
    "plat": 268435456,
    "sid": "bb4b30af-aaaa-aaaa-aaaa-f014ada33345",
    "tags": [
      "edr"
    ],
    "this": "a443f9c48bef700740ef27e062c333c6"
  }
}
```

---

#### Related articles

* [Platform Events Overview](/docs/platform-events-overview)
* [Endpoint Agent Events Overview](/docs/endpoint-agent-events-overview)

---

##### What's Next

* [Endpoint Agent Events Overview](/docs/endpoint-agent-events-overview)

Table of contents

+ [API](#api)

Tags

* [events](/docs/en/tags/events)
* [reference](/docs/en/tags/reference)

---

## Events

# Events
## Events Overview

LimaCharlie provides a multitude of events based on actions generated by sensors, systems, services, artifacts, and other key functions of the platform. The following pages provide details on structured events available in LimaCharlie. Note, this section only describes events generated by the LimaCharlie Endpoint Agent Sensor or the LimaCharlie platform. Events generated by third-party sources (i.e., ingested via an [Adapter](/v2/docs/adapters)) will be provided in their raw format, and can be addressed as such within [Detection & Response rules](/v2/docs/detection-and-response).

Missing events on a sensor timeline?

Not seeing an expected event in your timeline? Be sure that you included all events of interest in your [Exfil Control](/v2/docs/ext-exfil).

## Operationalizing Events

Events can be observed and matched by [Detection & Response rules](/v2/docs/detection-and-response) to automate behavior and can also be streamed via [Outputs](/v2/docs/outputs) to the destination of your choice.

## Schema

Specific Event schemas are learned and available through the Schema API, learn more [here](/v2/docs/event-schemas).

## Streams

There are 6 different event streams moving through LimaCharlie:

| Name | Description | D&R Target | Output |
| --- | --- | --- | --- |
| Events | Events sent from sensors | <default> | ✅ |
| Deployment | Lifecycle events sent from sensors | `deployment` | ✅ |
| Detections | Detections reported from D&R rules | `detection` | ✅ |
| Artifacts | Artifacts sent from sensors (or API) | `artifact` | ✅ |
| Artifact Events | Lifecycle events for artifacts | `artifact_event` | ✅ |
| Audit | Audit logs for management activity within LimaCharlie | `audit` | ✅ |
| Billing | Billing activity within LimaCharlie | `billing` | ✅ |

## Formatting

At a high level, events in LimaCharlie are in standard formatted JSON.

```json
{
  "type": "object",
  "properties": {
    "event": {
      "type": "any",
      "description": "Schema is determined by the routing/event_type"
    },
    "routing": {
      "type": "object",
      "properties": {
        "this": {
          "type": "string",
          "description": "GUID (i.e. 1e9e242a512d9a9b16d326ac30229e7b) - see 'Atoms' section for more detail",
          "format": "Atom"
        },
        "event_type": {
          "type": "string",
          "description": "The event type (e.g. NEW_PROCESS, NETWORK_SUMMARY) dictates the 'event' schema"
        },
        "event_time": {
          "type": "integer",
          "description": "The time the event was observed on the host"
        },
        "latency": {
          "type": "integer",
          "description": "The time difference between event time and event arrival, in milliseconds"
        },
        "event_id": {
          "type": "string",
          "format": "UUID"
        },
        "oid": {
          "type": "string",
          "format": "UUID",
          "description": "Organization ID"
        },
        "sid": {
          "type": ["string", "null"],
          "format": "UUID",
          "description": "Sensor ID"
        },
        "did": {
          "type": ["string", "null"],
          "format": "UUID",
          "description": "Device ID"
        },
        "iid": {
          "type": ["string", "null"],
          "format": "UUID",
          "description": "Installer Key ID"
        },
        "investigation_id": {
          "type": ["string", "null"],
          "format": "string",
          "description": "Events responding to a command will include this if it was provided along with the command"
        },
        "parent": {
          "type": ["string", "null"],
          "description": "Atom of possible parent event",
          "format": "Atom"
        },
        "target": {
          "type": ["string", "null"],
          "description": "Atom of possible target event",
          "format": "Atom"
        },
        "hostname": {
          "type": ["string", "null"],
        },
        "arch": {
          "type": ["integer", "null"],
          "description": "Integer corresponds with sensor architecture"
        },
        "plat": {
          "type": ["integer", "null"],
          "description": "Integer corresponds with sensor platform"
        },
        "tags": {
          "type": ["array"],
          "format": "string",
          "description": "Tags applied to sensor at the time the event was sent"
        },
      }
    }
  }
}
```

The following is a sample event utilizing the above schema:

```json
{
  "event": {
    "BASE_ADDRESS": 140702709383168,
    "COMMAND_LINE": "C:\\\\Windows\\\\System32\\\\evil.exe -Embedding",
    "FILE_IS_SIGNED": 1,
    "FILE_PATH": "C:\\\\Windows\\\\System32\\\\evil.exe",
    "HASH": "5ef1322b96f176c4ea4b8304caf8b45e2e42c3188aa52ed1fd6196afc04b7297",
    "MEMORY_USAGE": 9515008,
    "PARENT": {
      "BASE_ADDRESS": 140697905135616,
      "COMMAND_LINE": "C:\\\\Windows\\\\system32\\\\unknown.exe -k Launch",
      "CREATION_TIME": 1625797634428,
      "FILE_IS_SIGNED": 1,
      "FILE_PATH": "C:\\\\Windows\\\\system32\\\\unknown.exe",
      "HASH": "438b6ccd84f4dd32d9684ed7d58fd7d1e5a75fe3f3d14ab6c788e6bb0ffad5e7",
      "MEMORY_USAGE": 19070976,
      "PARENT_ATOM": "ebf1884039c7650401b2198f60f89d2d",
      "PARENT_PROCESS_ID": 123,
      "PROCESS_ID": 1234,
      "THIS_ATOM": "ad48d1f14a8e5a114e85f79b60f89d2d",
`      "THREADS": 14,
      "TIMESTAMP": 1626905901981,
      "USER_NAME": "NT AUTHORITY\\\\SYSTEM"
    },
    "PARENT_PROCESS_ID": 580,
    "PROCESS_ID": 5096,
    "THREADS": 6,
    "USER_NAME": "BUILTIN\\\\Administrators"
  },
  "routing": {
    "this": "655c970d2052b9f1c365839b611baf96",
    "parent": "ad48d1f14a3e5a114e85f79b60f89d2d",
    "arch": 2,
    "did": "3ef599f3-64dc-51f5-8322-62b0a6b8eef7",
    "event_id": "bdf6df69-b72c-470a-994b-216f1cdde9a7",
    "event_time": 1629204374140,
    "latency": 78,
    "event_type": "NEW_PROCESS",
    "ext_ip": "123.456.78.901",
    "hostname": "test-host-123",
    "iid": "e22638c9-44a6-455a-83e2-a689ac9868a7",
    "int_ip": "10.4.34.227",
    "moduleid": 2,
    "oid": "8cbe27f4-agh1-4afb-ba19-138cd51389cd",
    "plat": 268435456,
    "sid": "d3d17f12-eecf-5287-b3a1-bf267aabb3cf",
    "tags": ["server"],
  },
}
```

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

### Related articles

* [Event Schemas](/docs/event-schemas)
* [Reference: EDR Events](/docs/reference-edr-events)
* [Reference: Platform Events](/docs/reference-platform-events)
* [Platform Events Overview](/docs/platform-events-overview)
* [Reference: Schedule Events](/docs/reference-schedule-events)

---

#### What's Next

* [Event Schemas](/docs/event-schemas)

Table of contents

+ [Events Overview](#events-overview)
+ [Operationalizing Events](#operationalizing-events)
+ [Schema](#schema)
+ [Formatting](#formatting)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)
* [events](/docs/en/tags/events)
* [reference](/docs/en/tags/reference)

---

## Ingesting Defender Event Logs

# Ingesting Defender Event Logs
* 1 Minute to read

## Related articles

* [Ingesting Windows Event Logs](/docs/ingesting-windows-event-logs)
* [Artifacts](/docs/artifacts)
* [Ingesting Sysmon Event Logs](/docs/ingesting-sysmon-event-logs)
* [Microsoft Defender](/docs/adapter-types-microsoft-defender)

---

### What's Next

* [Test a New Sensor Version](/docs/test-a-new-sensor-version)

Tags

* [artifacts](/docs/en/tags/artifacts)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)
* [telemetry](/docs/en/tags/telemetry)
* [windows](/docs/en/tags/windows)

---

## Ingesting Sysmon Event Logs

# Ingesting Sysmon Event Logs
Sysmon can be a valuable addition to any defender's toolkit, given it's verbosity and generous log data. It's worth noting that LimaCharlie's native EDR capabilities mirror much of the same telemetry. However, Sysmon and LimaCharlie can be combined to provide granular coverage across Windows systems.

With Sysmon deployed, you can utilize LimaCharlie's native Windows Event Log (WEL) streaming capabilities to bring logs into the Sensor timeline.

1. Install [Sysmon](https://docs.microsoft.com/en-us/sysinternals/downloads/sysmon) on the endpoint.

   * This can easily be done via LimaCharlie's Payload functionality, with a  rule, or manually.
   * Please note that the LimaCharlie agent must be restarted in order for Sysmon data to show up in the timeline.
   * Example rule to deploy Sysmon via payloads on Windows systems tagged with `deploy-sysmon`:

     ```
     detect:
       events:
         - CONNECTED
       op: and
       rules:
         - op: is platform
           name: windows
         - op: is tagged
           tag: deploy-sysmon
     respond:
     - action: task
       command: put --payload-name sysmon.exe --payload-path "C:\Windows\Temp\sysmon.exe"
     - action: wait
       duration: 10s
     - action: task
       command: put --payload-name sysmon-config.xml --payload-path "C:\Windows\Temp\sysmon-config.xml"
     - action: wait
       duration: 10s
     - action: task
       command: run --shell-command "C:\Windows\Temp\sysmon.exe -accepteula -i C:\Windows\Temp\sysmon-config.xml"
     - action: wait
       duration: 10s
     - action: task
       command: file_del "C:\Windows\Temp\sysmon.exe"
     - action: task
       command: file_del "C:\Windows\Temp\sysmon-config.xml"
     - action: remove tag
       tag: deploy-sysmon
     - action: task
       command: restart
     ```
2. Within the Organization where you wish to collect Sysmon data, go to the `Event Collection > Event Collection Rules` section.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/ingest-sysmon-1.png)

3. Ensure that for Windows systems, `WEL` events are collected.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/ingest-sysmon-2.png)

4. Go to the `Artifact Collection` section and add a new collection rule with the following path to bring in all Sysmon events:

`wel://Microsoft-Windows-Sysmon/Operational:*`

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/ingest-sysmon-3.png)

**Note:** You can use tagging or other filters to narrow down the systems that logs are collected from.

Event Filtering

You can filter events by event ID to import select events. For example:

`wel://Microsoft-Windows-Sysmon/Operational:16`

`wel://Microsoft-Windows-Sysmon/Operational:25`

5. Allow up to 10 minutes for data to come into LimaCharlie after setting up a new Artifact Collection rule. Data will flow in real-time after that point.
6. Navigate to the Timeline view of a Sensor to confirm that Sysmon logs are present. You can search for Event Type `WEL` and Search for `Microsoft-Windows-Sysmon` to validate the telemetry.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%2896%29.png)

Endpoint Detection & Response

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

## Related articles

* [Sysmon Comparison](/docs/sysmon-comparison)
* [Ingesting Windows Event Logs](/docs/ingesting-windows-event-logs)

---

### What's Next

* [Ingesting Linux Audit Logs](/docs/ingesting-linux-audit-logs)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)
* [telemetry](/docs/en/tags/telemetry)
* [tutorial](/docs/en/tags/tutorial "Tutorial")
* [windows](/docs/en/tags/windows)

---

## Ingesting Windows Event Logs

# Ingesting Windows Event Logs
* 1 Minute to read

## Related articles

* [Windows Event Log](/docs/adapter-types-windows-event-log)
* [Windows Agent Installation](/docs/windows-agent-installation)
* [Windows Event Logs](/docs/adapter-examples-windows-event-logs)
* [EVTX](/docs/adapter-types-evtx)
* [Ingesting Sysmon Event Logs](/docs/ingesting-sysmon-event-logs)
* [Ingesting Defender Event Logs](/docs/ingesting-defender-event-logs)
* [Hayabusa](/docs/ext-hayabusa)

---

### What's Next

* [Ingesting MacOS Unified Logs](/docs/ingesting-macos-unified-logs)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)
* [telemetry](/docs/en/tags/telemetry)
* [tutorial](/docs/en/tags/tutorial "Tutorial")
* [windows](/docs/en/tags/windows)

---

## Platform Events Overview

# Platform Events Overview
* 1 Minute to read

## Related articles

* [Reference: Platform Events](/docs/reference-platform-events)
* [Platform Management](/docs/platform-management)

---

### What's Next

* [Reference: Platform Events](/docs/reference-platform-events)

Table of contents

+ [Overview](#overview)

Tags

* [events](/docs/en/tags/events)
* [platform](/docs/en/tags/platform)

---

## Reference: EDR Events

# Reference: EDR Events
## Overview

This page provides a detailed overview of all events generated by the LimaCharlie Endpoint Agent. Each event type represents a specific system activity, from process creation to network connections and file modifications. Events serve as key components in detection, response, and monitoring, enabling security teams to track, analyze, and take action on endpoint behavior. Use this guide to understand the purpose and structure of each event for effective threat detection and investigation.

Generally, event types ending with `*_REP` are emitted in response to a command being issued to the endpoint agent.

## EDR Events by Supported OS

These are the events emitted by the endpoint agent for each supported operating system. Below the table, you can find descriptions of each event type.

| EDR Event Type | macOS | Windows | Linux | Chrome | Edge |
| --- | --- | --- | --- | --- | --- |
| [AUTORUN\_CHANGE](/v2/docs/reference-edr-events#autorunchange) |  | ☑️ |  |  |  |
| [CLOUD\_NOTIFICATION](/v2/docs/reference-edr-events#cloudnotification) | ☑️ | ☑️ | ☑️ | ☑️ | ☑️ |
| [CODE\_IDENTITY](/v2/docs/reference-edr-events#codeidentity) | ☑️ | ☑️ | ☑️ |  |  |
| [CONNECTED](/v2/docs/reference-edr-events#connected) | ☑️ | ☑️ | ☑️ | ☑️ | ☑️ |
| [DATA\_DROPPED](/v2/docs/reference-edr-events#datadropped) | ☑️ | ☑️ | ☑️ |  |  |
| [DEBUG\_DATA\_REP](/v2/docs/reference-edr-events#getdebugdata) |  | ☑️ |  |  |  |
| [DELETED\_SENSOR](/v2/docs/reference-edr-events#deletedsensor) | ☑️ | ☑️ | ☑️ |  |  |
| [DIR\_FINDHASH\_REP](/v2/docs/reference-edr-events#dirfindhash) | ☑️ | ☑️ | ☑️ |  |  |
| [DIR\_LIST\_REP](/v2/docs/reference-edr-events#dirlist) | ☑️ | ☑️ | ☑️ |  |  |
| [DISCONNECTED](/v2/docs/reference-edr-events#disconnected) |  | ☑️ |  |  |  |
| [DNS\_REQUEST](/v2/docs/reference-edr-events#dnsrequest) | ☑️ | ☑️ | ☑️ | ☑️ | ☑️ |
| [DRIVER\_CHANGE](/v2/docs/reference-edr-events#driverchange) |  | ☑️ |  |  |  |
| [EXEC\_OOB](/v2/docs/reference-edr-events#execoob) | ☑️ |  | ☑️ |  |  |
| [EXISTING\_PROCESS](/v2/docs/reference-edr-events#existingprocess) | ☑️ | ☑️ | ☑️ |  |  |
| [EXPORT\_COMPLETE](/v2/docs/reference-edr-events#exportcomplete) | ☑️ | ☑️ | ☑️ |  |  |
| [FIM\_ADD](/v2/docs/reference-edr-events#fimadd) | ☑️ | ☑️ | ☑️ |  |  |
| [FIM\_DEL](/v2/docs/reference-edr-events#fimdel) | ☑️ | ☑️ | ☑️ |  |  |
| [FIM\_HIT](/v2/docs/reference-edr-events#fimhit) | ☑️ | ☑️ | ☑️ |  |  |
| [FILE\_CREATE](/v2/docs/reference-edr-events#filecreate) | ☑️ | ☑️ |  |  |  |
| [FILE\_DEL\_REP](/v2/docs/reference-edr-events#filedel) | ☑️ | ☑️ | ☑️ |  |  |
| [FILE\_DELETE](/v2/docs/reference-edr-events#filedelete) | ☑️ | ☑️ |  |  |  |
| [FILE\_GET\_REP](/v2/docs/reference-edr-events#fileget) | ☑️ | ☑️ | ☑️ |  |  |
| [FILE\_HASH\_REP](/v2/docs/reference-edr-events#filehash) | ☑️ | ☑️ | ☑️ |  |  |
| [FILE\_INFO\_REP](/v2/docs/reference-edr-events#fileinfo) | ☑️ | ☑️ | ☑️ |  |  |
| [FILE\_MODIFIED](/v2/docs/reference-edr-events#filemodified) | ☑️ | ☑️ |  |  |  |
| [FILE\_MOV\_REP](/v2/docs/reference-edr-events#filemov) | ☑️ | ☑️ | ☑️ |  |  |
| [FILE\_TYPE\_ACCESSED](/v2/docs/reference-edr-events#filetypeaccessed) | ☑️ | ☑️ |  |  |  |
| [GET\_DOCUMENT\_REP](/v2/docs/reference-edr-events#doccacheget) | ☑️ | ☑️ |  |  |  |
| [GET\_EXFIL\_EVENT\_REP](/v2/docs/reference-edr-events#exfilget) | ☑️ | ☑️ | ☑️ |  |  |
| [HIDDEN\_MODULE\_DETECTED](/v2/docs/reference-edr-events#hiddenmoduledetected) |  | ☑️ |  |  |  |
| [HISTORY\_DUMP\_REP](/v2/docs/reference-edr-events#historydump) | ☑️ | ☑️ | ☑️ |  |  |
| [HTTP\_REQUEST](/v2/docs/reference-edr-events#httprequest) |  |  |  | ☑️ | ☑️ |
| [HTTP\_REQUEST\_HEADERS](/v2/docs/reference-edr-events#httprequestheaders) |  |  |  | ☑️ |  |
| [HTTP\_RESPONSE\_HEADERS](/v2/docs/reference-edr-events#httpresponseheaders) |  |  |  | ☑️ |  |
| [INGEST](/v2/docs/reference-edr-events#ingest) | ☑️ | ☑️ | ☑️ |  |  |
| [LOG\_GET\_REP](/v2/docs/reference-edr-events#logget) |  |  |  |  |  |
| [LOG\_LIST\_REP](/v2/docs/reference-edr-events#loglist) |  |  |  |  |  |
| [MEM\_FIND\_HANDLES\_REP](/v2/docs/reference-edr-events#memfindhandle) |  | ☑️ |  |  |  |
| [MEM\_FIND\_STRING\_REP](/v2/docs/reference-edr-events#memfindstring) | ☑️ | ☑️ | ☑️ |  |  |
| [MEM\_HANDLES\_REP](/v2/docs/reference-edr-events#memhandles) |  | ☑️ |  |  |  |
| [MEM\_MAP\_REP](/v2/docs/reference-edr-events#memmap) | ☑️ | ☑️ | ☑️ |  |  |
| [MEM\_READ\_REP](/v2/docs/reference-edr-events#memread) | ☑️ | ☑️ | ☑️ |  |  |
| [MEM\_STRINGS\_REP](/v2/docs/reference-edr-events#memstrings) | ☑️ | ☑️ | ☑️ |  |  |
| [MODULE\_LOAD](/v2/docs/reference-edr-events#moduleload) |  | ☑️ | ☑️ |  |  |
| [MODULE\_MEM\_DISK\_MISMATCH](/v2/docs/reference-edr-events#modulememdiskmismatch) | ☑️ | ☑️ | ☑️ |  |  |
| [NETSTAT\_REP](/v2/docs/reference-edr-events#netstat) | ☑️ | ☑️ | ☑️ |  |  |
| [NETWORK\_CONNECTIONS](/v2/docs/reference-edr-events#networkconnections) | ☑️ | ☑️ | ☑️ |  |  |
| [NETWORK\_SUMMARY](/v2/docs/reference-edr-events#networksummary) | ☑️ | ☑️ | ☑️ |  |  |
| [NEW\_DOCUMENT](/v2/docs/reference-edr-events#newdocument) | ☑️ | ☑️ |  |  |  |
| [NEW\_NAMED\_PIPE](/v2/docs/reference-edr-events#newnamedpipe) |  | ☑️ |  |  |  |
| [NEW\_PROCESS](/v2/docs/reference-edr-events#newprocess) | ☑️ | ☑️ | ☑️ |  |  |
| [NEW\_REMOTE\_THREAD](/v2/docs/reference-edr-events#newremotethread) |  | ☑️ |  |  |  |
| [NEW\_TCP4\_CONNECTION](/v2/docs/reference-edr-events#newtcp4connection) | ☑️ | ☑️ | ☑️ |  |  |
| [NEW\_TCP6\_CONNECTION](/v2/docs/reference-edr-events#newtcp6connection) | ☑️ | ☑️ | ☑️ |  |  |
| [NEW\_UDP4\_CONNECTION](/v2/docs/reference-edr-events#newudp4connection) | ☑️ | ☑️ | ☑️ |  |  |
| [NEW\_UDP6\_CONNECTION](/v2/docs/reference-edr-events#newudp6connection) | ☑️ | ☑️ | ☑️ |  |  |
| [OPEN\_NAMED\_PIPE](/v2/docs/reference-edr-events#opennamedpipe) |  | ☑️ |  |  |  |
| [OS\_AUTORUNS\_REP](/v2/docs/reference-edr-events#osautoruns) | ☑️ | ☑️ |  |  |  |
| [OS\_DRIVERS\_REP](/v2/docs/reference-edr-events#osdrivers) |  | ☑️ |  |  |  |
| [OS\_KILL\_PROCESS\_REP](/v2/docs/reference-edr-events#oskillprocess) | ☑️ | ☑️ | ☑️ |  |  |
| [OS\_PACKAGES\_REP](/v2/docs/reference-edr-events#ospackages) |  | ☑️ |  |  |  |
| [OS\_PROCESSES\_REP](/v2/docs/reference-edr-events#osprocesses) | ☑️ | ☑️ | ☑️ |  |  |
| [OS\_RESUME\_REP](/v2/docs/reference-edr-events#osresume) | ☑️ | ☑️ | ☑️ |  |  |
| [OS\_SERVICES\_REP](/v2/docs/reference-edr-events#osservices) | ☑️ | ☑️ | ☑️ |  |  |
| [OS\_SUSPEND\_REP](/v2/docs/reference-edr-events#ossuspend) | ☑️ | ☑️ | ☑️ |  |  |
| [OS\_USERS\_REP](/v2/docs/reference-edr-events#osusers) |  | ☑️ |  |  |  |
| [OS\_VERSION\_REP](/v2/docs/reference-edr-events#osversion) | ☑️ | ☑️ | ☑️ |  |  |
| [PCAP\_LIST\_INTERFACES\_REP](/v2/docs/reference-edr-events#pcapifaces) |  |  | ☑️ |  |  |
| [PROCESS\_ENVIRONMENT](/v2/docs/reference-edr-events#processenvironment) |  | ☑️ | ☑️ |  |  |
| [RECEIPT](/v2/docs/reference-edr-events#receipt) | ☑️ | ☑️ | ☑️ | ☑️ |  |
| [REGISTRY\_CREATE](/v2/docs/reference-edr-events#registrycreate) |  | ☑️ |  |  |  |
| [REGISTRY\_DELETE](/v2/docs/reference-edr-events#registrydelete) |  | ☑️ |  |  |  |
| [REGISTRY\_LIST\_REP](/v2/docs/reference-edr-events#reglist) |  | ☑️ |  |  |  |
| [REGISTRY\_WRITE](/v2/docs/reference-edr-events#registrywrite) |  | ☑️ |  |  |  |
| [REJOIN\_NETWORK](/v2/docs/reference-edr-events#rejoinnetwork) | ☑️ | ☑️ | ☑️ | ☑️ |  |
| [REMOTE\_PROCESS\_HANDLE](/v2/docs/reference-edr-events#remoteprocesshandle) |  | ☑️ |  |  |  |
| [SEGREGATE\_NETWORK](/v2/docs/reference-edr-events#segregatenetwork) | ☑️ | ☑️ | ☑️ | ☑️ |  |
| [SENSITIVE\_PROCESS\_ACCESS](/v2/docs/reference-edr-events#sensitiveprocessaccess) |  | ☑️ |  |  |  |
| [SERVICE\_CHANGE](/v2/docs/reference-edr-events#servicechange) | ☑️ | ☑️ | ☑️ |  |  |
| [SHUTTING\_DOWN](/v2/docs/reference-edr-events#shuttingdown) | ☑️ | ☑️ | ☑️ |  |  |
| [SSH\_LOGIN](/v2/docs/reference-edr-events#sshlogin) | ☑️ |  |  |  |  |
| [SSH\_LOGOUT](/v2/docs/reference-edr-events#sshlogout) | ☑️ |  |  |  |  |
| [STARTING\_UP](/v2/docs/reference-edr-events#startingup) | ☑️ | ☑️ | ☑️ |  |  |
| [TERMINATE\_PROCESS](/v2/docs/reference-edr-events#terminateprocess) | ☑️ | ☑️ | ☑️ |  |  |
| [TERMINATE\_TCP4\_CONNECTION](/v2/docs/reference-edr-events#terminatetcp4connection) | ☑️ | ☑️ | ☑️ |  |  |
| [TERMINATE\_TCP6\_CONNECTION](/v2/docs/reference-edr-events#terminatetcp6connection) | ☑️ | ☑️ | ☑️ |  |  |
| [TERMINATE\_UDP4\_CONNECTION](/v2/docs/reference-edr-events#terminateudp4connection) | ☑️ | ☑️ | ☑️ |  |  |
| [TERMINATE\_UDP6\_CONNECTION](/v2/docs/reference-edr-events#terminateudp6connection) | ☑️ | ☑️ | ☑️ |  |  |
| [THREAD\_INJECTION](/v2/docs/reference-edr-events#threadinjection) |  | ☑️ |  |  |  |
| [USER\_LOGIN](/v2/docs/reference-edr-events#userlogin) | ☑️ |  |  |  |  |
| [USER\_LOGOUT](/v2/docs/reference-edr-events#userlogout) | ☑️ |  |  |  |  |
| [USER\_OBSERVED](/v2/docs/reference-edr-events#userobserved) | ☑️ | ☑️ | ☑️ |  |  |
| [VOLUME\_MOUNT](/v2/docs/reference-edr-events#volumemount) | ☑️ | ☑️ |  |  |  |
| [VOLUME\_UNMOUNT](/v2/docs/reference-edr-events#volumeunmount) | ☑️ | ☑️ |  |  |  |
| [WEL](/v2/docs/reference-edr-events#wel) |  | ☑️ |  |  |  |
| [YARA\_DETECTION](/v2/docs/reference-edr-events#yaradetection) | ☑️ | ☑️ | ☑️ |  |  |

---

## Event Descriptions

### AUTORUN\_CHANGE

Generated when an Autorun is changed.

**Platforms:**

```json
{
  "REGISTRY_KEY": "HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\Run",
  "TIMESTAMP": 1627497894000
}
```

---

### CLOUD\_NOTIFICATION

This event is a receipt from the agent that it has received the task sent to it, and includes high-level errors (if any).

**Platforms:**

```json
{
  "NOTIFICATION_ID": "ADD_EXFIL_EVENT_REQ",
  "NOTIFICATION": {
    "INVESTIGATION_ID": "digger-4afdeb2b-a0d8-4a37-83b5-48996117998e"
  },
  "HCP_IDENT": {
    "HCP_ORG_ID": "c82e5c17d5194ef5a4acc454a95d31db",
    "HCP_SENSOR_ID": "8fc370e6699a49858e75c1316b725570",
    "HCP_INSTALLER_ID": "00000000000000000000000000000000",
    "HCP_ARCHITECTURE": 0,
    "HCP_PLATFORM": 0
  },
  "EXPIRY": 0
}
```

---

### CODE\_IDENTITY

Unique combinations of file hash and file path. This event is emitted the first time the combination is seen, typically when the binary is executed or loaded. Therefore it's a great event to look for hashes without being overwhelmed by process execution or module loads.

ONGOING\_IDENTITY

The `ONGOING_IDENTITY` event emits code signature information even if not newly seen, however this data can become duplicative and verbose.

**Platforms:**

```json
{
  "MEMORY_SIZE": 0,
  "FILE_PATH": "C:\\Users\\dev\\AppData\\Local\\Temp\\B1B207E5-300E-434F-B4FE-A4816E6551BE\\dismhost.exe",
  "TIMESTAMP": 1456285265,
  "SIGNATURE": {
    "CERT_ISSUER": "C=US, S=Washington, L=Redmond, O=Microsoft Corporation, CN=Microsoft Code Signing PCA",
    "CERT_CHAIN_STATUS": 124,
    "FILE_PATH": "C:\\Users\\dev\\AppData\\Local\\Temp\\B1B207E5-300E-434F-B4FE-A4816E6551BE\\dismhost.exe",
    "CERT_SUBJECT": "C=US, S=Washington, L=Redmond, O=Microsoft Corporation, OU=MOPR, CN=Microsoft Corporation"
  },
  "HASH": "4ab4024eb555b2e4c54d378a846a847bd02f66ac54849bbce5a1c8b787f1d26c"
}
```

---

### CONNECTED

This event is generated when a Sensor connects to the cloud.

**Platforms:**

```json
{
    "HOST_NAME" : "demo-win-2016",
    "IS_SEGREGATED" : 0,
    "KERNEL_ACQ_AVAILABLE" : 1,
    "MAC_ADDRESS" : "42-01-0A-80-00-02"
}
```

---

### DEBUG\_DATA\_REP

Response from a `get_debug_data` request.

**Platforms:**

### DIR\_FINDHASH\_REP

Response event for the `dir_find_hash` sensor command.

**Platforms:**

**Sample Event:**

```json
{
    "DIRECTORY_LIST": [
        {
            "HASH": "f11dda931637a1a1bc614fc2f320326b24336c5155679aa062acae7c79f33d67",
            "ACCESS_TIME": 1535994794247,
            "FILE_SIZE": 113664,
            "CREATION_TIME": 1467173189067,
            "MODIFICATION_TIME": 1467173190171,
            "FILE_NAME": "MALWARE_DEMO_WINDOWS_1.exe",
            "ATTRIBUTES": 32,
            "FILE_PATH": "c:\\users\\dev\\desktop\\MALWARE_DEMO_WINDOWS_1.exe"
        },
        {
            "HASH": "e37726feee8e72f3ab006e023cb9d6fa1a4087274b47217d2462325fa8008515",
            "ACCESS_TIME": 1535989041078,
            "FILE_SIZE": 1016320,
            "CREATION_TIME": 1522507344821,
            "MODIFICATION_TIME": 1522507355732,
            "FILE_NAME": "lc_win_64.exe",
            "ATTRIBUTES": 32,
            "FILE_PATH": "c:\\users\\dev\\desktop\\lc_win_64.exe"
        }
    ],
    "HASH": [
        "f11dda931637a1a1bc614fc2f320326b24336c5155679aa062acae7c79f33d67",
        "e37726feee8e72f3ab006e023cb9d6fa1a4087274b47217d2462325fa8008515"
    ],
    "FILE_PATH": "*.exe",
    "DIRECTORY_LIST_DEPTH": 0,
    "DIRECTORY_PATH": "c:\\users\\dev\\desktop\\"
}
```

### DIR\_LIST\_REP

Response event for the `dir_list` sensor command. Includes Alternate Data Streams on Windows.

**Platforms:**

**Sample Event:**

```json
{
    "DIRECTORY_LIST": [
        {
            "FILE_NAME": "vssdk_full.exe",
            "CREATION_TIME": 1553437930012,
            "MODIFICATION_TIME": 1553437937000,
            "STREAMS": [
                {
                    "FILE_NAME": "::$DATA",
                    "SIZE": 13782032
                }
            ],
            "ACCESS_TIME": 1567868284440,
            "FILE_SIZE": 13782032,
            "ATTRIBUTES": 32,
            "FILE_PATH": "c:\\users\\dev\\desktop\\vssdk_full.exe"
        },
        {
            "FILE_NAME": "UniversalLog.txt",
            "CREATION_TIME": 1553028205525,
            "MODIFICATION_TIME": 1553028206289,
            "STREAMS": [
                {
                    "FILE_NAME": "::$DATA",
                    "SIZE": 125
                },
                {
                    "FILE_NAME": ":Zone.Identifier:$DATA",
                    "SIZE": 377
                }
            ],
            "ACCESS_TIME": 1567868284158,
            "FILE_SIZE": 125,
            "ATTRIBUTES": 32,
            "FILE_PATH": "c:\\users\\dev\\desktop\\UniversalLog.txt"
        }
    ]
}
```

---

### DISCONNECTED

This event is generated when a Sensor disconnects from the cloud.

**Platforms:**

```json
{
  "DISCONNECTED": {},
  "ts": 1455674775
}
```

---

### DNS\_REQUEST

Generated from DNS responses and therefore includes both the requested domain and the response from the server. If the server responds with multiple responses (as allowed by the DNS protocol) the N answers will become N DNS\_REQUEST events, so you can always assume one DNS\_REQUEST event means one answer.

**Platforms:**

```json
{
  "DNS_TYPE": 1,
  "TIMESTAMP": 1456285240,
  "DNS_FLAGS": 0,
  "DOMAIN_NAME": "time.windows.com"
}
```

---

### DRIVER\_CHANGE

Generated when a driver is changed.

**Platforms:**

```json
{
  "PROCESS_ID": 0,
  "SVC_DISPLAY_NAME": "HbsAcq",
  "SVC_NAME": "HbsAcq",
  "SVC_STATE": 1,
  "SVC_TYPE": 1,
  "TIMESTAMP": 1517377895873
}
```

---

### EXISTING\_PROCESS

This event is similar to the NEW\_PROCESS event.  It gets emitted when a process existed prior to the LimaCharlie sensor loading.

**Platforms:**

---

### FILE\_CREATE

Generated when a file is created.

**Platforms:**

```json
{
  "FILE_PATH": "C:\\Users\\dev\\AppData\\Local\\Microsoft\\Windows\\WebCache\\V01tmp.log",
  "TIMESTAMP": 1468335271948
}
```

---

### FILE\_DEL\_REP

Response event for the `file_del` sensor command.

**Platforms:**

**Sample Event:**

```json
{
  "FILE_PATH": "C:\\test\\test.txt"
}
```

---

### FILE\_DELETE

Generated when a file is deleted.

> Be Aware:
>
> When adding this event to an event collection rule, you will be monitoring system-wide. This could result in a large number of events.

> Best Practices:
>
> * Utilize this selectively (ex. deploy on only suspect systems)
> * Use Exfil watch rules to specify paths that are of high interest
> * Consider using File Integrity Monitoring (FIM)
> * Look for this on an ad-hoc basis from the Sensor Console. ex.
>
>   ```
>   history_dump -e FILE_DELETE
>   ```

**Platforms:**

```json
{
  "FILE_PATH": "C:\\Users\\dev\\AppData\\Local\\Temp\\EBA4E4F0-3020-459E-9E34-D5336E244F05\\api-ms-win-core-processthreads-l1-1-2.dll",
  "TIMESTAMP": 1468335611906
}
```

---

### FILE\_GET\_REP

Response event for the `file_get` sensor command.

**Platforms:**

**Sample Event:**

```json
{
  "FILE_CONTENT": "$BASE64_ENCODED_FILE_CONTENTS",
  "FILE_PATH": "C:\\windows\\system32\\svchost.exe",
  "FILE_SIZE": 78880
}
```

### FILE\_HASH\_REP

Response event for the `file_hash` sensor command.

**Platforms:**

**Sample Event:**

```json
{
  "FILE_IS_SIGNED": 1,
  "FILE_PATH": "C:\\Windows\\System32\\svchost.exe",
  "HASH": "31780ff2aaf7bc71f755ba0e4fef1d61b060d1d2741eafb33cbab44d889595a0",
  "SIGNATURE": {
    "CERT_ISSUER": "C=US, S=Washington, L=Redmond, O=Microsoft Corporation, CN=Microsoft Windows Production PCA 2011",
    "CERT_SUBJECT": "C=US, S=Washington, L=Redmond, O=Microsoft Corporation, CN=Microsoft Windows Publisher",
    "FILE_CERT_IS_VERIFIED_LOCAL": 1,
    "FILE_IS_SIGNED": 1,
    "FILE_PATH": "C:\\Windows\\System32\\svchost.exe"
  }
}
```

### FILE\_INFO\_REP

Response event for the `file_info` sensor command.

**Platforms:**

**Sample Event:**

```json
{
  "ACCESS_TIME": 1686685723546,
  "ATTRIBUTES": 0,
  "CREATION_TIME": 1686685723546,
  "FILE_IS_SIGNED": 1,
  "FILE_PATH": "C:\\Windows\\System32\\svchost.exe",
  "FILE_SIZE": 78880,
  "MODIFICATION_TIME": 1686685723546
}
```

---

### FILE\_MODIFIED

Generated when a file is modified.

> Be Aware:
>
> When adding this event to an event collection rule, you will be monitoring system-wide. This could result in a large number of events.

> Best Practices:
>
> * Utilize this selectively (ex. deploy on only suspect systems)
> * Use Exfil watch rules to specify paths that are of high interest
> * Consider using File Integrity Monitoring (FIM)
> * Look for this on an ad-hoc basis from the Sensor Console. ex.
>
>   ```
>   history_dump -e FILE_MODIFIED
>   ```

**Platforms:**

```json
{
  "FILE_PATH": "C:\\Users\\dev\\AppData\\Local\\Microsoft\\Windows\\WebCache\\V01.log",
  "TIMESTAMP": 1468335272949
}
```

---

### FILE\_MOV\_REP

Response event for the `file_mov` sensor command.

**Platforms:**

**Sample Event:**

```json
{
  "DESTINATION": "C:\\test\\test.txt.bak",
  "SOURCE": "C:\\test\\test.txt"
}
```

---

### FILE\_TYPE\_ACCESSED

Generated when a new process is observed interacting with certain file types.

The `RULE_NAME` component is the class of file extension involved:

* Rule 1: `.doc`, `.docm`, `.docx`
* Rule 2: `.xlt`, `.xlsm`, `.xlsx`
* Rule 3: `.ppt`, `.pptm`, `.pptx`, `.ppts`
* Rule 4: `.pdf`
* Rule 5: `.rtf`
* Rule 50: `.zip`
* Rule 51: `.rar`
* Rule 64: `.locky`, `.aesir`

**Platforms:**

```json
{
  "PROCESS_ID": 2048,
  "RULE_NAME": 50,
  "FILE_PATH": "C:\\Program Files\\7-Zip\\7zG.exe"
}
```

---

### FIM\_ADD

Response event for the `fim_add` sensor command. An `ERROR: 0` implies the path was successfully added.

**Platforms:**

**Output:**

```
"event": {
  "ERROR":0
}
```

### FIM\_DEL

Response event for the `fim_del` sensor command. An `ERROR: 0` implies the path was successfully removed.

An `ERROR: 3` response implies the provided path was not found in the list of FIM patterns.

**Platforms:**

**Output:**

```
"event": {
  "ERROR":0
}
```

---

### FIM\_HIT

A file, directory, or registry key being monitored by File & Registry Integrity Monitoring has been modified.

**Platforms:**

```json
{
  "PROCESS": {
    "MEMORY_USAGE": 25808896,
    "TIMESTAMP": 1541348299886,
    "COMMAND_LINE": "\"C:\\WINDOWS\\regedit.exe\" ",
    "PROCESS_ID": 4340,
    "THREADS": 3,
    "USER_NAME": "BUILTIN\\Administrators",
    "FILE_PATH": "C:\\WINDOWS\\regedit.exe",
    "PARENT_PROCESS_ID": 6260
  },
  "REGISTRY_KEY": "\\REGISTRY\\MACHINE\\SOFTWARE\\ActiveState\\New Value #1",
  "PROCESS_ID": 4340
}
```

---

### FIM\_LIST\_REP

Response event for the `fim_get` sensor command. The response will be a JSON list of FIM patterns.

**Platforms:**

**Output:**

```json
{
  "PATTERNS": [
    0: "/home/*",
    1: "/home/*/.ssh/*",
    2: "/root/.ssh/authorized_keys"
  ]
}
```

---

### GET\_DOCUMENT\_REP

Generated when a `doc_cache_get` task requests a cached document.

**Platforms:**

### GET\_EXFIL\_EVENT\_REP

Response from an `exfil_get` sensor command.

**Platforms:**

### HIDDEN\_MODULE\_DETECTED

Generated when a `hidden_module_scan` command is issued.

Note that the name of the event does not confirm the presence of a hidden module. Please check the output to

confirm whether a hidden module was detected.

**Platforms:**

**Sample Event:**

```json
{
  "ERROR": 0,
  "ERROR_MESSAGE": "done"
}
```

### HISTORY\_DUMP\_REP

Response from `history_dump` sensor command. Does not itself contain the historic events but will be generated along them.

**Platforms:**

---

### HTTP\_REQUEST

This event is emitted whenever an HTTP request is made.

**Platforms:**

**Sample Event:**

```json
{
  "URL": "https://play.google.com/log?authuser=0",
  "IP_ADDRESS": "172.217.2.142",
  "RESULT": 200,
  "PARENT": {
    "URL": "https://console.cloud.google.com"
  }
}
```

---

### HTTP\_REQUEST\_HEADERS

Provides HTTP Request headers.

**Platforms:**

**Sample Event:**

```json
{
  "HEADERS": [
    {
      "NAME": "User-Agent",
      "VALUE": "Mozilla/5.0 (X11; CrOS x86_64 14541.0.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
    },
    {
      "NAME": "Accept",
      "VALUE": "*/*"
    }
  ]
}
```

---

### HTTP\_RESPONSE\_HEADERS

Provides HTTP Response headers.

**Platforms:**

**Sample Event:**

```json
{
  "HEADERS": [
    {
      "NAME": "content-length",
      "VALUE": "859"
    },
    {
      "NAME": "cache-control",
      "VALUE": "max-age=3600"
    },
    {
      "NAME": "content-encoding",
      "VALUE": "br"
    },
    {
      "NAME": "content-type",
      "VALUE": "text/html; charset=utf-8"
    },
    {
      "NAME": "etag",
      "VALUE": "\"1540d7725dd15680377d45886baba56f620f7692faa530bc3597226ffadd77d1-br\""
    },
    {
      "NAME": "last-modified",
      "VALUE": "Thu, 21 Dec 2023 23:59:32 GMT"
    },
    {
      "NAME": "referrer-policy",
      "VALUE": "sameorigin"
    },
    {
      "NAME": "strict-transport-security",
      "VALUE": "max-age=3600 ; includeSubDomains"
    },
    {
      "NAME": "x-content-type-options",
      "VALUE": "nosniff"
    },
    {
      "NAME": "x-frame-options",
      "VALUE": "sameorigin"
    },
    {
      "NAME": "accept-ranges",
      "VALUE": "bytes"
    },
    {
      "NAME": "date",
      "VALUE": "Fri, 22 Dec 2023 19:10:58 GMT"
    },
    {
      "NAME": "x-served-by",
      "VALUE": "cache-dub4332-DUB"
    },
    {
      "NAME": "x-cache",
      "VALUE": "HIT"
    },
    {
      "NAME": "x-cache-hits",
      "VALUE": "1"
    },
    {
      "NAME": "x-timer",
      "VALUE": "S1703272259.579745,VS0,VE1"
    },
    {
      "NAME": "vary",
      "VALUE": "x-fh-requested-host, accept-encoding"
    },
    {
      "NAME": "alt-svc",
      "VALUE": "h3=\":443\";ma=86400,h3-29=\":443\";ma=86400,h3-27=\":443\";ma=86400"
    }
  ]
}
```

---

### LOG\_GET\_REP

Response from a `log_get` request.

### LOG\_LIST\_REP

Response from a `log_list` request.

### MEM\_FIND\_HANDLES\_REP

Response event for the `mem_find_handle` sensor command.

**Platforms:**

### MEM\_FIND\_STRING\_REP

Response event for the `mem_find_string` sensor command.

**Platforms:**

### MEM\_HANDLES\_REP

Response event for the `mem_handles` sensor command. This event will contain an array of handles identified in memory.

**Platforms:**

**Sample Event:**

```json
{
    "HANDLES": [
      {
        "HANDLE_NAME": "\\REGISTRY\\MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options",
        "HANDLE_TYPE": "Key",
        "HANDLE_VALUE": 4,
        "PROCESS_ID": 908
      },
      {
        "HANDLE_NAME": "\\KnownDlls",
        "HANDLE_TYPE": "Directory",
        "HANDLE_VALUE": 48,
        "PROCESS_ID": 908
      },
      "..."]
}
```

### MEM\_MAP\_REP

Response event for the `mem_map` sensor command. This event will contain an array of arrays, representing processes and their associated memory data.

**Platforms:**

Sample Event:

```json
{
    "MEMORY_MAP": [
      {
        "BASE_ADDRESS": 94100802174976,
        "MEMORY_ACCESS": 6,
        "MEMORY_SIZE": 4096,
        "MEMORY_TYPE": 3
      }
    ]
}
```

### MEM\_READ\_REP

Response event for the `mem_read` sensor command.

**Platforms:**

**Sample Event:**

```json
{
  "MEMORY_DUMP": "TGltYU...",
  "PROCESS_ID": 745
}
```

### MEM\_STRINGS\_REP

Response event for the `mem_strings` sensor command. The response will contain two arrays of arrays, `STRINGSA` and `STRINGSW`.

**Platforms:**

**Sample Event:**

```json
{
    "PROCESS_ID" : 745,
    "STRINGSA" : [
        [
            0 : "/lib64/ld-linux-x86-64.so.2",
            1 : "__gmon_start__"
        ]
    ]
}
```

---

### MODULE\_LOAD

Generated when a module (like DLL on Windows) is loaded in a process.

**Platforms:**

```json
{
  "MEMORY_SIZE": 241664,
  "PROCESS_ID": 2904,
  "FILE_PATH": "C:\\Windows\\System32\\imm32.dll",
  "MODULE_NAME": "imm32.dll",
  "TIMESTAMP": 1468335264989,
  "BASE_ADDRESS": 140715814092800
}
```

---

### NETSTAT\_REP

Response from a  `netstat` command to list active network sockets.

**Platforms:**

**Sample Event:**

```json
{
  "FRIENDLY": 0,
  "NETWORK_ACTIVITY": [
    {
      "DESTINATION": {
        "IP_ADDRESS": "0.0.0.0",
        "PORT": 0
      },
      "PROCESS_ID": 856,
      "PROTOCOL": "tcp4",
      "SOURCE": {
        "IP_ADDRESS": "0.0.0.0",
        "PORT": 135
      }
    }
  ]
}
```

---

### NETWORK\_CONNECTIONS

List of recent network connections performed by a process.

**Platforms:**

```json
{
  "NETWORK_ACTIVITY": [
    {
      "SOURCE": {
        "IP_ADDRESS": "172.16.223.138",
        "PORT": 50396
      },
      "IS_OUTGOING": 1,
      "DESTINATION": {
        "IP_ADDRESS": "23.214.49.56",
        "PORT": 80
      }
    },
    {
      "SOURCE": {
        "IP_ADDRESS": "172.16.223.138",
        "PORT": 50397
      },
      "IS_OUTGOING": 1,
      "DESTINATION": {
        "IP_ADDRESS": "189.247.166.18",
        "PORT": 80
      }
    },
    {
      "SOURCE": {
        "IP_ADDRESS": "172.16.223.138",
        "PORT": 50398
      },
      "IS_OUTGOING": 1,
      "DESTINATION": {
        "IP_ADDRESS": "23.217.70.67",
        "PORT": 80
      }
    },
    {
      "SOURCE": {
        "IP_ADDRESS": "172.16.223.138",
        "PORT": 50399
      },
      "IS_OUTGOING": 1,
      "DESTINATION": {
        "IP_ADDRESS": "104.110.238.53",
        "PORT": 80
      }
    },
    {
      "SOURCE": {
        "IP_ADDRESS": "172.16.223.138",
        "PORT": 50400
      },
      "IS_OUTGOING": 1,
      "DESTINATION": {
        "IP_ADDRESS": "23.214.49.56",
        "PORT": 80
      }
    },
    {
      "SOURCE": {
        "IP_ADDRESS": "172.16.223.138",
        "PORT": 50401
      },
      "IS_OUTGOING": 1,
      "DESTINATION": {
        "IP_ADDRESS": "204.79.197.203",
        "PORT": 80
      }
    }
  ],
  "HASH": "2de228cad2e542b2af2554d61fab5463ecbba3ff8349ba88c3e48637ed8086e9",
  "COMMAND_LINE": "C:\\WINDOWS\\system32\\msfeedssync.exe sync",
  "PROCESS_ID": 6968,
  "FILE_IS_SIGNED": 1,
  "USER_NAME": "WIN-5KC7E0NG1OD\\dev",
  "FILE_PATH": "C:\\WINDOWS\\system32\\msfeedssync.exe",
  "PARENT_PROCESS_ID": 1892
}
```

---

### NEW\_DOCUMENT

Generated when a file is created that matches a set list of locations and extensions. It indicates the file has been cached in memory and can be retrieved using the `doc_cache_get` task.

The following file patterns are considered "documents":

* `.bat`
* `.js`
* `.ps1`
* `.sh`
* `.py`
* `.exe`
* `.scr`
* `.pdf`
* `.doc`
* `.docm`
* `.docx`
* `.ppt`
* `.pptm`
* `.pptx`
* `.xlt`
* `.xlsm`
* `.xlsx`
* `.vbs`
* `.rtf`
* `.hta`
* `.lnk`
* `.xsl`
* `.com`
* `.png`
* `.jpg`
* `.asp`
* `.aspx`
* `.php`
* `\windows\system32\`

**Platforms:**

```json
{
  "FILE_PATH": "C:\\Users\\dev\\Desktop\\evil.exe",
  "TIMESTAMP": 1468335816308,
  "HASH": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
}
```

---

### NEW\_NAMED\_PIPE

This event is emitted when a new Named Pipe is created by a process.

**Platforms:**

```json
{
  "FILE_PATH": "\\Device\\NamedPipe\\LOCAL\\mojo.6380.1072.2134013463507075011",
  "PROCESS_ID": 6380
}
```

---

### NEW\_PROCESS

Generated when a new process starts.

**Platforms:**

```json
{
  "PARENT": {
    "PARENT_PROCESS_ID": 7076,
    "COMMAND_LINE": "\"C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\Common7\\IDE\\devenv.exe\"  ",
    "MEMORY_USAGE": 438730752,
    "PROCESS_ID": 5820,
    "THREADS": 39,
    "FILE_PATH": "C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\Common7\\IDE\\devenv.exe",
    "BASE_ADDRESS": 798949376
  },
  "PARENT_PROCESS_ID": 5820,
  "COMMAND_LINE": "-q  -s {0257E42D-7F05-42C4-B402-34C1CC2F2EAD} -p 5820",
  "FILE_PATH": "C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\vcpackages\\VCPkgSrv.exe",
  "PROCESS_ID": 1080,
  "THREADS": 9,
  "MEMORY_USAGE": 8282112,
  "TIMESTAMP": 1456285660,
  "BASE_ADDRESS": 4194304
}
```

---

### NEW\_REMOTE\_THREAD

Generated when a thread is created by a process in another process. This is often used by malware during various forms of code injection.

In this case, the process id `492` created a thread (with id `9012`) in the process id `7944`. The parent process is also globally uniquely identified by the `routing/parent` and the process where the thread was started is globally uniquely identified by the `routing/target` (not visible here).

**Platforms:**

```json
{
  "THREAD_ID": 9012,
  "PROCESS_ID": 7944,
  "PARENT_PROCESS_ID": 492
}
```

---

### NEW\_TCP4\_CONNECTION

Generated when a new TCPv4 connection is established, either inbound or outbound.

**Platforms:**

```json
{
  "PROCESS_ID": 6788,
  "DESTINATION": {
    "IP_ADDRESS": "172.16.223.219",
    "PORT": 80
  },
  "STATE": 5,
  "TIMESTAMP": 1468335512047,
  "SOURCE": {
    "IP_ADDRESS": "172.16.223.163",
    "PORT": 63581
  }
}
```

---

### NEW\_TCP6\_CONNECTION

Generated when a new TCPv6 connection is established, either inbound or outbound.

**Platforms:**

---

### NEW\_UDP4\_CONNECTION

Generated when a new UDPv4 socket "connection" is established, either inbound or outbound.

**Platforms:**

```json
{
  "TIMESTAMP": 1468335452828,
  "PROCESS_ID": 924,
  "IP_ADDRESS": "172.16.223.163",
  "PORT": 63057
}
```

---

### NEW\_UDP6\_CONNECTION

Generated when a new UDPv6 socket "connection" is established, either inbound or outbound.

**Platforms:**

---

### OPEN\_NAMED\_PIPE

This event is emitted when an existing Named Pipe is opened by a process.

**Platforms:**

```json
{
  "FILE_PATH": "\\Device\\NamedPipe\\lsass",
  "PROCESS_ID": 2232
}
```

---

### OS\_AUTORUNS\_REP

Response from an `os_autoruns` request.

**Platforms:**

**Sample Event:**

```json
{
  "TIMESTAMP": 1456194620,
  "AUTORUNS": [
    {
      "REGISTRY_KEY": "Software\\Microsoft\\Windows\\CurrentVersion\\Run\\VMware User Process",
      "FILE_PATH": "\"C:\\Program Files\\VMware\\VMware Tools\\vmtoolsd.exe\" -n vmusr",
      "HASH": "036608644e3c282efaac49792a2bb2534df95e859e2ddc727cd5d2e764133d14"
    }
  ]
}
```

### OS\_DRIVERS\_REP

Response from an `os_drivers` request.

**Platforms:**

**Sample Event:**

```json
{
  "SVCS": [
    {
      "PROCESS_ID": 0,
      "SVC_TYPE": 1,
      "SVC_NAME": "1394ohci",
      "SVC_STATE": 1,
      "HASH": "9ecf6211ccd30273a23247e87c31b3a2acda623133cef6e9b3243463c0609c5f",
      "SVC_DISPLAY_NAME": "1394 OHCI Compliant Host Controller",
      "EXECUTABLE": "\\SystemRoot\\System32\\drivers\\1394ohci.sys"
    }
  ]
}
```

### OS\_KILL\_PROCESS\_REP

Response from an `os_kill_process` request.

**Platforms:**

**Sample Event:**

```json
{
  "ERROR": 0,
  "PROCESS_ID": 579
}
```

### OS\_PACKAGES\_REP

List of packages installed on the system. This is currently Windows only but will be expanded to MacOS and Linux in the future.

**Platforms:**

**Sample Event:**

```
"PACKAGES": [
  {
    "PACKAGE_NAME": "Microsoft Windows Driver Development Kit Uninstall"
  }
]
```

### OS\_PROCESSES\_REP

Response from an `os_process` request.

**Platforms:**

**Sample Event:**

```json
{
  "PROCESSES": [
    {
      "COMMAND_LINE": "/sbin/init",
      "FILE_PATH": "/usr/lib/systemd/systemd",
      "HASH": "477209848fabcaf52c060d98287f880845cb07fc9696216dbcfe9b6ea8e72bcd"
    }
  ]
}
```

### OS\_RESUME\_REP

Response from an `os_resume` request.

**Platforms:**

### OS\_SERVICES\_REP

Response from an `os_services` request.

**Platforms:**

**Sample Event:**

```json
{
  "SVCS": [
    {
      "PROCESS_ID": 0,
      "SVC_TYPE": 32,
      "DLL": "%SystemRoot%\\System32\\AJRouter.dll",
      "SVC_NAME": "AJRouter"
    }
  ]
}
```

### OS\_SUSPEND\_REP

Response from an `os_suspend` request.

**Platforms:**

### OS\_USERS\_REP

Response from an `os_users` request.

**Platforms:**

**Sample Event:**

```json
{
  "USERS": [
    {
      "USER_NAME": "Administrator"
    }
  ]
}
```

### OS\_VERSION\_REP

Response from an `os_version` request.

**Platforms:**

**Sample Event:**

```json
{
  "BUILD_NUMBER": 20348
}
```

---

### PCAP\_LIST

\_INTERFACES\_REP
 Response from a `pcap_ifaces` request.

**Platforms:**

**Sample Event:**

```json
{
  "INTERFACE": [
    {
      "NAME": "ens4",
      "IPV4": ["10.128.15.198"]
    }
  ]
}
```

---

### PROCESS\_ENVIRONMENT

Generated when a process starts. It lists all environment variables associated with that new process.

**Platforms:**

```json
{
  "ENVIRONMENT_VARIABLES": [
    "LANG=en_US.UTF-8",
    "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
    "NOTIFY_SOCKET=/run/systemd/notify",
    "LISTEN_PID=18950",
    "LISTEN_FDS=2"
  ],
  "PROCESS_ID": 13463
}
```

---

### RECEIPT

This event is used as a generic response to some commands. The contents of a `RECEIPT` event usually contain an `ERROR` code that you can use to determine if the command was successful (`ERROR` codes can be explored [here](/v2/docs/reference-error-codes)). It's often a good idea to issue the original command with an `investigation_id` which will get echoed in the `RECEIPT` related to that command to make it easier to track.

**Platforms:**

---

### REGISTRY\_CREATE

This event is generated whenever a registry key / value is created on a Windows OS.

**Platforms:**

```json
{
  "PROCESS_ID":  764,
  "REGISTRY_KEY":   "\\REGISTRY\\A\\{fddf4643-a007-4086-903e-be998801d0f7}\\Events\\{8fb5d848-23dc-498f-ac61-84b93aac1c33}"
}
```

---

### REGISTRY\_DELETE

This event is generated whenever a registry key / value is deleted on a Windows OS.

**Platforms:**

```json
{
  "PROCESS_ID":  764,
  "REGISTRY_KEY":   "\\REGISTRY\\A\\{fddf4643-a007-4086-903e-be998801d0f7}\\Events\\{8fb5d848-23dc-498f-ac61-84b93aac1c33}"
}
```

---

### REGISTRY\_LIST\_REP

This event is generated in response to the `reg_list` command to list keys and values in a registry key.

**Platforms:**

**Sample Event:**

```json
{
    "REGISTRY_KEY": [
      "ActiveState"
    ],
    "ROOT": "hklm\\software",
    "REGISTRY_VALUE": [
      {
        "TYPE": 4,
        "NAME": "Order"
      }
    ],
    "ERROR": 0
}
```

---

### REGISTRY\_WRITE

This event is generated whenever a registry value is written to on a Windows OS.

The `REGISTRY_VALUE` contains the first 16 bytes of the value written to the registry. If this value is a valid ASCII or Unicode string, the value will be as-is. On the other hand if the value is binary data, it will be a base64 encoded string, see examples below.

The `SIZE` is the size value used in the original registry write call. The `TYPE` is the Windows data type of the entry written as per [Microsoft's definition](https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-rprn/25cce700-7fcf-4bb6-a2f3-0f6d08430a55).

**Platforms:**

Valid string payload:

```json
{
  "PROCESS_ID":1820,
  "REGISTRY_KEY":"\\REGISTRY\\MACHINE\\SOFTWARE\\Microsoft\\Windows Defender\\Diagnostics\\LastKnownGoodPlatformLocation",
  "REGISTRY_VALUE":"C:\\Progr",
  "SIZE":1,
  "TYPE":1,
}
```

Binary payload:

```json
{
  "PROCESS_ID": 1700,
  "REGISTRY_KEY": "\\REGISTRY\\MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Diagnostics\\DiagTrack\\HeartBeats\\Default\\LastHeartBeatTime",
  "REGISTRY_VALUE": "bMPGjjDM1wE=","SIZE": 11,
  "TYPE": 11
}
```

---

### REJOIN\_NETWORK

Emitted after a sensor is allowed network connectivity again (after it was previously segregated). An error code of 0 indicates success.

**Platforms:**

**Sample Event:**

```json
{
  "ERROR": 0
}
```

---

### REMOTE\_PROCESS\_HANDLE

Generated whenever a process opens a handle to another process with access flags like `VM_READ`, `VM_WRITE`, or `PROCESS_CREATE_THREAD`.

The `ACCESS_FLAGS` is the access mask as defined [here](https://docs.microsoft.com/en-us/windows/desktop/procthread/process-security-and-access-rights).

**Platforms:**

```json
{
  "ACCESS_FLAGS": 136208,
  "PARENT_PROCESS_ID": 6492,
  "PROCESS_ID": 2516
}
```

---

### SEGREGATE\_NETWORK

Emitted when a sensor is segregated (isolated) from the network using the `segregate_network` command. An error code of 0 indicates success.

**Platforms:**

**Sample Event:**

```json
{
  "ERROR": 0
}
```

---

### SENSITIVE\_PROCESS\_ACCESS

Generated when a process gains sensitive access to operating system processes like `lsass.exe` on Windows.

Note

SENSITIVE\_PROCESS\_ACCESS currently is only emitted for processes accessing `lsass.exe` on Windows.

**Platforms:**

```json
{
  "EVENTS": [
    {
      "event": {
        "COMMAND_LINE": "C:\\WINDOWS\\system32\\lsass.exe",
        "FILE_PATH": "C:\\WINDOWS\\system32\\lsass.exe",
        "PARENT_PROCESS_ID": 484,
        "PROCESS_ID": 636,
        "THREADS": 12,
        "USER_NAME": "BUILTIN\\Administrators"
      }
    }
  ]
}
```

---

### SERVICE\_CHANGE

Generated when a Service is changed.

**Platforms:**

```json
{
  "PROCESS_ID": 0,
  "SVC_TYPE": 32,
  "DLL": "%SystemRoot%\\system32\\wlidsvc.dll",
  "SVC_NAME": "wlidsvc",
  "SVC_STATE": 1,
  "HASH": "b37199495115ed423ba99b7317377ce865bb482d4e847861e871480ac49d4a84",
  "SVC_DISPLAY_NAME": "Microsoft Account Sign-in Assistant",
  "TIMESTAMP": 1467942600540,
  "EXECUTABLE": "%SystemRoot%\\system32\\svchost.exe -k netsvcs"
}
```

---

### SEGREGATE\_NETWORK

Emitted when a sensor is segregated (isolated) from the network using the `segregate_network` command.

**Platforms:**

---

### SSH\_LOGIN

Generated when a user logs in via SSH.

**Platforms:**

```json
{
  "USER_NAME": "root",
  "TIMESTAMP": 1468335816308
}
```

---

### SELF\_TEST

Internal event to manually request a power-on-self-test (POST) from the sensor.

---

### SHUTTING\_DOWN

Event generated when the sensor shuts down. Note: this event may not be observed if the host shuts down abruptly or too quickly.

**Platforms:**

**Event Data**

| Field | Type | Notes |
| --- | --- | --- |
| ts | Epoch timestamp |  |

**Sample Event:**

```json
{
  "SHUTTING_DOWN": {
    "ts": 1455674775
  }
}
```

---

### SSH\_LOGOUT

Generated when a user logs out via SSH.

**Platforms:**

```json
{
  "USER_NAME": "root",
  "TIMESTAMP": 1468335916308
}
```

---

### STARTING\_UP

Event generated when the sensor starts.

**Platforms:**

**Event Data**

| Field | Type | Notes |
| --- | --- | --- |
| ts | Epoch timestamp |  |

**Sample Event:**

```json
{
  "STARTING_UP": {
    "ts": 1455674775
  }
}
```

---

### TERMINATE\_PROCESS

Generated when a process exits.

**Platforms:**

```json
{
  "PARENT_PROCESS_ID": 5820,
  "TIMESTAMP": 1456285661,
  "PROCESS_ID": 6072
}
```

---

### TERMINATE\_TCP4\_CONNECTION

Generated when a TCPv4 connection terminates.

```json
{
  "DESTINATION": {
    "IP_ADDRESS": "61.55.252.93",
    "PORT": 443
  },
  "PROCESS_ID": 4784,
  "SOURCE": {
    "IP_ADDRESS": "172.16.223.138",
    "PORT": 50145
  }
}
```

---

### TERMINATE\_TCP6\_CONNECTION

Generated when a TCPv6 connection terminates.

---

### TERMINATE\_UDP4\_CONNECTION

Generated when a UDPv4 socket terminates.

---

### TERMINATE\_UDP6\_CONNECTION

Generated when a UDPv6 socket terminates.

---

### THREAD\_INJECTION

This event is generated when the sensor detects what looks like a thread injection into a remote process.

**Platforms:**

```json
{
  "event": {
    "EVENTS": [
      {
        "event": {
          "ACCESS_FLAGS": 2097151,
          "PARENT_PROCESS_ID": 5380,
          "PROCESS_ID": 4276,
          "SOURCE": {
            "BASE_ADDRESS": 140701160243200,
            "COMMAND_LINE": "\"C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\" --continue-active-setup",
            "FILE_IS_SIGNED": 1,
            "FILE_PATH": "C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe",
            "HASH": "c47fc20231ffc1e3befef952478363bff96cf3af1f36da4bd1129c8ed0e17fdb",
            "MEMORY_USAGE": 5881856,
            "PARENT_ATOM": "df4e951a09e365cb46c36c11659ee556",
            "PARENT_PROCESS_ID": 5972,
            "PROCESS_ID": 5380,
            "THIS_ATOM": "37b57d228af708b25d097f32659ee557",
            "THREADS": 3,
            "TIMESTAMP": 1704912214704,
            "USER_NAME": "WINDOWS-SERVER-\\whitney"
          },
          "TARGET": {
            "COMMAND_LINE": "C:\\Windows\\system32\\sppsvc.exe",
            "FILE_IS_SIGNED": 1,
            "FILE_PATH": "C:\\Windows\\system32\\sppsvc.exe",
            "HASH": "1ca5b9745872748575c452e456966b8ed1c4153757e9f4faf6f86c78c53d4ae8",
            "MEMORY_USAGE": 6156288,
            "PARENT_ATOM": "74be005ef68f6edb8682d972659ee024",
            "PARENT_PROCESS_ID": 628,
            "PROCESS_ID": 4276,
            "THIS_ATOM": "fe1dee93442392ea97becdad659ee516",
            "THREADS": 3,
            "TIMESTAMP": 1704912150174,
            "USER_NAME": "NT AUTHORITY\\NETWORK SERVICE"
          }
        },
        "routing": {
          "arch": 2,
          "did": "",
          "event_id": "d61caa47-225a-4f6a-9f3a-6094cdb3c383",
          "event_time": 1704912219717,
          "event_type": "REMOTE_PROCESS_HANDLE",
          "ext_ip": "104.198.223.172",
          "hostname": "windows-server-2022-bc76d608-9d83-4c6c-bdd5-f86bbd385a94-0.c.lc-demo-infra.internal.",
          "iid": "3c5c33e6-daaf-4029-be0b-94f50b86777e",
          "int_ip": "10.128.15.197",
          "moduleid": 2,
          "oid": "bc76d608-9d83-4c6c-bdd5-f86bbd385a94",
          "parent": "37b57d228af708b25d097f32659ee557",
          "plat": 268435456,
          "sid": "ccd0c386-88c1-4f8d-954c-581a95a1cc34",
          "tags": [
            "windows"
          ],
          "target": "fe1dee93442392ea97becdad659ee516",
          "this": "87509849fc608bce8a236f49659ee55b"
        }
      },
      {
        "event": {
          "PARENT_PROCESS_ID": 5380,
          "PROCESS_ID": 4276,
          "SOURCE": {
            "BASE_ADDRESS": 140701160243200,
            "COMMAND_LINE": "\"C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\" --continue-active-setup",
            "FILE_IS_SIGNED": 1,
            "FILE_PATH": "C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe",
            "HASH": "c47fc20231ffc1e3befef952478363bff96cf3af1f36da4bd1129c8ed0e17fdb",
            "MEMORY_USAGE": 5881856,
            "PARENT_ATOM": "df4e951a09e365cb46c36c11659ee556",
            "PARENT_PROCESS_ID": 5972,
            "PROCESS_ID": 5380,
            "THIS_ATOM": "37b57d228af708b25d097f32659ee557",
            "THREADS": 3,
            "TIMESTAMP": 1704912214704,
            "USER_NAME": "WINDOWS-SERVER-\\whitney"
          },
          "TARGET": {
            "COMMAND_LINE": "C:\\Windows\\system32\\sppsvc.exe",
            "FILE_IS_SIGNED": 1,
            "FILE_PATH": "C:\\Windows\\system32\\sppsvc.exe",
            "HASH": "1ca5b9745872748575c452e456966b8ed1c4153757e9f4faf6f86c78c53d4ae8",
            "MEMORY_USAGE": 6156288,
            "PARENT_ATOM": "74be005ef68f6edb8682d972659ee024",
            "PARENT_PROCESS_ID": 628,
            "PROCESS_ID": 4276,
            "THIS_ATOM": "fe1dee93442392ea97becdad659ee516",
            "THREADS": 3,
            "TIMESTAMP": 1704912150174,
            "USER_NAME": "NT AUTHORITY\\NETWORK SERVICE"
          },
          "THREAD_ID": 3672
        },
        "routing": {
          "arch": 2,
          "did": "",
          "event_id": "ece7d85e-a43c-49d3-bc9a-28ace6dc1b02",
          "event_time": 1704912219967,
          "event_type": "NEW_REMOTE_THREAD",
          "ext_ip": "104.198.223.172",
          "hostname": "windows-server-2022-bc76d608-9d83-4c6c-bdd5-f86bbd385a94-0.c.lc-demo-infra.internal.",
          "iid": "3c5c33e6-daaf-4029-be0b-94f50b86777e",
          "int_ip": "10.128.15.197",
          "moduleid": 2,
          "oid": "bc76d608-9d83-4c6c-bdd5-f86bbd385a94",
          "parent": "37b57d228af708b25d097f32659ee557",
          "plat": 268435456,
          "sid": "ccd0c386-88c1-4f8d-954c-581a95a1cc34",
          "tags": [
            "windows"
          ],
          "target": "fe1dee93442392ea97becdad659ee516",
          "this": "b30a499edf9ec2e424b07d20659ee55b"
        }
      }
    ]
  }
  "ts": "2024-01-10 18:43:39"
}
```

---

### USER\_LOGIN

Generated when a user logs in to the operating system.

**Platforms:**

---

### USER\_LOGOUT

Generated when a user logs out of the operating system.

**Platforms:**

---

### USER\_OBSERVED

Generated the first time a user is observed on a host.

**Platforms:**

```json
{
  "TIMESTAMP": 1479241363009,
  "USER_NAME": "root"
}
```

---

### VOLUME\_MOUNT

This event is generated when a volume is mounted.

**Platforms:**

```json
{
  "VOLUME_PATH": "E:",
  "DEVICE_NAME": "\\Device\\HarddiskVolume3"
}
```

---

### VOLUME\_UNMOUNT

This event is generated when a volume is unmounted.

**Platforms:**

```json
{
  "VOLUME_PATH": "/Volumes/RECOVERY",
  "VOLUME_NAME": "/dev/disk2s1"
}
```

---

### YARA\_DETECTION

Generated when a YARA scan finds a match.

**Platforms:**

```json
{
  "RULE_NAME": "malware_detection_rule",
  "FILE_PATH": "C:\\malicious.exe",
  "HASH": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
}
```

---

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

Endpoint Detection & Response

---

#### Related articles

* [Sysmon Comparison](/docs/sysmon-comparison)
* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Stateful Rules](/docs/stateful-rules)

---

##### What's Next

* [Reference: Error Codes](/docs/reference-error-codes)

Table of contents

+ [Overview](#overview)
+ [{{glossary.EDR}} Events by Supported OS](#{{glossary-edr}}-events-by-supported-os)
+ [Event Descriptions](#event-descriptions)

Tags

* [browser agent](/docs/en/tags/browser%20agent)
* [detection and response](/docs/en/tags/detection%20and%20response)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [linux](/docs/en/tags/linux)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)
* [telemetry](/docs/en/tags/telemetry)
* [windows](/docs/en/tags/windows)

---

## Reference: Platform Events

# Reference: Platform Events
## Event Details

---

### ACK\_MESSAGES

Acknowledge messages event is used by some LimaCharlie Sensors (e.g. USP). It is not used by the EDR.

---

### BACKOFF

Used for flow control. Provides a number of seconds that the Sensor should wait before sending events to the cloud.

---

### billing\_record

This event is emitted for all kinds of billable records for the Organization.

**Sample Event:**

```json
{
  "record": {
    "cat": "extension",
    "k": "ext-strelka:bytes_scanned",
    "oid": "8cbe27f4-aaaa-bbbb-cccc-138cd51389cd",
    "record_id": "3bbbe4d9-925b-4538-bcad-e2e1ba2be923-0",
    "ts": "2024-05-30 00:44:37",
    "v": 2797
  }
}
```

---

### CLOUD\_ADAPTER\_DISABLED

This event is emitted when a Cloud Adapter gets disabled because it has been erroring for a long period of time.

**Sample Event:**

```json
{
  "event":{
    "error": "invalid api key"
  },
  "routing": {
    "event_time": 1644444297696,
    "event_type": "cloud_adapter_disabled",
    "oid": "8cbe27f4-aaaa-cccc-bbbb-138cd51389cd"
  }
}
```

---

### DATA\_DROPPED

This event is generated by the Sensor when it has been offline and the events generated overflowed its internal buffer before they could be sent to the cloud, resulting in dropped events.

---

### DELETED\_SENSOR

Deleted Sensor deployment events are produced when a sensor that was previously deleted from an Org attempts to connect to the LimaCharlie cloud.

**Sample Event:**

```json
{
  "routing": {
    "oid": "d9ae5c17-d519-4ef5-a4ac-c454a95d31ca",
    "iid": "ca812425-5a36-4c73-a0a0-935a8ace6451",
    "sid": "a75cc927-bf28-4178-a42d-25ecc8a6be81",
    "plat": 536870912,
    "arch": 2,
    "ext_ip": "104.196.34.101",
    "int_ip": "172.17.0.2",
    "hostname": "linux-server-1",
    "event_type": "deleted_sensor",
    "event_time": 1561741553230
  },
  "event": {
    "denied_for": "720h0m0s"
  }
}
```

---

### ENROLLMENT

Enrollment deployment events are produced when a sensor enrolls into the Organization for the first time.

**Sample Event:**

```json
{
  "routing": {
    "oid": "d9ae5c17-d519-4ef5-a4ac-c454a95d31ca",
    "iid": "ca812425-5a36-4c73-a0a0-935a8ace6451",
    "sid": "a75cc927-bf28-4178-a42d-25ecc8a6be81",
    "plat": 536870912,
    "arch": 2,
    "event_type": "enrollment",
    "event_time": 1561741553230
  },
  "event": {
    "public_ip": "104.196.34.101",
    "internal_ip": "172.17.0.2",
    "host_name": "linux-server-1"
  }
}
```

---

### EXPORT\_COMPLETE

An export of artifact data is completed and ready for download.

**Sample Event:**

```json
{
  "routing" : {
    "log_id" : "ca812425-5a36-4c73-a0a0-935a8ace6451",
    "event_type" : "export_complete",
    "log_type" : "pcap",
    "oid" : "ca812425-5a36-4c73-a0a0-935a8ace6451",
    "event_time" : 1561741553230
  },
  "event" : {
    "size" : 2048,
    "source" : "a75cc927-bf28-4178-a42d-25ecc8a6be81",
    "original_path" : "/data/pcap/dat.pcap",
    "export_id" : "d9ae5c17-d519-4ef5-a4ac-c454a95d31ca"
  }
}
```

---

### INGEST

A new artifact has been ingested.

**Sample Event:**

```json
{
  "routing" : {
    "log_id" : "ca812425-5a36-4c73-a0a0-935a8ace6451",
    "event_type" : "ingest",
    "log_type" : "pcap",
    "oid" : "ca812425-5a36-4c73-a0a0-935a8ace6451",
    "event_time" : 1561741553230
  },
  "event" : {
    "size" : 2048,
    "source" : "a75cc927-bf28-4178-a42d-25ecc8a6be81",
    "original_path" : "/data/pcap/dat.pcap",
    "original_md5" : "adjfnwonefowrnfowef"
  }
}
```

---

### QUOTA\_CHANGED

Quota changed events are emitted when the quota for an Organization changes.

**Sample Event:**

```json
{
  "event":{
    "new_quota": 30,
    "old_quota": 25
  },
  "routing": {
    "event_time": 1644444297696,
    "event_type": "quota_changed",
    "oid": "8cbe27f4-aaaa-cccc-bbbb-138cd51389cd"
  }
}
```

---

### RUN

Emitted after a run command has been issued (e.g. to run a payload, shell command, etc.).

---

### SELF\_TEST\_RESULT

Internal event used during a power-on-self-test (POST) of the sensor.

---

### SENSOR\_CLONE

Sensor clone events are generated when the LimaCharlie Cloud detects that a specific Sensor ID may have been cloned.

**Sample Event:**

```json
{
  "routing": {
    "oid": "d9ae5c17-d519-4ef5-a4ac-c454a95d31ca",
    "iid": "ca812425-5a36-4c73-a0a0-935a8ace6451",
    "sid": "a75cc927-bf28-4178-a42d-25ecc8a6be81",
    "plat": 536870912,
    "arch": 2,
    "event_type": "sensor_clone",
    "event_time": 1561741553230
  },
  "event": {
    "previous_hostname" : "server-1",
    "new_hostname" : "server-2"
  }
}
```

---

### SENSOR\_CRASH

This event is generated when a Sensor has crashed. It will include some telemetry useful to help LimaCharlie troubleshoot the crash.

**Sample Event:**

```json
{
  "routing": {
    "arch": 2,
    "event_time": 1670861698000,
    "event_type": "sensor_crash",
    "hostname": "linux-server-1",
    "ext_ip": "104.196.34.101",
    "int_ip": "172.17.0.2",
    "oid": "8cbe27f4-aaaa-cccc-bbbb-138cd51389cd",
    "plat": 268435456,
    "iid": "ca812425-5a36-4c73-a0a0-935a8ace6451",
    "sid": "a75cc927-bf28-4178-a42d-25ecc8a6be81"
  },
  "event": {
    "crash_context": {
      "FILE_ID": 63,
      "LINE_NUMBER": 1216,
      "THREAD_ID": 7808
    }
  }
}
```

---

### SENSOR\_OVER\_QUOTA

Over quota deployment events are produced when a Sensor tries to connect but the Organization quota is already reached.

**Sample Event:**

```json
{
  "routing": {
    "oid": "d9ae5c17-d519-4ef5-a4ac-c454a95d31ca",
    "iid": "ca812425-5a36-4c73-a0a0-935a8ace6451",
    "sid": "a75cc927-bf28-4178-a42d-25ecc8a6be81",
    "plat": 536870912,
    "arch": 2,
    "event_type": "sensor_over_quota",
    "event_time": 1561741553230
  },
  "event": {
    "public_ip": "104.196.34.101",
    "internal_ip": "172.17.0.2",
    "host_name": "linux-server-1"
  }
}
```

---

### SET\_PERFORMANCE\_MODE

Enables performance mode in the kernel (e.g., disables file tracking on Windows).

---

### SYNC

Internal event used as a heartbeat to the cloud. Sent by default every 10 minutes.

---

### UNLOAD\_KERNEL

Allows manual unloading of kernel component.

---

### UPDATE

Internal event used to update the configuration of a specific collector within the endpoint.

---

### \*\_per\_cloud\_adapter

Events that are emitted once per period per cloud adapter. See [Schedule Events Reference](/v2/docs/reference-schedule-events) for more details.

**Sample Event:**

```json
{
  "event": {
    "frequency": 1800,
    "adapter_name": "office-audit",
    "runtime_mtd": {
      "entity_name": "81c72a07-9540-4341-9c35-66f6cfe1b9d7",
      "entity_type": "adapter",
      "mtd": {
        "platform": "office365",
        "hostname": "office-365-audit",
        "adapter_type": "office365"
      },
      "published_at": 1689858693935
    }
  }
}
```

---

### \*\_per\_org

Events that are emitted once per period per org. See [Schedule Events Reference](/v2/docs/reference-schedule-events) for more details.

**Sample Event:**

```json
{
  "event": {
    "frequency": 86400
  },
  "routing": {
    "event_id": "0f236fbb-31df-4d11-b6ab-c6b71a63a072",
    "event_time": 1673298756512,
    "event_type": "1h_per_org",
    "oid": "8cbe27f4-bfa1-4afb-ba19-138cd51389cd",
    "sid": "00000000-0000-0000-0000-000000000000",
    "tags": []
  }
}
```

---

### \*\_per\_sensor

Events that are emitted once per period per Sensor. See [Schedule Events Reference](/v2/docs/reference-schedule-events) for more details.

**Sample Event:**

```json
{
  "event": {
    "frequency": 1800,
    "runtime_mtd": {
      "entity_name": "81c72a07-9540-4341-9c35-66f6cfe1b9d7",
      "entity_type": "sensor",
      "mtd": {
        "bytes_recv": 6202524,
        "conn_at": 1689819872,
        "eps_in": 1,
        "eps_out": 0,
        "q_size": 0
      },
      "published_at": 1689858693935
    }
  }
}
```

---

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Endpoint Detection & Response

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

---

#### Related articles

* [Platform Events Overview](/docs/platform-events-overview)
* [Detection and Response](/docs/detection-and-response)
* [Hayabusa to BigQuery](/docs/hayabusa-to-bigquery)
* [Velociraptor to BigQuery](/docs/velociraptor-to-bigquery)

---

##### What's Next

* [Reference: Schedule Events](/docs/reference-schedule-events)

Table of contents

+ [Event Details](#event-details)

Tags

* [events](/docs/en/tags/events)
* [platform](/docs/en/tags/platform)
* [telemetry](/docs/en/tags/telemetry)

---

## Reference: Schedule Events

# Reference: Schedule Events
* 1 Minute to read

## Related articles

* [Detection on Alternate Targets](/docs/detection-on-alternate-targets)
* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Platform Events Overview](/docs/platform-events-overview)
* [Reference: Platform Events](/docs/reference-platform-events)

---

### What's Next

* [Query Console](/docs/query-console)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)
* [events](/docs/en/tags/events)
* [platform](/docs/en/tags/platform)

---

## Soteria EDR Rules

# Soteria EDR Rules
* 1 Minute to read

## Related articles

* [Reference: EDR Events](/docs/reference-edr-events)
* [Soteria M365 Rules](/docs/soteria-m365-rules)
* [Soteria AWS Rules](/docs/soteria-aws-rules)
* [Soteria Rules](/docs/soteria-rules)
* [Managed Rulesets](/docs/managed-rulesets)

---

### What's Next

* [Soteria M365 Rules](/docs/soteria-m365-rules)

Table of contents

+ [Enabling Soteria's EDR Rules](#enabling-soteria-s-edr-rules)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)
* [endpoint agent](/docs/en/tags/endpoint%20agent)

---

## Tutorial: Ingesting Telemetry from Cloud-Based External Sources

# Tutorial: Ingesting Telemetry from Cloud-Based External Sources
* 1 Minute to read

## Related articles

* [Adapter Deployment](/docs/adapter-deployment)
* [Adapter Usage](/docs/adapter-usage)
* [Adapters](/docs/adapters)
* [Adapter Types](/docs/adapter-types)
* [Adapter Examples](/docs/adapter-examples)
* [Tutorial: Creating a Webhook Adapter](/docs/tutorial-creating-a-webhook-adapter)

---

### What's Next

* [Adapter Usage](/docs/adapter-usage)

Tags

* [adapters](/docs/en/tags/adapters)
* [telemetry](/docs/en/tags/telemetry)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## Windows Event Log

# Windows Event Log
* 1 Minute to read

## Related articles

* [Windows Event Logs](/docs/adapter-examples-windows-event-logs)
* [Ingesting Windows Event Logs](/docs/ingesting-windows-event-logs)
* [Hayabusa](/docs/ext-hayabusa)

---

### What's Next

* [Zendesk](/docs/adapter-types-zendesk)

Table of contents

+ [Overview](#overview)
+ [Configurations](#configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## Windows Event Logs

# Windows Event Logs
* 1 Minute to read

## Related articles

* [Microsoft Defender](/docs/adapter-types-microsoft-defender)
* [Windows Event Log](/docs/adapter-types-windows-event-log)
* [EVTX](/docs/adapter-types-evtx)
* [Ingesting Windows Event Logs](/docs/ingesting-windows-event-logs)
* [Hayabusa](/docs/ext-hayabusa)

---

### What's Next

* [HubSpot](/docs/adapter-types-hubspot)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

# Query Console

## Building Reports with BigQuery + Looker Studio

# Building Reports with BigQuery + Looker Studio
LimaCharlie does not include reporting by default, however our granular and customizable [Output](/v2/docs/outputs) options allow you to push data to any source and use third-party tools for reporting. In this tutorial, we'll push a subset of LimaCharlie EDR telemetry to [BigQuery](https://cloud.google.com/bigquery) and analyze our data using Google's [Looker Studio](https://lookerstudio.google.com/). We'll be doing the work in the web UI, however this could also be done via the API.

For this example, we will aggregate and analyze Windows processes making network connections.

## Preparing BigQuery

Within your project of choice, begin by creating a new dataset. For the purposes of this tutorial, I'm going to create a dataset named `windows_process_details`. Within this dataset, I'll create a table named `network_connections`.

Let's examine this hierarchy for a moment:

```
├── limacharlie-bq-testing    # project
│   ├── windows_process_details    # dataset
│   │   ├── network_connections    # table
```

The nice part about this type of hierarchy is that I can build out multiple tables of process details within the same dataset, and then link/analyze them as needed. We'll focus on the `network_connections` data for now, but we could also look at exporting other process details into the same dataset.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%2897%29.png)

Within the Google Cloud Console, we also want to create a Service Account and gather an API key. More details on that can be found [here](https://cloud.google.com/iam/docs/service-accounts-create).

Copy the API key and keep it somewhere safe, we'll need to configure it in the output.

## Creating the BigQuery Output

Creating an Output within LimaCharlie is straightforward. Navigate to `Outputs` in the web UI, select `Add Output`, and select `Events`.

Note:

We want to export raw events in this case - however, we'll use filters to export only the events of interest to BigQuery.

Within the Output Destination menu, select `Google Cloud BigQuery`. You'll be prompted with a configuration menu; expand the `Advanced Options`, as we'll need those too.

The following values must be provided in order for the Output to work:

* Name (choose your own name)
* Dataset (from the previous section)
* Table (from the previous section)
* Project (from the previous section)
* Secret Key (the API key from the GCP service account)

Where to Store the Secret?

The secret key for this output can be inserted directly in the web app helper, however we recommend keeping secrets in the [Secret hive](/v2/docs/config-hive-secrets) for centralized management.

Within the `Advanced Options`, we'll need to provide the following details:

* Custom Transform - we don't want to include *all* the details from the `NETWORK_CONNECTIONS` event. For this output, we are interested in processes making network connections and the users associated with them. Thus, we'll apply the following transform to pare this down:

```json
{
  "hostname": "routing.hostname",
  "command_line": "event.COMMAND_LINE",
  "user": "event.USER_NAME"
}
```

Within the `Specific Event Types` field, we'll specify only `NETWORK_CONNECTIONS`. This is another way to pare down the number of events processed and exported.

Finally, we'll also specify a tag of `windows`, ensuring we only capture Windows systems (per our tagging - your tags may differ). Based on the values provided and discussed, here's a screenshot of the Output configuration (minus the API key):

![image](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/output-config.png)

Save the output details, and then check `View Samples` in the Outputs menu to see if you're successfully seeing events.

![image](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/output-sample.png)

## Analyzing Events in BigQuery + Looker Studio

Navigating back to BigQuery, we can see some initial events flowing in:

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28102%29.png)

Let's hop over to Looker Studio. Create a Blank Report, and select `BigQuery` in the `Connect to Data` menu.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28103%29.png)

Select the Project, Dataset, and Table of interest, and click `Add`.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28104%29.png)

Looker Studio may prompt you about permissions of connected data. However, once connected, we'll be able to see a starter table with aggregate details from our `network_connections` table.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28105%29.png)

And that's it! From here, you can manipulate and move around the data as needed. You can also blend with another table, allowing you to combine multiple data points.

Reports can also be styled, additional statistics generated, etc. The following example continues to pull on the basic data we exported to provide some unique insights:

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28106%29.png)

---

### Related articles

* [Google Cloud Pubsub](/docs/adapter-types-google-cloud-pubsub)
* [Google Cloud Storage](/docs/adapter-types-google-cloud-storage)
* [Google Workspace](/docs/adapter-types-google-workspace)
* [Google Cloud BigQuery](/docs/outputs-destinations-google-cloud-bigquery)
* [Google Cloud Pubsub](/docs/outputs-destinations-google-cloud-pubsub)
* [Google Cloud Storage](/docs/outputs-destinations-google-cloud-storage)
* [Google Cloud](/docs/ext-cloud-cli-google-cloud)

---

#### What's Next

* [FAQ - General](/docs/faq-general)

Table of contents

+ [Preparing BigQuery](#preparing-bigquery)
+ [Creating the BigQuery Output](#creating-the-bigquery-output)
+ [Analyzing Events in BigQuery + Looker Studio](#analyzing-events-in-bigquery-looker-studio)

Tags

* [gcp](/docs/en/tags/gcp)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## Google Cloud BigQuery

# Google Cloud BigQuery
* 1 Minute to read

## Related articles

* [Building Reports with BigQuery + Looker Studio](/docs/tutorials-reporting-building-reports-with-bigquery-looker-studio)
* [Google Cloud Pubsub](/docs/outputs-destinations-google-cloud-pubsub)
* [Google Cloud Storage](/docs/outputs-destinations-google-cloud-storage)
* [Google Workspace](/docs/adapter-types-google-workspace)
* [Google Cloud Storage](/docs/adapter-types-google-cloud-storage)
* [Tutorial: Ingesting Google Cloud Logs](/docs/tutorial-ingesting-google-cloud-logs)
* [Google Cloud](/docs/ext-cloud-cli-google-cloud)

---

### What's Next

* [Google Cloud Pubsub](/docs/outputs-destinations-google-cloud-pubsub)

Tags

* [gcp](/docs/en/tags/gcp)
* [outputs](/docs/en/tags/outputs)

---

## Hayabusa to BigQuery

# Hayabusa to BigQuery
## Overview

Our BigQuery output allows you to send Hayabusa analysis results to a BigQuery table allowing SQL-like queries against the data. This allows you to perform analysis at scale against massive datasets. For guidance on using Hayabusa within LimaCharlie, see [Hayabusa Extension](/v2/docs/ext-hayabusa).

Imagine you wanted to analyze event logs from 10s, 100s, or 1000s of systems using Hayabusa. You have a couple options:

1. Send the resulting CSV artifact to another platform, like [Timesketch](https://timesketch.org/), for further analysis, as the CSV generated by Hayabusa in LimaCharlie is compatible with Timesketch
2. Run queries against all of the data returned by Hayabusa in BigQuery

BigQuery dataset containing Hayabusa results:
![Screenshot 2024-02-27 10.50.46 AM.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/Screenshot%202024-02-27%2010.50.46%20AM.png)

### Steps to Accomplish

1. You will need a Google Cloud project
2. You will need to create a service account within your Google Cloud project

   1. Navigate to your project
   2. Navigate to IAM
   3. Navigate to Service Accounts > Create Service Account
   4. Click on newly created Service Account and create a new key

      1. ![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28188%29.png)
      2. This will provide you with the JSON format secret key you will later setup in your LimaCharlie output.
   5. In BigQuery, create a Dataset, Table, & Schema similar to the screenshot below. Keep in mind, the name of your dataset and table are arbitrary but they need to match what you configure in your output in LimaCharlie.

      1. Project - `your_project_name`
      2. Dataset - `hayabusa`
      3. Table - `hayabusa`
      4. Schema - `computer:STRING, message:STRING, timestamp:STRING, details:STRING, channel:STRING, event_id:STRING, level:STRING, mitre_tactics:STRING, mitre_tags:STRING, extra:STRING`

         1. Note that this can be any of the fields from the Hayabusa event that you wish to use. **This schema and transform are based on the CSV output using the** `timesketch-verbose` **profile.**
3. Now we're ready to create our LimaCharlie Events Output

   1. In the side navigation menu, click "Outputs" then add a new ouput

      1. **Output stream**: Events
      2. **Destination**: Google Cloud BigQuery

         1. **Name**: `hayabusa-bigquery`

            1. You can change this, but it affects a subsequent step so take note of the output name
         2. **schema**: `computer:STRING, message:STRING, timestamp:STRING, details:STRING, channel:STRING, event_id:STRING, level:STRING, mitre_tactics:STRING, mitre_tags:STRING, extra:STRING`

            1. Note that this can be any of the fields from the Hayabusa event that you wish to use. **This schema and transform are based on the CSV output using the** `timesketch-verbose` **profile.**
         3. **Dataset**: *whatever you named BQ your dataset above*
         4. **Table**: *whatever you named your BQ table above*
         5. **Project**: *your* GCP *project name*
         6. **Secret Key**: *provide the JSON secret key for your GCP service account*
         7. **Advanced Options**

            1. **Custom Transform**: paste in this JSON

               1. Note that this can be any of the fields from the Hayabusa event that you wish to use. **This schema and transform are based on the CSV output using the** `timesketch-verbose` **profile.**

```json
               {
               "channel": "event.results.Channel",
               "computer": "event.results.Computer",
               "message": "event.results.message",
               "timestamp": "event.results.datetime",
               "details": "event.results.Details",
               "event_id": "event.results.EventID",
               "level": "event.results.Level",
               "mitre_tactics": "event.results.MitreTactics",
               "mitre_tags": "event.results.MitreTags",
               "extra": "event.results.ExtraFieldInfo",
               }
               ```
            2. **Specific Event Types**: `hayabusa_event`
            3. **Sensor**: `ext-hayabusa`
4. You are now ready to send Hayabusa events to BigQuery!

Google Cloud Platform

---

#### Related articles

* [Hayabusa](/docs/ext-hayabusa)

---

##### What's Next

* [Velociraptor to BigQuery](/docs/velociraptor-to-bigquery)

Table of contents

+ [Overview](#overview)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [dfir](/docs/en/tags/dfir)
* [extensions](/docs/en/tags/extensions)
* [gcp](/docs/en/tags/gcp)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## LCQL Examples

# LCQL Examples
LimaCharlie Query Language (LCQL) lets you write well-structured queries to search across telemetry within LimaCharlie. The following examples can help you perform targeted searches or hunts across your telemetry, as well as modify them to build your own. Example queries are sorted by *source*, however can be adjusted for your environment.

Got a Unique Query?

If you've written a unique query or have one you'd like to share with the community, please join us in the [LimaCharlie Community](https://community.limacharlie.io)!

## General Queries

Search *all* event types across *all* Windows sytems for a particular string showing up in *any* field.
`-24h | plat == windows | * | event/* contains 'psexec'`

## GitHub Telemetry

GitHub logs can be an excellent source of telemetry to identify potential repository or account abuse or misuse. When ingested properly, GitHub log data can be observed via `plat == github`.

### GitHub Protected Branch Override

Show me all the GitHub branch protection override (force pushing to repo without all approvals) in the past 12h that came from a user outside the United States, with the repo, user and number of infractions.

`-12h | plat == github | protected_branch.policy_override | event/public_repo is false and event/actor_location/country_code is not "us" | event/repo as repo event/actor as actor COUNT(event) as count GROUP BY(repo actor)`

which could result in:

```
| actor    |   count | repo                               |
|----------|---------|------------------------------------|
| mXXXXXXa |      11 | acmeCorpCodeRep/customers          |
| aXXXXXXb |      11 | acmeCorpCodeRep/analysis           |
| cXXXXXXd |       3 | acmeCorpCodeRep/devops             |
```

## Network Telemetry

Network details recorded on endpoints, such as new connections or DNS requests, allow for combined insight. We can also query this data for aggregate details, and display data in an easily-consumed manner.

### Domain Count

Show me all domains resolved by Windows hosts that contain "google" in the last 10 minutes and the number of times each was resolved.

`-10m | plat == windows | DNS_REQUEST | event/DOMAIN_NAME contains 'google' | event/DOMAIN_NAME as domain COUNT(event) as count GROUP BY(domain)`

which could result in:

```
|   count | domain                     |
|---------|----------------------------|
|      14 | logging.googleapis.com     |
|      36 | logging-alv.googleapis.com |
```

### Domain Prevalence

Show me all domains resolved by Windows hosts that contain "google" in the last 10 minutes and the number of unique Sensors that have resolved them.

`-10m | plat == windows | DNS_REQUEST | event/DOMAIN_NAME contains 'google' | event/DOMAIN_NAME as domain COUNT_UNIQUE(routing/sid) as count GROUP BY(domain)`

which could result in:

```
|   count | domain                     |
|---------|----------------------------|
|       4 | logging.googleapis.com     |
|       3 | logging-alv.googleapis.com |
```

## Process Activity

### Unsigned Binaries

Grouped and counted.
`-24h | plat == windows | CODE_IDENTITY | event/SIGNATURE/FILE_IS_SIGNED != 1 | event/FILE_PATH as Path event/HASH as Hash event/ORIGINAL_FILE_NAME as OriginalFileName COUNT_UNIQUE(Hash) as Count GROUP BY(Path Hash OriginalFileName)`

### Process Command Line Args

`-1h | plat == windows | NEW_PROCESS EXISTING_PROCESS | event/COMMAND_LINE contains "psexec" | event/FILE_PATH as path event/COMMAND_LINE as cli routing/hostname as host`

### Stack Children by Parent

`-12h | plat == windows | NEW_PROCESS | event/PARENT/FILE_PATH contains "cmd.exe" | event/PARENT/FILE_PATH as parent event/FILE_PATH as child COUNT_UNIQUE(event) as count GROUP BY(parent child)`

## Windows Event Log (WEL)

When ingested with EDR telemetry, or as a separate Adapter, `WEL` type events are easily searchable via LimaCharlie. Sample queries are organized alphabetically, with threat/technique details provided where applicable.

### %COMSPEC% in Service Path

`-12h | plat == windows | WEL | event/EVENT/System/EventID == "7045" and event/EVENT/EventData/ImagePath contains "COMSPEC"`

### Overpass-the-Hash

`-12h | plat == windows | WEL | event/EVENT/System/EventID == "4624" and event/EVENT/EventData/LogonType == "9" and event/EVENT/EventData/AuthenticationPackageName == "Negotiate" and event/EVENT/EventData/LogonProcess == "seclogo"`

### Taskkill from a Non-System Account

*Requires process auditing to be enabled*

`-12h | plat == windows | WEL | event/EVENT/System/EventID == "4688" and event/EVENT/EventData/NewProcessName contains "taskkill" and event/EVENT/EventData/SubjectUserName not ends with "!"`

### Logons by Specific LogonType

`-24h | plat == windows | WEL | event/EVENT/System/EventID == "4624" AND event/EVENT/EventData/LogonType == "10"`

### Stack/Count All LogonTypes by User

`-24h | plat == windows | WEL | event/EVENT/System/EventID == "4624" | event/EVENT/EventData/LogonType AS LogonType event/EVENT/EventData/TargetUserName as UserName COUNT_UNIQUE(event) as Count GROUP BY(UserName LogonType)`

### Failed Logons

`-1h | plat==windows | WEL | event/EVENT/System/EventID == "4625" | event/EVENT/EventData/IpAddress as SrcIP event/EVENT/EventData/LogonType as LogonType event/EVENT/EventData/TargetUserName as Username event/EVENT/EventData/WorkstationName as SrcHostname`

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Endpoint Detection & Response

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

---

#### Related articles

* [LimaCharlie Query Language](/docs/lcql)
* [Query Console](/docs/query-console)
* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Reference: Sensor Selector Expressions](/docs/reference-sensor-selector-expressions)

---

##### What's Next

* [Detection and Response](/docs/detection-and-response)

Table of contents

+ [General Queries](#general-queries)
+ [GitHub Telemetry](#github-telemetry)
+ [Network Telemetry](#network-telemetry)
+ [Process Activity](#process-activity)
+ [Windows Event Log (WEL)](#windows-event-log-wel-)

Tags

* [lcql](/docs/en/tags/lcql)

---

## LimaCharlie Query Language

# LimaCharlie Query Language
Beta Feature

LCQL is currently in Beta, and features may change in the future.

LimaCharlie Query Language (LCQL) provides a flexible, intuitive and interactive way to explore your data in LimaCharlie. Telemetry ingested via EDR sensors or adapters are searchable via LCQL, and can be searched en masse. Sample use cases for LCQL include:

* Analyze your entire, multi-platform fleet for network connections of interest.
* Search across all Windows Event Logs for unique user activity.
* Look at all Linux systems for specific package installation events.
* Analyze all volume mounts and unmounts on macOS devices
* And many more!!!

The steps below walk you through creating your own LCQL queries. If you're looking for samples or LCQL inspiration, check out our [LCQL Examples](/v2/docs/lcql-examples) page.

## Building LimaCharlie Queries

LCQL queries contain 4 components with a 5th optional one, each component is separated by a pipe (`|`):

1. **Timeframe**: the time range the query applies to. This can be either a single offset in the past like `-1h` or `-30m`. Or it can be a date time range like `2022-01-22 10:00:00 to 2022-01-25 14:00:00`.

   Note: the time frame is still used in the CLI and API, but no longer exposed in the UI; use the time selector control instead.
2. **Sensor selector**: the set of sensors to query. This can be either `*` for all sensors, or a [Sensor Selector expression](/v2/docs/reference-sensor-selector-expressions), like `plat == windows` or `hostname == foo.com or hostname == bar.com`  (Note: a full list of platform types can be found in the [ID Schema Reference](/v2/docs/reference-id-schema))
3. **Event type**: the  event types to include in the query. Use  `or`  to search for multiple events at once, for example `NEW_PROCESS or DNS_REQUEST`, or a `*` to go over all event types.
4. **Filters**: the actual query filters. The filters are a series of statements combined with " and " and " or " that can be associated with parenthesis (`()`). String literals, when used, can be double-quoted to be case insensitive or single-quoted to be case sensitive. Selectors behave like  rules, for example: `event/FILE_PATH`.

The [Query Console UI](/v2/docs/query-console-ui) provides a type-ahead assistance to bring up the available operators and help design the query.

5. **Projection (optional**): a list of fields you would like to extract from the results with a possible alias, like: `event/FILE_PATH as path event/USER_NAME AS user_name event/COMMAND_LINE`. The Projection can also support a grouping functionality by adding `GROUP BY(field1 field2 ...)` at the end of the projection statement.

When grouping, all fields being projected must either be in the `GROUP BY` statement, or have an aggregator modifier. An aggregator modifer is, for example, `COUNT( host )` or `COUNT_UNIQUE( host )` instead of just `host`.

A full example with grouping is:

`-1h | * | DNS_REQUEST | event/DOMAIN_NAME contains "apple" | event/DOMAIN_NAME as dns COUNT_UNIQUE(routing/hostname) as hostcount GROUP BY(dns host)`

which would give you the number of hosts having resolved a domain containing `apple`, grouped by domain.

All of this can result in a query like:

`-30m | plat == windows | NEW_PROCESS | event/COMMAND_LINE contains "powershell" and event/FILE_PATH not contains "powershell" | event/COMMAND_LINE as cli event/FILE_PATH as path routing/hostname as host`

OR

`-30m | plat == windows | * | event/COMMAND_LINE contains "powershell" and event/FILE_PATH not contains "powershell"`

Projection Syntax

Note: There is no space between `BY` and the `(` opening of the parentheses in a projection.

Example: `GROUP BY(dns host)` or `COUNT_UNIQUE(routing/hostname)`

Endpoint Detection & Response

---

### Related articles

* [LCQL Examples](/docs/lcql-examples)
* [LimaCharlie SDK & CLI](/docs/limacharlie-sdk)
* [Query Console](/docs/query-console)

---

#### What's Next

* [Query with CLI](/docs/query-with-cli)

Table of contents

+ [Building LimaCharlie Queries](#building-limacharlie-queries)

Tags

* [lcql](/docs/en/tags/lcql)

---

## OpenSearch

# OpenSearch
* 1 Minute to read

## Related articles

* [Elastic](/docs/outputs-destinations-elastic)

---

### What's Next

* [SCP](/docs/outputs-destinations-scp)

Tags

* [outputs](/docs/en/tags/outputs)

---

## Query Console

# Query Console
* 1 Minute to read

## Related articles

* [LimaCharlie Query Language](/docs/lcql)

---

### What's Next

* [Query Console UI](/docs/query-console-ui)

---

## Query Console UI

# Query Console UI
Many critical security operations require a query console with strong search functionality. It enables analysts to query large volumes of telemetry, logs, and events for investigations, hunting, and incident response.

LimaCharlie’s Query Console (with integrated Search) brings this functionality to the SecOps Cloud Platform. We’ve combined familiar query workflows with features like type-ahead syntax, time range selection, and detection-as-code conversion. This lets your team quickly investigate alerts, analyze data across tenants, and extend LimaCharlie into other modern SIEM use cases.

All events ingested into LimaCharlie are retained and available for analysis. Data is parsed at ingest and saved in LimaCharlie hot storage. Search queries this large volume of telemetry for matches within the time frame you provide. Searches are billed based on the number of events scanned (measured in millions). See Pricing for specifics.

## Permissions

To view and operate the Query Console, the following permissions are required:

* `insight.evt.get` for search
* `org.get` for schema service access
* `query.set` for saving queries
* `query.get` for reading a list of queries (if you don’t have this set you will see an error saying you need `query.get.mtd`, but this is the permission you need)
* `query.del` for editing or deleting queries (editing is creating a new one and removing the old one)

### UI Element Overview

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(338).png)

1. **Source:** Select Events (everything that had been injected from endpoints and XDR sources, default), Detections, or Platform Audit events as the data source for the search.
2. **Query editor:** Enter a LimaCharlie Query Language (LCQL) query to include:

   1. *Sensor Selector -* precisely define the sensors that produced the desired events.
   2. *Event Type* - filter results to only return specific types of events.
   3. Filter - the actual query filter using individual fields and operations on top of them.
   4. Projections (optional) - control output columns, sort results via `ORDER BY` and/or aggregate the data with `GROUP BY` , `COUNT`, `COUNT_UNIQUE`  and more. See LCQL reference and Examples for details.
3. **Time period:** Set the searchable time period using three options: last [time period],  around [time frame], and absolute “from start→to finish”.

   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(340).png)

   * Enter a time `16:00`, or day and time `2025-01-16 08:52:54`, using most common time formats.  For example:

     + From `33m` to `now` - last 33 minutes
     + Around `2025-01-16 08:52:54` +- `15 minutes` - 15 minutes before and after the specified time stamp
     + From `10am` to `1:30pm`

     **Note:** All times are shown according to the timezone selected by the user in User Settings.
4. **Available Fields:** Managed data exploration

   1. Schema fields - a list of all the fields associated with ingested events.
   2. Event types - event types present in the returned portion of the query. As more data is churned to complete the specified time frame more event types may appear.
   3. Query fields - event fields present in the *portion of the result already fetched by the query*,  with a count of total occurrences. Clicking on the event field opens a details panel. From here you can add a term to the query.

      ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(341).png)
   4. Table columns: control the columns displayed in Table View.

   Note: While the schema fields are always available, the event types and query fields are only shown for portion of the time frame *searched so far*.  As more data is churned in the background (to complete your selected time frame), more event types and fields may appear.
5. **Query status:** Shows the state of your query in real time, highlighting any existing syntax errors or providing a cost estimate if the query is properly formed.

   As the query runs the status displays progress, query status, and a running total of the cost accrued.

   *Query cost estimation:* Queries are charged by the amount of data churned, measured and billed per one million events evaluated. This estimation shows the “at most” cost of a query for the selected time range. Only retrieved data is chargeable.

   *Performance tuning:* The better tuned the query, the faster the search and lower the cost. Using Sensor Selector and Event Type to precisely target the desired telemetry will increase search speeds and lower costs.
6. **Histogram:**

   When a search is run, a histogram appears below the query field showing the distribution of events over time. The portion with a vertical bar chart represents results  that have been retrieved so far. The non-bar chart portion shows the total number of events in the selected time frame. The histogram shows the progress of the search through the time frame.  As you paginate through the search, more events are evaluated, and more bars appear to signify the progress through the time frame.
7. **Search results:** displays results in two views, **timeline** and **table**. Timeline view shows matching events with the most recent on top.  Table view provides a way to sort results into desired columns. Find the desired field in Query Fields and use the `pin` icon to add it as a column.

   1. A **Tab Columns** section appears in the **Fields** sidebar when table view is selected. Columns can be viewed or removed here.
   2. **Event Details** allows you to click on an event and perform applicable event actions like **Build a D&R Rule**.
   3. **Download** all the events you’ve retrieved in a [.ndjson format](https://github.com/ndjson/ndjson-spec). The automatic download of the entire time range is coming soon.

   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(342).png)
8. **Saving Queries and Query Library.** A query can be saved in your private user library or shared via an org library. Use the library to browse queries and load the desired one to the query editor.

---

#### What's Next

* [LimaCharlie Query Language](/docs/lcql)

Table of contents

---

## Query with CLI

# Query with CLI
* 1 Minute to read

## What's Next

* [LCQL Examples](/docs/lcql-examples)

Table of contents

---

## Velociraptor to BigQuery

# Velociraptor to BigQuery
## Overview

Our BigQuery output allows you to send Velociraptor hunt results to a BigQuery table allowing SQL-like queries against the hunt data. This is very similar to using [Velociraptor notebooks](https://docs.velociraptor.app/docs/vql/notebooks/), allowing you to perform hunt analysis at scale against massive datasets. For guidance on using LimaCharlie to execute Velociraptor hunts, see [Velociraptor Extension](/v2/docs/ext-velociraptor).

Imagine you wanted to obtain running processes from 10s, 100s, or 1000s of systems using Velociraptor. You could easily issue a `Windows.System.Pslist` hunt across these systems, and let LimaCharlie push Velociraptor to the endpoints and collect the results. The issue is, if you want to run queries against all of the data returned by the hunts, you'll need a database-like tool to do that which is where BigQuery comes in.

BigQuery dataset containing Velociraptor hunt results:
![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28186%29.png)

### Steps to Accomplish

1. You will need a Google Cloud project
2. You will need to create a service account within your Google Cloud project

   1. Navigate to your project
   2. Navigate to IAM
   3. Navigate to Service Accounts > Create Service Account
   4. Click on newly created Service Account and create a new key

      1. ![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28188%29.png)
      2. This will provide you with the JSON format secret key you will later setup in your LimaCharlie output
   5. In BigQuery, create a Dataset, Table, & Schema similar to the screenshot below

      1. ![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28189%29.png)
3. Now we're ready to create our LimaCharlie tailored output

   1. In the side navigation menu, click "Outputs" then add a new output

      1. **Output stream**: Tailored
      2. **Destination**: Google Cloud BigQuery

         1. **Name**: `bigquery-tailored`

            1. You can change this, but it affects a subsequent step so take note of the output name
         2. **schema**: `sid:STRING, job_id:STRING, artifact:JSON`
         3. **Dataset**: *whatever you named BQ your dataset above*
         4. **Table**: *whatever you named your BQ table above*
         5. **Project**: *your GCP project name*
         6. **Secret Key**: *provide the JSON secret key for your GCP service account*
         7. **Advanced Options**

            1. **Custom Transform**: paste in this JSON

```json
               {
               "sid": "event.sid",
               "job_id": "event.job_id",
               "artifact": "{{ json .event.collection }}"
               }
               ```
            2. **Specific Event Types**: `velociraptor_collection`
      3. ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/velociraptor.png)
4. We now need a  rule that will watch for Velociraptor collections send send them to the new tailored output

   1. Create a new D&R rule

      1. Detection

         ```
         event: velociraptor_collection
         op: exists
         path: event/collection
         ```
      2. Response

         ```
         - action: output
           name: bigquery-tailored # must match the output name you created earlier
         - action: report
           name: Velociraptor hunt sent to BigQuery
         ```
5. You are now ready to send Velociraptor hunts to BigQuery!

## BigQuery Tips

### Query Examples

Once the data arrives in BigQuery, it will be in three simple columns: `sid`, `job_id`, and `artifact`. The `artifact` column contains the raw JSON of the hunt results from each sensor that returned results.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28191%29.png)

Let's say we wanted to split out all results of a `Windows.System.Pslist` hunt so that each process, from each system, is returned in it's own row. Here is an example notebook to accomplish this:

```
SELECT
  sid,
  json_extract_scalar(obj, '$.Name') as Name,
  json_extract_scalar(obj, '$.Exe') as Exe,
  json_extract_scalar(obj, '$.CommandLine') as CommandLine,
  json_extract_scalar(obj, '$.Authenticode.Trusted') as Authenticode,
  json_extract_scalar(obj, '$.Hash.SHA256') as SHA256,
  json_extract_scalar(obj, '$.Pid') as Pid,
  json_extract_scalar(obj, '$.Ppid') as Ppid,
  json_extract_scalar(obj, '$.Username') as Username
FROM
  `lc-demo-infra.velociraptor.hunts`,
  UNNEST(json_extract_array(artifact.Windows_System_Pslist)) as obj
LIMIT 1000
```

Be sure to swap out `lc-demo-infra.velociraptor.hunts` for your own `project.dataset.table` names.

This results in the following view of our data
![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28200%29.png)

Suppose we wanted to perform some stacking analysis to identify the rarest combinations of `Exe` and `CommandLine`; the following query could help:

```
SELECT
  json_extract_scalar(obj, '$.Exe') as Exe,
  json_extract_scalar(obj, '$.CommandLine') as CommandLine,
  COUNT(*) as Count
FROM
  `lc-demo-infra.velociraptor.hunts`,
  UNNEST(json_extract_array(artifact.Windows_System_Pslist)) as obj
GROUP BY
  Exe,
  CommandLine
ORDER BY
  Count ASC
```

This results in the following view of our data
![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28201%29.png)

Now let's say you wanted to look for only processes that are `Authenticode` = `untrusted`, you would use a query such as this:

```
SELECT
  sid,
  json_extract_scalar(obj, '$.Name') as Name,
  json_extract_scalar(obj, '$.Exe') as Exe,
  json_extract_scalar(obj, '$.CommandLine') as CommandLine,
  json_extract_scalar(obj, '$.Authenticode.Trusted') as Authenticode,
  json_extract_scalar(obj, '$.Hash.SHA256') as SHA256,
  json_extract_scalar(obj, '$.Pid') as Pid,
  json_extract_scalar(obj, '$.Ppid') as Ppid,
  json_extract_scalar(obj, '$.Username') as Username
FROM
  `lc-demo-infra.velociraptor.hunts`,
  UNNEST(json_extract_array(artifact.Windows_System_Pslist)) as obj
WHERE
  json_extract_scalar(obj, '$.Authenticode.Trusted') = 'untrusted'
LIMIT 1000
```

### WHERE Filters for Specific Conditions

Here are some brief examples of `WHERE` statements to perform specific filtering.

#### String presence

This example checks for the presence of a string `mimikatz` appearing anywhere within `CommandLine`

```
WHERE
  STRPOS(json_extract_scalar(obj, '$.CommandLine'), 'mimikatz') > 0 AND
```

#### Compare integers

This example checks for the presence of an integer `0` in a numeric field `GroupID`

```
WHERE
  CAST(json_extract_scalar(obj, '$.GroupID') AS INT64) = 0
```

### Parsing Nested JSON Objects

In the `Windows.System.Pslist` examples above, there are a few columns which contain nested JSON such as `Authenticode` and `Hash`. To expand these objects in their entirety in the corresponding column/row, we'd write a query like this:

```
SELECT
  json_extract(obj, '$.Authenticode') as Authenticode, # json_extract to unpack nested json
  json_extract_scalar(obj, '$.Authenticode.Trusted') as Trusted,
  json_extract(obj, '$.Hash') as Hashes, # json_extract to unpack nested json
  json_extract_scalar(obj, '$.Hash.SHA256') as SHA256, # extract a specific field from the nested json
FROM
  `lc-demo-infra.velociraptor.hunts`,
  UNNEST(json_extract_array(artifact.Windows_System_Pslist)) as obj
LIMIT 1000
```

See the output of this query below:
![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28202%29.png)

---

#### Related articles

* [Velociraptor](/docs/ext-velociraptor)
* [Google Cloud BigQuery](/docs/outputs-destinations-google-cloud-bigquery)
* [Hayabusa](/docs/ext-hayabusa)
* [Plaso](/docs/ext-plaso)

---

##### What's Next

* [Using Extensions](/docs/using-extensions)

Table of contents

+ [Overview](#overview)
+ [BigQuery Tips](#bigquery-tips)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [dfir](/docs/en/tags/dfir)
* [extensions](/docs/en/tags/extensions)
* [gcp](/docs/en/tags/gcp)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

# Detection Response

## Community Rules

# Community Rules
The LimaCharlie Endpoint Agent is a cross platform endpoint Sensor. It is a low-level, light-weight sensor which executes detection and response functionality in real-time.

Our Community Rules feature leverages the power of AI to quickly transform a plethora of third-party rules into LimaCharlie syntax so you can make them your own. The process is fast and efficient: Browse thousands of community rules, select one as a starting point, convert it to LimaCharlie syntax with one click, and customize it to your liking.

## Accessing the Community Rules

To access the Community Rules:

1. Log into LimaCharlie
2. Select an Organization
3. Click the Automation drop down on the left panel
4. Select  Rules
5. Look in the upper right corner of the D&R Rules page for the Add Rule button
6. Click the Add Rule button
7. Look in the upper right corner of the rule creation page for the Community Library button
8. Click the Community Library button

This takes you to the Community Rules search page, and gives you access to thousands of third-party detection rules. The library currently contains detection rules written by [Anvilogic](https://github.com/anvilogic-forge/armory/blob/main/detections/cloud/aws_disableawsserviceaccess/aws_disableawsserviceaccess-splunk-awscloudtrail.yml), [Sigma](https://github.com/SigmaHQ/sigma/blob/master/rules/network/zeek/zeek_http_susp_file_ext_from_susp_tld.yml), [Panther](https://github.com/panther-labs/panther-analysis/blob/develop/rules/gsuite_activityevent_rules/google_workspace_many_docs_downloaded.yml), and [Okta](https://github.com/okta/customer-detections).

> Rules are searchable by CVE number, keyword, or pre-defined descriptors (Tags). Searchable tags include attack techniques, MITRE ATT&CK id codes and other key rule identificators.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(337).png)

### Loading a Community Rule

Once you find the rule you want to use, import it to the organization by clicking “Load Rule”, and our AI engine will create it using verified LimaCharlie syntax.

> This process may take a few seconds so please be patient.

Once the rule is ready, it will return you to the Add Rule page in LimaCharlie. The Detect and Response sections of the rule will be filled out with LimaCharlie logic that includes explanatory comments. From here you can manage this rule just as you would any other D&R rule.

## Digging Deeper

As these rules are the property of third parties you may be interested in knowing more about their licensing or source code. This information is accessible through the Community Rules search page. To see these details click on a rule.

The example below shows what appears when you click Anvilogic’s Potential CVE-2021-44228 - Log4Shell rule

Under the rule name you will see the options to load the rule, check its source code, and read additional licensing information. There is also a reference section at the bottom left corner of the window providing links related to the rule.

**![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXf3SZQZu4j4kEp2Y0wpnoeHA0t_XaR5VqaoB9SupPHl0t91e-12QhMj0epDi742peW0gpu8e44HhJ4lDN1esspiMRUfpFr3W2aNiQcIeff2HhNCxmgp1h3oLqphpqJ8AohoDDxFdA?key=7BgiNipN3DxRQXGQyEk06w)**

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

---

### What's Next

* [Template Strings and Transforms](/docs/template-strings-and-transforms-2)

Table of contents

+ [Digging Deeper](#digging-deeper)

---

## Config Hive: Detection & Response Rules

# Config Hive: Detection & Response Rules
* 1 Minute to read

## Related articles

* [Config Hive: Yara](/docs/config-hive-yara)
* [Config Hive: Secrets](/docs/config-hive-secrets)
* [Config Hive: Cloud Sensors](/docs/config-hive-cloud-sensors)
* [Config Hive](/docs/config-hive)
* [Config Hive: Lookups](/docs/config-hive-lookups)

---

### What's Next

* [Config Hive: Lookups](/docs/config-hive-lookups)

Table of contents

+ [Format](#format)
+ [Permissions](#permissions)
+ [Command-Line Usage](#command-line-usage)
+ [Usage](#usage)
+ [Example](#example)

Tags

* [api](/docs/en/tags/api)
* [platform](/docs/en/tags/platform)

---

## Create a D&R Rule Using a Threat Feed

# Create a D&R Rule Using a Threat Feed
* 1 Minute to read

## Related articles

* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Lookups](/docs/lookups)
* [Lookup Manager](/docs/ext-lookup-manager)
* [API Integrations](/docs/add-ons-api-integrations)
* [VirusTotal](/docs/api-integrations-virustotal)

---

### What's Next

* [Detection Logic Operators](/docs/detection-logic-operators)

Table of contents

+ [Additional Telemetry Points](#additional-telemetry-points)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [detection and response](/docs/en/tags/detection%20and%20response)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## Detection Logic Operators

# Detection Logic Operators
Operators are used in the Detection part of a Detection & Response rule. Operators may also be accompanied by other available parameters, such as transforms, times, and others, referenced later in this page.

> For more information on how to use operators, read [Detection & Response Rules](/v2/docs/detection-and-response).

## Operators

### and, or

The standard logical boolean operations to combine other logical operations. Takes a single `rules:` parameter that contains a list of other operators to "AND" or "OR" together.

Example:

```
op: or
rules:
  - ...rule1...
  - ...rule2...
  - ...
```

### is

Tests for equality between the value of the `"value": <>` parameter and the value found in the event at the `"path": <>` parameter.

Supports the [file name](#file-name) and [sub domain](#sub-domain) transforms.

Example rule:

```
event: NEW_PROCESS
op: is
path: event/PARENT/PROCESS_ID
value: 9999
```

### exists

Tests if any elements exist at the given path (regardless of its value).

Example rule:

```
event: NEW_PROCESS
op: exists
path: event/PARENT
```

The `exists` operator also supports an optional `truthy` parameter. When `true`, this parameter indicates the `exists` should treat `null` and `""` (empty string) values as if they were non-existent like:

The rule:

```
op: exists
path: some/path
truthy: true
```

applied to:

```json
{
  "some": {
    "path": ""
  }
}
```

would NOT match.

### contains

The `contains` checks if a substring can be found in the value at the path.

An optional parameter `count: 3` can be specified to only match if the given
 substring is found *at least* 3 times in path.

Supports the [file name](#file-name) and [sub domain](#sub-domain) transforms.

Example rule:

```
event: NEW_PROCESS
op: contains
path: event/COMMAND_LINE
value: reg
count: 2
```

### ends with, starts with

The `starts with` checks for a prefix match and `ends with` checks for a suffix match.

They both check if the value found at `path` matches the given `value`, based on the operator.

Supports the [file name](#file-name) and [sub domain](#sub-domain) transforms.

### is greater than, is lower than

Check to see if a value is greater or lower (numerically) than a value in the event.

They both use the `path` and `value` parameters. They also both support the `length of` parameter as a boolean (true or false). If set to true, instead of comparing
 the value at the specified path, it compares the length of the value at that path.

### matches

The `matches` op compares the value at `path` with a regular expression supplied in the `re` parameter. Under the hood, this uses the Golang's `regexp` [package](https://golang.org/pkg/regexp/), which also enables you to apply the regexp to log files.

Supports the [file name](#file-name) and [sub domain](#sub-domain) transforms.

Example:

```
event: FILE_TYPE_ACCESSED
op: matches
path: event/FILE_PATH
re: .*\\system32\\.*\.scr
case sensitive: false
```

### not

The `not` operator inverts the result of its rule. For example, when applied to an `is` operator, it changes the logic from "equals" to "does not equal". When applied to an or operator, it changes the logic from "any of these conditions are true" to "none of these conditions are true"

Example:

```
event: NEW_PROCESS
op: is
not: true
path: event/PARENT/PROCESS_ID
value: 9999
```

### string distance

The `string distance` op looks up the [Levenshtein Distance](https://en.wikipedia.org/wiki/Levenshtein_distance) between two strings. In other words it generates the minimum number of character changes required for one string to become equal to another.

For example, the Levenshtein Distance between `google.com` and `googlr.com` (`r` instead of `e`) is 1.

This can be used to find variations of file names or domain names that could be used for phishing, for example.

Suppose your company is `onephoton.com`. Looking for the Levenshtein Distance between all `DOMAIN_NAME` in `DNS_REQUEST` events, compared to `onephoton.com` it could detect an attacker using `onephot0n.com` in a phishing email domain.

The operator takes a `path` parameter indicating which field to compare, a `max` parameter indicating the maximum Levenshtein Distance to match and a `value` parameter that is either a string or a list of strings that represent the value(s) to compare to. Note that although `string distance` supports the `value` to be a list, most other operators do not.

Supports the [file name](#file-name) and [sub domain](#sub-domain) transforms.

Example:

```
event: DNS_REQUEST
op: string distance
path: event/DOMAIN_NAME
value:
  - onephoton.com
  - www.onephoton.com
max: 2
```

This would match `onephotom.com` and `0nephotom.com` but NOT `0neph0tom.com`.

Using the [file name](#file-name) transform to apply to a file name in a path:

```
event: NEW_PROCESS
op: string distance
path: event/FILE_PATH
file name: true
value:
  - svchost.exe
  - csrss.exe
max: 2
```

This would match `svhost.exe` and `csrss32.exe` but NOT `csrsswin32.exe`.

### is 32 bit, is 64 bit, is arm

All of these operators take no additional arguments, they simply match if the relevant Sensor characteristic is correct.

Example:

```
op: is 64 bit
```

### is platform

Checks if the event under evaluation is from a sensor of the given platform.

Takes a `name` parameter for the platform name. The current platforms are:

* `windows`
* `linux`
* `macos`
* `ios`
* `android`
* `chrome`
* `vpn`
* `text`
* `json`
* GCP
* AWS
* `carbon_black`
* `crowdstrike`
* `1password`
* `office365`
* `msdefender`

Example:

```
op: is platform
name: 1password
```

### is tagged

Determines if the Tag supplied in the `tag` parameter is already associated with the sensor that the event under evaluation is from.

### lookup

Looks up a value against a [lookup add-on](https://app.limacharlie.io/add-ons/category/lookup) (a.k.a. resource) such as a threat feed.

```
event: DNS_REQUEST
op: lookup
path: event/DOMAIN_NAME
resource: hive://lookups/malwaredomains
case sensitive: false
```

This rule will get the `event/DOMAIN_NAME` of a `DNS_REQUEST` event and check if it's a member of the `lookup` named `malwaredomains`. If it is, then the rule is a match.

The value is supplied via the `path` parameter and the lookup is defined in the `resource` parameter. Resources are of the form `hive://lookups/RESOURCE_NAME`. In order to access a lookup, your Organization must be subscribed to it.

Supports the [file name](#file-name) and [sub domain](#sub-domain) transforms.

> API-based lookups, like VirusTotal and IP Geolocation, work a little bit differently. For more information, see [Using API-based lookups](/v2/docs/add-ons-api-integrations).

> You can create your own lookups and optionally publish them in the add-on marketplace. To learn more, see [Lookups](/v2/docs/config-hive-lookups) and [Lookup Manager](/v2/docs/ext-lookup-manager).

### scope

In some cases, you may want to limit the scope of the matching and the `path` you use to be within a specific part of the event. The `scope` operator allows you to do just that, reset the root of the `event/` in paths to be a sub-path of the event.

This comes in as very useful for example when you want to test multiple values of a connection in a `NETWORK_CONNECTIONS` event but always on a per-connection. If you  were to do a rule like:

```
event: NETWORK_CONNECTIONS
op: and
rules:
  - op: starts with
    path: event/NETWORK_ACTIVITY/?/SOURCE/IP_ADDRESS
    value: '10.'
  - op: is
    path: event/NETWORK_ACTIVITY/?/DESTINATION/PORT
    value: 445
```

you would hit on events where *any* connection has a source IP prefix of `10.` and *any* connection has a destination port of `445`. Obviously this is not what we had in mind, we wanted to know if a *single* connection has those two characteristics.

The solution is to use the `scope` operator. The `path` in the operator will become the new `event/` root path in all operators found under the `rule`. So the above would become

Example:

```
event: NETWORK_CONNECTIONS
op: scope
path: event/NETWORK_ACTIVITY/
rule:
  op: and
  rules:
    - op: starts with
      path: event/SOURCE/IP_ADDRESS
      value: '10.'
    - op: is
      path: event/DESTINATION/PORT
      value: 445
```

### cidr

The `cidr` checks if an IP address at the path is contained within a given
[CIDR network mask](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing).

Example rule:

```
event: NETWORK_CONNECTIONS
op: cidr
path: event/NETWORK_ACTIVITY/SOURCE/IP_ADDRESS
cidr: 10.16.1.0/24
```

### is private address

The `is private address` checks if an IP address at the path is a private address
 as defined by [RFC 1918](https://en.wikipedia.org/wiki/Private_network).

Example rule:

```
event: NETWORK_CONNECTIONS
op: is private address
path: event/NETWORK_ACTIVITY/SOURCE/IP_ADDRESS
```

### is public address

The `is public address` checks if an IP address at the path is a public address
 as defined by [RFC 1918](https://en.wikipedia.org/wiki/Private_network).

Example rule:

```
event: NETWORK_CONNECTIONS
op: is public address
path: event/NETWORK_ACTIVITY/SOURCE/IP_ADDRESS
```

## Transforms

Transforms are transformations applied to the value being evaluated in an event, prior to the evaluation.

### file name

Sample: `file name: true`

The `file name` transform takes a `path` and replaces it with the file name component of the `path`. This means that a `path` of `c:\windows\system32\wininet.dll` will become `wininet.dll`.

### sub domain

Sample: `sub domain: "-2:"`

The `sub domain` extracts specific components from a domain name. The value of `sub domain` is in [slice notation](https://stackoverflow.com/questions/509211/understanding-slice-notation). It looks like `startIndex:endIndex`, where the index is 0-based and indicates which parts of the domain to keep.

Some examples:

* `0:2` means the first 2 components of the domain: `aa.bb` for `aa.bb.cc.dd`.
* `-1` means the last component of the domain: `cc` for `aa.bb.cc`.
* `1:` means all components starting at 1: `bb.cc` for `aa.bb.cc`.
* `:` means to test the operator to every component individually.

### is older than

Test if a value in event at the `"path": <>` parameter, assumed to be either a second-based epoch or a millisecond-based epoch is older than a number of seconds as specified by the `seconds` parameter, centered in time at "now" during evaluation.

Example rule:

```
event: login-attempt
op: is older than
path: routing/event_time
seconds: 3600
```

where the example above would match on a `login-attempt` event that occurred more than 1h ago.

## Times

All operators support an optional parameter named `times`. When specified, it must contain a list of Time Descriptors when the accompanying operator is valid. Your rule can mix-and-match multiple Time Descriptors as part of a single rule on per-operator basis.

Here's an example rule that matches a Chrome process starting between 11PM and 5AM, Monday through Friday, Pacific Time:

```
event: NEW_PROCESS
op: ends with
path: event/FILE_PATH
value: chrome.exe
case sensitive: false
times:
  - day_of_week_start: 2     # 1 - 7
    day_of_week_end: 6       # 1 - 7
    time_of_day_start: 2200  # 0 - 2359
    time_of_day_end: 2359    # 0 - 2359
    tz: America/Los_Angeles  # time zone
  - day_of_week_start: 2
    day_of_week_end: 6
    time_of_day_start: 0
    time_of_day_end: 500
    tz: America/Los_Angeles
```

### Time Zone

The `tz` should match a TZ database name from the [Time Zones Database](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones).

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Google Cloud Platform

Amazon Web Services

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

#### Related articles

* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Detection on Alternate Targets](/docs/detection-on-alternate-targets)
* [Stateful Rules](/docs/stateful-rules)

---

##### What's Next

* [Response Actions](/docs/response-actions)

Table of contents

+ [Operators](#operators)
+ [Transforms](#transforms)
+ [Times](#times)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)
* [reference](/docs/en/tags/reference)

---

## Detection and Response

# Detection and Response
Detection & Response rules automate actions based on the real-time events streaming into LimaCharlie. Each rule has two YAML descriptors: one that describes what to detect, and another that describes how to respond.

Note

It's recommended to read about [Events](/v2/docs/events) before diving into  rules.

## A Basic Rule

Here's a rule that detects DNS requests to `example.com` and responds by reporting them within the Organization with a category name `DNS Hit example.com`.

```
# Detection
event: DNS_REQUEST
op: is
path: event/DOMAIN_NAME
value: example.com

# Response
- action: report
  name: DNS Hit example.com
```

This rule will detect and respond to requests to `example.com` within 100ms of the `DNS_REQUEST` event occurring. It uses the `is` operator to assess if the given `value` can be found inside the `event` at the given `path`.

Want more detection examples?

For examples, check out the [Detection and Response Examples](/v2/docs/detection-and-response-examples).

## Detection

### Targets and events

Detections must specify an `event` (or `events`), and may optionally specify a `target`. Each target offers different event types. Here are the 5 possible rule targets:

* `edr` (default): telemetry events from LimaCharlie sensors
* `detection`: detections generated by other rules
* `deployment`: lifecycle events around deployment & enrollment of sensors
* `artifact`: artifacts collected via REST API or via `artifact_get` Sensor command
* `artifact_event`: lifecycle events around artifacts such as ingestion

For a full list of events with examples, see [Events Reference](/v2/docs/events).

Most of this page focuses on `edr` events. For information about other targets, see [Detection on Alternate Targets](/v2/docs/detection-on-alternate-targets).

#### Detections against Adapter events

Similar to EDR telemetry, data received via Adapters are observable via Detection & Response rules. D&R rules that action on Adapter-based data are written the same way, with event and operator qualifiers and response actions based on successful detections.

Depending on the type of adapter, you can reference adapter data directly via the `platform` [sensor selector](/v2/docs/reference-sensor-selector-expressions) (e.g. `aws`, `msdefender`, `crowdstrike`, etc.)

### Operators

Detections must specify an `op` (logical operator). The types of operators used are a good indicator for how complex the rule will be.

Here's a simple detection that uses a single `is windows` operator to detect a Windows sensor connecting to the Internet:

```
event: CONNECTED
op: is windows
```

And here's a more complex detection that uses the `and` operator to detect a non-Windows sensor that's making a DNS request to example.com.

```
event: DNS_REQUEST
op: and
rules:
- op: is windows
  not: true
- op: is
  path: event/DOMAIN_NAME
  value: example.com
```

There are 3 operators here:

1. The `and` operator evaluates nested `rules` and will only itself be `true` if both of the rules inside it are `true`
2. The `is windows` operator is accompanied by the `not` parameter, reversing the matching outcome and effectively saying "anything but windows"
3. The `is` operator is comparing the `value` 'example.com' to the content of the event at the given `path`

Each operator may have parameters alongside it. Some parameters, such as `not`, are useable on all operators. Most operators have required parameters specific to them.

> For a full list of operators and their usage, see [Reference: Operators](/v2/docs/detection-logic-operators).

### Paths

The `path` parameter is used commonly in several operators to specify which part of the event should be evaluated.

Here's an example of a standard JSON `DNS_REQUEST` event from a sensor:

```json
{
  "event": {
    "DNS_TYPE": 1,
    "TIMESTAMP": 1456285240,
    "DNS_FLAGS": 0,
    "DOMAIN_NAME": "example.com"
  },
  "routing": {
    "event_type": "DNS_REQUEST",
    "oid": "8cbe27f4-agh1-4afb-ba19-138cd51389cd",
    "sid": "d3d17f12-eecf-5287-b3a1-bf267aabb3cf",
    "hostname": "test-host-123"
    // ...and other standardized routing data
  }
}
```

This detection will match the above event's hostname:

```
event: DNS_REQUEST
op: is
path: routing/hostname # where the value lives
value: test-host-123   # the expected value at that path
```

This works a lot like file paths in a directory system. Since LimaCharlie events are always formatted with separate `event` and `routing` data, almost all paths start with either `event/` or `routing/`.

> Tip: you can visit the Timeline view of any Sensor to browse historical events and bring them directly into the D&R rule editor.

Paths may also employ the use of wildcards `*` to represent 0 or more directory levels, or `?` to represent exactly 1 directory level. This can be useful when working with events like `NETWORK_CONNECTIONS`:

```json
{
  "event": {
    "NETWORK_ACTIVITY": [
      {
        "SOURCE": {
          "IP_ADDRESS": "172.16.223.138",
          "PORT": 50396
        },
        "IS_OUTGOING": 1,
        "DESTINATION": {
          "IP_ADDRESS": "23.214.49.56",
          "PORT": 80
        }
      },
      {
        "SOURCE": {
          "IP_ADDRESS": "172.16.223.138",
          "PORT": 50397
        },
        "IS_OUTGOING": 1,
        "DESTINATION": {
          "IP_ADDRESS": "189.247.166.18",
          "PORT": 80
        }
      },
      // ...there could be several connections
    ],
    "HASH": "2de228cad2e542b2af2554d61fab5463ecbba3ff8349ba88c3e48637ed8086e9",
    "COMMAND_LINE": "C:\\WINDOWS\\system32\\msfeedssync.exe sync",
    "PROCESS_ID": 6968,
    "FILE_IS_SIGNED": 1,
    "USER_NAME": "WIN-5KC7E0NG1OD\\dev",
    "FILE_PATH": "C:\\WINDOWS\\system32\\msfeedssync.exe",
    "PARENT_PROCESS_ID": 1892
  },
  "routing": { ... } // Omitted for brevity
}
```

Notice that the `NETWORK_ACTIVITY` inside this event is a list.

Here's a rule that would match a known destination IP in any of the entries within `NETWORK_ACTIVITY`:

```
event: NETWORK_CONNECTIONS
op: is
path: event/NETWORK_ACTIVITY/?/DESTINATION/IP_ADDRESS # <---
value: 189.247.166.18
```

The `?` saves us from enumerating each index within the list and instead evaluates *all* values at the indicated level. This can be very powerful when used in combination with lookups: lists of threat indicators such as known bad IPs or domains.

> To learn more about using lookups in detections, see the `lookup` [operator](/v2/docs/detection-logic-operators#lookup).

### Values

The `value` parameter is commonly used by several detection operations but can also be used by some response actions as well.

In most detections `value` will be used to specify a known value like all the previous examples on this page have done. They're also capable of referencing previously set sensor variables using `value: [[var-name]]` double square bracket syntax.

Values from events can also be forwarded in response actions using `value: <<event/FILE_PATH>>` double angle bracket syntax.

> To see how sensor variables and lookback values are used, see the `add var / del var` action in [Reference: Response Actions](/v2/docs/response-actions).

## Response

Responses are much simpler than Detections. They're a list of actions to perform upon a matching detection.

### Actions

The most common action is the `report` action, which creates a Detection that shows up in the LimaCharlie web app and passes it along to the `detections` output stream in real-time.

```
- action: report
  name: detected-something

# Example of accessing map values
- action: report
  name: Event detected by {{ .event.USER_NAME }} from {{ index (index .event.NETWORK_ACTIVITY 0) "SOURCE" "IP_ADDRESS" }}
```

Each item in the response specifies an `action` and any accompanying parameters for that `action`.

A more complex response action could include running an [endpoint agent command](/v2/docs/endpoint-agent-commands) such as `yara_scan` using a field from within the detected event. The following example looks for `NEW_DOCUMENT` events that meet certain criteria, then initiates a YARA scan against the offending file path.

Detect

```
event: NEW_DOCUMENT
op: and
rules:
  - case sensitive: false
    op: matches
    path: event/FILE_PATH
    re: .\:\\(users|windows\\temp)\\.*
  - case sensitive: false
    op: matches
    path: event/FILE_PATH
    re: .*\.(exe|dll)
```

Respond

```
# Report is optional, but informative
- action: report
  name: Executable written to Users or Temp (yara scan)

# Initiate a sensor command to yara scan the FILE_PATH
- action: task
  command: yara_scan hive://yara/malware-rule -f "{{ .event.FILE_PATH }}"
  investigation: Yara Scan Executable
  suppression:
    is_global: false
    keys:
      - '{{ .event.FILE_PATH }}'
      - Yara Scan Executable
    max_count: 1
    period: 1m
```

Notice the use of `suppression` to prevent the same `FILE_PATH` from being scanned more than once per minute to prevent a resource runaway situation.

Which D&R Rule Triggered a Command?

To determine which D&R rule triggered a command on an endpoint, navigate to the `Platform Logs` section. If a command was triggered by a D&R rule, the audit log will show the associate rule. If the command was sent via the API, the audit logs will show the API key name.

> To learn about all possible actions, see [Reference: Response Actions](/v2/docs/response-actions).

## Putting It All Together

Let's take this knowledge and write a rule to detect something a little more interesting.

On Windows there's a command called `icacls` which can be used to modify access control lists. Let's write a rule which detects any tampering via that command.

The first thing we can do is detect any new `icacls` processes:

```
event: NEW_PROCESS
op: ends with
path: event/FILE_PATH
value: icacls.exe
```

And we'll set a basic response action to report the detection, too:

```
- action: report
  name: win-acl-tampering
```

If we save that, we'll start to see detections for any `icacls` processes spawning. However, not all of them will be particularly interesting from a security perspective. In this case, we only really care about invocations of `icacls` where the `grant` parameter is specified.

Let's make this rule more specific. We can do this by using the `and` operator to match multiple operators. We'll check for the string `"grant"` in the `COMMAND_LINE`, and while we're at it we'll make sure we don't bother evaluating other platforms by using the `is windows` operator.

```
event: NEW_PROCESS
op: and
rules:
- op: is windows
- op: ends with
	path: event/FILE_PATH
	value: icacls.exe
- op: contains
  path: event/COMMAND_LINE
  value: grant
```

This more specific rule means we'll see fewer false positives to look at or exclude later.

However, we still might miss some invocations of `icacls` with this detection if they use any capital letters — our operators are being evaluated with an implicit `case sensitive: true` by default. Let's turn case sensitivity off and observe the final rule:

```
# Detection
event: NEW_PROCESS
op: and
rules:
- op: is windows
- op: ends with
	case sensitive: false
	path: event/FILE_PATH
	value: icacls.exe
- op: contains
	case sensitive: false
  path: event/COMMAND_LINE
  value: grant

# Response
- action: report
  name: win-acl-tampering
```

This rule combines multiple operators to specify the exact conditions which might make an `icacls` process interesting. If it sees one, it'll report it as a `win-acl-tampering` detection which will be forwarded to Outputs and become viewable in the Detections page.

> Tip: test your rules without waiting for events! We recommend enabling the replay add-on for a better D&R rule writing experience.
>
> * Visit Timeline of a sensor and `Build D&R Rule` directly from real events
> * While drafting a rule, `Replay` an event against the rule to see if it would match
> * Replay a rule over historical events to see if any detections would have occurred

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Endpoint Detection & Response

---

### Related articles

* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection on Alternate Targets](/docs/detection-on-alternate-targets)
* [Config Hive: Detection & Response Rules](/docs/config-hive-dr-rules)
* [Events](/docs/events)
* [Reference: EDR Events](/docs/reference-edr-events)

---

#### What's Next

* [Replay](/docs/replay)

Table of contents

+ [A Basic Rule](#a-basic-rule)
+ [Detection](#detection)
+ [Response](#response)
+ [Putting It All Together](#putting-it-all-together)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)

---

## Detection and Response Examples

# Detection and Response Examples
The following are sample detection and response rules can help you get started in crafting efficient  rules utilizing LimaCharlie's telemetry. In addition to these rules, we also recommend checking out [Sigma Rules](/v2/docs/sigma-rules) for more rules.

## Translating Existing Rules

Before listing examples, it's worth mentioning [uncoder.io](https://uncoder.io/) by [SOC Prime](https://socprime.com/) is a great resource for learning by analogy. If you're already familiar with another platform for rules or search queries (Sigma, Splunk, Kibana, etc.) you can use uncoder to translate to LimaCharlie's D&R rules.

Looking for more?

Check out this video that shows you the power of leveraging community resources with LimaCharlie

## Examples

Note that through limacharlie.io, in order to provide an easier to edit format, the same rule configuration is used but is in YAML format instead. For example:

```
# Detection
op: ends with
event: NEW_PROCESS
path: event/FILE_PATH
value: .scr

# Response
- action: report
  name: susp_screensaver
- action: add tag
  tag: uses_screensaver
  ttl: 80000
```

### WanaCry

Simple WanaCry detection and mitigation rule:

```
# Detection
op: ends with
event: NEW_PROCESS
path: event/FILE_PATH
value: wanadecryptor.exe
case sensitive: false

# Response
- action: report
  name: wanacry
- action: task
  command: history_dump
- action: task
  command:
    - deny_tree
    - <<routing/this>>
```

### Classify Users

Tag any Sensor where the CEO logs in with "vip".

```
# Detection
op: is
event: USER_OBSERVED
path: event/USER_NAME
value: stevejobs
case sensitive: false

# Response
- action: add tag
  tag: vip
```

### SSH from External IP Address

The following example looks for connections to/from `sshd` involving a non-RFC1918 IP Address. Be mindful that this is only looking for network connections, not actual logons, so this could be noisy on an internet-facing system but still indicative of an exposed service.

```
# Detection
event: NETWORK_CONNECTIONS
op: and
rules:
  - op: ends with
    path: event/FILE_PATH
    value: /sshd
  - op: is public address
    path: event/NETWORK_ACTIVITY/SOURCE/IP_ADDRESS

 # Response
- action: report
  name: >-
    SSH from EXTERNAL IP - {{ index (index .event.NETWORK_ACTIVITY 0) "SOURCE" "IP_ADDRESS" }}
```

The `report` uses [Go Templates](/v2/docs/template-strings-and-transforms) to include the offending IP address in the detection name.

### RDP from External IP Address

Similar to the above SSH example, this example looks for RDP connections from an external IP address. Be mindful that this is only looking for network connections, not actual logons, so this could be noisy on an internet-facing system but still indicative of an exposed service.

```
# Detection
event: NETWORK_CONNECTIONS
op: and
rules:
  - op: is
    path: event/FILE_PATH
    value: C:\WINDOWS\System32\svchost.exe
  - op: contains
    path: event/COMMAND_LINE
    value: TermService
  - op: is
    path: event/NETWORK_ACTIVITY/DESTINATION/PORT
    value: 3389
  - op: is public address
    path: event/NETWORK_ACTIVITY/SOURCE/IP_ADDRESS

# Response
- action: report
  name: >-
    RDP from EXTERNAL IP - {{ index (index .event.NETWORK_ACTIVITY 0) "SOURCE" "IP_ADDRESS" }}
```

The `report` uses [Go Templates](/v2/docs/template-strings-and-transforms) to include the offending IP address in the detection name.

### Suspicious Windows Executable Names

```
# Detection
event: CODE_IDENTITY
op: matches
path: event/FILE_PATH
case sensitive: false
re: .*((\\.txt)|(\\.doc.?)|(\\.ppt.?)|(\\.xls.?)|(\\.zip)|(\\.rar)|(\\.rtf)|(\\.jpg)|(\\.gif)|(\\.pdf)|(\\.wmi)|(\\.avi)|( {5}.*))\\.exe

# Response
- action: report
  name: Executable with suspicious double extension
```

### Disable an Event at the Source

Turn off the sending of a specific event to the cloud. Useful to limit some verbose data sources when not needed.

```
# Detection
event: CONNECTED
op: is platform
name: windows

# Response
- action: task
  command: exfil_del NEW_DOCUMENT
```

### Windows Event Logs

A simple example of looking for a specific Event ID in WEL events.

```
# Detection
event: WEL
op: and
rules:
  - op: is
    path: event/EVENT/System/EventID
    value: '4625'
  - op: is
    path: event/EVENT/System/Channel
    value: Security

# Response
- action: report
  name: Failed Logon
```

### Nested Logic

An example demonstrating nested boolean logic. This detection looks specifically for the following conditions:
 ((`4697` OR `7045`) in the `System` log) OR (`4698` in the `Security` log)

```
# Detection
event: WEL
op: or
rules:
  - op: and
    rules:
      - op: is
        path: event/EVENT/System/Channel
        value: System
      - op: or
        rules:
          - op: is
            path: event/EVENT/System/EventID
            value: '4697'
          - op: is
            path: event/EVENT/System/EventID
            value: '7045'
  - op: and
    rules:
      - op: is
        path: event/EVENT/System/Channel
        value: Security
      - op: is
        path: event/EVENT/System/EventID
        value: '4698'
```

### File Integrity Monitoring

#### Monitoring Sensitive Directories

Make sure the File Integrity Monitoring of some directories is enabled whenever Windows sensors connect.

```
# Detection
event: CONNECTED
op: is platform
name: windows

# Response
- action: task
  command: fim_add --pattern 'C:\*\Programs\Startup\*' --pattern '\REGISTRY\*\Microsoft\Windows\CurrentVersion\Run*'
```

Similar example for a Linux web server.

```
# Detection
event: CONNECTED
op: is platform
name: linux

# Response
- action: task
  command: fim_add --pattern '/var/www/*'
```

#### FIM Hit Detection

Adding a FIM pattern with `fim_add` by itself will only cause `FIM_HIT` events to be generated on the affected system's timeline. To know that we have positive hits on a FIM rule, we want to capture the relevant event and generate a proper Detection.

```
# Detection
event: FIM_HIT
op: exists
path: event/FILE_PATH

# Response
- action: report
  name: FIM Hit - {{ .event.FILE_PATH }}
```

### YARA Scanning

Resource Utilization

Performing CPU intensive actions such as YARA scanning can impact endpoint performance if not optimized. Be sure to always test rules that carry out sensor commands (like the examples below) before deploying at scale in production. Use [suppression](/v2/docs/response-actions#suppression) to prevent runaway conditions.

Here are a few examples of using D&R rules to initiate automatic YARA scans on an endpoint. Note that the defined YARA rule must exist in your org before using it in a D&R rule.

#### YARA Scan Processes

This  example looks for `NEW_PROCESS` events that meet certain criteria, then initiates a YARA scan against the offending process ID in memory. Note, this or a similar D&R rule will also depend on a companion [YARA Detection](/v2/docs/detection-and-response-examples#yara-detections) rule.

```
# Detection
event: NEW_PROCESS
op: and
rules:
  - op: starts with
    path: event/FILE_PATH
    value: C:\Users\
  - op: contains
    path: event/FILE_PATH
    value: \Downloads\

# Response
## Report is optional, but informative
- action: report
  name: Execution from Downloads directory
## Initiate a sensor command to yara scan the PROCESS_ID
- action: task
  command: yara_scan hive://yara/malware-rule --pid "{{ .event.PROCESS_ID }}"
  investigation: Yara Scan Process
  suppression:
    is_global: false
    keys:
      - '{{ .event.PROCESS_ID }}'
      - Yara Scan Process
    max_count: 1
    period: 1m
```

Notice the use of `suppression` to prevent the same `PROCESS_ID` from being scanned more than once per minute to prevent a resource runaway situation.

#### YARA Scan Files

This  example looks for `NEW_DOCUMENT` events that meet certain criteria, then initiates a YARA scan against the offending file path. Note, this or a similar D&R rule will also depend on a companion [YARA Detection](/v2/docs/detection-and-response-examples#yara-detections) rule.

```
# Detection
event: NEW_DOCUMENT
op: and
rules:
  - case sensitive: false
    op: matches
    path: event/FILE_PATH
    re: .\:\\(users|windows\\temp)\\.*
  - case sensitive: false
    op: matches
    path: event/FILE_PATH
    re: .*\.(exe|dll)

# Response
## Report is optional, but informative
- action: report
  name: Executable written to Users or Temp (yara scan)
## Initiate a sensor command to yara scan the FILE_PATH
- action: task
  command: yara_scan hive://yara/malware-rule -f "{{ .event.FILE_PATH }}"
  investigation: Yara Scan Executable
  suppression:
    is_global: false
    keys:
      - '{{ .event.FILE_PATH }}'
      - Yara Scan Executable
    max_count: 1
    period: 1m
```

Notice the use of `suppression` to prevent the same `FILE_PATH` from being scanned more than once per minute to prevent a resource runaway situation.

### YARA Detections

Running a YARA scan by itself only sends a `YARA_DETECTION` event to the affected system's timeline. To know that we have positive hits on a YARA scan, we want to capture the relevant event and generate a proper Detection. The following two examples split out a YARA detection on-disk, versus in-memory. Notice we simply check for the presence of `event/PROCESS/*` fields to determine if it's a file or process detection, which may have different severities to security teams (dormant malware versus running malware).

#### YARA Detection On-Disk (file)

```
# Detection
event: YARA_DETECTION
op: and
rules:
  - not: true
    op: exists
    path: event/PROCESS/*
  - op: exists
    path: event/RULE_NAME

# Response
- action: report
  name: YARA Detection on Disk - {{ .event.RULE_NAME }}
- action: add tag
  tag: yara_detection_disk
  ttl: 80000
```

#### YARA Detection In-Memory (process)

```
# Detection
event: YARA_DETECTION
op: and
rules:
  - op: exists
    path: event/RULE_NAME
  - op: exists
    path: event/PROCESS/*

# Response
- action: report
  name: YARA Detection in Memory - {{ .event.RULE_NAME }}
- action: add tag
  tag: yara_detection_memory
  ttl: 80000
```

Both rules will generate a Detection report and add a tag to the system which the detection occurred on.

### Mention of an Internal Resource

Look for references to private URLs in proxy logs.

```
# Detection
target: artifact
op: contains
path: /text
value: /corp/private/info

# Response
- action: report
  name: web-proxy-private-url
```

### De-duplicate Cloned Sensors

Sometimes users install a sensor on a VM image by mistake. This means every time a new instance of the image gets started the same sensor ID (SID) is used for multiple boxes with different names. When detected, LimaCharlie produces a `sensor_clone` event.

We can use these events to deduplicate. This example targets Windows clones.

```
# Detection
target: deployment
event: sensor_clone
op: is platform
name: windows

# Response
- action: re-enroll
```

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

#### Related articles

* [Detection and Response](/docs/detection-and-response)
* [Detection on Alternate Targets](/docs/detection-on-alternate-targets)
* [Stateful Rules](/docs/stateful-rules)

---

##### What's Next

* [Detection on Alternate Targets](/docs/detection-on-alternate-targets)

Table of contents

+ [Translating Existing Rules](#translating-existing-rules)
+ [Examples](#examples)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)
* [Getting started](/docs/en/tags/Getting%20started "Getting started")
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## Detection on Alternate Targets

# Detection on Alternate Targets
Detection & Response rules run against `edr` events by default, however, there are 7 other targets:

* `detection`
* `deployment`
* `artifact`
* `artifact_event`
* `schedule`
* `audit`
* `billing`

This article is to give some ideas of what they're used for, and how they're used.

## Target: detection

You can run rules on detections generated by other rules. This allows you to further filter existing detections
and change add a response behavior to certain special cases.

In the `detection` target, the `event:` or `events:` specified refer to the `name` of the detection specified in the
original detection's `report` action.

The `detection` target supports all of the same operators and actions as regular `edr` rules.

### Example

```
# Detection
target: detection
op: and
rules:
- op: is
  path: cat
  value: virus-total-hit
- op: is
  path: routing/hostname
  value: ceo-laptop

# Response
- action: extension request
  extension name: pagerduty
  extension action: run
  request:
    group: '{{ "lc-alerts" }}'
    severity: '{{ "critical" }}'
    component: '{{ "vip-alert" }}'
    summary: '{{ "Alert on a VIP endpoint." }}'
    source: '{{ "limacharlie.io" }}'
    class: '{{ "dr-rules" }}'
```

This rule takes a pre-existing detection report named `virus-total-hit` and sends it to PagerDuty if it occurs on a specific hostname.

## Target: deployment

Deployment events relate to sensors connecting to the cloud: `enrollment`, `sensor_clone`, `sensor_over_quota`, `deleted_sensor`.

Take the `sensor_clone` event as an example. This event can happen when a Sensor is installed in a VM image, leading to duplicate sensor IDs connecting to the cloud. When this is detected we can use this event to automate behavior to de-duplicate the sensor.

The `deployment` target supports all of the same operators and actions as regular `edr` rules.

### Example

```
# Detection
target: deployment
event: sensor_clone
op: is windows

# Response
- action: task
  command: file_del %windir%\system32\hcp.dat
- action: task
  command: file_del %windir%\system32\hcp_hbs.dat
- action: task
  command: file_del %windir%\system32\hcp_conf.dat
- action: task
  command: restart
```

This rule de-duplicates sensors on Windows by deleting `.dat` files specific to the Windows installation and then issuing a `restart` sensor command.

> For samples of each `deployment` event type, see [Reference: Platform Events](/v2/docs/reference-platform-events).

## Target: artifact

Parsed artifacts can be run through the rule engine as if they were regular `edr` events, but there are some key differences. Namely, they support a subset of operators and actions, while adding some special parameters.

### Example

This rule will target parsed `/var/log/auth.log` entries to see if there are are auth failures.

```
# Detection
target: artifact
artifact type: txt
artifact path: /var/log/auth.log
op: matches
re: .*(authentication failure|Failed password).*
path: /text
case sensitive: false

# Response
- action: report
  name: Failed Auth
```

### Supported Operators

* `is`
* `and`
* `or`
* `exists`
* `contains`
* `starts with`
* `ends with`
* `is greater than`
* `is lower than`
* `matches`
* `string distance`

### Supported Resources

`lookup` and `external` resources are supported within rules just like the `edr` target.

### Supported Actions

The only response action supported for the `artifact` target is the `report` action.

### Special Parameters

* `artifact path`: matches the start of the artifact's `path` string, e.g. `/auth.log`
* `artifact type`: matches the artifact's `type` string, e.g. `pcap`, `zeek`, `auth`, `wel`
* `artifact source`: matches the artifact's `source` string, e.g. `hostname-123`

> Note: for duplicate Windows Event Log ingestions, the rule engine will use the log's `EventRecordID` to ensure a rule will not run more than once over the same record.

## Target: artifact\_event

For unparsed logs, it can be useful to use the `ingest` and `export_complete` lifecycle events from the `artifact_event` target to automate behaviors in response to artifacts.

> For samples of `ingest` and `export_complete`, see [Reference: Platform Events](/v2/docs/reference-platform-events).

### Example

```
# Detection
target: artifact_event
event: export_complete
op: starts with
path: routing/log_type
value: pcap
case sensitive: false

# Response
- action: report
  name: PCAP Artifact ready to Download
```

## Target: schedule

Schedule events are triggered automatically at various intervals per Organization or per Sensor, observable in  rules via the `schedule` target.

For more information, see [Reference: Schedule Events](/v2/docs/reference-schedule-events)

## Target: audit

Audit events are generated by the LimaCharlie platform and track changes and events from within the platform such as tasking, replays, hive changes, etc. These events can be viewed within the "Platform Logs" menu or by viewing events from the `audit-logs` sensor.

## Target: billing

Billing events are generated by the LimaCharlie platform and are related to aspects of the platform such as quotas, thresholds, and other cost-associated events. For an example, see the [Usage Alerts Extension](/v2/docs/ext-usage-alerts) documentation

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

### Related articles

* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Stateful Rules](/docs/stateful-rules)

---

#### What's Next

* [False Positive Rules](/docs/false-positive-rules)

Table of contents

+ [Target: detection](#target-detection)
+ [Target: deployment](#target-deployment)
+ [Target: artifact](#target-artifact)
+ [Target: artifact\_event](#target-artifact_event)
+ [Target: schedule](#target-schedule)
+ [Target: audit](#target-audit)
+ [Target: billing](#target-billing)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)

---

## False Positive Rules

# False Positive Rules
To reduce the number of false positives, you may want to create false positive (FP) rules. FP rules filter out detections generated by the `report` action of detection & response (D&R) rules. These rules apply globally across all rule namespaces and targets.

There are multiple ways to create a false positive rule in LimaCharlie web app.

Have multiple organizations?

Similar to detection & response rules, false positive rules are created on a per tenant level. This means that if you have more than one organization you want to apply the rule to, you will want to:

* re-create the same rule in multiple organizations, or
* using our infrastructure as code functionality, push your FP rules to multiple tenants within seconds.

## Use Cases

The typical use case for FP rules is to add exceptions from some detections that are cross-cutting (for example ignore all detections from a specific host), organization-specific exceptions (like ignoring alerts relating to a custom piece of software used in an organization), or suppressing errors from managed  rules you don't have direct access to.

## Structure

False positive rules are structured roughly the same as the detection part of a D&R rule. The main difference is that instead of a direct event, the rule applies to the content of a detection, as can be seen in the **Detections** section of the web app.

The originating event for the detection can still be accessed at the `detect` path. This means that if ignoring something based on the event content, we only need to add `detect/` to the front of the `path` (see [example](#ignore-detections-for-specific-file-name)).

## Create a False Positive Rule From Detections

This is the quickest and the most common way to create a FP rule. On every detection, you can click the `Mark False Positive` button.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/fp-rules-1.png)

Clicking the button will pre-populate the details of the event and automatically generate a draft false positive rule which you can edit before saving.

After the rule is saved, it will appear in the **False Positives Rules** section and can be edited/deleted there.

## Create a False Positive rule from scratch

While creating FP rule from detections is a common and easy way to reduce the number of false positives, you do not need to wait for the detection to happen before creating a FP rule. The `False Positive Rules` section under `Automation` allows you to create a false positive rule from scratch.

To create a new false positive rule, click the `New Rule` button.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/fp-rules-2.png)

This will open a rule editor allowing you to create a new rule.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/fp-rules-3.png)

An FP rule is structured with the same format at the detection component of a D&R rule. The main difference is that the rule applies to the content of a detection, as can be seen in the Detections section of the web app.

You have the ability to set a rule name as well as an **Expiry Date** (optional). Setting an expiry date allows you to create a rule that will expire at a certain time.

Please note that expiry times must be set in the user's preferred time (not in UTC).

## Examples

Clicking the button will pre-populate the details of the event and automatically generate a draft false positive rule which you can edit before saving. The details about the structure of the false positive rules can be found in our technical documentation.

### Suppress a Specific Detection

Prevent a specific detection:

```
op: is
path: cat
value: my-detect-name
```

### Ignore Detections for Specific File Name

Ignore any detection that relates to a file name in any path.

```
op: ends with
path: detect/event/FILE_PATH
value: this_is_fine.exe
```

### Ignore Detections on a Specific Host

Any detection originating from a specific host will be ignored.

```
op: is
path: routing/hostname
value: web-server-2
```

---

#### Related articles

* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Detection on Alternate Targets](/docs/detection-on-alternate-targets)
* [Stateful Rules](/docs/stateful-rules)

---

##### What's Next

* [Stateful Rules](/docs/stateful-rules)

Table of contents

+ [Use Cases](#use-cases)
+ [Structure](#structure)
+ [Create a False Positive Rule From Detections](#create-a-false-positive-rule-from-detections)
+ [Create a False Positive rule from scratch](#create-a-false-positive-rule-from-scratch)
+ [Examples](#examples)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)

---

## Incident Response

# Incident Response
* 1 Minute to read

## What's Next

* [Build CTI Capabilities](/docs/build-cti-capabilities)

Tags

* [dfir](/docs/en/tags/dfir)
* [incident response](/docs/en/tags/incident%20response)
* [IR](/docs/en/tags/IR)
* [use case](/docs/en/tags/use%20case)

---

## Managed Rulesets

# Managed Rulesets
* 1 Minute to read

## Related articles

* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Soteria M365 Rules](/docs/soteria-m365-rules)
* [Soteria AWS Rules](/docs/soteria-aws-rules)
* [Stateful Rules](/docs/stateful-rules)
* [Detection on Alternate Targets](/docs/detection-on-alternate-targets)
* [Soteria Rules](/docs/soteria-rules)
* [Soteria EDR Rules](/docs/soteria-edr-rules)
* [Sigma Rules](/docs/sigma-rules)
* [Sigma Converter](/docs/sigma-converter)
* [Quickstart](/docs/quickstart)
* [SOC Prime Rules](/docs/soc-prime-rules)

---

### What's Next

* [Sigma Rules](/docs/sigma-rules)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)

---

## Reference

# Reference
2 Articles  in this category

---

## Replay

# Replay
Replay allows you to run [Detection & Response (D&R) rules](/v2/docs/detection-and-response) against historical traffic.
 This can be done in a few combinations of sources:

Rule Source:

* Existing rule in the organization, by name.
* Rule in the replay request.

Traffic:

* Sensor historical traffic.
* Local events provided during request.

## Using

Using the Replay API requires the [API key](/v2/docs/api-keys) to have the following permissions:

* `insight.evt.get`

The returned data from the API contains the following:

* `responses`: a list of the actions that would have been taken by the rule (like `report`, `task`, etc).
* `num_evals`: a number of evaluation operations performed by the rule. This is a rough estimate of the performance of the rule.
* `num_events`: the number of events that were replayed.
* `eval_time`: the number of seconds it took to replay the data.

```json
{
  "error": "",        // if an error occured.
  "stats": {
    "n_proc": 0,      // the number of events processed
    "n_shard": 0,     // the number of chunks the replay job was broken into
    "n_eval": 0,      // the number of operator evaluations performed
    "wall_time": 0    // the number of real-world seconds the job took
  },
  "did_match": false, // indicates if the rule matched any event at all
  "results": [],      // a list of dictionaries containing the details of actions the engine would have taken
  "traces": []        // a list of trace items to help you troubleshoot where a rule failed
}
```

### Query Language

To use Replay in [LCQL Mode](/v2/docs/lcql) (LimaCharlie Query Language), you can specify your query in the `query` parameter of the Replay Request (defined below) when using the REST interface, or you can use the LimaCharlie Python SDK/CLI's [query interface](https://github.com/refractionPOINT/python-limacharlie/blob/master/limacharlie/Query.py): `limacharlie query --help`.

### Python CLI

The [Python CLI](https://github.com/refractionPOINT/python-limacharlie) gives you a friendly way to replay data, and to do so across larger datasets by automatically splitting up your query into multiple queries that can run in parallel.

Sample command line to query one sensor:

```
limacharlie-replay --sid 9cbed57a-6d6a-4af0-b881-803a99b177d9 --start 1556568500 --end 1556568600 --rule-content ./test_rule.txt
```

Sample command line to query an entire organization:

```
limacharlie-replay --entire-org --start 1555359000 --end 1556568600 --rule-name my-rule-name
```

If specifying a rule as content with the `--rule-content`, the format should be
 in `JSON` or `YAML` like:

```
detect:
  event: DNS_REQUEST
  op: is
  path: event/DOMAIN_NAME
  value: www.dilbert.com
respond:
  - action: report
    name: dilbert-is-here
```

Instead of specifying the `--entire-org` or `--sid` flags, you may use events from a local file via the `--events` flag.

We invite you to look at the command line usage itself, as the tool evolves.

### REST API

The Replay API is available to all DataCenter locations using a per-location URL.
 To get the appropriate URL for your organization, use the REST endpoint to retrieve the URLs found [here](https://api.limacharlie.io/static/swagger/#/Organizations/getOrgURLs) named `replay`.

Having per-location URLs will allow us to guarantee that processing occurs within the geographical area you chose. Currently, some locations are NOT guaranteed to be in the same area due to the fact we are using the Google Cloud Run product which is not available globally. For these cases, processing is currently done in the United States, but as soon as it becomes available in your area, the processing will be moved transparently.

Authentication to this API works with the same JWTs as the main limacharlie.io API.

For this example, we will use the experimental datacenter's URL:

```
https://0651b4f82df0a29c.replay.limacharlie.io/
```

The API mainly works on a per-sensor basis, on a limited amount of time. Replaying for multiple sensors (or entire org), or longer time period is done through multiple parallel API calls. This multiplexing is taken care of by the Python CLI above.

To query Replay, do a `POST` with a `Content-Type` header of `application-json` and with a JSON body like:

```json
{
  "oid": "",             // OID this query relates to
  "rule_source": {       // rule source information (use one of "rule_name" or "rule")
    "rule_name": "",     // pre-existing rule name to run
    "namespace": "", // default: general namespace, can also be "managed" and "service"
    "rule": {            // literal rule to run
      "detect": {},
      "respond": []
    }
  },
  "event_source": {      // event source information (use one of "sensor_events" or "events")
    "sensor_events": {   // use historical events from sensors
      "sid": "",         // sensor id to replay from, or entire org if empty
      "start_time": 0,   // start second epoch time to replay from
      "end_time": 0      // end second epoch time to replay to
    },
    "events": [{}]       // literal list of events to replay
    "stream": "" // defaults to events, can also be "audit" or "detect"
  },
  "limit_event": 0,      // optional approximate number of events to process
  "limit_eval": 0,       // optional approximate number of operator evaluations to perform
  "trace": false,        // optional, if true add trace information to response, VERY VERBOSE
  "is_dry_run": false,   // optional, if true, an estimate of the total cost of the query will be returned
  "query": ""            // optional alternative way to describe a replay query as a LimaCharlie Query Language (LCQL) query.
}
```

Like the other endpoints you can also submit a `rule_name` in the URL query if you want
 to use an existing organization rule.

You may also specify a `limit_event` and `limit_eval` parameter as integers. They will limit the number of events evaluated and the number of rule evaluations performed (approximately). If the limits are reached, the response will contain an item named `limit_eval_reached: true` and `limit_event_reached: true`.

Finally, you may also set `trace` to `true` in the request to receive a detailed trace of the rule evaluation. This is useful in the development of new rules to find where rules are failing.

## Billing

The Replay service is billed on a per event evaluated.

---

### What's Next

* [Unit Tests](/docs/unit-tests)

Table of contents

+ [Using](#using)
+ [Billing](#billing)

---

## Response Actions

# Response Actions
## Overview

Actions in LimaCharlie Detection & Response () rules define what happens after a detection is triggered. Common actions include generating reports, tagging sensors, isolating networks, and the frequently used `task` action, which sends commands to an Endpoint Agent to interrogate or take action on the endpoint. This is useful for tasks like gathering system information or isolating a compromised endpoint. Suppression settings manage repetitive alerts by limiting action frequency, ensuring efficient automation and response workflows.

> For more information on how to use Actions, read [Detection & Response rules](/v2/docs/detection-and-response).

## Suppression

Suppression is valuable to help manage repetitive or noisy alerts.

### Reduce Frequency

In some cases, you may want to limit the number of times a specific Action is executed over a certain period of time. You can achieve this through `suppression`. This feature is supported in every Actions.

A suppression descriptor can be added to an Action like:

```
- action: report
  name: evil-process-detected
  suppression:
    max_count: 1
    period: 1h
    is_global: true
    keys:
      - '{{ .event.FILE_PATH }}'
      - 'evil-process-detected'
```

The above example means that the `evil-process-detected` detection will be generated up to once per hour per `FILE_PATH`. Beyond the first `report` with a given `FILE_PATH`, during the one hour period, new `report` actions from this rule will be skipped.

The `is_global: true` means that the suppression should operate globally within the Org (tenant), if the value was `false`, the suppression would be scoped per-Sensor.

The `keys` parameter is a list of strings that support [templating](/v2/docs/template-strings-and-transforms). Together, the unique combination of values of all those strings (ANDed) will be the uniqueness key this suppression rule uses. By adding to the keys the `{{ .event.FILE_PATH }}` template, we indicate that the `FILE_PATH` of the event generating this `report` is part of the key, while the constant string `evil-process detected` is just a convenient way for us to specify a value related to this specific detection. If the `evil process-detected` component of the key was not specified, then *all* actions that also just specify the `{{ .event.FILE_PATH }}` would be contained in this suppression. This means that using `is_global: true` and a complex key set, it is possible to suppress some actions across multiple Actions across multiple D&R rules.

> Supported Time Period Formats
>
> LimaCharlie supports the following formats for time periods: **ns**, **us** (or **µs**, both are accepted), **ms**, **s**, **m**, **h** (nanoseconds, microseconds, milliseconds, seconds, minutes, and hours, respectively)

### Threshold Activation

The other way to use suppression is using the `min_count` parameter. When set, the specific action will be suppressed until `min_count` number of activations have been received in that period.

Here's an example of this:

```
- action: report
  name: high-alerts
  suppression:
    min_count: 3
    max_count: 3
    period: 24h
```

The above example means the `high-alerts` detection will be generated once per hour but only after the rule the action belongs to has matched 3 times within that period.

This could be useful if you wanted to create higher order alerts that trigger a different type of detection, or send a page alert to a SOC, when more than X alerts occurred on a single host per period.

> Note: Both `min_count` and `max_count` must be specified when setting a threshold.

### Variable Count

It is also possible to increment a suppression by a value that's not one (`1`). This is achieved using the `count_path` parameter, which is a path (like `event/record/v`) pointing to an integer that should be used to increment the suppression counter.

This is useful for things like billing alerts, where we set a threshold activation (meaning "alert me if above X") where the threshold is reached by increments of billable values.

Here's an example of this:

```
detect:
    event: billing_record
    op: is
    path: event/record/k
    target: billing
    value: ext-strelka:bytes_scanned

respond:
    - action: report
      name: strelka-bytes-reached
      suppression:
        count_path: event/record/v
        is_global: true
        keys:
          - strelka-bytes-usage
        max_count: 1048576
        min_count: 1048576
        period: 24h
```

The above will alert (generate a detection in this case) when 1MB (1024 x 1024 x 1) of bytes have been billed by the Strelka Extension based on the `bytes_scanned` SKU, per 24h.

It does so by incrementing the suppression counter by the billed value (found in `event/record/v`), resetting after 24h, and if the value of 1MB is reached, alert once and only once.

## Available Actions

Actions allow you to specify "what" happens after a detection is found.

### add tag, remove tag

```
- action: add tag
  tag: vip
  entire_device: false # defaults to false
  ttl: 30 # optional
```

Adds or removes Tags on the sensor.

#### Optional Parameters

The `add tag` action can optionally take a `ttl` parameter that is a number of seconds the tag should remain applied to the sensor.

The `add tag` action can optionally have the `entire_device` parameter set to `true`. When enabled, the new tag will apply to the entire Device ID, meaning that every sensor that shares this Device ID will have the tag applied (and relevant TTL). If a Device ID is unavailable for the sensor, it will still be tagged.

This can be used as a mechanism to synchronize and operate changes across an entire device. A D&R rule could detect a behavior and then tag all sensors on the device so they may act accordingly, like start doing full pcap.

For example, this would apply the `full_pcap` to all sensors on the device for 5 minutes:

```
- action: add tag
  tag: full_pcap
  ttl: 300
  entire_device: true
```

### add var, del var

Add or remove a value from the variables associated with a sensor.

```
- action: add var
  name: my-variable
  value: <<event/VOLUME_PATH>>
  ttl: 30 # optional
```

The `add var` action can optionally take a `ttl` parameter that is a number of seconds the variable should remain in state for the sensor.

### extension request

Perform an asynchronous request to an extension the Organization is subscribed to.

```
- action: extension request
  extension name: dumper # name of the extension
  extension action: dump # action to trigger
  extension request:     # request parameters
    sid: '{{ .routing.sid }}'
    pid: event.PROCESS_ID
```

The `extension request` parameters will vary depending on the extension (see the relevant extension's schema). The `extension request` parameter is a [transform](/v2/docs/template-strings-and-transforms).

You can also specify a `based on report: true` parameter. When true (defaults to false), the transform for the `extension request` will be based on the latest `report` action's report instead of the original event. This means you MUST have a `report` action *before* the `extension request`.

### isolate network

Isolates the sensor from the network in a persistent fashion (if the sensor/host reboots, it will remain isolated). Only works on platforms supporting the `segregate_network` [sensor command](/v2/docs/reference-endpoint-agent-commands#segregatenetwork).

```
- action: isolate network
```

When the network isolation feature is used, LimaCharlie will block connections to all destinations other than the LimaCharlie cloud (so that you can perform an investigation, take remediation actions, and then ultimately remove the isolation to resume normal network operation). The host will maintain internet connectivity to allow for you to perform those actions.

> The `segregate_network` command is stateless, so if the endpoint reboots, it will not be in effect. The isolate network command in D&R rules is stateful, so it sets a flag in the cloud to make sure the endpoint remains isolated even after reboots.

### seal

Seals the sensor in a persistent fashion (if the sensor/host reboots, it will remain sealed). Only works on platforms supporting the `seal` [sensor command](/v2/docs/reference-endpoint-agent-commands#seal).

```
- action: seal
```

Sealing a sensor enables tamper resistance, preventing direct modifications to the installed EDR.

> The `seal` command is stateless, so if the endpoint reboots, it will not be in effect. The seal command in D&R rules is stateful, so it sets a flag in the cloud to make sure the endpoint remains sealed even after reboots.

### unseal

Removes the seal status of a sensor that had it set using `seal`.

```
- action: unseal
```

### output

Forwards the matched event to an Output identified by `name` in the `tailored` [stream](/v2/docs/outputs).

This allows you to create highly granular Outputs for specific events.

The `name` parameter is the name of the Output.

Example:

```
- action: output
  name: my-output
```

### rejoin network

Removes the isolation status of a sensor that had it set using `isolate network`.

```
- action: rejoin network
```

### report

```
- action: report
  name: my-detection-name
  publish: true # defaults to true
  priority: 3   # optional
  metadata:     # optional & free-form
    author: Alice (alice@wonderland.com)
  detect_data:  # additional free-form field that can be used for extraction of specific elements
```

Reports the match as a detection. Think of it as an alert. Detections go a few places:

* The `detection` Output stream
* The organization's Detections page (if `insight` is enabled)
* The D&R rule engine, for chaining detections

The `name`, `metadata` and `detect_data` parameters support [string templates](/v2/docs/template-strings-and-transforms) like `detected {{ .cat }} on {{ .routing.hostname }}`, note that the context of the transform is the detection itself and not the original event, so you would refer to `.detect.event.USER_NAME` and not `.event.USER_NAME` for example.

The `metadata` is generally used to populate information about the rule, its author, remediation etc.

The `detect_data` is generally used to extract specific parts of the detected event into a known format that can be common across multiple detection, like extracting the `domain` or `hash` field for example.

#### Limiting Scope

There is a mechanism for limiting scope of a `report`, prefixing `name` with `__` (double underscore). This will cause the detection
generated to be visible to chained D&R rules and Services, but the detection will *not* be sent to the Outputs for storage.

This is a useful mechanism to automate behavior using D&R rules without generating extra traffic that is not useful.

#### Optional Parameters

The `priority` parameter, if set, should be an integer. It will be added to the root of the detection report as `priority`.

The `metadata` parameter, if set, can include any data. It will be added to the root of the detection report as `detect_mtd`. This can be used to include information for internal use like reference numbers or URLs.

### task

```
- action: task
  command: history_dump
  investigation: susp-process-inv
```

Sends a task in the `command` parameter to the sensor that the event under evaluation is from.

An optional `investigation` parameter can be given to create a unique identifier for the task and any events emitted from the sensor as a result of the task.

The `command` parameter supports [string templates](/v2/docs/template-strings-and-transforms) like `artifact_get {{ .event.FILE_PATH }}`.

> To view all possible commands, see [Endpoint Agent Commands](/v2/docs/reference-endpoint-agent-commands)

### undelete sensor

Un-deletes a sensor that was previously deleted.

```
detect:
    target: deployment
    event: deleted_sensor
    op: is
    path: routing/event_type
    value: deleted_sensor
respond:
    - action: undelete sensor
```

This can be used in conjunction with the `deleted_sensor` event to allow sensors to rejoin the fleet.

### wait

Adds a delay (up to 1 minute) before running the next response action.

This can be useful if a previous response action needs to finish running (i.e. a command or payload run via `task`) before you can execute the next action.

> The `wait` action will block processing any events from that sensor for the specified duration of time. This is because D&R rules are run at wire-speed and in-order.

The `duration` parameter supports two types of values:

* A string describing a duration, like `5s` for 5 seconds or `10ms` for 10 milliseconds, as defined by [this function call](https://pkg.go.dev/time#ParseDuration).
* An integer representing a number of seconds.

Example:

```
- action: wait
  duration: 10s
```

and

```
- action: wait
  duration: 5
```

### add hive tag

Adds a tag to a Hive record. This can be used to mark some Hive records like D&R rules automatically.

```
- action: add hive tag
  hive name: dr-general
  record name: my-rule
  tag: high-hit
```

Unless the rule is not expected to hit often, you likely want to couple this with a `suppression` statement to avoid doing a lot of tagging of the same rules like:

```
- action: add hive tag
  hive name: dr-general
  record name: my-rule
  tag: high-hit
  suppression:
    max_count: 1
    period: 1h
    is_global: true
    keys:
      - 'high-hit'
      - 'hive-tag'
```

### remove hive tag

Removes a tag from a Hive record.

```
- action: remove hive tag
  hive name: dr-general
  record name: my-rule
  tag: high-hit
```

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Endpoint Detection & Response

---

#### Related articles

* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Stateful Rules](/docs/stateful-rules)
* [Endpoint Agent Commands](/docs/endpoint-agent-commands)
* [Reference: EDR Events](/docs/reference-edr-events)

---

##### What's Next

* [Platform Management](/docs/platform-management)

Table of contents

+ [Overview](#overview)
+ [Suppression](#suppression)
+ [Available Actions](#available-actions)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)
* [dfir](/docs/en/tags/dfir)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [reference](/docs/en/tags/reference)

---

## SOC Prime Rules

# SOC Prime Rules
* 1 Minute to read

## Related articles

* [Managed Rulesets](/docs/managed-rulesets)
* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Soteria Rules](/docs/soteria-rules)

---

### What's Next

* [Community Rules](/docs/community-rules)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)

---

## Sigma Rules

# Sigma Rules
* 1 Minute to read

## Related articles

* [Sigma Converter](/docs/sigma-converter)
* [Managed Rulesets](/docs/managed-rulesets)
* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Quickstart](/docs/quickstart)

---

### What's Next

* [Sigma Converter](/docs/sigma-converter)

Table of contents

+ [Enabling Sigma](#enabling-sigma)
+ [Identifying Sigma Rule Hits](#identifying-sigma-rule-hits)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)

---

## Soteria AWS Rules

# Soteria AWS Rules
* 1 Minute to read

## Related articles

* [Soteria M365 Rules](/docs/soteria-m365-rules)
* [Soteria Rules](/docs/soteria-rules)
* [Soteria EDR Rules](/docs/soteria-edr-rules)
* [Managed Rulesets](/docs/managed-rulesets)

---

### What's Next

* [Soteria EDR Rules](/docs/soteria-edr-rules)

Table of contents

+ [Enabling Soteria's AWS Rules](#enabling-soteria-s-aws-rules)

Tags

* [aws](/docs/en/tags/aws)
* [detection and response](/docs/en/tags/detection%20and%20response)

---

## Soteria M365 Rules

# Soteria M365 Rules
Soteria's O365 ruleset provides coverage across O365 (aka M365) telemetry streams. The ruleset is designed for in-depth analysis of the Office 365 ecosystem which includes:

* Teams
* Word
* Excel
* PowerPoint
* Outlook
* OneDrive
* ...and other productivity applications.

Data access

Please note that Soteria won’t get access to your data, and you won’t be able to see or edit their rules - LimaCharlie acts as a broker between the two parties.

To leverage detection logic provided by the ruleset:

1. Subscribe your tenant to the [Soteria Office 365 ruleset extension](https://app.limacharlie.io/add-ons/extension-detail/soteria-rules-o365)
2. Subscribe your tenant to [tor](https://app.limacharlie.io/add-ons/detail/tor-ips) lookup (provided at no cost).
3. Configure Office 365 Sensor to start collecting [Office 365 audit logs](/v2/docs/adapter-types-microsoft-365).

## Enabling Soteria's O365 Rules

Soteria's O365 rules can be activated via two means.

### Activating via the Web UI

To enable Soteria's O365 ruleset, navigate to the Extensions section of the Add-On Marketplace and search for Soteria. You can also directly select `soteria-rules-o365`.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/soteria-o365-1.png)

*Please note: Pricing may reflect when the screenshot was taken, not the actual pricing*

Under the Organization dropdown, select a tenant (organization) you want to subscribe to Soteria O365 rules and click **Subscribe**.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/soteria-o365-2.png)

You can also manage add-ons from the **Subscriptions** menu under **Billing**.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/soteria-o365-3.png)

### Infrastructure as Code

Alternatively, to manage tenants and LimaCharlie functionality at scale, you can leverage our Infrastructure as Code functionality.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

#### Related articles

* [Soteria AWS Rules](/docs/soteria-aws-rules)
* [Soteria Rules](/docs/soteria-rules)
* [Soteria EDR Rules](/docs/soteria-edr-rules)
* [Managed Rulesets](/docs/managed-rulesets)
* [Microsoft 365](/docs/adapter-types-microsoft-365)
* [Microsoft 365](/docs/ext-cloud-cli-microsoft365)
* [Cloud CLI](/docs/ext-cloud-cli)

---

##### What's Next

* [SOC Prime Rules](/docs/soc-prime-rules)

Table of contents

+ [Enabling Soteria's O365 Rules](#enabling-soteria-s-o365-rules)

Tags

* [azure](/docs/en/tags/azure)
* [detection and response](/docs/en/tags/detection%20and%20response)
* [m365](/docs/en/tags/m365)

---

## Soteria Rules

# Soteria Rules
* 1 Minute to read

## Related articles

* [Soteria M365 Rules](/docs/soteria-m365-rules)
* [Soteria EDR Rules](/docs/soteria-edr-rules)
* [Soteria AWS Rules](/docs/soteria-aws-rules)
* [Managed Rulesets](/docs/managed-rulesets)

---

### What's Next

* [Soteria AWS Rules](/docs/soteria-aws-rules)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)

---

## Stateful Rules

# Stateful Rules
## Overview

> It's recommended to first read [Detection & Response rules](/v2/docs/detection-and-response) before diving into stateful rules.

In LimaCharlie, a Stateful Rule tracks and remembers the state of past events to make decisions based on historical context. Unlike stateless rules, which evaluate events in isolation, stateful rules can detect patterns over time, such as multiple failed logins within an hour. This enables more complex and accurate detection, allowing users to trigger actions only when specific conditions are met across multiple events or timeframes.

Events in LimaCharlie have well-defined relationships to one another using `routing/this`, `routing/parent`, `routing/target`, and can even be implicitly related by occurring in a similar timeframe. The relation context can be useful for writing more complex rules.

These are called "stateful" rules.

## Detecting Children / Descendants

To detect events in a tree you can use the following parameters:

* `with child`: matches children of the initial event
* `with descendant`: matches descendants (children, grandchildren, etc.) of the initial event

Aside from how deep they match, the `with child` and `with descendant` parameters operate identically: they declare a nested stateful rule.

For example, let's detect a `cmd.exe` process spawning a `calc.exe` process:

```
# Detect initial event
event: NEW_PROCESS
op: ends with
path: event/FILE_PATH
value: cmd.exe
case sensitive: false
with child: # Wait for child matching this nested rule
  op: ends with
  event: NEW_PROCESS
  path: event/FILE_PATH
  value: calc.exe
  case sensitive: false
```

Simply put, this will detect:

```
cmd.exe --> calc.exe
```

Because it uses `with child` it will not detect:

```
cmd.exe --> firefox.exe --> calc.exe
```

To do that, we could use `with descendant` instead.

## Detecting Proximal Events

To detect repetition of events close together on the same Sensor, we can use `with events`.

The `with events` parameter functions very similarly to `with child` and `with descendant`: it declares a nested stateful rule.

For example, let's detect a scenario where `5` bad login attempts occur within `60` seconds.

```
event: WEL
op: is windows
with events:
  event: WEL
  op: is
  path: event/EVENT/System/EventID
  value: '4625'
  count: 5
  within: 60
```

The top-level rule filters down meaningful events to `WEL` ones sent from Windows sensors using the `is windows` operator, and then it declares a stateful rule inside `with events`. It uses `count` and `within` to declare a suitable timespan to evaluate matching events.

## Stateful Rules

Stateful rules — the rules declared within `with child`, `with descendant` or `with events` — have full range. They can do anything a normal rule might do, including declaring nested stateful rules or using `and`/`or` operators to write more complex rules.

Here's a stateful rule that uses `and` to detect a specific combination of child events:

```
event: NEW_PROCESS
op: ends with
path: event/FILE_PATH
value: outlook.exe
case sensitive: false
with child:
  op: and
  rules:
    - op: ends with
      event: NEW_PROCESS
      path: event/FILE_PATH
      value: chrome.exe
      case sensitive: false
    - op: ends with
      event: NEW_DOCUMENT
      path: event/FILE_PATH
      value: .ps1
      case sensitive: false
```

The above example is looking for an `outlook.exe` process that spawns a `chrome.exe` process and drops a `.ps1` (powershell) file to disk. Like this:

```
outlook.exe
|--+--> chrome.exe
|--+--> .ps1 file
```

### Counting Events

Rules declared using `with child` or `with descendant` also have the ability to use `count` and `within` to help scope the events it will statefully match.

For example, a rule that matches on Outlook writing 5 new `.ps1` documents within 60 seconds:

```
event: NEW_PROCESS
op: ends with
path: event/FILE_PATH
value: outlook.exe
case sensitive: false
with child:
  op: ends with
  event: NEW_DOCUMENT
  path: event/FILE_PATH
  value: .ps1
  case sensitive: false
  count: 5
  within: 60
```

### Choosing Event to Report

A reported detection will include a copy of the event that was detected. When writing detections that match multiple events, the default behavior will be to include a copy of the initial parent event.

In many cases it's more desirable to get the latest event in the chain instead. For this, there's a `report latest event: true` flag that can be set. Piggy-backing on the earlier example:

```
# Detection
event: NEW_PROCESS
op: ends with
path: event/FILE_PATH
value: outlook.exe
case sensitive: false
report latest event: true
with child:
  op: and
  rules:
    - op: ends with
      event: NEW_PROCESS
      path: event/FILE_PATH
      value: chrome.exe
      case sensitive: false
    - op: ends with
      event: NEW_DOCUMENT
      path: event/FILE_PATH
      value: .ps1
      case sensitive: false

# Response
- action: report
  name: Outlook Spawning Chrome & Powershell
```

The event returned in the detection will be either the `chrome.exe` `NEW_PROCESS` event or the `.ps1` `NEW_DOCUMENT` event, whichever was last. Without `report latest event: true` being set, it would default to including the `outlook.exe` `NEW PROCESS` event.

### Flipping back to stateless

Since all operators under the `with child` and `with descentant` are operating in stateful mode (meaning all the nodes don’t have to match a single event, but can match over multiple events), sometimes you want a operator and the operators underneath to flip back to stateless mode where they must match a single event. You can achieve this by setting `is stateless: true` in the operator like:

```
# Detection
event: NEW_PROCESS
op: ends with
path: event/FILE_PATH
value: outlook.exe
case sensitive: false
report latest event: true
with child:
  op: and
  is stateless: true
  rules:
    - op: ends with
      event: NEW_PROCESS
      path: event/FILE_PATH
      value: evil.exe
      case sensitive: false
    - op: contains
      event: COMMAND_LINE
      path: event/FILE_PATH
      value: something-else
      case sensitive: false
```

## Caveats

### Testing Stateful Rules

Stateful rules are forward-looking only and changing a rule will reset its state.

Practically speaking, this means that if you change a rule that detects `excel.exe -> cmd.exe`, `excel.exe` will need to be relaunched while the updated rule is running for it to then begin watching for `cmd.exe`.

### Using Events in Actions

Using `report` to report a detection works according to the [Choosing Event to Report](#choosing-event-to-report) section earlier. Other actions have a subtle difference: they will *always* observe the latest event in the chain.

Consider the `excel.exe -> cmd.exe` example. The `cmd.exe` event will be referenced inside the response action if using lookbacks (i.e. `<<routing/this>>`). If we wanted to end the `excel.exe` process (and its descendants), we would write a `task` that references the parent of the current event (`cmd.exe`):

```
- action: task
  command: deny_tree <<routing/parent>>
```

In LimaCharlie, a Stateful Rule tracks and remembers the state of past events to make decisions based on historical context. Unlike stateless rules, which evaluate events in isolation, stateful rules can detect patterns over time, such as multiple failed logins within an hour. This enables more complex and accurate detection, allowing users to trigger actions only when specific conditions are met across multiple events or timeframes.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

#### Related articles

* [Detection on Alternate Targets](/docs/detection-on-alternate-targets)
* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)

---

##### What's Next

* [Managed Rulesets](/docs/managed-rulesets)

Table of contents

+ [Overview](#overview)
+ [Detecting Children / Descendants](#detecting-children-descendants)
+ [Detecting Proximal Events](#detecting-proximal-events)
+ [Stateful Rules](#stateful-rules)
+ [Caveats](#caveats)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)

---

## Tutorials

# Tutorials
2 Articles  in this category

---

## Writing and Testing Rules

# Writing and Testing Rules
Detection & Response () Rules are similar to Google Cloud Functions or AWS Lambda.
They allow you to push D&R rules to the LimaCharlie cloud where the rules will be applied
in real-time to data coming from the sensors.

D&R rules can also be applied to [Artifact Collection](/v2/docs/artifacts), but for now we will focus
on the simple case where it is applied to Sensor events.

For a full list of all rule operators and detailed documentation see the [Detection and Response](/v2/docs/detection-and-response) section.

## Life of a Rule

D&R rules are generally applied on a per-event basis. When the rule is applied, the "detection"
component of the rule is processed to determine if it matches. If there is a match, the "response"
component is applied.

The detection is processed one step at a time, starting at the root of the detection. If the
root matches, the rule is considered to be matching.

The detection component is composed of "nodes", where each node has an operator describing the
logical evaluation. Most operators are simple, like `is`, `starts with` etc. These simple nodes
can be combined with Boolean (true/false) logic using the `and` and `or` operators, which
themselves reference a series of nodes. The `and` node matches if all the sub-nodes match, while
the `or` node matches if any one of the sub-nodes matches.

When evaluating an `or`, as soon as the first matching sub-node is found, the rest of the sub-nodes
are skipped since they will have no impact on the final matching state of the "or". Similarly, failure of a sub-node in an "and" node will immediately terminate its evaluation.

If the "detection" component is matched, then the "response" evaluation begins.

The "response" component is a list of actions that should be taken. When an action refers to a
sensor, that sensor is assumed to be the sensor the event being evaluated is coming from.

The best general strategy for D&R rules is to put the parts of the rule most likely
to eliminate the event at the beginning of the rule, so that LC may move on to the next event
as quickly as possible.

## Introduction

### Goal

The goal of is code lab will be to create a D&R rule to detect the MITRE ATT&CK framework
[Control Panel Items](https://attack.mitre.org/techniques/T1196/) execution.

### Services Used

This code lab will use the Replay service to validate and test the rule prior to pushing it to production.

## Setup and Requirements

This code lab assumes you have access to a Linux host (MacOS terminal with `brew`). This
code lab also assumes you have "owner" access to an LC Organization. If you don't have
one already, create one, this code lab is compatible with the free tier that comes with
all organizations.

### Install CLI

Interacting with LC can always be done via the [web app](https://app.limacharlie.io) but
day to day operations and automation can be done via the Command Line Interface (CLI). This
will make following this code lab easier.

Install the CLI: `pip install limacharlie --user`. If you don't have `pip` installed, install
it, the exact instructions will depend on your Linux distribution.

### Create REST API Key

We need to create an API key we can use in the CLI to authenticate with LC. To do so, go
to the REST API section of the web app.

1. In the REST API section, click the "+" button in the top right of the page.
2. Give your key a name.
3. For simplicity, click the "Select All" button to enable all permissions. Obviously this would not be a recommended in a production environment,
4. Click the copy-to-clipboard button for the new key and take note of it (pasting it in a temporary text note for example).
5. Back on the REST API page, copy the "Organization ID" at the top of the page and keep note of it like the API key in the previous step.

The Organization ID (OID) identifies uniquely your organization while the API key grants specific permissions to this organization.

### Login to the CLI

Back in your terminal, log in with your credentials: `limacharlie login`.

1. When asked for the Organization ID, paste your OID from the previous step.
2. When asked for a name for this access, you can leave it blank to set the default credentials.
3. When asked for the secret API key, enter the key you got from the previous step.

You're done! If you issue a `limacharlie dr list` you should not get any errors.

## Draft Rule

To draft our rule, open your preferred text editor and save the rule to a file, we'll call it `T1196.rule`.
The format of a rule is [YAML](https://en.wikipedia.org/wiki/YAML), if you are unfamiliar with it, there is benefit to spending a few minutes getting familiar. It won't take long as it is not overly complex.

For our rules based on the [T1196](https://attack.mitre.org/techniques/T1196/) technique, we need
to apply the following constraints:

1. It only applies to Windows.
2. The event is a module (DLL for example on Windows) loading.
3. The module loading ends with `.cpl` (control panel extension).
4. The module is loading from outside of the `C:\windows\` directory.

LC supports a lot of different event types, this means that the first thing we should strive to
do to try to make the rule fail as quickly as possible is to filter all events we don't care about.

In this case, we only care about [CODE\_IDENTITY](/v2/docs/reference-edr-events#codeidentity) events. We also know that
our rule will use more than one criteria, and those criteria will be AND-ed together because we only
want to match when they all match.

```
op: and
event: CODE_IDENTITY
rules:
  -
```

The above sets up the criteria #2 preceding it, with the AND-ing that will follow. Since the AND is at the
top of our rule, and it has an `event:` clause, it will ensure that any event processed by this rule
but is NOT a `CODE_IDENTITY` event will be skipped over right away.

Next, we should look at the other criteria, and add them to the `rules:` list, which are all the sub-nodes
that will be AND-ed together.

Criteria #1 was to limit to Windows, that's easy:

```
op: and
event: CODE_IDENTITY
rules:
  - op: is windows
  -
```

Next up is criteria #3 and #4. Both of those can be determined using the `FILE_PATH` component of the
`CODE_IDENTITY` event. If you are unure what those events look like, the best way to get a positive confirmation
of the structure is simply to open the Historic View, start a new process on that specific host and look for
the relevant event. If we were to do this on a Windows host, we'd get an example like this one:

```json
{
    "routing": {
        "parent": "...",
        "this": "...",
        "hostname": "WIN-...",
        "event_type": "CODE_IDENTITY",
        "event_time": 1567438408423,
        "ext_ip": "XXX.176.XX.148",
        "event_id": "11111111-1111-1111-1111-111111111111",
        "oid": "11111111-1111-1111-1111-111111111111",
        "plat": 268435456,
        "iid": "11111111-1111-1111-1111-111111111111",
        "sid": "11111111-1111-1111-1111-111111111111",
        "int_ip": "172.XX.223.XXX",
        "arch": 2,
        "tags": [
            "..."
        ],
        "moduleid": 2
    },
    "ts": "2019-09-02 15:33:28",
    "event": {
        "HASH_MD5": "7812c2c0a46d1f0a1cf8f2b23cd67341",
        "HASH": "d1d59eefe1aeea20d25a848c2c4ee4ffa93becaa3089745253f9131aedc48515",
        "ERROR": 0,
        "FILE_INFO": "10.0.17134.1",
        "HASH_SHA1": "000067ac70f0e38f46ce7f93923c6f5f06ecef7b",
        "SIGNATURE": {
            "FILE_CERT_IS_VERIFIED_LOCAL": 1,
            "CERT_SUBJECT": "C=US, S=Washington, L=Redmond, O=Microsoft Corporation, CN=Microsoft Windows",
            "FILE_PATH": "C:\\Windows\\System32\\setupcln.dll",
            "FILE_IS_SIGNED": 1,
            "CERT_ISSUER": "C=US, S=Washington, L=Redmond, O=Microsoft Corporation, CN=Microsoft Windows Production PCA 2011"
        },
        "FILE_PATH": "C:\\Windows\\System32\\setupcln.dll"
    }
}
```

This means what we want is to apply rules to the `event/FILE_PATH`. First part, #3 is easy, we just want
to test for the `event/FILE_PATH` ends in `.cpl`, we can do this using the `ends with` operator.

Most operators will use a `path` and a `value`. General convention is the `path` describes
how to get to a value we want to compare within the event. So `event/FILE_PATH` says "starting in the `event`
then get the `FILE_PATH`. The `value` generally represents a value we want to compare to the element found
in the `path`. How it is compared depends on the operator.

```
op: and
event: CODE_IDENTITY
rules:
  - op: is windows
  - op: ends with
    path: event/FILE_PATH
    value: .cpl
```

That was easy, but we're missing a critical component! By default, D&R rules operate in a case sensitive mode.
This means that the above node we added will match `.cpl` but will NOT match `.cPl`. To fix this, we just add
the `case sensitive: false` statement.

```
op: and
event: CODE_IDENTITY
rules:
  - op: is windows
  - op: ends with
    path: event/FILE_PATH
    value: .cpl
    case sensitive: false
  -
```

Finally, we want to make sure the `event/FILE_PATH` is NOT in the `windows` directory. To do this, we will use
a regular expression with a `matches` operator. But in this case, we want to EXCLUDE the paths that include
the `windows` directory, so we want to "invert" the match. We can do this with the `not: true` statement.

```
op: and
event: CODE_IDENTITY
rules:
  - op: is windows
  - op: ends with
    path: event/FILE_PATH
    value: .cpl
    case sensitive: false
  - op: matches
    path: event/FILE_PATH
    re: ^.\:\\windows\\
    case sensitive: false
    not: true
```

Here we go, we're done drafting our first rule.

## Validate Rule

What we want to do now is validate the rule. If the rule validates, it doesn't mean it's correct, it
just means that the structure is correct, the operators we use are known, etc. It's the first pass at
detecting possible formatting issues or typos.

To validate, we will simply leverage the Replay service. This service can be used to test rules or replay
historical events against a rule. In this case however, we just want to start by validating.

Up until now we focused on the "detection" part of the rule. But a full rule also contains a "response"
component. So before we proceed, we'll add this structure. For a response, we will use a
simple `action: report`. The `report` creates a "detection" (alert).

```
detect:
  op: and
  event: CODE_IDENTITY
  rules:
    - op: is windows
    - op: ends with
      path: event/FILE_PATH
      value: .cpl
      case sensitive: false
    - op: matches
      path: event/FILE_PATH
      re: ^.\:\\windows\\
      case sensitive: false
      not: true
respond:
  - action: report
    name: T1196
```

Now validate: `limacharlie replay --validate --rule-content T1196.rule`

After a few seconds, you should see a response with `success: true` if the rule
validates properly.

## Test rule

### Test Plan

Now that we know our rule is generally sound, we need to test it against some events.

Our test plan will take the following approach:

1. Test a positive (a `.cpl` loading outside of `windows`).
2. Test a negative for the major criteria:

   1. Test a non-`.cpl` loading outside of `windows` does not match.
   2. Test a `.cpl` loading within `windows` does not match.
3. Test on historical data.

With this plan, #1 and #2 lend themselves well to [unit tests](https://en.wikipedia.org/wiki/Unit_testing)
while #3 can be done more holistically by using Replay to run historical events
through the rule and evaluate if there are any [false positives](https://en.wikipedia.org/wiki/False_positives_and_false_negatives).

This may be excessive for you, or for certain rules which are very simple, we leave that
evaluation to you. For the sake of this code lab, we will do a light version to demonstrate
how to do tests.

### Testing a Single Event

To test #1 and #2, let's just create some synthetic events. It's always better to use
real-world samples, but we'll leave that up to you.

Take the event sample we had in the "Draft Rule" section and copy it to two new files
we will name `positive.json`, `negative-1.json` and `negative-2.json`.

Modify the `positive.json` file by renaming the `FILE_PATH` at the bottom from
`"C:\\Windows\\System32\\setupcln.dll"` to `"C:\\temp\\System32\\setupcln.cpl"` so that
the event now describes a `.cpl` loading in the `temp` directory, which we should detect.

Then modify the `negative-1.json` file by changing the same `.dll` to `.cpl`. This should NOT
match because the path is still in the `windows` directory.

Then modify the `negative-2.json` file by changing the `windows` directory to `temp`. This
should still NOT match because it's not a `.cpl`.

Now we can run our 3 samples against the rule using Replay,

`limacharlie replay --rule-content T1196.rule --events positive.json` should output a result
indicating the event matched (by actioning the `report`) like:

```json
{
  "num_evals": 4,
  "eval_time": 0.00020599365234375,
  "num_events": 1,
  "responses": [
    {
      "report": {
        "source": "11111111-1111-1111-1111-111111111111.11111111-1111-1111-1111-111111111111.11111111-1111-1111-1111-111111111111.10000000.2",
        "routing": {
...
```

`limacharlie replay --rule-content T1196.rule --events negative-1.json` should output a result
indicating the event did NOT match like:

```json
{
  "num_evals": 4,
  "eval_time": 0.00011777877807617188,
  "num_events": 1,
  "responses": [],
  "errors": []
}
```

`limacharlie replay --rule-content T1196.rule --events negative-2.json` be the same as `negative-1.json`.

### Testing Historical Data

The final test is to run the rule against historical data. If you are not using an
organization on the free tier, note that the Replay API is billed on usage. In the
following step we will run against all historical data from the organization, so if
your organization is not on the free tier and it is large, there may be non-trivial
costs associated.

Running our rule against the last week of data is simple:

`limacharlie replay --rule-content T1196.rule --entire-org --last-seconds 604800`

No matches should look like that:

```json
{
  "num_evals": 67354,
  "eval_time": 1107.2150619029999,
  "num_events": 222938,
  "responses": [],
  "errors": []
}
```

### Moving to Unit Tests

Once your rule is done and you’ve evaluated various events for matches, you can move these to [D&R Rules Unit Tests](/v2/docs/unit-tests) so that the tests are run during rule update.

## Publish Rule

Now is the time to push the new rule to production, the easy part.

Simply run `limacharlie dr add --rule-name T1196 --rule-file T1196.rule`
and confirm it is operational by running `limacharlie dr list`.

Amazon Web Services

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Command-line Interface

In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

In LimaCharlie, an Organization ID (OID) is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

---

### Related articles

* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Detection on Alternate Targets](/docs/detection-on-alternate-targets)
* [Sigma Converter](/docs/sigma-converter)

---

#### What's Next

* [Create a D&R Rule Using a Threat Feed](/docs/create-a-dr-rule-using-a-threat-feed)

Table of contents

+ [Introduction](#introduction)
+ [Setup and Requirements](#setup-and-requirements)
+ [Draft Rule](#draft-rule)
+ [Validate Rule](#validate-rule)
+ [Test rule](#test-rule)
+ [Publish Rule](#publish-rule)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

# Platform Management

## API Integrations

# API Integrations
* 1 Minute to read

## Related articles

* [Create a D&R Rule Using a Threat Feed](/docs/create-a-dr-rule-using-a-threat-feed)

---

### What's Next

* [alphaMountain](/docs/api-integrations-alphamountain)

Table of contents

+ [Mechanics](#mechanics)
+ [Configuration](#configuration)
+ [Available Lookups](#available-lookups)

Tags

* [add-ons](/docs/en/tags/add-ons)

---

## API Keys

# API Keys
LimaCharlie Cloud has a concept of API keys. Those are secret keys that can be created and named, and then in turn be used to retrieve a JWT that can be associated with the LC REST API at https://api.limacharlie.io.

This allows construction of headless applications able to securely acquire time-restricted REST authentication tokens it can then use.

The list of available permissions can be programmatically retrieved from this URL: <https://app.limacharlie.io/owner_permissions>

## Managing

The API Keys are managed through the Organization view of the https://limacharlie.io web interface.

## Getting a JWT

Simply issue an HTTP POST such as:

`curl -X POST "https://jwt.limacharlie.io" -H "Content-Type: application/x-www-form-urlencoded" -d "oid=<YOUR_OID>&secret=<YOUR_API_KEY>"`

where the `oid` parameter is the Organization ID as found through the web interface and the `secret` parameter is the API key.

The return value is a simple JSON response with a `jwt` component which is the JSON web token. This token is only valid for one hour to limit the possible damage of a leak, and make the deletion of the API keys easier.

Response:

`{ "jwt": "<JWT_VALUE_HERE>" }`

### User API Keys

User API keys are to generate JSON web tokens (JWTs) for the REST API. In contrast to Organization API keys, the User API keys are associated with a specific user and provide the exact same access across all organizations.

This makes User API Keys very powerful but also riskier to manage. Therefore we recommend using Organization API keys whenever possible.

The User API keys can be used through all the same interfaces as the Organization API keys. The only difference is how you get the JWT. Instead of giving an `oid` parameter to `https://jwt.limacharlie.io/`, provide it with a `uid` parameter available through the LimaCharlie web interface.

`curl -X POST "https://jwt.limacharlie.io" -H "Content-Type: application/x-www-form-urlencoded" -d "uid=<YOUR_USER_ID>&secret=<YOUR_API_KEY>"`

In some instances, the JWT resulting from a User API key may be to large for normal API use, in which case you will get an `HTTP 413 Payload too large` from the API gateway. In those instances, also provide an `oid` (on top of the `uid`) to the `jwt.limacharlie.io` REST endpoint to get a JWT valid only for that organization.

`curl -X POST "https://jwt.limacharlie.io" -H "Content-Type: application/x-www-form-urlencoded" -d "oid=<YOUR_OID>&uid=<YOUR_USER_ID>&secret=<YOUR_API_KEY>"`

You may also use a User API Key to get the list of organizations available to it by querying the following REST endpoint:

`https://app.limacharlie.io/user_key_info?secret=<YOUR_USER_API_KEY>&uid=<YOUR_USER_ID>&with_names=true`

#### Ingestion Keys

The [artifact collection](/v2/docs/artifacts) in LC requires Ingestion Keys, which can be managed through the REST API section of the LC web interface. Access to manage these Ingestion Keys requires the `ingestkey.ctrl` permission.

## Python

A simple [Python API](https://github.com/refractionpoint/python-limacharlie/) is also provided that simplifies usage of the REST API by taking care of the API Key -> JWT exchange as necessary and wraps the functionality into nicer objects.

## Privileges

API Keys have several on-off privileges available.

To see a full list, see the "REST API" section of your organization.

Making a REST call will fail with a `401` if your API Key / token is missing some privileges and the missing privilege will be specified in the error.

## Required Privileges

Below is a list of privileges required for some common tasks.

### Go Live

When "going Live" through the web UI, the following is required by the user:

* `output.*`: for the creation of the real-time output via HTTP to the browser.
* `sensor.task`: to send the commands (both manually for the console and to populate the various tabs) to the Sensor.

## Flair

API Keys may have "flair" as part of the key name. A flair is like a tag surrounded by `[]`. Although it is not required, we advise to put the flair at the end of the API key name for readability.

For example:
`orchestration-key[bulk]` is a key with a `bulk` flair.

Flairs are used to modify the behavior of an API key or provide some usage hints to various systems in LimaCharlie.

The following flairs are currently supported:

* `bulk`: indicates to the REST API that this key is meant to do a large amount of calls, the API gateway tweaks the API call limits accordingly.
* `segment`: indicates that only resources created by this key will be visible by this key. This is useful to provide access to a 3rd party in a limited fashion.

## Allowed IP Range

When creating an API key, you can optionally include an `allowed_ip_range`, which should be a [CIDR notation](https://aws.amazon.com/what-is/cidr/) IP range from which the API key can be used. Any use of the API key from a different IP address will fail. This is currently only configurable when creating an API key via the API and not in the UI.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

### Related articles

* [LimaCharlie SDK & CLI](/docs/limacharlie-sdk)

---

#### What's Next

* [User Access](/docs/user-access)

Table of contents

+ [Managing](#managing)
+ [Getting a JWT](#getting-a-jwt)
+ [Python](#python)
+ [Privileges](#privileges)
+ [Required Privileges](#required-privileges)
+ [Flair](#flair)
+ [Allowed IP Range](#allowed-ip-range)

Tags

* [api](/docs/en/tags/api)
* [platform](/docs/en/tags/platform)

---

## AWS CloudTrail

# AWS CloudTrail
[AWS CloudTrail](https://docs.aws.amazon.com/cloudtrail/) logs allow you to monitor AWS deployments. CloudTrail logs can provide granular visibility into AWS instances and can be used within [D&R rules](/v2/docs/detection-and-response) to identify AWS abuse.

This Adapter allows you to ingest AWS CloudTrail events via either an [S3 bucket](https://aws.amazon.com/s3/) or [SQS message queue](https://aws.amazon.com/sqs/).

CloudTrail events can be addressed in LimaCharlie as the `aws` platform.

## Adapter Deployment

All adapters support the same `client_options`, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.

* `client_options.identity.oid`: the LimaCharlie Organization ID (OID) this adapter is used with.
* `client_options.identity.installation_key`: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.
* `client_options.platform`: the type of data ingested through this adapter, like `text`, `json`, `gcp`, `carbon_black`, etc.
* `client_options.sensor_seed_key`: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.

### Adapter-specific Options

CloudTrail logs can be collected via a cloud-to-cloud Adapter, or via the CLI Adapter. Furthermore, within each option, there is a choice of collecting logs from an S3 bucket or an SQS message queue.

## Cloud-to-Cloud Adapter

Within the LimaCharlie web application, you can create an AWS CloudTrail Cloud Connector using the `+ Add Sensor` option.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28160%29.png)

After providing an Installation Key, you will be guided through connecting either an S3 bucket or SQS queue to ingest AWS CloudTrail events.

### Collecting AWS CloudTrail Logs via an S3 Bucket

If collecting CloudTrail logs via an S3 bucket, you will need the following parameters:

* `bucket_name` - The name of the S3 bucket holding the data)
* `secret_key` - The API key for AWS that has access to the respective bucket.
* `access_key` - The AWS access key for the API key

The following sample configuration can be used to create an S3 CLI Adapter for AWS CloudTrail events:

```
s3:
  client_options:
    hostname: aws-cloudtrail-logs
    identity:
      installation_key: <INSTALLATION_KEY>
      oid: <OID>
    platform: aws
    sensor_seed_key: super-special-seed-key
  bucket_name: <S3_BUCKET_NAME>
  secret_key: <S3_SECRET_KEY>
  access_key: <S3_ACCESS_KEY>
```

#### Collecting AWS CloudTrail Logs via an SQS Queue

If collecting CloudTrail logs via an SQS queue, you will need the following parameters:

* `secret_key` - The API key for AWS that has access to the respective bucket.
* `access_key` - The AWS access key for the API key
* `region` - The AWS region where the SQS instance lives
* `queue_url` - The URL to the SQS instance

The following sample configuration can be used to create an SQS CLI Adapter for AWS CloudTrail events:

```
sqs:
  client_options:
    hostname: aws-cloudtrail-logs
    identity:
      installation_key: <INSTALLATION_KEY>
      oid: <OID>
    platform: aws
    sensor_seed_key: super-special-seed-key
  region: <SQS_REGION>
  secret_key: <SQS_SECRET_KEY>
  access_key: <SQS_ACCESS_KEY>
  queue_url: <SQS_QUEUE_URL>
```

Amazon Web Services

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

##### Related articles

* [AWS GuardDuty](/docs/adapter-types-aws-guardduty)
* [AWS](/docs/ext-cloud-cli-aws)
* [Soteria AWS Rules](/docs/soteria-aws-rules)
* [Amazon S3](/docs/outputs-destinations-amazon-s3)
* [S3](/docs/adapter-types-s3)
* [SQS](/docs/adapter-types-sqs)

---

###### What's Next

* [AWS GuardDuty](/docs/adapter-types-aws-guardduty)

Table of contents

+ [Adapter Deployment](#adapter-deployment)
+ [Cloud-to-Cloud Adapter](#cloud-to-cloud-adapter)

Tags

* [adapters](/docs/en/tags/adapters)
* [aws](/docs/en/tags/aws)
* [sensors](/docs/en/tags/sensors)

---

## AWS GuardDuty

# AWS GuardDuty
## Overview

This Adapter allows you to ingest AWS GuardDuty events via either an [S3 bucket](https://aws.amazon.com/s3/) or [SQS message queue](https://aws.amazon.com/sqs/).

[AWS GuardDuty](https://aws.amazon.com/guardduty/) helps you protect your AWS accounts with intelligent threat detection.

Telemetry Platform: `guard_duty`

## Deployment Configurations

All adapters support the same `client_options`, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.

* `client_options.identity.oid`: the LimaCharlie Organization ID (OID) this adapter is used with.
* `client_options.identity.installation_key`: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.
* `client_options.platform`: the type of data ingested through this adapter, like `text`, `json`, `gcp`, `carbon_black`, etc.
* `client_options.sensor_seed_key`: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.

### Adapter-specific Options

#### Collecting AWS GuardDuty Logs via an S3 Bucket

If collecting GuardDuty logs via an S3 bucket, you will need the following parameters:

* `bucket_name` - The name of the S3 bucket holding the data)
* `secret_key` - The API key for AWS that has access to the respective bucket.
* `access_key` - The AWS access key for the API key

The following command will create an Adapter using the (1) Adapter binary and (2) logs stored in an S3 bucket:

```
./lc_adapter s3 client_options.identity.installation_key=<INSTALLATION_KEY> \
client_options.identity.oid=<OID> \
client_options.platform=guard_duty \
bucket_name=lc-ct-test \
access_key=YYYYYYYYYY \
secret_key=XXXXXXXX \
client_options.hostname=guardduty-logs
```

#### Collecting AWS GuardDuty Logs via an SQS Queue

If collecting GuardDuty logs via an SQS queue, you will need the following parameters:

* `secret_key` - The API key for AWS that has access to the respective bucket.
* `access_key` - The AWS access key for the API key
* `region` - The AWS region where the SQS instance lives
* `queue_url` - The URL to the SQS instance

The following command will create an Adapter using the (1) Adapter binary and (2) logs stored in an SQS queue:

```
./lc_adapter sqs client_options.identity.installation_key=<INSTALLATION_KEY> \
client_options.identity.oid=<OID> \
client_options.platform=guard_duty \
client_options.sensor_seed_key=<SENSOR_SEED_KEY> \
client_options.hostname=guardduty-logs \
access_key=YYYYYYYYYY \
secret_key=XXXXXXXX \
queue_url=<QUEUE_URL> \
region=<AWS-REGION>
```

## Guided Deployment

Within the LimaCharlie web application, you can create an AWS GuardDuty Cloud Connector using the `+ Add Sensor` option.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(304).png)

[AWS CloudTrail](https://docs.aws.amazon.com/cloudtrail/) logs allow you to monitor AWS deployments. CloudTrail logs can provide granular visibility into AWS instances and can be used within [D&R rules](/v2/docs/detection-and-response) to identify AWS abuse.

This adapter allows you to ingest AWS CloudTrail events via either an [S3 bucket](https://aws.amazon.com/s3/) or [SQS message queue](https://aws.amazon.com/sqs/).

CloudTrail events can be addressed in LimaCharlie as the `aws` platform.

## Adapter Deployment

All adapters support the same `client_options`, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.

* `client_options.identity.oid`: the LimaCharlie Organization ID (OID) this adapter is used with.
* `client_options.identity.installation_key`: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.
* `client_options.platform`: the type of data ingested through this adapter, like `text`, `json`, `gcp`, `carbon_black`, etc.
* `client_options.sensor_seed_key`: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.

### Adapter-specific Options

CloudTrail logs can be collected via a cloud-to-cloud Adapter, or via the CLI Adapter. Furthermore, within each option, there is a choice of collecting logs from an S3 bucket or an SQS message queue.

## Cloud-to-Cloud Adapter

Within the LimaCharlie web application, you can create an AWS CloudTrail Cloud Connector using the `+ Add Sensor` option.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(306).png)

After providing an Installation Key, you will be guided through connecting either an S3 bucket or SQS queue to ingest AWS CloudTrail events.

### Collecting AWS CloudTrail Logs via an S3 Bucket

If collecting CloudTrail logs via an S3 bucket, you will need the following parameters:

* `bucket_name` - The name of the S3 bucket holding the data)
* `secret_key` - The API key for AWS that has access to the respective bucket.
* `access_key` - The AWS access key for the API key

The following sample configuration can be used to create an S3 CLI Adapter for AWS CloudTrail events:

```
s3:
  client_options:
    hostname: aws-cloudtrail-logs
    identity:
      installation_key: <INSTALLATION_KEY>
      oid: <OID>
    platform: aws
    sensor_seed_key: super-special-seed-key
  bucket_name: <S3_BUCKET_NAME>
  secret_key: <S3_SECRET_KEY>
  access_key: <S3_ACCESS_KEY>
```

#### Collecting AWS CloudTrail Logs via an SQS Queue

If collecting CloudTrail logs via an SQS queue, you will need the following parameters:

* `secret_key` - The API key for AWS that has access to the respective bucket.
* `access_key` - The AWS access key for the API key
* `region` - The AWS region where the SQS instance lives
* `queue_url` - The URL to the SQS instance

The following sample configuration can be used to create an SQS CLI Adapter for AWS CloudTrail events:

```
sqs:
  client_options:
    hostname: aws-cloudtrail-logs
    identity:
      installation_key: <INSTALLATION_KEY>
      oid: <OID>
    platform: aws
    sensor_seed_key: super-special-seed-key
  region: <SQS_REGION>
  secret_key: <SQS_SECRET_KEY>
  access_key: <SQS_ACCESS_KEY>
  queue_url: <SQS_QUEUE_URL>
```

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Amazon Web Services

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

##### Related articles

* [AWS](/docs/ext-cloud-cli-aws)
* [AWS CloudTrail](/docs/adapter-types-aws-cloudtrail)
* [Soteria AWS Rules](/docs/soteria-aws-rules)
* [Amazon S3](/docs/outputs-destinations-amazon-s3)
* [S3](/docs/adapter-types-s3)
* [SQS](/docs/adapter-types-sqs)

---

###### What's Next

* [Azure Event Hub](/docs/adapter-types-azure-event-hub)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [Guided Deployment](#guided-deployment)
+ [Adapter Deployment](#adapter-deployment)
+ [Cloud-to-Cloud Adapter](#cloud-to-cloud-adapter)

Tags

* [adapters](/docs/en/tags/adapters)
* [aws](/docs/en/tags/aws)
* [sensors](/docs/en/tags/sensors)

---

## Adapter Deployment

# Adapter Deployment
Adapters can be deployed in one of two ways:

* **On-prem**, Adapters utilize the LC Adapter binary to ingest a data source and forward it to LimaCharlie.
* **Cloud-to-cloud**, connects the LimaCharlie cloud directly with your cloud source and automatically ingests data.

Which Adapter Do I Use for Cloud Data?

You can use on-prem adapters to forward cloud data, or you could acquire the same data with a cloud-to-cloud connection. So, which one to use?

The answer lies in *how* you want to send your data to LimaCharlie. Are you OK with configuring a connector from our platform, or would you rather use a bastion box in between? Either way works for us!

The data ingested from adapters is parsed/mapped into JSON by LimaCharlie, according to the parameters you provided, unless using a pre-defined format.

## Adapter Binaries

Software-based, or "on-prem" adapters are available in the following formats:

* Binaries:

  + \*nix

    - [AIX ppc64](https://downloads.limacharlie.io/adapter/aix/ppc64)
    - [Linux (Generic) 64-bit](https://downloads.limacharlie.io/adapter/linux/64)
    - [Linux (Generic) arm](https://downloads.limacharlie.io/adapter/linux/arm)
    - [Linux (Generic) arm64](https://downloads.limacharlie.io/adapter/linux/arm64)
    - [FreeBSD 64-bit](https://downloads.limacharlie.io/adapter/freebsd/64)
    - [OpenBSD 64-bit](https://downloads.limacharlie.io/adapter/openbsd/64)
    - [NetBSD 64-bit](https://downloads.limacharlie.io/adapter/netbsd/64)
    - [Solaris 64-bit](https://downloads.limacharlie.io/adapter/solaris/64)
  + macOS

    - [macOS x64](https://downloads.limacharlie.io/adapter/mac/64)
    - [macOS arm64](https://downloads.limacharlie.io/adapter/mac/arm64)
  + Windows

    - [Windows x64](https://downloads.limacharlie.io/adapter/windows/64)
* Docker:

  + <https://hub.docker.com/r/refractionpoint/lc-adapter>

Another platform?

If you need support for a specific platform, or require more information about supported platforms, please [let us know](https://www.limacharlie.io/contact).

## On-Prem + Cloud Management

LimaCharlie Adapters deployed manually (on-prem) also support cloud-based management. This makes the deployment of the adapter extremely easy while also making it easy to update the configs remotely after the fact. This is particularly critical for service providers that may be deploying adapters on customer networks where gaining access to the local adapter may be difficult.

To accomplish this, you need the `externaladapter.*` permissions.

### Preparing

The first step of deploying this way is to create a new External Adapter record. These are found in the `external_adapter` Hive or under the Sensors section of the web app.

The content of an external adapter is exactly the same as a traditional [adapter configuration](/v2/docs/adapter-usage) in YAML. It describes what you want your external adapter to do, like collect from file, operate as a syslog server etc. For example:

```
sensor_type: syslog
syslog:
  client_options:
    buffer_options: {}
    hostname: test-syslog
    identity:
      installation_key: aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa
      oid: bbbbbbbb-bbbb-bbbb-bbbb-bbbbbbbbbbbb
    mapping: {}
    platform: text
    sensor_seed_key: test-syslog
  port: 4242
```

Once your external adapter record is created, take note of the `GUID` (Globally Unique ID) found under the `sys_mtd` section of the JSON record, or on the right-hand side of the record view in the web app

.![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(308).png)

This `GUID` is a shared secret value you will use in the deployed adapter to reference it to the record it should update and operate from.

### Deploying

Now that the configuration of the adapter is ready, you can deploy the adapter on-prem according to the [normal process](/v2/docs/adapter-usage). The only difference is that instead of running it with the full configuration locally, you can run it with the `cloud` collection method like this:

```
./lc_adapter cloud conf_guid=XXXXXXXXXXXXXXXXXXXXx oid=YYYYYYYYYYYYYYYYYYY
```

This will start the adapter telling it to fetch the configuration it requires from the cloud based on the Organization ID (your tenant in LC) and the `GUID` of the record it should use.

From this point on, updating the record in LimaCharlie will automatically reconfigure the adapter on-prem, within about 1 minute of the change.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

---

#### Related articles

* [Adapter Usage](/docs/adapter-usage)
* [Adapter Types](/docs/adapter-types)
* [Adapter Examples](/docs/adapter-examples)
* [Adapter Tutorials](/docs/adapter-tutorials)
* [Tutorial: Ingesting Telemetry from Cloud-Based External Sources](/docs/tutorial-ingesting-telemetry-from-cloud-based-external-sources)
* [Installation Keys](/docs/installation-keys)
* [Mimecast](/docs/adapter-types-mimecast)

---

##### What's Next

* [Adapters as a Service](/docs/adapters-as-a-service)

Table of contents

+ [Adapter Binaries](#adapter-binaries)
+ [On-Prem + Cloud Management](#on-prem-cloud-management)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Adapter Examples

# Adapter Examples
3 Articles  in this category

---

## Adapter Tutorials

# Adapter Tutorials
3 Articles  in this category

---

## Adapter Types

# Adapter Types
39 Articles  in this category

---

## Adapter Usage

# Adapter Usage
The Adapter can be used to access many different sources and many different event types. The main mechanisms specifying the source and type of events are:

1. Adapter Type: this indicates the technical source of the events, like `syslog` or S3 buckets.
2. Platform: the platform indicates the type of events that are acquired from that source, like `text` or `carbon_black`.

Depending on the Adapter Type specified, configurations that can be specified will change. Running the adapter with no command line arguments will list all available Adapter Types and their configurations.

Configurations can be provided to the adapter in one of three ways:

1. By specifying a configuration file.
2. By specifying the configurations via the command line in the format `config-name=config-value`.
3. By specifying the configurations via the environment variables in the format `config-name=config-value`.

Here's an example config as a config file for an adapter using the `file` method of collection:

```
file: // The root of the config is the adapter collection method.
  client_options:
    identity:
      installation_key: e9a3bcdf-efa2-47ae-b6df-579a02f3a54d
      oid: 8cbe27f4-bfa1-4afb-ba19-138cd51389cd
    platform: json
    sensor_seed_key: testclient3
    mapping:
      event_type_path: syslog-events
  file_path: /var/log/syslog
```

## Multi-Adapter

It is possible to execute multiple instances of adapters of the same type within the same adapter process, for example to have a single adapter process monitor files in multiple directories with slightly different configurations.

This is achieved by using a configuration file (as described above) with multiple YAML "documents" within like this:

```
file:
  client_options:
    identity:
      installation_key: e9a3bcdf-efa2-47ae-b6df-579a02f3a54d
      oid: 8cbe27f4-bfa1-4afb-ba19-138cd51389cd
    platform: json
    sensor_seed_key: testclient1
    mapping:
      event_type_path: syslog-events
  file_path: /var/log/dir1/*

---

file:
  client_options:
    identity:
      installation_key: e9a3bcdf-efa2-47ae-b6df-579a02f3a54d
      oid: 8cbe27f4-bfa1-4afb-ba19-138cd51389cd
    platform: json
    sensor_seed_key: testclient2
    mapping:
      event_type_path: syslog-events
  file_path: /var/log/dir2/*

---

file:
  client_options:
    identity:
      installation_key: e9a3bcdf-efa2-47ae-b6df-579a02f3a54d
      oid: 8cbe27f4-bfa1-4afb-ba19-138cd51389cd
    platform: json
    sensor_seed_key: testclient3
    mapping:
      event_type_path: syslog-events
  file_path: /var/log/dir3/*
```

## Runtime Configuration

The Adapter runtime supports some custom behaviors to make it more suitable for specific deployment scenarios:

* `healthcheck`: an integer that specifies a port to start an HTTP server on that can be used for healthchecks.

## Core Configuration

All Adapter types support the same `client_options`, plus type-specific configurations. The following configurations are *required* for every Adapter:

* `client_options.identity.oid`: the LimaCharlie Organization ID (OID) this adapter is used with.
* `client_options.identity.installation_key`: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.
* `client_options.platform`: the type of data ingested through this adapter, like `text`, `json`, `gcp`, `carbon_black`, etc.
* `client_options.sensor_seed_key`: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.
* `client_options.hostname`: a hostname for the adapter.

### Example

Using inline parameters:

```
./lc-adapter file file_path=/path/to/logs.json \
  client_options.identity.installation_key=<INSTALLATION KEY> \
  client_options.identity.oid=<ORG ID> \
  client_options.platform=json \
  client_options.sensor_seed_key=<SENSOR SEED KEY> \
  client_options.mapping.event_type_path=<EVENT TYPE FIELD> \
  client_options.hostname=<HOSTNAME>
```

Using Docker:

```
docker run -d --rm -it -p 4404:4404/udp refractionpoint/lc-adapter syslog \
  client_options.identity.installation_key=<INSTALLATION KEY> \
  client_options.identity.oid=<ORG ID> \
  client_options.platform=cef \
  client_options.hostname=<HOSTNAME> \
  client_options.sensor_seed_key=<SENSOR SEED KEY> \
  port=4404 \
  iface=0.0.0.0 \
  is_udp=true
```

Using a configuration file:

```
./lc-adapter file config_file.yaml
```

## Parsing and Mapping

### Transformation Order

Data sent via USP can be formatted in many different ways. Data is processed in a specific order as a pipeline:

1. Regular Expression with named capture groups parsing a string into a JSON object.
2. Built-in (in the cloud) LimaCharlie parsers that apply to specific `platform` values (like `carbon_black`).
3. The various "extractors" defined, like `EventTypePath`, `EventTimePath`, `SensorHostnamePath` and `SensorKeyPath`.
4. Custom `Mappings` directives provided by the client.

### Configurations

The following configurations allow you to customize the way data is ingested by the platform, including mapping and redefining fields such as the event type path and time.

* `client_options.mapping.parsing_re`: regular expression with [named capture groups](https://github.com/StefanSchroeder/Golang-Regex-Tutorial/blob/master/01-chapter2.markdown#named-matches). The name of each group will be used as the key in the converted JSON parsing.
* `client_options.mapping.parsing_grok:`  grok pattern parsing for structured data extraction from unstructured log messages. Grok patterns combine regular expressions with predefined patterns to simplify log parsing and field extraction.
* `client_options.mapping.sensor_key_path`: indicates which component of the events represent unique sensor identifiers.
* `client_options.mapping.hostname`: indicates which component of the event represents the hostname of the resulting Sensor in LimaCharlie.
* `client_options.mapping.event_type_path`: indicates which component of the event represents the Event Type of the resulting event in LimaCharlie. It also supports [template strings](/v2/docs/template-strings-and-transforms) based on each event.
* `client_options.mapping.event_time_path`: indicates which component of the event represents the Event Time of the resulting event in LimaCharlie.
* `client_options.mapping.rename_only`: *deprecated*
* `client_options.mapping.mappings`: *deprecated*
* `client_options.mapping.transform`: a [Transform](/v2/docs/template-strings-and-transforms) to apply to events.
* `client_options.mapping.drop_fields`: a list of field paths to be dropped from the data before being processed and retained.

Mapping Fields Deprecated

The `client_options.mapping.rename_only` and `client_options.mapping.mappings` fields have been deprecated in favor of `client_options.mapping.transform`. Please see [associated documentation](/v2/docs/template-strings-and-transforms) for use of the `transform` config.

### Parsing

#### Named Group Parsing

If the data ingested in LimaCharlie is text (a syslog line for example), you may automatically parse it into a JSON format. To do this, you need to define one of the following:

* a grok pattern, using the `client_options.mapping.parsing_grok` option
* a regular expression, using the `client_options.mapping.parsing_re` option

#### Grok Patterns

##### Basic Syntax

Grok patterns use the following syntax:

The grok pattern line must start with **message:** , followed by the patterns, as in the example below

* `%{PATTERN_NAME:field_name}` - Extract a pattern into a named field
* `%{PATTERN_NAME}` - Match a pattern without extraction

Custom patterns can be defined using the pattern name as a key

##### Built-in Patterns

LimaCharlie includes standard Grok patterns for common data types:

* `%{IP:field_name}` - IP addresses (IPv4/IPv6)
* `%{NUMBER:field_name}` - Numeric values
* `%{WORD:field_name}` - Single words (no whitespace)
* `%{DATA:field_name}` - Any data up to delimiter
* `%{GREEDYDATA:field_name}` - All remaining data
* `%{TIMESTAMP_ISO8601:field_name}` - ISO 8601 timestamps
* `%{LOGLEVEL:field_name}` - Log levels (DEBUG, INFO, WARN, ERROR)

**Example Firewall Log Record:**

```
2024-01-01 12:00:00 ACCEPT TCP 192.168.1.100:54321 10.0.0.5:443 packets=1 bytes=78
```

**LimaCharlie Configuration to Match Firewall Log:**

```
client_options:
  mapping:
    parsing_grok:
      message: '%{TIMESTAMP_ISO8601:timestamp} %{WORD:action} %{WORD:protocol} %{IP:src_ip}:%{NUMBER:src_port} %{IP:dst_ip}:%{NUMBER:dst_port} packets=%{NUMBER:packets} bytes=%{NUMBER:bytes}'
    event_type_path: "action"
    event_time_path: "timestamp"
```

**Fields Extracted by the Above Configuration:**

```json
{
  "timestamp": "2024-01-01 12:00:00",
  "action": "ACCEPT",
  "protocol": "TCP",
  "src_ip": "192.168.1.100",
  "src_port": "54321",
  "dst_ip": "10.0.0.5",
  "dst_port": "443",
  "packets": "1",
  "bytes": "78"
}
```

#### Regular Expressions

**With this log line as an example:**

```
Nov 09 10:57:09 penguin PackageKit[21212]: daemon quit
```

**you could apply the following regular expression as** `parsing_re`**:**

```
(?P<date>... \d\d \d\d:\d\d:\d\d) (?P<host>.+) (?P<exe>.+?)\[(?P<pid>\d+)\]: (?P<msg>.*)
```

which would result in the following event in LimaCharlie:

```json
{
  "date": "Nov 09 10:57:09",
  "host": "penguin",
  "exe": "PackageKit",
  "pid": "21212",
  "msg": "daemon quit"
}
```

#### Key/Value Parsing

Alternatively you can specify a regular expression that does NOT contain Named Groups, like this:

```
(?:<\d+>\s*)?(\w+)=(".*?"|\S+)
```

When in this mode, LimaCharlie assumes the regular expression will generate a list of matches where each match has 2 submatches, and submatch index 1 is the Key name, and submatch index 2 is the value. This is compatible with logs like CEF for example where the log could look like:

```
<20>hostname=my-host log_name=http_logs timestamp=....
```

which would end up generating:

```json
{
  "hostname" : "my-host",
  "log_name": "http_logs",
  "timestamp": "..."
}
```

#### Extraction

LimaCharlie has a few core constructs that all events and sensors have.
Namely:

* Sensor ID
* Hostname
* Event Type
* Event Time

You may specify certain fields from the JSON logs to be extracted into these common fields.

This process is done by specifying the "path" to the relevant field in the JSON data. Paths are like a directory path using `/` for each sub directory except that in our case, they describe how to get to the relevant field from the top level of the JSON.

For example, using this event:

```json
{
  "a": "x",
  "b": "y",
  "c": {
    "d": {
      "e": "z"
    }
  }
}
```

The following paths would yield the following results:

* `a`: `x`
* `b`: `y`
* `c/d/e`: `z`

The following extractors can be specified:

* `client_options.mapping.sensor_key_path`: indicates which component of the events represent unique sensor identifiers.
* `client_options.mapping.sensor_hostname_path`: indicates which component of the event represents the hostname of the resulting Sensor in LimaCharlie.
* `client_options.mapping.event_type_path`: indicates which component of the event represents the Event Type of the resulting event in LimaCharlie. It also supports [template strings](/v2/docs/template-strings-and-transforms) based on each event.
* `client_options.mapping.event_time_path`: indicates which component of the event represents the Event Time of the resulting event in LimaCharlie.

### Indexing

Indexing occurs in one of 3 ways:

1. By the built-in indexer for specific platforms like Carbon Black.
2. By a generic indexer applied to all fields if no built-in indexer was available.
3. Optionally, user-specific indexing guidelines.

#### User Defined Indexing

An Adapter can be configured to do custom indexing on the data it feeds.

This is done by setting the `indexing` element in the `client_options`. This field contains a list of index descriptors.

An index descriptor can have the following fields:

* `events_included`: optionally, a list of event\_type that this descriptor applies to.
* `events_excluded`: optionally, a list of event\_type this descriptor *does not* apply to.
* `path`: the element path this descriptor targets, like `user/metadata/user_id`.
* `regexp`: optionally, a regular expression used on the `path` field to extract the item to index, like `email: (.+)`.
* `index_type`: the category of index the value extracted belongs to, like `user` or `file_hash`.

Here is an example of a simple index descriptor:

```
events_included:
  - PutObject
path: userAgent
index_type: user
```

Put together in a client option, you could have:

```json
{
  "client_options": {
    ...,
    "indexing": [{
      "events_included": ["PutObject"],
      "path": "userAgent",
      "index_type": "user"
    }, {
      "events_included": ["DelObject"],
      "path": "original_user/userAgent",
      "index_type": "user"
    }]
  }
}
```

#### Supported Indexes

This is the list of currently supported index types:

* `file_hash`
* `file_path`
* `file_name`
* `domain`
* `ip`
* `user`
* `service_name`
* `package_name`

### Sensor IDs

USP Clients generate LimaCharlie Sensors at runtime. The ID of those sensors (SID) is generated based on the Organization ID (OID) and the Sensor Seed Key.

This implies that if want to re-key an IID (perhaps it was leaked), you may replace the IID with a new valid one. As long as you use the same OID and Sensor Seed Key, the generated SIDs will be stable despite the IID change.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

#### Related articles

* [Adapter Deployment](/docs/adapter-deployment)
* [Adapter Types](/docs/adapter-types)
* [Adapter Tutorials](/docs/adapter-tutorials)
* [Adapter Examples](/docs/adapter-examples)
* [Tutorial: Ingesting Telemetry from Cloud-Based External Sources](/docs/tutorial-ingesting-telemetry-from-cloud-based-external-sources)
* [Installation Keys](/docs/installation-keys)
* [Mimecast](/docs/adapter-types-mimecast)

---

##### What's Next

* [Template Strings and Transforms](/docs/template-strings-and-transforms-1)

Table of contents

+ [Runtime Configuration](#runtime-configuration)
+ [Core Configuration](#core-configuration)
+ [Parsing and Mapping](#parsing-and-mapping)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Adapters

# Adapters
The LimaCharlie Adapter provides real-time ingestion of logs and other telemetry. Adapters allow you to send *any* data to LimaCharlie, which becomes an observable telemetry stream. All ingested data is recognized as a first-class data source, allowing you to write [detection & response rules](/v2/docs/detection-and-response) directly against Adapter events or [output](/v2/docs/outputs) Adapter data to other destinations.

The LimaCharlie Adapter:

* Supports ingestion of any structured data, such as JSON, Syslog, or CEFL
* Can be deployed on-prem or via a cloud-to-cloud connector
* Ingest log data without the need for an Endpoint Agent.
* Can run alongside the Endpoint Agent to allow for additional telemetry collection.

For certain well known Adapter sources, we offer built-in mapping and recognition of events. This allows you to ingest a known source without the need to parse event structure yourself. Well-known Adapter types include cloud platforms, various third-party applications, and sources like Windows Event Logs.

Key concepts of Adapters include [deployment options](/v2/docs/adapter-deployment) and [usage/configurations](/v2/docs/adapter-usage).

## Text Adapters

Text-based Adapters facilitate the ingestion of *any* structured text into LimaCharlie. Events are ingested and normalized as JSON text events, however custom mapping options allow you to customize fields and data structures as you see fit. Ingested data is also observed via detection and response rules, allowing you to ingest any data source and automate on those events.

## Pre-defined Adapters

LimaCharlie has pre-defined Adapter types that offer built-in mapping and guided adapter setups. Note that our guided setups often utilize common ingestion methods, however are designed to help you quickly deploy an Adapter for frequent log sources.

For example, AWS CloudTrail *and* Amazon GuardDuty logs are available for ingestion from either an AWS S3 bucket or Simple Queue Service (SQS) events. Thus, the web app "helper" walks you through setting up either one of those sources, depending on your needs and architecture.

Cloud Adapter Sinks

Note - certain cloud-to-cloud adapters, such as AWS S3 and Google Cloud Storage ingest data as a sink, meaning blobs will be deleted as they are consumed. The ingestion API will require the ability to delete objects in these adapters. To avoid any errors, we recommend creating a dedicated bucket (with appropriate permissions) to ingest logs into LimaCharlie.

For other data streams, where unique connector details are required (e.g. Office 365 or Slack), we will provide guidance on establishing those connections. More information on pre-defined Adapters can be found [here](/v2/docs/adapter-types).

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

---

### Related articles

* [Tutorial: Ingesting Telemetry from Cloud-Based External Sources](/docs/tutorial-ingesting-telemetry-from-cloud-based-external-sources)
* [Installation Keys](/docs/installation-keys)
* [Template Strings and Transforms](/docs/template-strings-and-transforms)

---

#### What's Next

* [Stdin](/docs/adapter-examples-stdin)

Table of contents

+ [Text Adapters](#text-adapters)
+ [Pre-defined Adapters](#pre-defined-adapters)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Adapters as a Service

# Adapters as a Service
* 1 Minute to read

## What's Next

* [Tutorial: Creating a Webhook Adapter](/docs/tutorial-creating-a-webhook-adapter)

Table of contents

+ [Service Installation](#service-installation-)
+ [Service Uninstallation](#service-uninstallation-)

---

## Canarytokens

# Canarytokens
Canarytokens are a free, quick, painless way to help defenders discover they've been breached (by having attackers announce themselves). Canarytokens are digital traps, or tripwires, that can be placed in an organization's network as a "lure" for adversaries. When actioned against, canaries will fire an alert, that can be forwarded to LimaCharlie.

Canarytokens can be ingested in LimaCharlie via a Webhook Adapter, and are recognized as the `canary_token` platform.

A Little More

LimaCharlie published a blog post in April 2023 to discuss the Canarytoken integration. You can read more about that [here](https://limacharlie.io/blog/early-warnings-with-limacharlie-and-canarytokens).

## Adapter Deployment

Canarytoken alerts are ingested via a cloud-to-cloud webhook Adapter configured to receive JSON events. The LimaCharlie platform has pre-built mapping for Canarytoken alerts. A Canarytokens Adapter can be initially deployed in two ways:

* Via the LimaCharlie web UI
* Via the LimaCharlie CLI

Regardless of which method utilized, Steps 2 and 3 will still be the same.

### 1a. Initial deployment via the LimaCharlie web UI

Within the LimaCharlie UI, navigate to **Sensors** > **Sensors List** > **+ Add** Sensor. Select the **Canary Token** option.

After selecting or creating an Installation Key, the web UI will ask you to name the Adapter and select a Secret value.

Click **Complete Cloud Installation** to create the cloud-to-cloud Adapter. Proceed to step 2 to continue.

### 1b. Initial deployment via the LimaCharlie CLI

A Canarytokens Adapter can be deployed via the LimaCharlie CLI. The following step is modified from the generic Webhook Adapter created documentation, found [here](/v2/docs/tutorial-creating-a-webhook-adapter).

The following configuration can be modified to easily configure a Webhook Adapter for receiving Canarytokens events.

```json
{
    "sensor_type": "webhook",
    "webhook": {
       "secret": "canarytoken-secret",
        "client_options": {
            "hostname": "canarytokens",
            "identity": {
                "oid": "<your_oid>",
                "installation_key": "<your_installation_key>"
            },
            "platform": "canary_token",
            "sensor_seed_key": "canary-super-secret-key",
            "mapping" : {
                "event_type_path" : {{ 'Canarytoken Hit' }}
            }
        }
    }
}
```

Note that in the mapping above, the `event_type_path` field is set to a static string of `Canarytoken Hit`. You can change this to any desired value.

To create this webhook adapter, run the following command, replacing `<json_config_file>` with the name of the config file from above:

`limacharlie hive set cloud_sensor --key canarytoken --data <json_config_file>`

### 2. Building the Webhook URL

After creating the webhook, you'll need to retrieve the webhook URL from the [Get Org URLs](https://docs.limacharlie.io/apidocs/get-org-urls) API call. You'll need the following information to complete the Webhook URL:

* Organization ID
* Webhook name (from the config)
* Secret (from the config)

Let's assume the returned domain looks like `9157798c50af372c.hook.limacharlie.io`, the format of the URL would be:

`https://9157798c50af372c.hook.limacharlie.io/OID/HOOKNAME/SECRET`

Note that the `secret` value can be provided in the webhook URL or as an HTTP header named `lc-secret`.

### 3. Configuring the Canaryalert Webhook Output

Navigate to the [Canarytokens generate page](https://canarytokens.org/generate) to create your token of choice.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28173%29.png)

Utilize the URL from Step 2 as the webhook URL. Provide a reminder note, which will also appear in the Canarytoken alert when tripped. Click **Create my Canarytoken**, which will provide you the content related to the selected token. When the Canarytoken is tripped, a webhook alert will be forwarded to the LimaCharlie Adapter.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

#### What's Next

* [Cato](/docs/adapter-types-cato)

Table of contents

+ [Adapter Deployment](#adapter-deployment)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Cato

# Cato
* 1 Minute to read

## What's Next

* [CrowdStrike Falcon Cloud](/docs/adapter-types-crowdstrike-falcon-cloud)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## CrowdStrike Falcon Cloud

# CrowdStrike Falcon Cloud
* 1 Minute to read

## Related articles

* [Okta](/docs/ext-cloud-cli-okta)
* [Cloud CLI](/docs/ext-cloud-cli)

---

### What's Next

* [Duo](/docs/adapter-types-duo)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Duo

# Duo
* 1 Minute to read

## What's Next

* [EVTX](/docs/adapter-types-evtx)

Table of contents

+ [Overview](#overview)
+ [Configurations](#configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## EVTX

# EVTX
* 1 Minute to read

## Related articles

* [Windows Event Logs](/docs/adapter-examples-windows-event-logs)
* [Ingesting Windows Event Logs](/docs/ingesting-windows-event-logs)
* [Hayabusa](/docs/ext-hayabusa)
* [Artifact](/docs/ext-artifact)

---

### What's Next

* [File](/docs/adapter-types-file)

Table of contents

+ [Overview](#overview)
+ [Configurations](#configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## EchoTrail

# EchoTrail
[EchoTrail](https://echotrail.io/) is an API service that allows you to perform a lookup of a file name or hash value. EchoTrail will return a summary of statistical details that describes the behavior of the submitted value, as observed from their sensors over time.

LimaCharlie has an integration available for EchoTrail's `insights` API lookup, accepting one of the following:

* MD5 Hash
* SHA256 Hash
* Windows filename with extension

## Detection & Response Rule

The following detection and response rule utilizes a file name from a `NEW_PROCESS` event to query the EchoTrail `insights` API:

```
event: NEW_PROCESS
op: lookup
path: event/FILE_PATH
resource: hive://lookup/echotrail-insights
```

EchoTrail's response data includes the following:

```json
{
  "rank": 24,
  "host_prev": "94.4",
  "eps": "96.07",
  "paths": [
    [
      "C:\\Windows\\System32",
      "99.92"
    ],
    [
      "C:\\WINDOWS\\System32",
      "0.07"
    ],
    [
      "C:\\Windows\\SysWOW64",
      "0.00"
    ],
    [
      "C:\\Users\\...",
      "0.00"
    ],
    [
      "C:\\Windows\\Temp\\...",
      "0.00"
    ],
    [
      "C:\\...",
      "0.00"
    ]
  ],
  "parents": [
    [
      "services.exe",
      "99.65"
    ],
    [
      "MsMpEng.exe",
      "0.35"
    ],
    [
      "rpcnet.exe",
      "0.00"
    ],
    [
      "svchost.exe",
      "0.00"
    ],
    [
      "MRT.exe",
      "0.00"
    ],
    [
      "cmd.exe",
      "0.00"
    ],
    [
      "consent.exe",
      "0.00"
    ],
    [
      "explorer.exe",
      "0.00"
    ],
    [
      "python.exe",
      "0.00"
    ],
    [
      "MRT-KB890830.exe",
      "0.00"
    ]
  ],
  "children": [
    [
      "WmiPrvSE.exe",
      "12.44"
    ],
    [
      "wmiprvse.exe",
      "7.96"
    ],
    [
      "backgroundTaskHost.exe",
      "7.76"
    ],
    [
      "taskhostw.exe",
      "6.76"
    ],
    [
      "backgroundtaskhost.exe",
      "4.96"
    ],
    [
      "dllhost.exe",
      "4.58"
    ],
    [
      "RuntimeBroker.exe",
      "3.95"
    ],
    [
      "runtimebroker.exe",
      "3.48"
    ],
    [
      "spatialaudiolicensesrv.exe",
      "2.47"
    ],
    [
      "werfault.exe",
      "1.65"
    ],
    [
      "GoogleUpdate.exe",
      "1.62"
    ],
    [
      "wermgr.exe",
      "1.55"
    ],
    [
      "gpupdate.exe",
      "1.44"
    ],
    [
      "filecoauth.exe",
      "1.40"
    ],
    [
      "FCHelper64.exe",
      "1.26"
    ],
    [
      "HxTsr.exe",
      "1.20"
    ],
    [
      "googleupdate.exe",
      "1.15"
    ],
    [
      "TiWorker.exe",
      "1.08"
    ],
    [
      "audiodg.exe",
      "1.05"
    ],
    [
      "tiworker.exe",
      "0.96"
    ]
  ],
  "grandparents": [
    [
      "wininit.exe",
      "99.89"
    ],
    [
      "services.exe",
      "0.11"
    ],
    [
      "explorer.exe",
      "0.00"
    ],
    [
      "cmd.exe",
      "0.00"
    ],
    [
      "userinit.exe",
      "0.00"
    ],
    [
      "svchost.exe",
      "0.00"
    ],
    [
      "Windows-KB890830-x64-V5.72-delta.exe",
      "0.00"
    ],
    [
      "Windows-KB890830-x64-V5.71-delta.exe",
      "0.00"
    ],
    [
      "Windows-KB890830-x64-V5.70-delta.exe",
      "0.00"
    ],
    [
      "Windows-KB890830-x64-V5.69-delta.exe",
      "0.00"
    ],
    [
      "Windows-KB890830-x64-V5.65.exe",
      "0.00"
    ],
    [
      "Windows-KB890830-x64-V5.62-delta.exe",
      "0.00"
    ],
    [
      "Windows-KB890830-x64-V5.58-delta.exe",
      "0.00"
    ],
    [
      "Windows-KB890830-x64-V5.57-delta.exe",
      "0.00"
    ]
  ],
  "network": [
    [
      "443",
      "45.89"
    ],
    [
      "80",
      "32.37"
    ],
    [
      "5353",
      "2.71"
    ],
    [
      "53",
      "1.17"
    ],
    [
      "5355",
      "0.61"
    ],
    [
      "1900",
      "0.31"
    ],
    [
      "54188",
      "0.17"
    ],
    [
      "3702",
      "0.16"
    ],
    [
      "54189",
      "0.07"
    ],
    [
      "67",
      "0.06"
    ],
    [
      "547",
      "0.05"
    ],
    [
      "53240",
      "0.05"
    ],
    [
      "59298",
      "0.05"
    ],
    [
      "53242",
      "0.05"
    ],
    [
      "53241",
      "0.04"
    ],
    [
      "53048",
      "0.04"
    ],
    [
      "62120",
      "0.04"
    ],
    [
      "64473",
      "0.03"
    ],
    [
      "58569",
      "0.03"
    ],
    [
      "50531",
      "0.03"
    ]
  ],
  "description": "Svchost.exe is the name for services that run from dynamic-linked libraries (DLLs). The Service Host Process acts like a shell for loading services from DLL files. Those services are partitioned into groups and each group is run in a different instance of the Service Host Process. This prevents problems in one instance from affecting other instances. That is also why you will see multiple instances of svchost.exe running at the same time.",
  "intel": "It is normal to see many svchost processes running on a single machine. It usually has elevated privileges and a tremendous amount of trust from Windows and third-party applications, leading to its abuse during a variety of attacks. Automated, opportunistic malware as well as manual, targeted tools commonly abuse this process in a few ways:\n\nName masquerading - More common to commodity, non-targeted attacks, malware will disguise itself as an svchost process by changing one or more characters in the name (e.g. svch0st, svchosts, scvhost, suchost, svchost32, etc.). These tend to be simple to identify by a human, but they can be more complicated to detect by algorithms or automated detection solutions if they are more than one character off the true name “svchost.”\n\nPath masquerading - Not uncommon to commodity malware but more common to targeted attack scenarios, malware or other tools used abused malicious purposes may disguise itself with an “svchost.exe” filename but located in a directory of the attacker’s choosing. It is not a legitimate svchost process. The legitimate svchost will always run from C:\\Windows\\System32 or C:\\Windows\\SysWOW64. If “svchost.exe” is running from any other directory, it is worth investigation. With endpoint process data, each running process’ path is simple to examine and, hence, simple to detect svchost path abuse.\n\nProcess migration - This type of abuse is more common to targeted or advanced attacks. Rather than running a malicious tool with the name “svchost.exe,” process migration allows an attacker to use a legitimate, currently running svchost process to effect their objectives. This typically occurs after privileged remote access is already gained to a system through a malicious remote administration tool (RAT). This sort of svchost abuse may be identifiable by uncommon behaviors of svchost, such as its launching of unusual executables, accessing unusual websites or IP addresses, performing host or network reconnaissance, or some combination thereof.\n",
  "truncated": {
    "paths": 5,
    "parents": 10,
    "grandparents": 13,
    "children": 1328,
    "network": 32667,
    "filenames": 1
  },
  "filenames": [
    [
      "svchost.exe",
      "100.00"
    ]
  ]
}
```

---

### What's Next

* [GreyNoise](/docs/api-integrations-greynoise)

Table of contents

+ [Detection &amp; Response Rule](#detection-amp-response-rule)

Tags

* [add-ons](/docs/en/tags/add-ons)

---

## File

# File
* 1 Minute to read

## What's Next

* [Google Cloud Pubsub](/docs/adapter-types-google-cloud-pubsub)

Table of contents

+ [Overview](#overview)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Google Cloud Pubsub

# Google Cloud Pubsub
## Overview

This Adapter allows you to ingest events from a Google Cloud Pubsub subscription.

## Configurations

Adapter Type: `pubsub`

* `client_options`: common configuration for adapter as defined [here](/v2/docs/adapters#usage).
* `sub_name`: the name of the subscription to subscribe to.
* `service_account_creds`: the string version of the JSON credentials for a (Google) Service Account to use accessing the subscription.
* `project_name`: project name where the `sub_name` exists.

### CLI Deployment

This example assumes that the Adapter is running from a host that has [default credentials](https://cloud.google.com/docs/authentication/production) (via the `GOOGLE_APPLICATION_CREDENTIALS` environment variable) setup. If it's not the case you will need to use `service_account_creds` to provide the contents of the JSON credentials of the GCP Service Account to use.

```
./lc_adapter pubsub client_options.identity.installation_key=f5eaaaad-575a-498e-bfc2-5f83e249a646 \
    client_options.identity.oid=8cbe27f4-bfa1-4afb-ba19-138cd51389cd \
    client_options.platform=gcp \
    sub_name=usp \
    project_name=monitored-proj \
    client_options.sensor_seed_key=gcplogs
```

Here's the breakdown of the above example:

* `lc_adapter`: simply the CLI Adapter.
* `pubsub`: the method the Adapter should use to collect data locally.
* `client_options.identity.installation_key=....`: the Installation Key value from LimaCharlie.
* `client_options.identity.oid=....`: the Organization ID from LimaCharlie the installation key above belongs to.
* `client_options.platform=gcp`: this indicates that the data read is logs from Google Cloud Platform.
* `client_options.sensor_seed_key=....`: this is the value that identifies this instance of the Adapter. Record it to re-use the Sensor ID generated for this Adapter later if you have to re-install the Adapter.
* `sub_name=usp`: the Subscription name to consume the logs from.
* `project_name=monitored-proj`: the GCP Project name this Subscription belongs to.

### Infrastructure as Code Deployment

```
# Google Cloud Pub/Sub Specific Docs: https://docs.limacharlie.io/docs/adapter-types-google-cloud-pubsub

sensor_type: "pubsub"
pubsub:
  sub_name: "your-pubsub-subscription-name"
  project_name: "your-gcp-project-id"
  service_account_creds: "hive://secret/gcp-pubsub-service-account"
  client_options:
    identity:
      oid: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
      installation_key: "YOUR_LC_INSTALLATION_KEY_PUBSUB"
    platform: "json"
    sensor_seed_key: "gcp-pubsub-sensor"
    mapping:
      # Map Pub/Sub message to sensor fields
      sensor_hostname_path: "attributes.hostname"
      event_type_path: "attributes.eventType"
      event_time_path: "publishTime"
    indexing: []
  # Optional configuration
  max_ps_buffer: 1048576  # 1MB buffer (optional)
```

## API Doc

See the [official documentation](https://cloud.google.com/pubsub).

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Command-line Interface

Google Cloud Platform

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

### Related articles

* [Google Cloud Storage](/docs/outputs-destinations-google-cloud-storage)
* [Google Cloud Storage](/docs/adapter-types-google-cloud-storage)
* [Building Reports with BigQuery + Looker Studio](/docs/tutorials-reporting-building-reports-with-bigquery-looker-studio)
* [Google Workspace](/docs/adapter-types-google-workspace)
* [Google Cloud BigQuery](/docs/outputs-destinations-google-cloud-bigquery)
* [Tutorial: Ingesting Google Cloud Logs](/docs/tutorial-ingesting-google-cloud-logs)
* [Google Cloud Pubsub](/docs/outputs-destinations-google-cloud-pubsub)
* [Google Cloud](/docs/ext-cloud-cli-google-cloud)

---

#### What's Next

* [Google Cloud Storage](/docs/adapter-types-google-cloud-storage)

Table of contents

+ [Overview](#overview)
+ [Configurations](#configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [gcp](/docs/en/tags/gcp)
* [sensors](/docs/en/tags/sensors)

---

## Google Cloud Storage

# Google Cloud Storage
* 1 Minute to read

## Related articles

* [Google Cloud Storage](/docs/outputs-destinations-google-cloud-storage)
* [Building Reports with BigQuery + Looker Studio](/docs/tutorials-reporting-building-reports-with-bigquery-looker-studio)
* [Google Workspace](/docs/adapter-types-google-workspace)
* [Google Cloud BigQuery](/docs/outputs-destinations-google-cloud-bigquery)
* [Tutorial: Ingesting Google Cloud Logs](/docs/tutorial-ingesting-google-cloud-logs)
* [Google Cloud Pubsub](/docs/outputs-destinations-google-cloud-pubsub)
* [Google Cloud Pubsub](/docs/adapter-types-google-cloud-pubsub)
* [Google Cloud](/docs/ext-cloud-cli-google-cloud)

---

### What's Next

* [SQS](/docs/adapter-types-sqs)

Table of contents

+ [Overview](#overview)
+ [Configurations](#configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [gcp](/docs/en/tags/gcp)
* [sensors](/docs/en/tags/sensors)

---

## Google Workspace

# Google Workspace
* 1 Minute to read

## Related articles

* [Google Cloud Storage](/docs/outputs-destinations-google-cloud-storage)
* [Building Reports with BigQuery + Looker Studio](/docs/tutorials-reporting-building-reports-with-bigquery-looker-studio)
* [Google Cloud BigQuery](/docs/outputs-destinations-google-cloud-bigquery)
* [Tutorial: Ingesting Google Cloud Logs](/docs/tutorial-ingesting-google-cloud-logs)
* [Google Cloud Pubsub](/docs/outputs-destinations-google-cloud-pubsub)
* [Google Cloud Storage](/docs/adapter-types-google-cloud-storage)
* [Google Cloud Pubsub](/docs/adapter-types-google-cloud-pubsub)
* [Google Cloud](/docs/ext-cloud-cli-google-cloud)

---

### What's Next

* [Azure Key Vault](/docs/azure-logs-key-vault)

Table of contents

+ [Adapter Deployment](#adapter-deployment)

Tags

* [adapters](/docs/en/tags/adapters)
* [gcp](/docs/en/tags/gcp)
* [google workspace](/docs/en/tags/google%20workspace)
* [sensors](/docs/en/tags/sensors)

---

## GreyNoise

# GreyNoise
* 1 Minute to read

## What's Next

* [Hybrid Analysis](/docs/api-integrations-hybrid-analysis)

Table of contents

+ [IP Context](#ip-context)
+ [RIOT IP Lookup](#riot-ip-lookup)

Tags

* [add-ons](/docs/en/tags/add-ons)

---

## HubSpot

# HubSpot
* 1 Minute to read

## Related articles

* [Okta](/docs/ext-cloud-cli-okta)
* [Cloud CLI](/docs/ext-cloud-cli)

---

### What's Next

* [Google Workspace](/docs/adapter-types-google-workspace)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Hybrid Analysis

# Hybrid Analysis
Hybrid Analysis, aka Falcon Sandbox, is a powerful, free malware analysis service for the community that detects and analyzes unknown threats. Hybrid Analysis has its own unique approach, and offers both public-facing and private team-based sandboxing capabilities.

LimaCharlie integrates with the following Hybrid Analysis API calls:

* [Overview](https://www.hybrid-analysis.com/docs/api/v2#/Analysis%20Overview/get_overview__sha256_)
* [Search](https://www.hybrid-analysis.com/docs/api/v2#/Search/post_search_hash)

## Detection & Response Rules

### Overview

The Search API accepts a SHA256 value, and provides an extensive overview of a hash (if previously observed by the platform).

**Rule:**

The following D&R rule

```
event: NEW_PROCESS
op: lookup
path: event/HASH
resource: hive://lookup/hybrid-analysis-overview
```

**Response Data:**

```json
{
  "result": {
    "analysis_start_time": "2023-07-17T18:31:04+00:00",
    "architecture": "WINDOWS",
    "children_in_progress": 0,
    "children_in_queue": 0,
    "last_file_name": "cmd.exe",
    "last_multi_scan": "2023-07-17T18:31:09+00:00",
    "multiscan_result": 0,
    "other_file_name": [
      "Utilman.exe",
      "file",
      "kiss.exe",
      "osk.exe",
      "sethc.exe",
      "utilman.exe"
    ],
    "related_children_hashes": [],
    "related_parent_hashes": [
      "c502bd80423e10dcc4b59fe4b523acb5ce0bd07748f73c7bdc6c797883b8a417"
    ],
    "related_reports": [
      {
        "environment_id": 100,
        "error_origin": null,
        "error_type": null,
        "job_id": "627e3011d695730f2c3ad419",
        "sha256": "c502bd80423e10dcc4b59fe4b523acb5ce0bd07748f73c7bdc6c797883b8a417",
        "state": "SUCCESS",
        "verdict": "no verdict"
      }
    ],
    "reports": [
      "58593319aac2edc56d351531",
      "5a34f2a27ca3e13531789a95",
      "5f196598eac13102deff3d42",
      "64b588e7e14d64e6a60b2130",
      "5965d8027ca3e10ec737634f",
      "60251a499b1b3016bb674fb4",
      "637f3600a3d94f1ecc7c1800"
    ],
    "scanners": [
      {
        "anti_virus_results": [],
        "error_message": null,
        "name": "CrowdStrike Falcon Static Analysis (ML)",
        "percent": 0,
        "positives": null,
        "progress": 100,
        "status": "clean",
        "total": null
      },
      {
        "anti_virus_results": [],
        "error_message": null,
        "name": "Metadefender",
        "percent": 0,
        "positives": 0,
        "progress": 100,
        "status": "clean",
        "total": 27
      },
      {
        "anti_virus_results": [],
        "error_message": null,
        "name": "VirusTotal",
        "percent": 0,
        "positives": 0,
        "progress": 100,
        "status": "clean",
        "total": 75
      }
    ],
    "scanners_v2": {
      "bfore_ai": null,
      "clean_dns": null,
      "crowdstrike_ml": {
        "anti_virus_results": [],
        "error_message": null,
        "name": "CrowdStrike Falcon Static Analysis (ML)",
        "percent": 0,
        "progress": 100,
        "status": "clean"
      },
      "metadefender": {
        "anti_virus_results": [],
        "error_message": null,
        "name": "Metadefender",
        "percent": 0,
        "positives": 0,
        "progress": 100,
        "status": "clean",
        "total": 27
      },
      "scam_adviser": null,
      "urlscan_io": null,
      "virustotal": {
        "error_message": null,
        "name": "VirusTotal",
        "percent": 0,
        "positives": 0,
        "progress": 100,
        "status": "clean",
        "total": 75
      }
    },
    "sha256": "935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2",
    "size": 232960,
    "submit_context": [],
    "tags": [],
    "threat_score": null,
    "type": "PE32+ executable (console) x86-64, for MS Windows",
    "type_short": [
      "peexe",
      "64bits",
      "executable"
    ],
    "url_analysis": false,
    "verdict": "no specific threat",
    "vx_family": null,
    "whitelisted": false
  }
}
```

### Search

The Search lookup provides a basic lookup of a hash value. This look accepts one of the following values:

* MD5
* SHA1
* SHA256

**D&R Rule:**

```
event: NEW_PROCESS
op: lookup
path: event/HASH
resource: hive://lookup/hybrid-analysis-search
```

**Response Data:**

```json
[
  {
    "classification_tags": [],
    "tags": [],
    "submissions": [
      {
        "submission_id": "64b588e7e14d64e6a60b2131",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2023-07-17T18:31:03+00:00"
      }
    ],
    "machine_learning_models": [],
    "crowdstrike_ai": {
      "executable_process_memory_analysis": [],
      "analysis_related_urls": []
    },
    "job_id": "64b588e7e14d64e6a60b2130",
    "environment_id": 160,
    "environment_description": "Windows 10 64 bit",
    "size": 232960,
    "type": "PE32+ executable (console) x86-64, for MS Windows",
    "type_short": [
      "peexe",
      "64bits",
      "executable"
    ],
    "target_url": null,
    "state": "SUCCESS",
    "error_type": null,
    "error_origin": null,
    "submit_name": "cmd.exe",
    "md5": "f4f684066175b77e0c3a000549d2922c",
    "sha1": "99ae9c73e9bee6f9c76d6f4093a9882df06832cf",
    "sha256": "935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2",
    "sha512": "fe8f0593cc335ad28eb90211bc4ff01a3d2992cffb3877d04cefede9ef94afeb1a7d7874dd0c0ae04eaf8308291d5a4d879e6ecf6fe2b8d0ff1c3ac7ef143206",
    "ssdeep": "3072:bkd4COZG6/A1tO1Y6TbkX2FtynroeJ/MEJoSsasbLLkhyjyGe:bkuC9+Af0Y6TbbFtkoeJk1KsfLXm",
    "imphash": "3062ed732d4b25d1c64f084dac97d37a",
    "entrypoint": "0x140015190",
    "entrypoint_section": ".text",
    "image_base": "0x140000000",
    "subsystem": "Windows Cui",
    "image_file_characteristics": [
      "EXECUTABLE_IMAGE",
      "LARGE_ADDRESS_AWARE"
    ],
    "dll_characteristics": [
      "GUARD_CF",
      "TERMINAL_SERVER_AWARE",
      "DYNAMIC_BASE",
      "NX_COMPAT",
      "HIGH_ENTROPY_VA"
    ],
    "major_os_version": 10,
    "minor_os_version": 0,
    "av_detect": 0,
    "vx_family": null,
    "url_analysis": false,
    "analysis_start_time": "2023-07-17T18:31:04+00:00",
    "threat_score": null,
    "interesting": false,
    "threat_level": 0,
    "verdict": "no specific threat",
    "certificates": [],
    "is_certificates_valid": false,
    "certificates_validation_message": "No signature was present in the subject. (0x800b0100)",
    "domains": [],
    "compromised_hosts": [],
    "hosts": [],
    "total_network_connections": 0,
    "total_processes": 1,
    "total_signatures": 99,
    "extracted_files": [],
    "file_metadata": null,
    "processes": [],
    "mitre_attcks": [
      {
        "tactic": "Execution",
        "technique": "Shared Modules",
        "attck_id": "T1129",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1129",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 3,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Execution",
        "technique": "Native API",
        "attck_id": "T1106",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 2,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 10,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Execution",
        "technique": "Windows Command Shell",
        "attck_id": "T1059.003",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1059/003",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": {
          "technique": "Command and Scripting Interpreter",
          "attck_id": "T1059",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1059"
        }
      },
      {
        "tactic": "Persistence",
        "technique": "Windows Service",
        "attck_id": "T1543.003",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1543/003",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 2,
        "informative_identifiers": [],
        "parent": {
          "technique": "Create or Modify System Process",
          "attck_id": "T1543",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1543"
        }
      },
      {
        "tactic": "Persistence",
        "technique": "Create or Modify System Process",
        "attck_id": "T1543",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1543",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Persistence",
        "technique": "Registry Run Keys / Startup Folder",
        "attck_id": "T1547.001",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1547/001",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": {
          "technique": "Boot or Logon Autostart Execution",
          "attck_id": "T1547",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1547"
        }
      },
      {
        "tactic": "Privilege Escalation",
        "technique": "Windows Service",
        "attck_id": "T1543.003",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1543/003",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 2,
        "informative_identifiers": [],
        "parent": {
          "technique": "Create or Modify System Process",
          "attck_id": "T1543",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1543"
        }
      },
      {
        "tactic": "Privilege Escalation",
        "technique": "Token Impersonation/Theft",
        "attck_id": "T1134.001",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1134/001",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 3,
        "informative_identifiers": [],
        "parent": {
          "technique": "Access Token Manipulation",
          "attck_id": "T1134",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1134"
        }
      },
      {
        "tactic": "Privilege Escalation",
        "technique": "Create or Modify System Process",
        "attck_id": "T1543",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1543",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Privilege Escalation",
        "technique": "Create Process with Token",
        "attck_id": "T1134.002",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1134/002",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": {
          "technique": "Access Token Manipulation",
          "attck_id": "T1134",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1134"
        }
      },
      {
        "tactic": "Privilege Escalation",
        "technique": "Dynamic-link Library Injection",
        "attck_id": "T1055.001",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1055/001",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": {
          "technique": "Process Injection",
          "attck_id": "T1055",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1055"
        }
      },
      {
        "tactic": "Privilege Escalation",
        "technique": "Thread Execution Hijacking",
        "attck_id": "T1055.003",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1055/003",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 1,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 0,
        "informative_identifiers": [],
        "parent": {
          "technique": "Process Injection",
          "attck_id": "T1055",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1055"
        }
      },
      {
        "tactic": "Privilege Escalation",
        "technique": "Process Injection",
        "attck_id": "T1055",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1055",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 2,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Privilege Escalation",
        "technique": "Registry Run Keys / Startup Folder",
        "attck_id": "T1547.001",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1547/001",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": {
          "technique": "Boot or Logon Autostart Execution",
          "attck_id": "T1547",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1547"
        }
      },
      {
        "tactic": "Privilege Escalation",
        "technique": "Extra Window Memory Injection",
        "attck_id": "T1055.011",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1055/011",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 1,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 0,
        "informative_identifiers": [],
        "parent": {
          "technique": "Process Injection",
          "attck_id": "T1055",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1055"
        }
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Obfuscated Files or Information",
        "attck_id": "T1027",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1027",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 2,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Match Legitimate Name or Location",
        "attck_id": "T1036.005",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1036/005",
        "malicious_identifiers_count": 1,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 0,
        "informative_identifiers": [],
        "parent": {
          "technique": "Masquerading",
          "attck_id": "T1036",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1036"
        }
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Debugger Evasion",
        "attck_id": "T1622",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1622",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 2,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Defense Evasion",
        "technique": "File and Directory Permissions Modification",
        "attck_id": "T1222",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1222",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Token Impersonation/Theft",
        "attck_id": "T1134.001",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1134/001",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 3,
        "informative_identifiers": [],
        "parent": {
          "technique": "Access Token Manipulation",
          "attck_id": "T1134",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1134"
        }
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Timestomp",
        "attck_id": "T1070.006",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1070/006",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 2,
        "informative_identifiers": [],
        "parent": {
          "technique": "Indicator Removal",
          "attck_id": "T1070",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1070"
        }
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Modify Registry",
        "attck_id": "T1112",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1112",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 4,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Disable or Modify Tools",
        "attck_id": "T1562.001",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1562/001",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": {
          "technique": "Impair Defenses",
          "attck_id": "T1562",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1562"
        }
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Create Process with Token",
        "attck_id": "T1134.002",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1134/002",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": {
          "technique": "Access Token Manipulation",
          "attck_id": "T1134",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1134"
        }
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Dynamic-link Library Injection",
        "attck_id": "T1055.001",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1055/001",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": {
          "technique": "Process Injection",
          "attck_id": "T1055",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1055"
        }
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Thread Execution Hijacking",
        "attck_id": "T1055.003",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1055/003",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 1,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 0,
        "informative_identifiers": [],
        "parent": {
          "technique": "Process Injection",
          "attck_id": "T1055",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1055"
        }
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Process Injection",
        "attck_id": "T1055",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1055",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 2,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Defense Evasion",
        "technique": "File Deletion",
        "attck_id": "T1070.004",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1070/004",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": {
          "technique": "Indicator Removal",
          "attck_id": "T1070",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1070"
        }
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Direct Volume Access",
        "attck_id": "T1006",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1006",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Time Based Evasion",
        "attck_id": "T1497.003",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1497/003",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 2,
        "informative_identifiers": [],
        "parent": {
          "technique": "Virtualization/Sandbox Evasion",
          "attck_id": "T1497",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1497"
        }
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Software Packing",
        "attck_id": "T1027.002",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1027/002",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 3,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 0,
        "informative_identifiers": [],
        "parent": {
          "technique": "Obfuscated Files or Information",
          "attck_id": "T1027",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1027"
        }
      },
      {
        "tactic": "Defense Evasion",
        "technique": "Extra Window Memory Injection",
        "attck_id": "T1055.011",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1055/011",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 1,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 0,
        "informative_identifiers": [],
        "parent": {
          "technique": "Process Injection",
          "attck_id": "T1055",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1055"
        }
      },
      {
        "tactic": "Credential Access",
        "technique": "Credential API Hooking",
        "attck_id": "T1056.004",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1056/004",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 1,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 0,
        "informative_identifiers": [],
        "parent": {
          "technique": "Input Capture",
          "attck_id": "T1056",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1056"
        }
      },
      {
        "tactic": "Discovery",
        "technique": "File and Directory Discovery",
        "attck_id": "T1083",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1083",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 7,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "Process Discovery",
        "attck_id": "T1057",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1057",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 1,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 4,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "Query Registry",
        "attck_id": "T1012",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1012",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 1,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 4,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "System Service Discovery",
        "attck_id": "T1007",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1007",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "System Information Discovery",
        "attck_id": "T1082",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1082",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 9,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "System Language Discovery",
        "attck_id": "T1614.001",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1614/001",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": {
          "technique": "System Location Discovery",
          "attck_id": "T1614",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1614"
        }
      },
      {
        "tactic": "Discovery",
        "technique": "Debugger Evasion",
        "attck_id": "T1622",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1622",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 2,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "System Owner/User Discovery",
        "attck_id": "T1033",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1033",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "System Network Connections Discovery",
        "attck_id": "T1049",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1049",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "System Network Configuration Discovery",
        "attck_id": "T1016",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1016",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "Network Share Discovery",
        "attck_id": "T1135",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1135",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "System Location Discovery",
        "attck_id": "T1614",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1614",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "System Time Discovery",
        "attck_id": "T1124",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1124",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "Time Based Evasion",
        "attck_id": "T1497.003",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1497/003",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 2,
        "informative_identifiers": [],
        "parent": {
          "technique": "Virtualization/Sandbox Evasion",
          "attck_id": "T1497",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1497"
        }
      },
      {
        "tactic": "Lateral Movement",
        "technique": "Lateral Tool Transfer",
        "attck_id": "T1570",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1570",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Collection",
        "technique": "Credential API Hooking",
        "attck_id": "T1056.004",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1056/004",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 1,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 0,
        "informative_identifiers": [],
        "parent": {
          "technique": "Input Capture",
          "attck_id": "T1056",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1056"
        }
      },
      {
        "tactic": "Collection",
        "technique": "Local Data Staging",
        "attck_id": "T1074.001",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1074/001",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": {
          "technique": "Data Staged",
          "attck_id": "T1074",
          "attck_id_wiki": "https://attack.mitre.org/techniques/T1074"
        }
      },
      {
        "tactic": "Command and Control",
        "technique": "Application Layer Protocol",
        "attck_id": "T1071",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1071",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Command and Control",
        "technique": "Ingress Tool Transfer",
        "attck_id": "T1105",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1105",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Exfiltration",
        "technique": "Scheduled Transfer",
        "attck_id": "T1029",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1029",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Impact",
        "technique": "Service Stop",
        "attck_id": "T1489",
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1489",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      }
    ],
    "network_mode": "default",
    "signatures": [
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "api-7",
        "type": 6,
        "relevance": 1,
        "name": "Loads modules at runtime",
        "description": "\"cmd.exe\" loaded module \"KERNEL32\" at base e8360000\n \"cmd.exe\" loaded module \"API-MS-WIN-CORE-STRING-L1-1-0\" at base e5170000\n \"cmd.exe\" loaded module \"API-MS-WIN-CORE-DATETIME-L1-1-1\" at base e5170000\n \"cmd.exe\" loaded module \"API-MS-WIN-CORE-LOCALIZATION-OBSOLETE-L1-2-0\" at base e5170000\n \"cmd.exe\" loaded module \"%WINDIR%\\SYSTEM32\\IMM32.DLL\" at base e5be0000\n \"cmd.exe\" loaded module \"API-MS-WIN-CORE-SYNCH-L1-2-0\" at base e5170000\n \"cmd.exe\" loaded module \"API-MS-WIN-CORE-FIBERS-L1-1-1\" at base e5170000\n \"cmd.exe\" loaded module \"API-MS-WIN-CORE-LOCALIZATION-L1-2-1\" at base e5170000\n \"cmd.exe\" loaded module \"%WINDIR%\\TEMP\\VXOLE64.DLL\" at base d3ef0000\n \"cmd.exe\" loaded module \"KERNEL32.DLL\" at base e8360000",
        "origin": "API Call",
        "attck_id": "T1129",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1129"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "api-175",
        "type": 6,
        "relevance": 1,
        "name": "Calls an API typically used to load libraries",
        "description": "\"cmd.exe\" called \"LoadLibrary\" with a parameter api-ms-win-core-synch-l1-2-0 (UID: 00000000-00004716)\n \"cmd.exe\" called \"LoadLibrary\" with a parameter api-ms-win-core-fibers-l1-1-1 (UID: 00000000-00004716)\n \"cmd.exe\" called \"LoadLibrary\" with a parameter api-ms-win-core-localization-l1-2-1 (UID: 00000000-00004716)\n \"cmd.exe\" called \"LoadLibrary\" with a parameter kernel32 (UID: 00000000-00004716)",
        "origin": "API Call",
        "attck_id": "T1129",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1129"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "api-176",
        "type": 6,
        "relevance": 1,
        "name": "Calls an API typically used to retrieve function addresses",
        "description": "\"cmd.exe\" called \"GetProcAddress\" with a parameter InitializeCriticalSectionEx (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter FlsAlloc (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter FlsSetValue (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter FlsGetValue (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter LCMapStringEx (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter FlsFree (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter InitOnceExecuteOnce (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter CreateEventExW (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter CreateSemaphoreW (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter CreateSemaphoreExW (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter CreateThreadpoolTimer (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter SetThreadpoolTimer (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter WaitForThreadpoolTimerCallbacks (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter CloseThreadpoolTimer (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter CreateThreadpoolWait (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter SetThreadpoolWait (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter CloseThreadpoolWait (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter FlushProcessWriteBuffers (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter FreeLibraryWhenCallbackReturns (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter GetCurrentProcessorNumber (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter CreateSymbolicLinkW (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter GetCurrentPackageId (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter GetTickCount64 (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter GetFileInformationByHandleEx (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter SetFileInformationByHandle (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter GetSystemTimePreciseAsFileTime (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter InitializeConditionVariable (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter WakeConditionVariable (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter WakeAllConditionVariable (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter SleepConditionVariableCS (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter InitializeSRWLock (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter AcquireSRWLockExclusive (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter TryAcquireSRWLockExclusive (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter ReleaseSRWLockExclusive (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter SleepConditionVariableSRW (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter CreateThreadpoolWork (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter SubmitThreadpoolWork (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter CloseThreadpoolWork (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter CompareStringEx (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter GetLocaleInfoEx (UID: 00000000-00004716)\n \"cmd.exe\" called \"GetProcAddress\" with a parameter AreFileApisANSI (UID: 00000000-00004716)",
        "origin": "API Call",
        "attck_id": "T1106",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "module-10",
        "type": 10,
        "relevance": 0,
        "name": "Loads the RPC (Remote Procedure Call) module DLL",
        "description": "\"cmd.exe\" loaded module \"%WINDIR%\\System32\\rpcrt4.dll\" at E8420000",
        "origin": "Loaded Module",
        "attck_id": "T1129",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1129"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "module-9",
        "type": 10,
        "relevance": 0,
        "name": "Loads the Bcrypt module DLL",
        "description": "\"cmd.exe\" loaded module \"%WINDIR%\\System32\\bcryptprimitives.dll\" at E55D0000",
        "origin": "Loaded Module",
        "attck_id": "T1027",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1027"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "registry-25",
        "type": 3,
        "relevance": 3,
        "name": "Reads information about supported languages",
        "description": "\"cmd.exe\" (Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\NLS\\CUSTOMLOCALE\"; Key: \"EN-US\")\n \"cmd.exe\" (Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\NLS\\EXTENDEDLOCALE\"; Key: \"EN-US\")\n \"cmd.exe\" (Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\NLS\\LOCALE\"; Key: \"00000409\")",
        "origin": "Registry Access",
        "attck_id": "T1082",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1082"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-101",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to execute Windows APIs",
        "description": "Found reference to API (Indicator: \"SetConsoleInputExeNameW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"IsDebuggerPresent\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"CopyFileExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetThreadUILanguage\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"NtQueryInformationProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RtlCreateUnicodeStringFromAsciiz\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RtlNtStatusToDosError\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"NtSetInformationProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RtlFreeUnicodeString\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RtlDosPathNameToRelativeNtPathName_U_WithStatus\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"NtSetInformationFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RtlReleaseRelativeName\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"NtQueryVolumeInformationFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"NtOpenFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RtlFindLeastSignificantBit\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RtlDosPathNameToNtPathName_U\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"NtFsControlFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RtlFreeHeap\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RtlCaptureContext\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RtlLookupFunctionEntry\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RtlVirtualUnwind\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"CopyFileW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"ReadFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetThreadLocale\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FindFirstFileW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetConsoleScreenBufferInfo\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"HeapFree\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetFullPathNameW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FindNextFileW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetConsoleOutputCP\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetStdHandle\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetCPInfo\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetFilePointer\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FindClose\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"CreateFileW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"MultiByteToWideChar\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetLastError\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FillConsoleOutputCharacterW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"ReadConsoleW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"CloseHandle\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"ReleaseSRWLockShared\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"HeapAlloc\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FlushConsoleInputBuffer\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"WriteConsoleW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetProcAddress\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"AcquireSRWLockShared\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetFileSize\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetProcessHeap\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetModuleHandleW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"WideCharToMultiByte\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetFileType\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetConsoleCursorPosition\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RevertToSelf\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"VirtualQuery\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetLocalTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetLocaleInfoW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetUserDefaultLCID\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FileTimeToSystemTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FileTimeToLocalFileTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetLocalTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetTimeFormatW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SystemTimeToFileTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetSystemTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetDateFormatW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetNumaHighestNodeNumber\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetCommandLineW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetConsoleMode\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetEnvironmentVariableW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetEnvironmentVariableW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FreeEnvironmentStringsW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetConsoleMode\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetEnvironmentStringsW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetEnvironmentStringsW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetStartupInfoW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RegQueryValueExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"NeedCurrentDirectoryForExePathW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetLastError\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RegDeleteValueW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"InitializeProcThreadAttributeList\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"CreateProcessAsUserW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RegOpenKeyExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetErrorMode\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetConsoleTitleW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetFileAttributesW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RegSetValueExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RegEnumKeyExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"UpdateProcThreadAttribute\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RegCreateKeyExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"DeleteProcThreadAttributeList\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"ReadProcessMemory\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"CreateProcessW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RegDeleteKeyExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RegCloseKey\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"LoadLibraryExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"MoveFileWithProgressW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"LocalFree\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"MoveFileExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetConsoleTitleW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetVolumeInformationW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SearchPathW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"WriteFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GlobalAlloc\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GlobalFree\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetFilePointerEx\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetConsoleCtrlHandler\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"EnterCriticalSection\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"TryAcquireSRWLockExclusive\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"ExpandEnvironmentStringsW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetModuleFileNameW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"LeaveCriticalSection\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"InitializeCriticalSection\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetVersion\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"ReleaseSRWLockExclusive\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetWindowsDirectoryW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetFileAttributesExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetDriveTypeW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetCurrentThreadId\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"HeapSetInformation\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"OpenThread\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"VirtualFree\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"VirtualAlloc\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"HeapSize\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"HeapReAlloc\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"DuplicateHandle\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FlushFileBuffers\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetACP\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FormatMessageW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetConsoleTextAttribute\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"ScrollConsoleScreenBufferW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FillConsoleOutputAttribute\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"CreateDirectoryW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetFileTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetEndOfFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetFileAttributesW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"DeleteFileW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"TerminateProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"WaitForSingleObject\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetCurrentDirectoryW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetExitCodeProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetCurrentDirectoryW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetFileInformationByHandleEx\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"RemoveDirectoryW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"CompareFileTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"DeviceIoControl\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetFileSecurityW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetSecurityDescriptorOwner\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetDiskFreeSpaceExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"FindFirstFileExW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"ResumeThread\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetThreadGroupAffinity\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetNumaNodeProcessorMaskEx\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetThreadLocale\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"CreateHardLinkW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetVolumePathNameW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"CreateSymbolicLinkW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"Sleep\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"UnhandledExceptionFilter\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetUnhandledExceptionFilter\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetCurrentProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"QueryPerformanceCounter\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetCurrentProcessId\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetSystemTimeAsFileTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"GetTickCount\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"lstrcmpiW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"lstrcmpW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"SetProcessAffinityMask\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"NtOpenProcessToken\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"NtQueryInformationToken\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"NtClose\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"NtOpenThreadToken\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"DelayLoadFailureHook\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API (Indicator: \"Beep\"; Source: \"00000000-00004716.00000000.77972.48F50000.00000002.mdmp, 00000000-00004716.00000001.79890.48F50000.00000002.mdmp, 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetConsoleInputExeNameW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"IsDebuggerPresent\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"CopyFileExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetThreadUILanguage\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"NtQueryInformationProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RtlCreateUnicodeStringFromAsciiz\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RtlNtStatusToDosError\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"NtSetInformationProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RtlFreeUnicodeString\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RtlDosPathNameToRelativeNtPathName_U_WithStatus\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"NtSetInformationFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RtlReleaseRelativeName\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"NtQueryVolumeInformationFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"NtOpenFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RtlFindLeastSignificantBit\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RtlDosPathNameToNtPathName_U\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"NtFsControlFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RtlFreeHeap\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RtlCaptureContext\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RtlLookupFunctionEntry\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RtlVirtualUnwind\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"CopyFileW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"ReadFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetThreadLocale\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FindFirstFileW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetConsoleScreenBufferInfo\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"HeapFree\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetFullPathNameW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FindNextFileW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetConsoleOutputCP\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetStdHandle\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetCPInfo\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetFilePointer\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FindClose\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"CreateFileW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"MultiByteToWideChar\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetLastError\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FillConsoleOutputCharacterW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"ReadConsoleW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"CloseHandle\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"ReleaseSRWLockShared\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"HeapAlloc\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FlushConsoleInputBuffer\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"WriteConsoleW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetProcAddress\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"AcquireSRWLockShared\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetFileSize\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetProcessHeap\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetModuleHandleW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"WideCharToMultiByte\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetFileType\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetConsoleCursorPosition\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RevertToSelf\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"VirtualQuery\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetLocalTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetLocaleInfoW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetUserDefaultLCID\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FileTimeToSystemTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FileTimeToLocalFileTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetLocalTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetTimeFormatW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SystemTimeToFileTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetSystemTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetDateFormatW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetNumaHighestNodeNumber\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetCommandLineW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetConsoleMode\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetEnvironmentVariableW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetEnvironmentVariableW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FreeEnvironmentStringsW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetConsoleMode\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetEnvironmentStringsW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetEnvironmentStringsW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetStartupInfoW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RegQueryValueExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"NeedCurrentDirectoryForExePathW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetLastError\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RegDeleteValueW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"InitializeProcThreadAttributeList\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"CreateProcessAsUserW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RegOpenKeyExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetErrorMode\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetConsoleTitleW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetFileAttributesW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RegSetValueExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RegEnumKeyExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"UpdateProcThreadAttribute\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RegCreateKeyExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"DeleteProcThreadAttributeList\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"ReadProcessMemory\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"CreateProcessW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RegDeleteKeyExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RegCloseKey\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"LoadLibraryExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"MoveFileWithProgressW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"LocalFree\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"MoveFileExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetConsoleTitleW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetVolumeInformationW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SearchPathW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"WriteFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GlobalAlloc\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GlobalFree\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetFilePointerEx\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetConsoleCtrlHandler\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"EnterCriticalSection\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"TryAcquireSRWLockExclusive\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"ExpandEnvironmentStringsW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetModuleFileNameW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"LeaveCriticalSection\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"InitializeCriticalSection\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetVersion\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"ReleaseSRWLockExclusive\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetWindowsDirectoryW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetFileAttributesExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetDriveTypeW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetCurrentThreadId\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"HeapSetInformation\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"OpenThread\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"VirtualFree\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"VirtualAlloc\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"HeapSize\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"HeapReAlloc\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"DuplicateHandle\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FlushFileBuffers\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetACP\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FormatMessageW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetConsoleTextAttribute\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"ScrollConsoleScreenBufferW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FillConsoleOutputAttribute\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"CreateDirectoryW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetFileTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetEndOfFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetFileAttributesW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"DeleteFileW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"TerminateProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"WaitForSingleObject\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetCurrentDirectoryW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetExitCodeProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetCurrentDirectoryW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetFileInformationByHandleEx\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"RemoveDirectoryW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"CompareFileTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"DeviceIoControl\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetFileSecurityW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetSecurityDescriptorOwner\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetDiskFreeSpaceExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"FindFirstFileExW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"ResumeThread\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetThreadGroupAffinity\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetNumaNodeProcessorMaskEx\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetThreadLocale\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"CreateHardLinkW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetVolumePathNameW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"CreateSymbolicLinkW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"Sleep\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"UnhandledExceptionFilter\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetUnhandledExceptionFilter\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetCurrentProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"QueryPerformanceCounter\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetCurrentProcessId\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetSystemTimeAsFileTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"GetTickCount\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"lstrcmpiW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"lstrcmpW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"SetProcessAffinityMask\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"NtOpenProcessToken\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"NtQueryInformationToken\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"NtClose\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"NtOpenThreadToken\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API (Indicator: \"DelayLoadFailureHook\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1106",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-7",
        "type": 2,
        "relevance": 1,
        "name": "Contains PDB pathways",
        "description": "\"cmd.pdb\"",
        "origin": "File/Memory",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-240",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to execute an application (API string)",
        "description": "Found reference to API \"ShellExecuteWorker\" (Indicator: \"ShellExecute\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"ShellExecuteWorker\" (Indicator: \"ShellExecute\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1106",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-315",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to create/open files (API string)",
        "description": "Found reference to API \"NtOpenFile\" (Indicator: \"NtOpenFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"CreateFileW\" (Indicator: \"CreateFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtOpenFile\" (Indicator: \"NtOpenFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"CreateFileW\" (Indicator: \"CreateFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1106",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-220",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to create/control drivers (API string)",
        "description": "Found reference to API \"NtFsControlFile\" (Indicator: \"FsControlFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"DeviceIoControl\" (Indicator: \"DeviceIoControl\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtFsControlFile\" (Indicator: \"FsControlFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"DeviceIoControl\" (Indicator: \"DeviceIoControl\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1543.003",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1543/003"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-319",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to set/get the last-error code for a calling thread (API string)",
        "description": "Found reference to API \"GetLastError\" (Indicator: \"GetLastError\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"SetLastError\" (Indicator: \"SetLastError\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetLastError\" (Indicator: \"GetLastError\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"SetLastError\" (Indicator: \"SetLastError\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1106",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-272",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve/open a process (API string)",
        "description": "Found reference to API \"GetProcessHeap\" (Indicator: \"GetProcessHeap\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtOpenProcessToken\" (Indicator: \"OpenProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetProcessHeap\" (Indicator: \"GetProcessHeap\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"NtOpenProcessToken\" (Indicator: \"OpenProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1057",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1057"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-206",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve the command-line string for the current process (API string)",
        "description": "Found reference to API \"GetCommandLineW\" (Indicator: \"GetCommandLine\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetCommandLineW\" (Indicator: \"GetCommandLine\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1059.003",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1059/003"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-204",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to create a new process (API string)",
        "description": "Found reference to API \"CreateProcessAsUserW\" (Indicator: \"CreateProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"CreateProcessW\" (Indicator: \"CreateProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"CreateProcessAsUserW\" (Indicator: \"CreateProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"CreateProcessW\" (Indicator: \"CreateProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1106",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-307",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to create/load registry keys (API string)",
        "description": "Found reference to API \"RegCreateKeyExW\" (Indicator: \"RegCreateKey\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"RegCreateKeyExW\" (Indicator: \"RegCreateKey\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1112",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1112"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-345",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to disable/close registry key (API string)",
        "description": "Found reference to API \"RegCloseKey\" (Indicator: \"RegCloseKey\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"RegCloseKey\" (Indicator: \"RegCloseKey\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1112",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1112"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-322",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to move file or directory (API string)",
        "description": "Found reference to API \"MoveFileWithProgressW\" (Indicator: \"MoveFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"MoveFileExW\" (Indicator: \"MoveFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"MoveFileWithProgressW\" (Indicator: \"MoveFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"MoveFileExW\" (Indicator: \"MoveFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1570",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1570"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-161",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve/modify process thread (API string)",
        "description": "Found reference to API \"OpenThread\" (Indicator: \"OpenThread\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"ResumeThread\" (Indicator: \"ResumeThread\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtOpenThreadToken\" (Indicator: \"OpenThread\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"OpenThread\" (Indicator: \"OpenThread\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"ResumeThread\" (Indicator: \"ResumeThread\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"NtOpenThreadToken\" (Indicator: \"OpenThread\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1106",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-423",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to create directories (API string)",
        "description": "Found reference to API \"CreateDirectoryW\" (Indicator: \"CreateDirectory\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"CreateDirectoryW\" (Indicator: \"CreateDirectory\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1074.001",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1074/001"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-120",
        "type": 2,
        "relevance": 1,
        "name": "Contains registry location strings",
        "description": "\"Software\\Microsoft\\Command Processor\" in Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\n \"Software\\Policies\\Microsoft\\Windows\\System\" in Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\n \"Software\\Classes\" in Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\n \"\\Registry\\Machine\\System\\CurrentControlSet\\Control\\Keyboard Layout\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"Software\\Microsoft\\RegEdt32\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"SOFTWARE\\\\MICROSOFT\\\\CLOCK\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"Software\\Microsoft\\Windows NT\\CurrentVersion\\Devices\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"SOFTWARE\\\\MICROSOFT\\\\WINDOWS NT\\\\CURRENTVERSION\\\\EXTENSIONS\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"SOFTWARE\\\\MICROSOFT\\\\CHARMAP\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"SOFTWARE\\\\MICROSOFT\\\\WINDOWS NT\\\\CURRENTVERSION\\\\NETWORK\\\\PERSISTENT CONNECTIONS\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"Software\\Microsoft\\Windows NT\\CurrentVersion\\PrinterPorts\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"SOFTWARE\\\\MICROSOFT\\\\WINDOWS NT\\\\CURRENTVERSION\\\\TRUETYPE\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"SOFTWARE\\\\MICROSOFT\\\\WINDOWS NT\\\\CURRENTVERSION\\\\TWAIN\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"SOFTWARE\\\\MICROSOFT\\\\WINDOWS HELP\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"Software\\Microsoft\\Windows NT\\CurrentVersion\\Windows\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\n \"Software\\Microsoft\\Command Processor\" in Source: 00000000-00004716.00000000.77972.49307000.00000002.mdmp\n 00000000-00004716.00000001.79890.49307000.00000002.mdmp\n 00000000-00004716.00000002.81813.49307000.00000002.mdmp\n \"Software\\Policies\\Microsoft\\Windows\\System\" in Source: 00000000-00004716.00000000.77972.49307000.00000002.mdmp\n 00000000-00004716.00000001.79890.49307000.00000002.mdmp\n 00000000-00004716.00000002.81813.49307000.00000002.mdmp\n \"Software\\Classes\" in Source: 00000000-00004716.00000000.77972.49307000.00000002.mdmp\n 00000000-00004716.00000001.79890.49307000.00000002.mdmp\n 00000000-00004716.00000002.81813.49307000.00000002.mdmp",
        "origin": "File/Memory",
        "attck_id": "T1012",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1012"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "static-157",
        "type": 0,
        "relevance": 0,
        "name": "Matched Compiler/Packer signature (DIE)",
        "description": "\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" was detected as \"Microsoft Visual C/C++\"  and name: \"Compiler\"\n \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" was detected as \"Microsoft Linker\"  and name: \"Linker\"",
        "origin": "Static Parser",
        "attck_id": "T1027",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1027"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "static-93",
        "type": 0,
        "relevance": 1,
        "name": "PE file has a high image base",
        "description": "\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" has high imagebase  \"0x140000000\"",
        "origin": "Static Parser",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "static-154",
        "type": 0,
        "relevance": 0,
        "name": "File contains dynamic base/NX flags",
        "description": "\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" has flags like  IMAGE_DLLCHARACTERISTICS_GUARD_CF\n IMAGE_DLLCHARACTERISTICS_TERMINAL_SERVER_AWARE\n IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE\n IMAGE_DLLCHARACTERISTICS_NX_COMPAT\n IMAGE_DLLCHARACTERISTICS_HIGH_ENTROPY_VA",
        "origin": "Static Parser",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "static-96",
        "type": 0,
        "relevance": 0,
        "name": "PE file entrypoint instructions",
        "description": "\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" file has an entrypoint instructions - \"sub\trsp, 0x28,call\t0x1400156b4,add\trsp, 0x28,jmp\t0x140014fc0,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,nop\tword ptr [rax + rax],cmp\trcx, qword ptr [rip + 0x19e41],jne\t0x1400151d9,rol\trcx, 0x10,test\tcx, 0xffff,jne\t0x1400151d5,ret\t,ror\trcx, 0x10,jmp\t0x140015220,int3\t,int3\t,int3\t,int3\t,int3\t,int3\t,push\trbx,sub\trsp, 0x20,mov\trbx, rcx,xor\tecx, ecx,\"",
        "origin": "Static Parser",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "static-80",
        "type": 0,
        "relevance": 1,
        "name": "PE file contains executable sections",
        "description": "\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" has an executable section named \".text\"",
        "origin": "Static Parser",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "static-95",
        "type": 0,
        "relevance": 0,
        "name": "PE file contains writable sections",
        "description": "\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" has an writable section named \".data\"\n \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" has an writable section named \".didat\"",
        "origin": "Static Parser",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "static-146",
        "type": 0,
        "relevance": 0,
        "name": "PE file contains Debug data directory",
        "description": "\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" has Debug data directory \"IMAGE_DIRECTORY_ENTRY_DEBUG\"",
        "origin": "Static Parser",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "stream-103",
        "type": 1,
        "relevance": 3,
        "name": "Contains ability to delay the execution of current thread",
        "description": "Sleep at 61526-1-0000000140015190",
        "origin": "Hybrid Analysis Technology",
        "attck_id": "T1497.003",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1497/003"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-625",
        "type": 2,
        "relevance": 1,
        "name": "References Windows filepaths for DLLs (possible dropped files)",
        "description": "Observed system executable string:\"C:\\windows\\temp\\VxSSL64.dll\" [Source: 00000000-00004716.00000000.77972.67BF0000.00000020.mdmp\n 00000000-00004716.00000001.79890.67BF0000.00000020.mdmp\n 00000000-00004716.00000002.81813.67BF0000.00000020.mdmp]\n Observed system executable string:\"C:\\WINDOWS\\system32\\sxsoa.dll\" [Source: 00000000-00004716.00000000.77972.67C20000.00000002.mdmp\n 00000000-00004716.00000001.79890.67C20000.00000002.mdmp\n 00000000-00004716.00000002.81813.67C20000.00000002.mdmp]\n Observed system executable string:\"C:\\WINDOWS\\system32\\GdiPlus.dll\" [Source: 00000000-00004716.00000000.77972.67C20000.00000002.mdmp\n 00000000-00004716.00000001.79890.67C20000.00000002.mdmp\n 00000000-00004716.00000002.81813.67C20000.00000002.mdmp]\n Observed system executable string:\"C:\\WINDOWS\\system32\\comctl32.dll\" [Source: 00000000-00004716.00000000.77972.67C20000.00000002.mdmp\n 00000000-00004716.00000001.79890.67C20000.00000002.mdmp\n 00000000-00004716.00000002.81813.67C20000.00000002.mdmp]\n Observed system executable string:\"C:\\WINDOWS\\system32\\sxsoaps.dll\" [Source: 00000000-00004716.00000000.77972.67C20000.00000002.mdmp\n 00000000-00004716.00000001.79890.67C20000.00000002.mdmp\n 00000000-00004716.00000002.81813.67C20000.00000002.mdmp]\n Observed system executable string:\"C:\\WINDOWS\\system32\\comctl32.dll.mui\" [Source: 00000000-00004716.00000000.77972.67C20000.00000002.mdmp\n 00000000-00004716.00000001.79890.67C20000.00000002.mdmp\n 00000000-00004716.00000002.81813.67C20000.00000002.mdmp]\n Observed system executable string:\":\\WINDOWS\\SYSTEM32\\ntdll.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\KERNEL32.DLL\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\msvcrt.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\KERNELBASE.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\windows\\temp\\VxSSL64.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\WS2_32.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\"C:\\windows\\temp\\VxOle64.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000000.77972.69E40000.00000020.mdmp\n 00000000-00004716.00000000.77972.69E70000.00000002.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69E40000.00000020.mdmp\n 00000000-00004716.00000001.79890.69E70000.00000002.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69E40000.00000020.mdmp\n 00000000-00004716.00000002.81813.69E70000.00000002.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\RPCRT4.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\SYSTEM32\\FLTLIB.DLL\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\"C:\\WINDOWS\\SYSTEM32\\gdi32full.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\ucrtbase.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\USER32.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\ADVAPI32.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\ole32.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\GDI32.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\gdi32full.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\combase.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\msvcp_win.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\n Observed system executable string:\":\\WINDOWS\\System32\\sechost.dll\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]",
        "origin": "File/Memory",
        "attck_id": "T1083",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1083"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Unusual Characteristics",
        "identifier": "registry-26",
        "type": 3,
        "relevance": 2,
        "name": "Reads the windows installation language",
        "description": "\"cmd.exe\" (Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\NLS\\LANGUAGE GROUPS\"; Key: \"1\")",
        "origin": "Registry Access",
        "attck_id": "T1614.001",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1614/001"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Installation/Persistence",
        "identifier": "api-126",
        "type": 6,
        "relevance": 3,
        "name": "Tries to access non-existent files (executable)",
        "description": "\"cmd.exe\" trying to access non-existent file \"C:\\FLTLIB.DLL\"\n \"cmd.exe\" trying to access non-existent file \"C:\\NETMSG.DLL\"\n \"cmd.exe\" trying to access non-existent file \"C:\\netmsg.dll\"",
        "origin": "API Call",
        "attck_id": "T1083",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1083"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Installation/Persistence",
        "identifier": "api-263",
        "type": 6,
        "relevance": 1,
        "name": "Touches files",
        "description": "\"cmd.exe\" trying to touch file \"C:\\FLTLIB.DLL\"\n \"cmd.exe\" trying to touch file \"C:\\Windows\\System32\\fltLib.dll\"\n \"cmd.exe\" trying to touch file \"C:\\Windows\\System32\\KernelBase.dll\"\n \"cmd.exe\" trying to touch file \"C:\\windows\\temp\\VxOle64.dll\"\n \"cmd.exe\" trying to touch file \"C:\\Windows\\System32\\imm32.dll\"\n \"cmd.exe\" trying to touch file \"C:\\WINDOWS\\system32\\IMM32.DLL\"\n \"cmd.exe\" trying to touch file \"C:\\EN-US\\CMD.EXE.MUI\"\n \"cmd.exe\" trying to touch file \"C:\\EN\\CMD.EXE.MUI\"\n \"cmd.exe\" trying to touch file \"C:\\cmd.exe\"\n \"cmd.exe\" trying to touch file \"C:\\Windows\\System32\\oleaut32.dll\"",
        "origin": "API Call",
        "attck_id": "T1083",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1083"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Installation/Persistence",
        "identifier": "api-235",
        "type": 6,
        "relevance": 1,
        "name": "Queries basic information of the specified process",
        "description": "\"cmd.exe\" queries basic process information of the  \"C:\\cmd.exe\" (UID: 4716)",
        "origin": "API Call",
        "attck_id": "T1057",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1057"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Installation/Persistence",
        "identifier": "registry-177",
        "type": 3,
        "relevance": 1,
        "name": "Opens registry keys",
        "description": "\"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\SESSION MANAGER\\SEGMENT HEAP\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\SESSION MANAGER\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKLM\\SOFTWARE\\MICROSOFT\\WINDOWS NT\\CURRENTVERSION\\IMAGE FILE EXECUTION OPTIONS\\CONHOST.EXE\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\SERVICES\\BAM\\USERSETTINGS\\S-1-5-21-735145574-3570218355-1207367261-1001\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\SESSION MANAGER\\BAM\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\SAFEBOOT\\OPTION\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\SRP\\GP\\DLL\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKLM\\SOFTWARE\\POLICIES\\MICROSOFT\\WINDOWS\\SAFER\\CODEIDENTIFIERS\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKCU\\SOFTWARE\\POLICIES\\MICROSOFT\\WINDOWS\\SAFER\\CODEIDENTIFIERS\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\FILESYSTEM\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\NLS\\SORTING\\VERSIONS\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKCU\\CONTROL PANEL\\DESKTOP\\MUICACHED\\MACHINELANGUAGECONFIGURATION\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKLM\\SOFTWARE\\POLICIES\\MICROSOFT\\MUI\\SETTINGS\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKCU\\SOFTWARE\\POLICIES\\MICROSOFT\\CONTROL PANEL\\DESKTOP\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"OPEN\"; Path: \"HKCU\\CONTROL PANEL\\DESKTOP\\LANGUAGECONFIGURATION\"; Key: \"\"; Value: \"\")",
        "origin": "Registry Access",
        "attck_id": "T1012",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1012"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Installation/Persistence",
        "identifier": "registry-172",
        "type": 3,
        "relevance": 1,
        "name": "Queries registry keys",
        "description": "\"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\SESSION MANAGER\"; Key: \"RESOURCEPOLICIES\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\SERVICES\\BAM\\USERSETTINGS\\S-1-5-21-735145574-3570218355-1207367261-1001\"; Key: \"\\DEVICE\\HARDDISKVOLUME2\\WINDOWS\\SYSTEM32\\CONHOST.EXE\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SOFTWARE\\POLICIES\\MICROSOFT\\WINDOWS\\SAFER\\CODEIDENTIFIERS\"; Key: \"TRANSPARENTENABLED\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\FILESYSTEM\"; Key: \"LONGPATHSENABLED\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\NLS\\SORTING\\VERSIONS\"; Key: \"\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKCU\\CONTROL PANEL\\DESKTOP\"; Key: \"PREFERREDUILANGUAGES\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKCU\\CONTROL PANEL\\DESKTOP\\MUICACHED\"; Key: \"MACHINEPREFERREDUILANGUAGES\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SOFTWARE\\MICROSOFT\\WINDOWS\\CURRENTVERSION\\SIDEBYSIDE\"; Key: \"PREFEREXTERNALMANIFEST\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\SESSION MANAGER\"; Key: \"SAFEDLLSEARCHMODE\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\LSA\\FIPSALGORITHMPOLICY\"; Key: \"ENABLED\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\LSA\"; Key: \"FIPSALGORITHMPOLICY\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\LSA\\FIPSALGORITHMPOLICY\"; Key: \"MDMENABLED\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SOFTWARE\\MICROSOFT\\OLE\"; Key: \"PAGEALLOCATORUSESYSTEMHEAP\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SOFTWARE\\MICROSOFT\\OLE\"; Key: \"PAGEALLOCATORSYSTEMHEAPISPRIVATE\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SOFTWARE\\MICROSOFT\\OLE\"; Key: \"AGGRESSIVEMTATESTING\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SOFTWARE\\MICROSOFT\\WINDOWS NT\\CURRENTVERSION\\GRE_INITIALIZE\"; Key: \"DISABLEMETAFILES\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKCU\\CONTROL PANEL\\DESKTOP\"; Key: \"ENABLEPERPROCESSSYSTEMDPI\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SOFTWARE\\MICROSOFT\\WINDOWS NT\\CURRENTVERSION\\COMPATIBILITY32\"; Key: \"CMD\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\CONTROL\\CMF\\CONFIG\"; Key: \"SYSTEM\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SOFTWARE\\MICROSOFT\\WINDOWS NT\\CURRENTVERSION\\WINDOWS\"; Key: \"LOADAPPINIT_DLLS\"; Value: \"\")\n \"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKCU\\SOFTWARE\\POLICIES\\MICROSOFT\\WINDOWS\\SYSTEM\"; Key: \"DISABLECMD\"; Value: \"\")",
        "origin": "Registry Access",
        "attck_id": "T1012",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1012"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Installation/Persistence",
        "identifier": "string-310",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to load modules (API string)",
        "description": "Found reference to API \"LoadLibraryExW\" (Indicator: \"LoadLibrary\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"LoadLibraryExW\" (Indicator: \"LoadLibrary\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1106",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Installation/Persistence",
        "identifier": "string-443",
        "type": 2,
        "relevance": 1,
        "name": "Contains registry location which perform auto-execute functionality",
        "description": "Found string \"Software\\Microsoft\\Command Processor\" (Indicator: \"software\\microsoft\\command processor\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found string \"Software\\Microsoft\\Command Processor\" (Indicator: \"software\\microsoft\\command processor\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1547.001",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1547/001"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Anti-Detection/Stealthyness",
        "identifier": "string-304",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to modify registry key/value (API string)",
        "description": "Found reference to API \"RegSetValueExW\" (Indicator: \"RegSetValue\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"RegSetValueExW\" (Indicator: \"RegSetValue\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1112",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1112"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Anti-Detection/Stealthyness",
        "identifier": "string-318",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to load/free library (API string)",
        "description": "Found reference to API \"LoadLibraryExW\" (Indicator: \"LoadLibrary\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"LoadLibraryExW\" (Indicator: \"LoadLibrary\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1055.001",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1055/001"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Anti-Detection/Stealthyness",
        "identifier": "string-92",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to inject code into another process (API string)",
        "description": "Found reference to API \"VirtualFree\" (Indicator: \"VirtualFree\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"VirtualAlloc\" (Indicator: \"VirtualAlloc\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"VirtualFree\" (Indicator: \"VirtualFree\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"VirtualAlloc\" (Indicator: \"VirtualAlloc\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1055",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1055"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Anti-Detection/Stealthyness",
        "identifier": "string-409",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to set file time (API string)",
        "description": "Found reference to API \"SetFileTime\" (Indicator: \"SetFileTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"SetFileTime\" (Indicator: \"SetFileTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1070.006",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1070/006"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Anti-Detection/Stealthyness",
        "identifier": "string-226",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to delay execution by waiting for signal/timeout (API string)",
        "description": "Found reference to API \"WaitForSingleObject\" (Indicator: \"WaitForSingleObject\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"WaitForSingleObject\" (Indicator: \"WaitForSingleObject\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Anti-Detection/Stealthyness",
        "identifier": "string-306",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to impersonate access tokens (API string)",
        "description": "Found reference to API \"NtOpenProcessToken\" (Indicator: \"OpenProcessToken\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtOpenThreadToken\" (Indicator: \"OpenThreadToken\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtOpenProcessToken\" (Indicator: \"OpenProcessToken\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"NtOpenThreadToken\" (Indicator: \"OpenThreadToken\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1134.001",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1134/001"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Anti-Detection/Stealthyness",
        "identifier": "memorydump-8",
        "type": 20,
        "relevance": 1,
        "name": "Found PE header in memory",
        "description": "Found PE header \"MZ\" - Source: \"00000000-00004716.00000000.77972.492E0000.00000002.mdmp\")\n Found PE header \"MZ\" - Source: \"00000000-00004716.00000001.79890.492E0000.00000002.mdmp\")\n Found PE header \"MZ\" - Source: \"00000000-00004716.00000002.81813.492E0000.00000002.mdmp\")",
        "origin": "Memory Dumps",
        "attck_id": "T1055",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1055"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Anti-Reverse Engineering",
        "identifier": "string-183",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to check debugger is running (API string)",
        "description": "Found reference to API \"IsDebuggerPresent\" (Indicator: \"IsDebuggerPresent\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtQueryInformationProcess\" (Indicator: \"NtQueryInformationProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"QueryPerformanceCounter\" (Indicator: \"QueryPerformanceCounter\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetTickCount\" (Indicator: \"GetTickCount\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")",
        "origin": "File/Memory",
        "attck_id": "T1622",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1622"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Anti-Reverse Engineering",
        "identifier": "string-148",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to register a top-level exception handler (API string)",
        "description": "Found reference to API \"UnhandledExceptionFilter\" (Indicator: \"UnhandledExceptionFilter\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"SetUnhandledExceptionFilter\" (Indicator: \"SetUnhandledExceptionFilter\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"SetUnhandledExceptionFilter\" (Indicator: \"UnhandledExceptionFilter\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")",
        "origin": "File/Memory",
        "attck_id": "T1622",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1622"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "registry-78",
        "type": 3,
        "relevance": 1,
        "name": "Contains ability to read software policies",
        "description": "\"cmd.exe\" (Path: \"HKLM\\SOFTWARE\\POLICIES\\MICROSOFT\\WINDOWS\\SAFER\\CODEIDENTIFIERS\"; Key: \"TRANSPARENTENABLED\")",
        "origin": "Registry Access",
        "attck_id": "T1082",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1082"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-222",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve network parameters of a computer (API string)",
        "description": "Found reference to API \"WNetGetConnectionWStub\" (Indicator: \"NetGetConnection\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"WNetGetConnectionWStub\" (Indicator: \"NetGetConnection\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1016",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1016"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-89",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve information about the current system (API string)",
        "description": "Found reference to API \"RtlNtStatusToDosError\" (Indicator: \"RtlNtStatusToDosError\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"ExpandEnvironmentStringsW\" (Indicator: \"ExpandEnvironmentStrings\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"RtlNtStatusToDosError\" (Indicator: \"RtlNtStatusToDosError\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"ExpandEnvironmentStringsW\" (Indicator: \"ExpandEnvironmentStrings\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1082",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1082"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-162",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve volume information (API string)",
        "description": "Found reference to API \"NtQueryVolumeInformationFile\" (Indicator: \"NtQueryVolumeInformationFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetVolumeInformationW\" (Indicator: \"GetVolumeInformation\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtQueryVolumeInformationFile\" (Indicator: \"NtQueryVolumeInformationFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetVolumeInformationW\" (Indicator: \"GetVolumeInformation\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1082",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1082"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-201",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to query system locale (API string)",
        "description": "Found reference to API \"GetLocaleInfoW\" (Indicator: \"GetLocaleInfo\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetUserDefaultLCID\" (Indicator: \"GetUserDefaultLCID\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetLocaleInfoW\" (Indicator: \"GetLocaleInfo\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetUserDefaultLCID\" (Indicator: \"GetUserDefaultLCID\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1614",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1614"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-249",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve file time (API string)",
        "description": "Found reference to API \"FileTimeToSystemTime\" (Indicator: \"FileTimeToSystemTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"FileTimeToLocalFileTime\" (Indicator: \"FileTimeToLocalFileTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"SystemTimeToFileTime\" (Indicator: \"SystemTimeToFileTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetSystemTimeAsFileTime\" (Indicator: \"GetSystemTimeAsFileTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"FileTimeToSystemTime\" (Indicator: \"FileTimeToSystemTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"FileTimeToLocalFileTime\" (Indicator: \"FileTimeToLocalFileTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"SystemTimeToFileTime\" (Indicator: \"SystemTimeToFileTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetSystemTimeAsFileTime\" (Indicator: \"GetSystemTimeAsFileTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1070.006",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1070/006"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-365",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to perform scheduled transfer (API string)",
        "description": "Found reference to API \"GetLocalTime\" (Indicator: \"GetLocalTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetSystemTime\" (Indicator: \"GetSystemTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetSystemTimeAsFileTime\" (Indicator: \"GetSystemTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetLocalTime\" (Indicator: \"GetLocalTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetSystemTime\" (Indicator: \"GetSystemTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetSystemTimeAsFileTime\" (Indicator: \"GetSystemTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1029",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1029"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-247",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve machine time (API string)",
        "description": "Found reference to API \"GetLocalTime\" (Indicator: \"GetLocalTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetSystemTime\" (Indicator: \"GetSystemTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetSystemTimeAsFileTime\" (Indicator: \"GetSystemTime\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetLocalTime\" (Indicator: \"GetLocalTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetSystemTime\" (Indicator: \"GetSystemTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetSystemTimeAsFileTime\" (Indicator: \"GetSystemTime\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1124",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1124"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-167",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve the contents of the STARTUPINFO structure (API string)",
        "description": "Found reference to API \"GetStartupInfoW\" (Indicator: \"GetStartupInfo\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")",
        "origin": "File/Memory",
        "attck_id": "T1543",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1543"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-171",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve the OS information (API string)",
        "description": "Found reference to API \"GetVersion\" (Indicator: \"GetVersion\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetVersion\" (Indicator: \"GetVersion\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1082",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1082"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-312",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve path in which Windows is installed (API string)",
        "description": "Found reference to API \"GetWindowsDirectoryW\" (Indicator: \"GetWindowsDirectory\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetWindowsDirectoryW\" (Indicator: \"GetWindowsDirectory\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1083",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1083"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-193",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to query volume/memory size (API string)",
        "description": "Found reference to API \"GetDiskFreeSpaceExW\" (Indicator: \"GetDiskFreeSpace\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetDiskFreeSpaceExW\" (Indicator: \"GetDiskFreeSpace\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1082",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1082"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "string-194",
        "type": 2,
        "relevance": 1,
        "name": "Contains the ability to enumerate volumes (API string)",
        "description": "Found reference to API \"GetVolumePathNameW\" (Indicator: \"GetVolumePathName\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetVolumePathNameW\" (Indicator: \"GetVolumePathName\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1006",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1006"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "api-103",
        "type": 6,
        "relevance": 3,
        "name": "Calls an API typically used for taking snapshot of the specified processes",
        "description": "\"cmd.exe\" called \"CreateToolhelp32Snapshot\" with parameters {\"dwFlags\": \"4\"\n \"th32ProcessID\": \"0\"}",
        "origin": "API Call",
        "attck_id": "T1057",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1057"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-85",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to enumerate process and/or its information (API string)",
        "description": "Found reference to API \"NtQueryInformationProcess\" (Indicator: \"QueryInformationProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetModuleHandleW\" (Indicator: \"GetModuleHandle\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetEnvironmentStringsW\" (Indicator: \"GetEnvironmentStrings\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetCurrentProcess\" (Indicator: \"GetCurrentProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetCurrentProcessId\" (Indicator: \"GetCurrentProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtQueryInformationProcess\" (Indicator: \"QueryInformationProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetModuleHandleW\" (Indicator: \"GetModuleHandle\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetEnvironmentStringsW\" (Indicator: \"GetEnvironmentStrings\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetCurrentProcess\" (Indicator: \"GetCurrentProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetCurrentProcessId\" (Indicator: \"GetCurrentProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1057",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1057"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-121",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve usernames and/or user information (API string)",
        "description": "Found reference to API \"NtQueryInformationProcess\" (Indicator: \"NtQueryInformationProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"LookupAccountSidWStub\" (Indicator: \"LookupAccountSid\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtOpenProcessToken\" (Indicator: \"NtOpenProcessToken\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtOpenProcessToken\" (Indicator: \"OpenProcessToken\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtQueryInformationToken\" (Indicator: \"NtQueryInformationToken\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtOpenThreadToken\" (Indicator: \"NtOpenThreadToken\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtQueryInformationProcess\" (Indicator: \"NtQueryInformationProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"LookupAccountSidWStub\" (Indicator: \"LookupAccountSid\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"NtOpenProcessToken\" (Indicator: \"NtOpenProcessToken\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"NtOpenProcessToken\" (Indicator: \"OpenProcessToken\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"NtQueryInformationToken\" (Indicator: \"NtQueryInformationToken\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"NtOpenThreadToken\" (Indicator: \"NtOpenThreadToken\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1033",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1033"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-534",
        "type": 2,
        "relevance": 0,
        "name": "Contains ability to read files (API string)",
        "description": "Found reference to API \"ReadFile\" (Indicator: \"ReadFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"ReadFile\" (Indicator: \"ReadFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1083",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1083"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-83",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to enumerate files on disk (API string)",
        "description": "Found reference to API \"FindFirstFileW\" (Indicator: \"FindFirstFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"FindNextFileW\" (Indicator: \"FindNextFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"FindFirstFileExW\" (Indicator: \"FindFirstFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"FindFirstFileW\" (Indicator: \"FindFirstFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"FindNextFileW\" (Indicator: \"FindNextFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"FindFirstFileExW\" (Indicator: \"FindFirstFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1083",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1083"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-317",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve address of exported function from a DLL (API string)",
        "description": "Found reference to API \"GetProcAddress\" (Indicator: \"GetProcAddress\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetProcAddress\" (Indicator: \"GetProcAddress\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1106",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-207",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve file and directory information (API string)",
        "description": "Found reference to API \"GetFileSize\" (Indicator: \"GetFileSize\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetFileAttributesW\" (Indicator: \"GetFileAttributes\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetFileAttributesExW\" (Indicator: \"GetFileAttributes\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetCurrentDirectoryW\" (Indicator: \"GetCurrentDirectory\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetFileInformationByHandleEx\" (Indicator: \"GetFileInformationByHandle\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetFileSize\" (Indicator: \"GetFileSize\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetFileAttributesW\" (Indicator: \"GetFileAttributes\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetFileAttributesExW\" (Indicator: \"GetFileAttributes\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetCurrentDirectoryW\" (Indicator: \"GetCurrentDirectory\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetFileInformationByHandleEx\" (Indicator: \"GetFileInformationByHandle\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1083",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1083"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-427",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve a module handle (API string)",
        "description": "Found reference to API \"GetModuleHandleW\" (Indicator: \"GetModuleHandle\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetModuleHandleW\" (Indicator: \"GetModuleHandle\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1082",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1082"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-107",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve the host's architecture (API string)",
        "description": "Found reference to API \"GetEnvironmentVariableW\" (Indicator: \"GetEnvironmentVariable\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetEnvironmentVariableW\" (Indicator: \"GetEnvironmentVariable\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1082",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1082"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-229",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to query registry keys (API string)",
        "description": "Found reference to API \"RegQueryValueExW\" (Indicator: \"RegQueryValue\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"RegOpenKeyExW\" (Indicator: \"RegOpenKey\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"RegEnumKeyExW\" (Indicator: \"RegEnumKey\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"RegQueryValueExW\" (Indicator: \"RegQueryValue\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"RegOpenKeyExW\" (Indicator: \"RegOpenKey\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"RegEnumKeyExW\" (Indicator: \"RegEnumKey\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1012",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1012"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-164",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve the fully qualified path of module (API string)",
        "description": "Found reference to API \"GetModuleFileNameW\" (Indicator: \"GetModuleFileName\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetModuleFileNameW\" (Indicator: \"GetModuleFileName\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1106",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-80",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to determine disk drive type (API string)",
        "description": "Found reference to API \"GetDriveTypeW\" (Indicator: \"GetDriveType\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetDriveTypeW\" (Indicator: \"GetDriveType\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1082",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1082"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Spyware/Information Retrieval",
        "identifier": "string-205",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to retrieve the time elapsed since the system was started (API string)",
        "description": "Found reference to API \"GetTickCount\" (Indicator: \"GetTickCount\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetTickCount\" (Indicator: \"GetTickCount\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1497.003",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1497/003"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Network Related",
        "identifier": "string-3",
        "type": 2,
        "relevance": 3,
        "name": "Found potential URL in binary/memory",
        "description": "Heuristic match: \"fD9.tH\"\n Pattern match: \"http://schemas.microsoft.com/SMI/2005/WindowsSettings\"\n Heuristic match: \"(s.IL\"",
        "origin": "File/Memory",
        "attck_id": "T1071",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1071"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Network Related",
        "identifier": "string-257",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to enumerate network resources (API string)",
        "description": "Found reference to API \"WNetGetConnectionWStub\" (Indicator: \"NetGetConnection\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"WNetAddConnection2WStub\" (Indicator: \"NetAddConnection\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"WNetGetConnectionWStub\" (Indicator: \"NetGetConnection\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"WNetAddConnection2WStub\" (Indicator: \"NetAddConnection\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1049",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1049"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Network Related",
        "identifier": "string-113",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to provide information and utilities for managing network resources (API string)",
        "description": "Found reference to API \"WNetCancelConnection2WStub\" (Indicator: \"WNetCancelConnection\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")",
        "origin": "File/Memory",
        "attck_id": "T1135",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1135"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "System Security",
        "identifier": "registry-173",
        "type": 3,
        "relevance": 1,
        "name": "Queries services related registry keys",
        "description": "\"cmd.exe\" (Access type: \"QUERYVAL\"; Path: \"HKLM\\SYSTEM\\CONTROLSET001\\SERVICES\\BAM\\USERSETTINGS\\S-1-5-21-735145574-3570218355-1207367261-1001\"; Key: \"\\DEVICE\\HARDDISKVOLUME2\\WINDOWS\\SYSTEM32\\CONHOST.EXE\"; Value: \"\")",
        "origin": "Registry Access",
        "attck_id": "T1007",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1007"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "System Security",
        "identifier": "string-426",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to modify file attributes (API string)",
        "description": "Found reference to API \"NtSetInformationFile\" (Indicator: \"SetInformationFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtSetInformationFile\" (Indicator: \"NtSetInformationFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"SetFileAttributesW\" (Indicator: \"SetFileAttributes\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"NtSetInformationFile\" (Indicator: \"SetInformationFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"NtSetInformationFile\" (Indicator: \"NtSetInformationFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"SetFileAttributesW\" (Indicator: \"SetFileAttributes\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1222",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1222"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "System Security",
        "identifier": "string-114",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to obtains specified information about the security of a file or directory (API string)",
        "description": "Found reference to API \"RevertToSelf\" (Indicator: \"RevertToSelf\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetFileSecurityW\" (Indicator: \"GetFileSecurityW\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"GetSecurityDescriptorOwner\" (Indicator: \"GetSecurityDescriptorOwner\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"RevertToSelf\" (Indicator: \"RevertToSelf\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetFileSecurityW\" (Indicator: \"GetFileSecurityW\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"GetSecurityDescriptorOwner\" (Indicator: \"GetSecurityDescriptorOwner\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1134.001",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1134/001"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "System Security",
        "identifier": "string-230",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to delete registry key/value (API string)",
        "description": "Found reference to API \"RegDeleteValueW\" (Indicator: \"RegDeleteValue\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"RegDeleteKeyExW\" (Indicator: \"RegDeleteKey\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"RegDeleteValueW\" (Indicator: \"RegDeleteValue\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"RegDeleteKeyExW\" (Indicator: \"RegDeleteKey\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1112",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1112"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "System Security",
        "identifier": "string-402",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to modify process attributes (API string)",
        "description": "Found reference to API \"InitializeProcThreadAttributeList\" (Indicator: \"InitializeProcThreadAttributeList\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"UpdateProcThreadAttribute\" (Indicator: \"UpdateProcThreadAttribute\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"InitializeProcThreadAttributeList\" (Indicator: \"InitializeProcThreadAttributeList\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"UpdateProcThreadAttribute\" (Indicator: \"UpdateProcThreadAttribute\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1562.001",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1562/001"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "System Security",
        "identifier": "string-168",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to create process with token (API string)",
        "description": "Found reference to API \"CreateProcessAsUserW\" (Indicator: \"CreateProcessAsUser\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")",
        "origin": "File/Memory",
        "attck_id": "T1134.002",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1134/002"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "System Security",
        "identifier": "string-535",
        "type": 2,
        "relevance": 0,
        "name": "Contains ability to write files (API string)",
        "description": "Found reference to API \"WriteFile\" (Indicator: \"WriteFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"WriteFile\" (Indicator: \"WriteFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1105",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1105"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "System Security",
        "identifier": "string-308",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to delete files/directories (API string)",
        "description": "Found reference to API \"DeleteFileW\" (Indicator: \"DeleteFile\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"RemoveDirectoryW\" (Indicator: \"RemoveDirectory\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"DeleteFileW\" (Indicator: \"DeleteFile\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")\n Found reference to API \"RemoveDirectoryW\" (Indicator: \"RemoveDirectory\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1070.004",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1070/004"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "System Security",
        "identifier": "string-316",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to terminate a process (API string)",
        "description": "Found reference to API \"TerminateProcess\" (Indicator: \"TerminateProcess\"; File: \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\")\n Found reference to API \"TerminateProcess\" (Indicator: \"TerminateProcess\"; Source: \"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1489",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1489"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "System Security",
        "identifier": "static-87",
        "type": 0,
        "relevance": 1,
        "name": "Imports system security related APIs",
        "description": "Observed import api \"GetFileSecurityW\" which can \"Obtains specified information about the security of a file or directory\" [Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin]\n Observed import api \"GetSecurityDescriptorOwner\" which can \"Retrieves the owner information from a security descriptor\" [Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin]\n Observed import api \"RevertToSelf\" which can \"Terminates the impersonation of a client application\" [Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin]",
        "origin": "Static Parser",
        "attck_id": "T1134.001",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1134/001"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "System Security",
        "identifier": "string-474",
        "type": 2,
        "relevance": 1,
        "name": "Contains ability to access device drivers",
        "description": "Found string \"\\Device\\HarddiskVolume2\\cmd.exe\" (Indicator: \"\\Device\\\"; Source: \"00000000-00004716.00000000.77972.69D30000.00000004.mdmp, 00000000-00004716.00000001.79890.69D30000.00000004.mdmp, 00000000-00004716.00000002.81813.69D30000.00000004.mdmp\")",
        "origin": "File/Memory",
        "attck_id": "T1543.003",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1543/003"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "External Systems",
        "identifier": "avtest-1",
        "type": 12,
        "relevance": 10,
        "name": "Sample was identified as clean by Antivirus engines",
        "description": "0/71 Antivirus vendors marked sample as malicious (0% detection rate)",
        "origin": "External System",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 1,
        "threat_level_human": "suspicious",
        "category": "General",
        "identifier": "static-92",
        "type": 0,
        "relevance": 5,
        "name": "PE file has unusual entropy resources",
        "description": "\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" has resource with unusual entropy  \"RT_ICON:7.85051980666\"",
        "origin": "Static Parser",
        "attck_id": "T1027.002",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1027/002"
      },
      {
        "threat_level": 1,
        "threat_level_human": "suspicious",
        "category": "Unusual Characteristics",
        "identifier": "hooks-8",
        "type": 11,
        "relevance": 10,
        "name": "Installs hooks/patches the running process",
        "description": "\"cmd.exe\" wrote bytes \"e0e8c4d7f97f0000\" to virtual address \"0x4932E000\" (part of module \"CMD.EXE\")\n \"cmd.exe\" wrote bytes \"a09d036a5b010000608e036a5b01000090b7016a5b010000a090036a5b010000508d016a5b010000502e016a5b01000020c4036a5b01000070bb036a5b01000080bc036a5b0100004078046a5b010000a0ba036a5b0100000088036a5b010000\" to virtual address \"0xE7D74030\" (part of module \"GDI32.DLL\")",
        "origin": "Hook Detection",
        "attck_id": "T1056.004",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1056/004"
      },
      {
        "threat_level": 1,
        "threat_level_human": "suspicious",
        "category": "Unusual Characteristics",
        "identifier": "static-1",
        "type": 0,
        "relevance": 1,
        "name": "Imports suspicious APIs",
        "description": "UnhandledExceptionFilter\n GetDriveTypeW\n GetFileAttributesW\n GetFileSize\n CreateDirectoryW\n DeleteFileW\n WriteFile\n FindNextFileW\n FindFirstFileW\n FindFirstFileExW\n GetFileAttributesExW\n CreateFileW\n DeviceIoControl\n CopyFileW\n GetProcAddress\n LoadLibraryExW\n GetModuleFileNameW\n GetModuleHandleW\n VirtualAlloc\n ReadProcessMemory\n GetCommandLineW\n TerminateProcess\n CreateProcessW\n GetStartupInfoW\n CreateProcessAsUserW\n RegCreateKeyExW\n RegDeleteValueW\n RegCloseKey\n RegEnumKeyExW\n RegOpenKeyExW\n RegDeleteKeyExW\n Sleep\n GetTickCount\n NtQueryInformationToken\n NtQueryInformationProcess",
        "origin": "Static Parser",
        "attck_id": "T1106",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1106"
      },
      {
        "threat_level": 1,
        "threat_level_human": "suspicious",
        "category": "Anti-Reverse Engineering",
        "identifier": "static-6",
        "type": 0,
        "relevance": 3,
        "name": "PE file has unusual entropy sections",
        "description": ".didat with unusual entropies 0.907093089296",
        "origin": "Static Parser",
        "attck_id": "T1027.002",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1027/002"
      },
      {
        "threat_level": 2,
        "threat_level_human": "malicious",
        "category": "Anti-Detection/Stealthyness",
        "identifier": "target-94",
        "type": 9,
        "relevance": 3,
        "name": "Found a system process name at an unusual pathway",
        "description": "Process \"cmd.exe\" has a system process name but is not located in a Windows (sub-)directory (UID: 00000000-00004716)",
        "origin": "Monitored Target",
        "attck_id": "T1036.005",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/techniques/T1036/005"
      }
    ]
  },
  {
    "classification_tags": [],
    "tags": [],
    "submissions": [
      {
        "submission_id": "60f5dadb3ddbd71a493b4e50",
        "filename": "file",
        "url": null,
        "created_at": "2021-07-19T20:04:43+00:00"
      },
      {
        "submission_id": "60e87e8ed717cf14e5771f4f",
        "filename": "file",
        "url": null,
        "created_at": "2021-07-09T16:51:26+00:00"
      },
      {
        "submission_id": "5f196598c665454d4960c94d",
        "filename": "file",
        "url": null,
        "created_at": "2020-07-23T10:25:28+00:00"
      }
    ],
    "machine_learning_models": [],
    "crowdstrike_ai": {
      "executable_process_memory_analysis": [],
      "analysis_related_urls": []
    },
    "job_id": null,
    "environment_id": null,
    "environment_description": "Static Analysis",
    "size": 232960,
    "type": "PE32+ executable (console) x86-64, for MS Windows",
    "type_short": [
      "peexe",
      "64bits",
      "executable"
    ],
    "target_url": null,
    "state": "SUCCESS",
    "error_type": null,
    "error_origin": null,
    "submit_name": "file",
    "md5": "f4f684066175b77e0c3a000549d2922c",
    "sha1": "99ae9c73e9bee6f9c76d6f4093a9882df06832cf",
    "sha256": "935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2",
    "sha512": "fe8f0593cc335ad28eb90211bc4ff01a3d2992cffb3877d04cefede9ef94afeb1a7d7874dd0c0ae04eaf8308291d5a4d879e6ecf6fe2b8d0ff1c3ac7ef143206",
    "ssdeep": null,
    "imphash": null,
    "entrypoint": null,
    "entrypoint_section": null,
    "image_base": null,
    "subsystem": null,
    "image_file_characteristics": [],
    "dll_characteristics": [],
    "major_os_version": null,
    "minor_os_version": null,
    "av_detect": 0,
    "vx_family": null,
    "url_analysis": false,
    "analysis_start_time": "2020-07-23T10:25:28+00:00",
    "threat_score": null,
    "interesting": false,
    "threat_level": 0,
    "verdict": "no specific threat",
    "certificates": [],
    "is_certificates_valid": null,
    "certificates_validation_message": null,
    "domains": [],
    "compromised_hosts": [],
    "hosts": [],
    "total_network_connections": 0,
    "total_processes": 0,
    "total_signatures": 0,
    "extracted_files": [],
    "file_metadata": null,
    "processes": [],
    "mitre_attcks": [],
    "network_mode": "default",
    "signatures": []
  },
  {
    "classification_tags": [],
    "tags": [],
    "submissions": [
      {
        "submission_id": "60195513efa3090ef70210f9",
        "filename": "utilman.exe",
        "url": null,
        "created_at": "2021-02-02T13:35:15+00:00"
      },
      {
        "submission_id": "5fd594e5fbef250536222759",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2020-12-13T04:13:25+00:00"
      },
      {
        "submission_id": "5f75727102a5f179cd29069e",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2020-10-01T06:08:49+00:00"
      },
      {
        "submission_id": "5ec0ceb2d7ce6a2712303213",
        "filename": "Utilman.exe",
        "url": null,
        "created_at": "2020-05-17T05:42:10+00:00"
      },
      {
        "submission_id": "5e53273fb30de355842896a2",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2020-02-24T01:30:39+00:00"
      },
      {
        "submission_id": "5d288eb0038838a74cfa9906",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2019-07-12T13:44:16+00:00"
      },
      {
        "submission_id": "5d2500bd0288388e538437b1",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2019-07-09T21:01:49+00:00"
      },
      {
        "submission_id": "5cbea1b4038838399c0365ff",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2019-04-23T05:25:08+00:00"
      },
      {
        "submission_id": "5c35e7b37ca3e11e9f79e9a4",
        "filename": "sethc.exe",
        "url": null,
        "created_at": "2019-01-09T06:23:15-06:00"
      },
      {
        "submission_id": "5c35cef37ca3e1571e6b9436",
        "filename": "sethc.exe",
        "url": null,
        "created_at": "2019-01-09T04:37:39-06:00"
      },
      {
        "submission_id": "5c35cdce7ca3e1550a1e6a92",
        "filename": "sethc.exe",
        "url": null,
        "created_at": "2019-01-09T04:32:46-06:00"
      },
      {
        "submission_id": "5b577fba7ca3e13656490373",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-07-24T14:36:26-05:00"
      },
      {
        "submission_id": "5b5601b37ca3e171691d73e2",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-07-23T11:26:27-05:00"
      },
      {
        "submission_id": "5b0e04857ca3e14c8f62c6fb",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-05-29T20:55:17-05:00"
      },
      {
        "submission_id": "5ad854a47ca3e1453f07bc82",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-04-19T03:34:44-05:00"
      },
      {
        "submission_id": "5ab269537ca3e101fb04a953",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-03-21T09:16:51-05:00"
      },
      {
        "submission_id": "5ab0cffe7ca3e12af23357d3",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-03-20T04:10:22-05:00"
      },
      {
        "submission_id": "5a94e29e7ca3e122510713e2",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-02-26T22:46:22-06:00"
      },
      {
        "submission_id": "5a26f15e7ca3e1169435c782",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2017-12-05T13:19:58-06:00"
      },
      {
        "submission_id": "5a26f0c47ca3e1158b6ee0e2",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2017-12-05T13:17:24-06:00"
      }
    ],
    "machine_learning_models": [],
    "crowdstrike_ai": {
      "executable_process_memory_analysis": [],
      "analysis_related_urls": []
    },
    "job_id": "58593319aac2edc56d351531",
    "environment_id": 100,
    "environment_description": "Windows 7 32 bit",
    "size": 232960,
    "type": "PE32+ executable (console) x86-64, for MS Windows",
    "type_short": [
      "peexe",
      "64bits",
      "executable"
    ],
    "target_url": null,
    "state": "SUCCESS",
    "error_type": null,
    "error_origin": null,
    "submit_name": "cmd.exe",
    "md5": "f4f684066175b77e0c3a000549d2922c",
    "sha1": "99ae9c73e9bee6f9c76d6f4093a9882df06832cf",
    "sha256": "935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2",
    "sha512": "fe8f0593cc335ad28eb90211bc4ff01a3d2992cffb3877d04cefede9ef94afeb1a7d7874dd0c0ae04eaf8308291d5a4d879e6ecf6fe2b8d0ff1c3ac7ef143206",
    "ssdeep": "3072:bkd4COZG6/A1tO1Y6TbkX2FtynroeJ/MEJoSsasbLLkhyjyGe:bkuC9+Af0Y6TbbFtkoeJk1KsfLXm",
    "imphash": "3062ed732d4b25d1c64f084dac97d37a",
    "entrypoint": "0x140015190",
    "entrypoint_section": ".text",
    "image_base": null,
    "subsystem": null,
    "image_file_characteristics": [],
    "dll_characteristics": [],
    "major_os_version": null,
    "minor_os_version": null,
    "av_detect": 0,
    "vx_family": null,
    "url_analysis": false,
    "analysis_start_time": "2020-02-24T01:30:48+00:00",
    "threat_score": 30,
    "interesting": false,
    "threat_level": 3,
    "verdict": "no verdict",
    "certificates": [],
    "is_certificates_valid": null,
    "certificates_validation_message": null,
    "domains": [],
    "compromised_hosts": [],
    "hosts": [],
    "total_network_connections": 0,
    "total_processes": 1,
    "total_signatures": 14,
    "extracted_files": [],
    "file_metadata": null,
    "processes": [],
    "mitre_attcks": [
      {
        "tactic": "Discovery",
        "technique": "System Time Discovery",
        "attck_id": "T1124",
        "attck_id_wiki": "https://attack.mitre.org/wiki/Technique/T1124",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "File and Directory Discovery",
        "attck_id": "T1083",
        "attck_id_wiki": "https://attack.mitre.org/wiki/Technique/T1083",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      }
    ],
    "network_mode": "default",
    "signatures": [
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-7",
        "type": 2,
        "relevance": 1,
        "name": "Contains PDB pathways",
        "description": "\"cmd.pdb\"",
        "origin": "File/Memory",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Anti-Reverse Engineering",
        "identifier": "stream-4",
        "type": 1,
        "relevance": 1,
        "name": "Contains ability to register a top-level exception handler (often used as anti-debugging trick)",
        "description": "SetUnhandledExceptionFilter@api-ms-win-core-errorhandling-l1-1-1.dll at 43727-268-00000001400151E4",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "stream-49",
        "type": 1,
        "relevance": 1,
        "name": "Contains ability to query the system locale",
        "description": "GetUserDefaultLCID@api-ms-win-core-localization-l1-2-1.dll at 43727-287-00000001400069BC",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "stream-2",
        "type": 1,
        "relevance": 1,
        "name": "Contains ability to query machine time",
        "description": "GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-284-0000000140002BA0\n GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-285-000000014001F53C\n GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-296-00000001400020C8\n GetLocalTime@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-993-000000014001F6C3\n GetSystemTimeAsFileTime@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-599-00000001400156B4",
        "origin": "Hybrid Analysis Technology",
        "attck_id": "T1124",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/wiki/Technique/T1124"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "stream-3",
        "type": 1,
        "relevance": 1,
        "name": "Contains ability to query the machine version",
        "description": "GetVersion@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-439-0000000140001008",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "stream-37",
        "type": 1,
        "relevance": 3,
        "name": "Contains ability to query volume size",
        "description": "GetDiskFreeSpaceExW@api-ms-win-core-file-l1-2-1.dll at 43727-485-000000014002542C",
        "origin": "Hybrid Analysis Technology",
        "attck_id": "T1083",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/wiki/Technique/T1083"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "stream-31",
        "type": 1,
        "relevance": 1,
        "name": "Possibly tries to detect the presence of a debugger",
        "description": "GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-314-000000014000BC30\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-316-0000000140008FA0\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-270-000000014000B4A0\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-271-000000014000B530\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-277-0000000140011840\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-297-000000014000E278\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-298-000000014000E2EC\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-305-0000000140005C6C\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-661-00000001400016F0\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-331-0000000140014D2C\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-355-0000000140005954\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-366-00000001400032FC\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-383-000000014000D360\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-441-000000014000D110\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-511-000000014000B170\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-523-000000014000BCE0\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-588-0000000140006418\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-596-000000014001168C\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-605-0000000140014190\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-607-0000000140014044",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Network Related",
        "identifier": "string-3",
        "type": 2,
        "relevance": 10,
        "name": "Found potential URL in binary/memory",
        "description": "Pattern match: \"http://schemas.microsoft.com/SMI/2005/WindowsSettings\"",
        "origin": "File/Memory",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "External Systems",
        "identifier": "avtest-1",
        "type": 12,
        "relevance": 10,
        "name": "Sample was identified as clean by Antivirus engines",
        "description": "0/68 Antivirus vendors marked sample as malicious (0% detection rate)\n 0/22 Antivirus vendors marked sample as malicious (0% detection rate)",
        "origin": "External System",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 1,
        "threat_level_human": "suspicious",
        "category": "Unusual Characteristics",
        "identifier": "static-60",
        "type": 0,
        "relevance": 10,
        "name": "PE file contains unusual section name",
        "description": "\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" has a section named \".didat\"",
        "origin": "Static Parser",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 1,
        "threat_level_human": "suspicious",
        "category": "Unusual Characteristics",
        "identifier": "static-1",
        "type": 0,
        "relevance": 1,
        "name": "Imports suspicious APIs",
        "description": "UnhandledExceptionFilter\n GetDriveTypeW\n GetFileAttributesW\n GetFileSize\n CreateDirectoryW\n DeleteFileW\n WriteFile\n FindNextFileW\n FindFirstFileW\n FindFirstFileExW\n GetFileAttributesExW\n CreateFileW\n DeviceIoControl\n CopyFileW\n GetProcAddress\n LoadLibraryExW\n GetModuleFileNameW\n GetModuleHandleW\n VirtualAlloc\n ReadProcessMemory\n GetCommandLineW\n TerminateProcess\n CreateProcessW\n GetStartupInfoW\n CreateProcessAsUserW\n RegCreateKeyExW\n RegDeleteValueW\n RegCloseKey\n RegEnumKeyExW\n RegOpenKeyExW\n RegDeleteKeyExW\n Sleep\n GetTickCount\n NtQueryInformationToken\n NtQueryInformationProcess",
        "origin": "Static Parser",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 1,
        "threat_level_human": "suspicious",
        "category": "Anti-Detection/Stealthyness",
        "identifier": "stream-42",
        "type": 1,
        "relevance": 3,
        "name": "Possibly tries to hide a process launching it with different user credentials",
        "description": "CreateProcessAsUserW@api-ms-win-core-processthreads-l1-1-2.dll at 43727-828-000000014000EFFE",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 2,
        "threat_level_human": "malicious",
        "category": "General",
        "identifier": "stream-21",
        "type": 1,
        "relevance": 8,
        "name": "Contains ability to start/interact with device drivers",
        "description": "DeviceIoControl@api-ms-win-core-io-l1-1-1.dll at 43727-611-0000000140013690",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 2,
        "threat_level_human": "malicious",
        "category": "Unusual Characteristics",
        "identifier": "stream-22",
        "type": 1,
        "relevance": 5,
        "name": "Contains native function calls",
        "description": "NtFsControlFile@ntdll.dll at 43727-309-00000001400268C4\n NtCancelSynchronousIoFile@ntdll.dll at 43727-532-00000001400227A0\n NtOpenThreadToken@ntdll.dll at 43727-585-00000001400029C0\n NtQueryInformationToken@ntdll.dll at 43727-586-0000000140002A84\n NtQueryInformationToken@ntdll.dll at 43727-587-0000000140002AD4\n NtQueryInformationProcess@ntdll.dll at 43727-630-0000000140004480\n NtOpenFile@ntdll.dll at 43727-643-00000001400042DC\n NtQueryVolumeInformationFile@ntdll.dll at 43727-644-00000001400043D8",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      }
    ]
  },
  {
    "classification_tags": [],
    "tags": [],
    "submissions": [
      {
        "submission_id": "5f85aeb7dbdeb607bb5e34eb",
        "filename": "kiss.exe",
        "url": null,
        "created_at": "2020-10-13T13:42:15+00:00"
      },
      {
        "submission_id": "5d8b4dbf028838d6417f6d53",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2019-09-25T11:21:35+00:00"
      },
      {
        "submission_id": "5d8b4db702883891837f6b95",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2019-09-25T11:21:27+00:00"
      },
      {
        "submission_id": "5d4846eb0288385a279299b7",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2019-08-05T15:10:35+00:00"
      },
      {
        "submission_id": "5d250066038838da118437b2",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2019-07-09T21:00:22+00:00"
      },
      {
        "submission_id": "5ce828c5038838ca61130390",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2019-05-24T17:24:21+00:00"
      },
      {
        "submission_id": "5cb263840388384184827cf6",
        "filename": "sethc.exe",
        "url": null,
        "created_at": "2019-04-13T22:32:36+00:00"
      },
      {
        "submission_id": "5b69b6167ca3e129e233b695",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-08-07T10:09:10-05:00"
      },
      {
        "submission_id": "5b576e3e7ca3e1632e094913",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-07-24T13:21:50-05:00"
      },
      {
        "submission_id": "5b576ce57ca3e15a46380635",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-07-24T13:16:05-05:00"
      },
      {
        "submission_id": "5ab0d1057ca3e12dbd5d09f2",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-03-20T04:14:45-05:00"
      },
      {
        "submission_id": "5a7c75817ca3e13c9b2ebf52",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2018-02-08T10:06:25-06:00"
      },
      {
        "submission_id": "5a34f2a27ca3e13531789a94",
        "filename": "cmd.exe",
        "url": null,
        "created_at": "2017-12-16T04:17:06-06:00"
      }
    ],
    "machine_learning_models": [],
    "crowdstrike_ai": {
      "executable_process_memory_analysis": [],
      "analysis_related_urls": []
    },
    "job_id": "5a34f2a27ca3e13531789a95",
    "environment_id": 120,
    "environment_description": "Windows 7 64 bit",
    "size": 232960,
    "type": "PE32+ executable (console) x86-64, for MS Windows",
    "type_short": [
      "peexe",
      "64bits",
      "executable"
    ],
    "target_url": null,
    "state": "SUCCESS",
    "error_type": null,
    "error_origin": null,
    "submit_name": "cmd.exe",
    "md5": "f4f684066175b77e0c3a000549d2922c",
    "sha1": "99ae9c73e9bee6f9c76d6f4093a9882df06832cf",
    "sha256": "935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2",
    "sha512": "fe8f0593cc335ad28eb90211bc4ff01a3d2992cffb3877d04cefede9ef94afeb1a7d7874dd0c0ae04eaf8308291d5a4d879e6ecf6fe2b8d0ff1c3ac7ef143206",
    "ssdeep": "3072:bkd4COZG6/A1tO1Y6TbkX2FtynroeJ/MEJoSsasbLLkhyjyGe:bkuC9+Af0Y6TbbFtkoeJk1KsfLXm",
    "imphash": "3062ed732d4b25d1c64f084dac97d37a",
    "entrypoint": "0x140015190",
    "entrypoint_section": ".text",
    "image_base": null,
    "subsystem": null,
    "image_file_characteristics": [],
    "dll_characteristics": [],
    "major_os_version": null,
    "minor_os_version": null,
    "av_detect": 0,
    "vx_family": null,
    "url_analysis": false,
    "analysis_start_time": "2019-09-25T11:21:32+00:00",
    "threat_score": 30,
    "interesting": false,
    "threat_level": 3,
    "verdict": "no verdict",
    "certificates": [],
    "is_certificates_valid": null,
    "certificates_validation_message": null,
    "domains": [],
    "compromised_hosts": [],
    "hosts": [],
    "total_network_connections": 0,
    "total_processes": 1,
    "total_signatures": 14,
    "extracted_files": [],
    "file_metadata": null,
    "processes": [],
    "mitre_attcks": [
      {
        "tactic": "Discovery",
        "technique": "File and Directory Discovery",
        "attck_id": "T1083",
        "attck_id_wiki": "https://attack.mitre.org/wiki/Technique/T1083",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      },
      {
        "tactic": "Discovery",
        "technique": "System Time Discovery",
        "attck_id": "T1124",
        "attck_id_wiki": "https://attack.mitre.org/wiki/Technique/T1124",
        "malicious_identifiers_count": 0,
        "malicious_identifiers": [],
        "suspicious_identifiers_count": 0,
        "suspicious_identifiers": [],
        "informative_identifiers_count": 1,
        "informative_identifiers": [],
        "parent": null
      }
    ],
    "network_mode": "default",
    "signatures": [
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "General",
        "identifier": "string-7",
        "type": 2,
        "relevance": 1,
        "name": "Contains PDB pathways",
        "description": "\"cmd.pdb\"",
        "origin": "File/Memory",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Anti-Reverse Engineering",
        "identifier": "stream-4",
        "type": 1,
        "relevance": 1,
        "name": "Contains ability to register a top-level exception handler (often used as anti-debugging trick)",
        "description": "SetUnhandledExceptionFilter@api-ms-win-core-errorhandling-l1-1-1.dll at 12264-268-00000001400151E4",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "stream-31",
        "type": 1,
        "relevance": 1,
        "name": "Possibly tries to detect the presence of a debugger",
        "description": "GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-314-000000014000BC30\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-316-0000000140008FA0\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-270-000000014000B4A0\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-271-000000014000B530\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-277-0000000140011840\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-331-0000000140014D2C\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-297-000000014000E278\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-298-000000014000E2EC\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-305-0000000140005C6C\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-383-000000014000D360\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-355-0000000140005954\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-366-00000001400032FC\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-441-000000014000D110\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-511-000000014000B170\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-523-000000014000BCE0\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-588-0000000140006418\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-596-000000014001168C\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-605-0000000140014190\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-623-00000001400123F0\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-607-0000000140014044",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "stream-37",
        "type": 1,
        "relevance": 3,
        "name": "Contains ability to query volume size",
        "description": "GetDiskFreeSpaceExW@api-ms-win-core-file-l1-2-1.dll at 12264-485-000000014002542C",
        "origin": "Hybrid Analysis Technology",
        "attck_id": "T1083",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/wiki/Technique/T1083"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "stream-2",
        "type": 1,
        "relevance": 1,
        "name": "Contains ability to query machine time",
        "description": "GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-284-0000000140002BA0\n GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-285-000000014001F53C\n GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-296-00000001400020C8\n GetSystemTimeAsFileTime@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-599-00000001400156B4\n GetLocalTime@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-993-000000014001F6C3",
        "origin": "Hybrid Analysis Technology",
        "attck_id": "T1124",
        "capec_id": null,
        "attck_id_wiki": "https://attack.mitre.org/wiki/Technique/T1124"
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "stream-3",
        "type": 1,
        "relevance": 1,
        "name": "Contains ability to query the machine version",
        "description": "GetVersion@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-439-0000000140001008",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Environment Awareness",
        "identifier": "stream-49",
        "type": 1,
        "relevance": 1,
        "name": "Contains ability to query the system locale",
        "description": "GetUserDefaultLCID@api-ms-win-core-localization-l1-2-1.dll at 12264-287-00000001400069BC",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "Network Related",
        "identifier": "string-3",
        "type": 2,
        "relevance": 10,
        "name": "Found potential URL in binary/memory",
        "description": "Pattern match: \"http://schemas.microsoft.com/SMI/2005/WindowsSettings\"",
        "origin": "File/Memory",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 0,
        "threat_level_human": "informative",
        "category": "External Systems",
        "identifier": "avtest-1",
        "type": 12,
        "relevance": 10,
        "name": "Sample was identified as clean by Antivirus engines",
        "description": "0/16 Antivirus vendors marked sample as malicious (0% detection rate)\n 0/70 Antivirus vendors marked sample as malicious (0% detection rate)",
        "origin": "External System",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 1,
        "threat_level_human": "suspicious",
        "category": "Unusual Characteristics",
        "identifier": "static-60",
        "type": 0,
        "relevance": 10,
        "name": "PE file contains unusual section name",
        "description": "\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\" has a section named \".didat\"",
        "origin": "Static Parser",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 1,
        "threat_level_human": "suspicious",
        "category": "Unusual Characteristics",
        "identifier": "static-1",
        "type": 0,
        "relevance": 1,
        "name": "Imports suspicious APIs",
        "description": "UnhandledExceptionFilter\n GetDriveTypeW\n GetFileAttributesW\n GetFileSize\n CreateDirectoryW\n DeleteFileW\n WriteFile\n FindNextFileW\n FindFirstFileW\n FindFirstFileExW\n GetFileAttributesExW\n CreateFileW\n DeviceIoControl\n CopyFileW\n GetProcAddress\n LoadLibraryExW\n GetModuleFileNameW\n GetModuleHandleW\n VirtualAlloc\n ReadProcessMemory\n GetCommandLineW\n TerminateProcess\n CreateProcessW\n GetStartupInfoW\n CreateProcessAsUserW\n RegCreateKeyExW\n RegDeleteValueW\n RegCloseKey\n RegEnumKeyExW\n RegOpenKeyExW\n RegDeleteKeyExW\n Sleep\n GetTickCount\n NtQueryInformationToken\n NtQueryInformationProcess",
        "origin": "Static Parser",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 1,
        "threat_level_human": "suspicious",
        "category": "Anti-Detection/Stealthyness",
        "identifier": "stream-42",
        "type": 1,
        "relevance": 3,
        "name": "Possibly tries to hide a process launching it with different user credentials",
        "description": "CreateProcessAsUserW@api-ms-win-core-processthreads-l1-1-2.dll at 12264-828-000000014000EFFE",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 2,
        "threat_level_human": "malicious",
        "category": "General",
        "identifier": "stream-21",
        "type": 1,
        "relevance": 8,
        "name": "Contains ability to start/interact with device drivers",
        "description": "DeviceIoControl@api-ms-win-core-io-l1-1-1.dll at 12264-611-0000000140013690",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      },
      {
        "threat_level": 2,
        "threat_level_human": "malicious",
        "category": "Unusual Characteristics",
        "identifier": "stream-22",
        "type": 1,
        "relevance": 5,
        "name": "Contains native function calls",
        "description": "NtFsControlFile@ntdll.dll at 12264-309-00000001400268C4\n NtCancelSynchronousIoFile@ntdll.dll at 12264-532-00000001400227A0\n NtOpenProcessToken@ntdll.dll at 12264-585-00000001400029C0\n NtQueryInformationToken@ntdll.dll at 12264-586-0000000140002A84\n NtQueryInformationToken@ntdll.dll at 12264-587-0000000140002AD4\n NtSetInformationProcess@ntdll.dll at 12264-630-0000000140004480\n NtOpenFile@ntdll.dll at 12264-643-00000001400042DC\n NtQueryVolumeInformationFile@ntdll.dll at 12264-644-00000001400043D8",
        "origin": "Hybrid Analysis Technology",
        "attck_id": null,
        "capec_id": null,
        "attck_id_wiki": null
      }
    ]
  }
]
```

---

#### What's Next

* [IP Geolocation](/docs/api-integrations-ip-geolocation)

Table of contents

+ [Detection &amp; Response Rules](#detection-amp-response-rules)

Tags

* [add-ons](/docs/en/tags/add-ons)

---

## IIS Logs

# IIS Logs
Microsoft's Internet Information Services (IIS) web server is a web server commonly found on Microsoft Windows servers. This Adapter assists with sending IIS web logs to LimaCharlie via the Adapter binary.

Telemetry Platform (if applicable): `iis`

## Deployment Configurations

All adapters support the same `client_options`, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.

* `client_options.identity.oid`: the LimaCharlie Organization ID (OID) this adapter is used with.
* `client_options.identity.installation_key`: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.
* `client_options.platform`: the type of data ingested through this adapter, like `text`, `json`, `gcp`, `carbon_black`, etc.
* `client_options.sensor_seed_key`: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.

### Adapter-specific Options

IIS web logs often have a standardized schema, unless manually changed by administrators. The `iis` platform in LimaCharlie expects the following structure:

`#Fields: date time s-ip cs-method cs-uri-stem cs-uri-query s-port cs-username c-ip cs(User-Agent) cs(Referer) sc-status sc-substatus sc-win32-status time-taken`

Log Structure

If your IIS logs are a different structure from above, please let us know and we can assist in customizing the parser!

The structure of these fields is as follows:

| Field Name | Explanation |
| --- | --- |
| date | Date of log entry |
| time | Time of log entry |
| s-ip | The IP address of the web server |
| cs-method | The method of request from the client |
| cs-uri-stem | The URI requested by the client |
| cs-uri-query | The query added to the URI in the client request |
| s-port | The server port) |
| cs-username | The client username (if provided) |
| c-ip | The IP address of the client |
| cs-user-agent | The user-agent of the client |
| cs-referer | The referer that directed the client to the site |
| sc-status | The service status code |
| sc-substatus | The service substatus code (if applicable) |
| sc-win32-status | The Windows status code |
| time-taken | The time taken to render the request resource(s) |

## Configuration File

IIS logs are typically stored "on disk" of the web server, in files that roll daily. Thus, collecting IIS web logs would be done with a binary Adapter that can monitor specific IIS log folder(s) for new files. The Adapter type would be `file`, while the platform is `iis`.

The following configuration file can be used as a starter to monitor IIS web log directories. Replace any values with `< >` characters with values unique to your Organization and/or deployment. *Do not include the* `<` *or* `>` *characters in your config file!*

*Please customize according to your environment/LimaCharlie organization*

```
file:
  client_options:
    identity:
      installation_key: <installation key>
      oid: <organization id>
    platform: iis
    sensor_seed_key: <sensor_seed_key>
    // The following will map the timestamp of the event to the timestamp in the web log. Remove if you'd prefer to keep the event time as the time of ingestion.
    mapping:
      event_time_path: ts
  file_path: <C:\path\to\web\logs\u*.log>
  no_follow: false
```

A few notes about the IIS platform parser:

* The server IP address (identified in the logs as `s-ip` will be used as the hostname within LimaCharlie.
* The `date` and `time` fields are combined to a single field represented as `ts`. The above configuration uses this field as the event time, unless removed.
* The `sensor_seed_key` can be any value of your choosing, please make sure it's unique per web server.
* You can specify multiple configurations in one file if you wish to collect logs from multiple folders.
* The `no_follow: false` specification ensures that the Adapter monitors for new files and/or writes to existing files. You can exclude this option if you are going to ingest "dead" log files.
* All IIS events will be represented as `IIS_WEBLOG` in the Adapter telemetry.

If you have any questions about collecting IIS web logs, please reach out to the LimaCharlie team.

Once the config file is set, you can run the Adapter on Windows with the following command (assuming the file is named `config.yaml`):

`<adapter_name>.exe file config.yaml`

## Example Event

```json
{
    "c-ip": "192.168.1.11",
    "cs-method": "GET",
    "cs-referer)": "-",
    "cs-uri-query": "-",
    "cs-uri-stem": "/path/to/my/web/page",
    "cs-user-agent": "Mozilla/5.0+(Windows+NT+10.0;+Win64;+x64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/128.0.0.0+Safari/537.36",
    "cs-username": "-",
    "s-ip": "192.168.1.10",
    "s-port": "99",
    "sc-status": "401",
    "sc-substatus": "2",
    "sc-win32-status": "5",
    "time-taken": "143",
    "ts": "2024-09-05 12:36:14"
}
```

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

---

### What's Next

* [IMAP](/docs/adapter-types-imap)

Table of contents

+ [Deployment Configurations](#deployment-configurations)
+ [Configuration File](#configuration-file)
+ [Example Event](#example-event)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## IMAP

# IMAP
## Overview

This Adapter allows you to ingest emails as events from an IMAP server.

## Configurations

Adapter Type: `imap`

* `client_options`: common configuration for adapter as defined [here](/v2/docs/adapters#usage).
* `server`: the domain and port of the IMAP server, like `imap.gmail.com:993`.
* `username`: the user name to log in to IMAP as.
* `password`: the password for the above user name.
* `inbox_name`: the name of the inbox to monitor.
* `is_insecure`: do NOT connect using SSL.
* `from_zero`: collect all existing emails in the inbox.
* `include_attachments`: send attachment data to LimaCharlie, used to generate attachent hashes in the cloud.
* `max_body_size`: only send attachments below this many bytes to LimaCharlie.
* `attachment_ingest_key`: if specified, an [Ingestion Key](/v2/docs/api-keys) used to ingest attachment as Artifacts into LimaCharlie.
* `attachment_retention_days`: the number of days to retain Artifact attachment for.

### Infrastructure as Code Deployment

```
# IMAP Specific Docs: https://docs.limacharlie.io/docs/adapter-types-imap

sensor_type: "imap"
imap:
  server: "imap.yourmailserver.com:993"
  username: "hive://secret/imap-username"
  password: "hive://secret/imap-password"
  client_options:
    identity:
      oid: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
      installation_key: "YOUR_LC_INSTALLATION_KEY_IMAP"
    hostname: "imap-email-collector"
    platform: "json"
    sensor_seed_key: "imap-sensor-001"
    mapping:
      sensor_hostname_path: "headers.X-Originating-IP"
      event_type_path: "headers.Subject"
      event_time_path: "headers.Date"
    indexing: []
  # Optional IMAP-specific configuration
  inbox_name: "INBOX"                    # Default: "INBOX"
  is_insecure: false                     # Default: false (use SSL/TLS)
  from_zero: false                       # Default: false (only new emails)
  include_attachments: true              # Default: false
  max_body_size: 102400                  # Default: 0 (no limit)
  attachment_ingest_key: "attachments_data"      # Default: empty
  attachment_retention_days: 30          # Default: 0 (no retention)
```

## Use Cases

Although this Adapter can be used on any IMAP server for any inbox, it is often used to perform enterprise wide analysis and alerting using Email Journaling.

Email Journaling is supported by all major email platforms to perform analysis at scale. It generally involves enabling a data flow of all emails on the platform towards a specific email account where all emails accumulate.

Documentation for common platforms:

* [Exchange Online](https://learn.microsoft.com/en-us/exchange/security-and-compliance/journaling/journaling)
* [Google Workspace](https://support.google.com/a/answer/7276605?product_name=UnuFlow&hl=en&visit_id=638608978952474178-2452031765&rd=1&src=supportwidget0&hl=en)

## Example Format

Emails ingested through the IMAP Adapter are in raw format so that detailed header information can be included and analyzed. Below is an example of an email received into LimaCharlie from a Google Workspace mailbox:

```json
{
    "event": {
        "headers": {
            "arc-authentication-results": [
                "i=1; mx.google.com; dkim=pass header.i=@evil.com header.s=google header.b=LdyiNwmQ; spf=pass (google.com: domain of badguy@evil.com designates 209.85.220.41 as permitted sender) smtp.mailfrom=badguy@evil.com; dmarc=pass (p=NONE sp=NONE dis=NONE) header.from=evil.com; dara=pass header.i=@gmail.com"
            ],
            "arc-message-signature": [
                "i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816; h=to:subject:message-id:date:from:mime-version:dkim-signature; bh=NWZDzWD3fcPGImfiLFJgiOAWQBc6o9f064zRNQOEAZA=; fh=LdhDNbjh6ex3RxMo3wPAKsbuLWT+x/GDPYiwjW9lr10=; b=Y4WpYrqSVH+EuabO9I4v/LUf9MpLBNxghhA3btw3i31h3YHwssUKcYmfGu/LN5+2qc O4h7QYPT8oq5Sbk5T9NYYXb/u2XEyFmcHq78X9r1VBGgRXVzDVoAVE6uYdE+bMSsnBCx grJrZV+HEejJh91iNRlJ8+RDlESBAWastC6YpDHmZkAveUjMUzFBYzTiqCmGBjNYjfoF FOZSrlXMPj4fitoFunI57miFMXjXxiselSo9UEMuyeEcHAuiGZUyNHhLDTri+Nmf/5w1 QvaKCTx7iL4HpeS7budFLf4CuPbqNVIKmvsGq5vn68WFSO8i8AOW08IsKVlw/13KWQlu 6pTg==; dara=google.com"
            ],
            "arc-seal": [
                "i=1; a=rsa-sha256; t=1725302104; cv=none; d=google.com; s=arc-20160816; b=VPXTfX1HVTFWRixWBstbi2VEAFi6Tt7tfZPEn+4DBZ84n6Jn0MxTWRLP/2Y2GZkDC4 /ugCK/hRaxSqb9UzO9H/AGyrc2qX+rrX1OwLyQqSX5mA6ovrtNOuuHdS5BIBZjNQJS9X +aZICM/ZlkBvcPTKk8xLv/7yLD08xfaIZLdDWmbasg+pxKE5l+nLaxg7mXNC++8PaJRV ziaF9M7xd+Cx1kzDaSMBjTaubqtv3k7rQCqCN7WSLtxn0l2oz/Mdzvntdfcc7/qLrwNi yfmoG/lB4SrikCJJ7DsnGBvn7uCQZjsVbVTi4wLzIUCjqk5XNjIbTVZ1zVQ/HNwvg43g 6MiQ=="
            ],
            "authentication-results": [
                "mx.google.com; dkim=pass header.i=@evil.com header.s=google header.b=LdyiNwmQ; spf=pass (google.com: domain of badguy@evil.com designates 209.85.220.41 as permitted sender) smtp.mailfrom=badguy@evil.com; dmarc=pass (p=NONE sp=NONE dis=NONE) header.from=evil.com; dara=pass header.i=@gmail.com"
            ],
            "content-type": [
                "multipart/alternative; boundary=\"00000000000006151206212733f4\""
            ],
            "date": [
                "Mon, 2 Sep 2024 11:34:26 -0700"
            ],
            "delivered-to": [
                "acme@gmail.com"
            ],
            "dkim-signature": [
                "v=1; a=rsa-sha256; c=relaxed/relaxed; d=evil.com; s=google; t=1725302104; x=1725906904; dara=google.com; h=to:subject:message-id:date:from:mime-version:from:to:cc:subject :date:message-id:reply-to; bh=NWZDzWD3fcPGImfiLFJgiOAWQBc6o9f064zRNQOEAZA=; b=LdyiNwmQU+l8TQfVFgJYRNMvGqiplaqTOqlGWpSMUGm8891aHvKrxkqpjnHULKaY5l PzU3i0TK4Xl5Mdhjde5ewyD1o5BWTx8qEOFMuiZBOwOQys6nzcwBzQxKEuc8d6+GN8Z1 2H4uBqSxYfOaHAVU5qVx5/7IJF4TMDY/LK8A4="
            ],
"from": [
                "Bad Guy <badguy@evil.io>"
            ],
            "message-id": [
                "<CAD-4=gGtg=3dbuOO8M6pLairyXpnTD6Oh3P1OXauW5-SOXV0yw@mail.gmail.com>"
            ],
            "mime-version": [
                "1.0"
            ],
            "received": [
                "by 2002:a05:7010:161f:b0:3f2:d648:d2e9 with SMTP id l31csp230833mdi; Mon, 2 Sep 2024 11:35:05 -0700 (PDT)",
                "from mail-sor-f41.google.com (mail-sor-f41.google.com. [209.85.220.41]) by mx.google.com with SMTPS id d2e1a72fcca58-715e5749b07sor4893537b3a.11.2024.09.02.11.35.04 for <acme@gmail.com> (Google Transport Security); Mon, 02 Sep 2024 11:35:04 -0700 (PDT)"
            ],
            "received-spf": [
                "pass (google.com: domain of badguy@evil.com designates 209.85.220.41 as permitted sender) client-ip=209.85.220.41;"
            ],
            "return-path": [
                "<badguy@evil.com>"
            ],
            "subject": [
                "more testing"
            ],
            "to": [
                "acme@gmail.com"
            ],
            "x-gm-message-state": [
                "AOJu0YzthcsAvu7FAaCG7tVsbF4IP4NAAP2ICmXBCZM3q/X+EjpqD6L+ HBDMSMll8JxmIsLL9Hq4U6l/4iwLiRBys3iUsJ3A03Tr5TQVO+PUZyvd5CBxtrsj0Hy675LgaQ7 0oJ2lN6XxBJuSm+/UvFWcTafXVHpnHqvcnYE6cByvJzwFOaEV06U="
            ],
"x-google-dkim-signature": [
                "v=1; a=rsa-sha256; c=relaxed/relaxed; d=1e100.net; s=20230601; t=1725302104; x=1725906904; h=to:subject:message-id:date:from:mime-version:x-gm-message-state :from:to:cc:subject:date:message-id:reply-to; bh=NWZDzWD3fcPGImfiLFJgiOAWQBc6o9f064zRNQOEAZA=; b=VNAyNje9Qf3Xz7pGtX6FCaK67/ICW8aVWws/VdEDA/Ay1XO91LBQdEv7cKjZ+mcm1K uS5gPPVBMXVf+68KmiWyoiartMf/X4VsuTWzJRHyrtL9O8fX26xcgElzkAmm9N6/hKYg qsZujh4fpii2jk8VIz3jGNWB41qUbJklu9BNSRLiwzQnew9Av/J48+JaxfZA38qD08x4 o7UPxTick1figeCmYpAR0x16ETNg6lLC8GdJEnnWlIUZJN+K2z3A7xwD6SdAjsy6HFur 6oonKeJjVIzirWToF2mspK5MHbGI8aXmFzpu51gvQsC9caRDNaod9C9GlwSM/2oLhQWN kozw=="
            ],
            "x-google-smtp-source": [
                "AGHT+IF4ypTOZTFYRo4zx1pdxWk8sJAzLq+8GoGM8toOjlzCT7o9u5Tw0AWDAwK+2MjV6eBL1v0fhHbYcjfipAgz4Y4="
            ],
"x-received": [
                "by 2002:a05:6a00:9451:b0:714:3153:ab4 with SMTP id d2e1a72fcca58-717458aeedemr5351482b3a.27.1725302104964; Mon, 02 Sep 2024 11:35:04 -0700 (PDT)",
                "by 2002:a05:6a20:c68e:b0:1ce:d412:f407 with SMTP id adf61e73a8af0-1ced412f48bmr6010277637.18.1725302103735; Mon, 02 Sep 2024 11:35:03 -0700 (PDT)"
            ]
        },
        "parts": [
            {
                "body_text": "One more test email.\r\n",
                "hashes": {
                    "md5": "cbe37e2ee4cf3c35d67a7c4a8e6a9e35",
                    "sha1": "c2f203f43304ab0a4c3154a84d0c876fa9c23204",
                    "sha256": "95dbb63f3fd41f7852395d84ef9570ef4db567c43d20e3f1e27c72c903b94686"
                },
                "headers": {
                    "content-type": [
                        "text/plain; charset=\"UTF-8\""
                    ]
                }
            },
            {
                "body_text": "<div dir=\"ltr\">One more test email.</div>\r\n",
                "hashes": {
                    "md5": "a2fcd5c1aa40abe526bbbbd58251a90f",
                    "sha1": "5748cc5fc2cd318a5584651731887ac9d9df4df2",
                    "sha256": "1f3877f593c1af2ad3e482aee2f4181a34e0f502799908f4ca330f3327d6c175"
                },
                "headers": {
                    "content-type": [
                        "text/html; charset=\"UTF-8\""
                    ]
                }
            }
        ]
    },
    "routing": {
        "arch": 9,
        "did": "",
        "event_id": "fb9554d8-522e-4977-a378-df7f3fcc186a",
        "event_time": 1725302106808,
        "event_type": "email",
        "ext_ip": "internal",
        "hostname": "testimap",
        "iid": "XXXXXXX",
        "int_ip": "",
        "moduleid": 6,
        "oid": "YYYYYY",
        "plat": 436207616,
        "sid": "ZZZZZZZZ",
        "tags": [
            "cloud2"
        ],
        "this": "f4925ea82ef44d18b349695466d6055a"
    }
}
```

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

### Related articles

* [SMTP](/docs/outputs-destinations-smtp)

---

#### What's Next

* [IT Glue](/docs/adapter-types-it-glue)

Table of contents

+ [Overview](#overview)
+ [Configurations](#configurations)
+ [Use Cases](#use-cases)
+ [Example Format](#example-format)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## IP Geolocation

# IP Geolocation
* 1 Minute to read

## What's Next

* [Pangea](/docs/api-integrations-pangea)

Tags

* [add-ons](/docs/en/tags/add-ons)

---

## IT Glue

# IT Glue
* 1 Minute to read

## What's Next

* [JSON](/docs/adapter-types-json)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## JSON

# JSON
* 1 Minute to read

## Related articles

* [Stdin JSON](/docs/adapter-examples-stdin-json)

---

### What's Next

* [Kubernetes Pods Logs](/docs/adapter-types-kubernetes-pods-logs)

Table of contents

+ [Overview](#overview)
+ [Configuration](#configuration)
+ [Deployment](#deployment)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Kubernetes Pods Logs

# Kubernetes Pods Logs
## Overview

This Adapter allows you to ingest the logs from the pods running in a Kubernetes cluster.

The adapter relies on local filesystem access to the standard Kubernetes pod logging structure. This means the adapter is best run as a Daemon Set in Kubernetes with the pod logs location mounted (usually `/var/log/pods`).

A public Docker container is available [here](https://hub.docker.com/r/refractionpoint/lc-adapter-k8s-pods) as `refractionpoint/lc-adapter-k8s-pods`.

## Configurations

Adapter Type: `k8s_pods`

The following fields are required for configuration:

* `client_options`: common configuration for adapter as defined [here](/v2/docs/adapters#usage).
* `root`: The root of the Kubernetes directory storing logs, usually `/var/log/pods`.

### Infrastructure as Code Deployment

```
# Kubernetes Pods Specific Docs: https://docs.limacharlie.io/docs/adapter-types-k8s-pods

sensor_type: "k8_pods"
k8s_pods:
    client_options:
      identity:
        oid: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
        installation_key: "YOUR_LC_INSTALLATION_KEY_K8SPODS"
      hostname: "k8s-worker-node"
      platform: "k8s_pods"
      sensor_seed_key: "k8s-pods-sensor"
    root: "/var/log/pods"                              # Required: Pod logs directory
    write_timeout_sec: 600                             # Optional: defaults to 600
    include_pods_re: "^production_.*"                  # Optional: include filter
    exclude_pods_re: "^kube-system_kube-proxy-.*$"    # Optional: exclude filter
```

## Sample Kubernetes Configuration

An example Daemon Set configuration for Kubernetes:

```
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: lc-adapter-k8s-pods
  namespace: default
spec:
  minReadySeconds: 30
  selector:
    matchLabels:
      name: lc-adapter-k8s-pods
  template:
    metadata:
      labels:
        name: lc-adapter-k8s-pods
    spec:
      containers:
      - image: refractionpoint/lc-adapter-k8s-pods
        name: lc-adapter-k8s-pods
        volumeMounts:
        - mountPath: /k8s-pod-logs
          name: pod-logs
        env:
        - name: K8S_POD_LOGS
          value: /k8s-pod-logs
        - name: OID
          value: aaaaaaaa-bfa1-bbbb-cccc-138cd51389cd
        - name: IKEY
          value: aaaaaaaa-9ae6-bbbb-cccc-5e42b854adf5
        - name: NAME
          value: k8s-pods
      volumes:
      - hostPath:
          path: /var/log/pods
        name: pod-logs
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
```

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

### Related articles

* [Container Clusters](/docs/container-clusters)
* [Docker Agent Installation](/docs/docker-agent-installation)

---

#### What's Next

* [Mac Unified Logging](/docs/adapter-types-mac-unified-logging)

Table of contents

+ [Overview](#overview)
+ [Configurations](#configurations)
+ [Sample Kubernetes Configuration](#sample-kubernetes-configuration)

Tags

* [adapters](/docs/en/tags/adapters)
* [linux](/docs/en/tags/linux)
* [sensors](/docs/en/tags/sensors)

---

## LimaCharlie SDK & CLI

# LimaCharlie SDK & CLI
## Go

The Go library is a simple abstraction to the [LimaCharlie.io REST API](https://api.limacharlie.io/). The REST API currently supports many more functions. If it's missing a function available in the REST API that you would like to use, let us know at support@limacharlie.io.

* Repo - <https://github.com/refractionPOINT/go-limacharlie>

### Getting Started

#### Authentication

You can use Client Options to declare your client/org, or you can use environment variables.

**Using Environment Variables:**

* `LC_OID`: Organization ID
* `LC_API_KEY`: your LC API KEY
* `LC_UID`: optional, your user ID

```
package main

import (
	"fmt"

	"github.com/refractionPOINT/go-limacharlie/limacharlie"
)

func main() {
    client, err := limacharlie.NewClientFromLoader(limacharlie.ClientOptions{}, nil, &limacharlie.EnvironmentClientOptionLoader{})
    if err != nil {
        fmt.Println(err)
    }

    org, _ := limacharlie.NewOrganization(client)
    fmt.Printf("Hello, this is %s", org.GetOID())
}
```

**Using Client Options:**

```
package main

import (
	"fmt"

	"github.com/refractionPOINT/go-limacharlie/limacharlie"
)

func main() {
    clientOptions = limacharlie.ClientOptions{
        OID: "MY_OID",
        APIKey: "MY_API_KEY",
        UID: "MY_UID",
    }
    org, _ := limacharlie.NewOrganizationFromClientOptions(clientOptions, nil)
    fmt.Printf("Hello, this is %s", org.GetOID())
}
```

### SDK

#### Examples

```
package main

import (
	"fmt"

	"github.com/refractionPOINT/go-limacharlie/limacharlie"
)

func main() {
    client, err := limacharlie.NewClientFromLoader(limacharlie.ClientOptions{}, nil, &limacharlie.EnvironmentClientOptionLoader{})
    if err != nil {
        fmt.Println(err)
    }

    org, _ := limacharlie.NewOrganization(client)

    // List all sensors
    sensors, err := org.ListSensors()
    if err != nil {
        fmt.Println(err)
    }
    for sid, sensor := range sensors {
        fmt.Printf("%s - %s", sid, sensor.Hostname)
    }

    // List D&R rules from Hive
    hiveClient := limacharlie.NewHiveClient(org)
    rules, _ := hiveClient.List(limacharlie.HiveArgs{
        HiveName:     "dr-general",
        PartitionKey:  org.GetOID(),
    })
    for rule_name, _ := range rules {
        fmt.Println(rule_name)
    }

    // Add D&R rule to Hive
    enabled := true
    case_sensitive := false
    if _, err := hiveClient.Add(limacharlie.HiveArgs{
        HiveName:     "dr-general",
        PartitionKey: org.GetOID(),
        Key:          "test_rule_name",
        Enabled:      &enabled,
        Data: limacharlie.Dict{
            "detect": limacharlie.Dict{
                "event":            "NEW_PROCESS",
                "op":               "is",
                "path":             "event/COMMAND_LINE",
                "value":            "whoami",
                "case sensitive":   &case_sensitive,
            },
            "respond": []limacharlie.Dict{{
                "action": "report",
                "name":   "whoami detection",
            }},
        },
    }); err != nil {
        fmt.Println(err)
    }

    // List extensions
    extensions, _ := org.Extensions()
    for _, extension_name := range extensions {
        fmt.Println(extension_name)
    }

    // Subscribe to extension
    subscription_request := org.SubscribeToExtension("binlib")
    if subscription_request != nil {
        fmt.Println(subscription_request)
    }

    // List payloads
    payloads, _ := org.Payloads()
    for payload, _ := range payloads {
        fmt.Println(payload)
    }

    // List installation keys
    installation_keys, _ := org.InstallationKeys()
    for _, key := range installation_keys {
        fmt.Println(key.Description)
    }

    // Create installation key
    key_request, _ := org.AddInstallationKey(InstallationKey{
		Description: "my-test-key",
		Tags:        []string{"tag", "another-tag"},
	})

}
```

## Python

The Python library is a simple abstraction to the [LimaCharlie.io REST API](https://api.limacharlie.io/). The REST API currently supports many more functions. If it's missing a function available in the REST API that you would like to use, let us know at support@limacharlie.io.

* Repo - <https://github.com/refractionpoint/python-limacharlie>

### Getting Started

#### Installing

##### PyPi (pip)

The library and the CLI is available as a Python package on PyPi (<https://pypi.org/project/limacharlie/>). It can be installed using pip as shown below.

```
pip install limacharlie
```

##### Docker Image

In addition to the PyPi distribution we also offer a pre-built Docker image on DockerHub (<https://hub.docker.com/r/refractionpoint/limacharlie>).

```
docker run refractionpoint/limacharlie:latest whoami

# Using a specific version (Docker image tag matches the library version)
docker run refractionpoint/limacharlie:4.9.13 whoami

# If you already have a credential file locally, you can mount it inside the Docker container
docker run -v ${HOME}/.limacharlie:/root/.limacharlie:ro refractionpoint/limacharlie:latest whoami
```

#### Credentials

Authenticating to use the SDK / CLI can be done in a few ways.

**Option 1 - Logging In**
 The simplest is to login to an Organization using an [API key](https://doc.limacharlie.io/docs/documentation/docs/api_keys.md).

Use `limacharlie login` to store credentials locally. You will need an `OID` (Organization ID) and an API key, and (optionally) a `UID` (User ID), all of which you can get from the Access Management --> REST API section of the web interface.

The login interface supports named environments, or a default one used when no environment is selected.

To list available environments:

```
limacharlie use
```

Setting a given environment in the current shell session can be done like this:

```
limacharlie use my-dev-org
```

You can also specify a `UID` (User ID) during login to use a *user* API key representing
 the total set of permissions that user has (see User Profile in the web interface).

**Option 2 - Environment Variables**
 You can use the `LC_OID` and `LC_API_KEY` and `LC_UID` environment variables to replace the values used logging in. The environment variables will be used if no other credentials are specified.

### SDK

The root of the functionality in the SDK is from the `Manager` object. It holds the credentials and is tied to a specific LimaCharlie Organization.

You can authenticate the `Manager` using an `oid` (and optionally a `uid`), along with either a `secret_api_key` or `jwt` directly. Alternatively you can just use an environment name (as specified in `limacharlie login`). If no creds are provided, the `Manager` will try to use the default environment and credentials.

#### Importing

```python
import limacharlie

YARA_SIG = 'https://raw.githubusercontent.com/Yara-Rules/rules/master/Malicious_Documents/Maldoc_PDF.yar'

# Create an instance of the SDK.
mgr = limacharlie.Manager()

# Get a list of all the sensors in the current Organization.
all_sensors = mgr.sensors()

# Select the first sensor in the list.
sensor = all_sensors[0]

# Tag this sensor with a tag for 10 minutes.
sensor.tag( 'suspicious', ttl = 60 * 10 )

# Send a task to the sensor (unidirectionally, not expecting a response).
sensor.task( 'os_processes' )

# Send a yara scan to that sensor for processes "evil.exe".
sensor.task( 'yara_scan -e *evil.exe ' + YARA_SIG )
```

#### Use of gevent

Note that the SDK uses the `gevent` package which sometimes has issues with other
 packages that operate at a low level in python. For example, Jupyter notebooks
 may see freezing on importing `limacharlie` and require a tweak to load:

```json
{
 "display_name": "IPython 2 w/gevent",
 "language": "python",
 "argv": [
  "python",
  "-c", "from gevent.monkey import patch_all; patch_all(thread=False); from ipykernel.kernelapp import main; main()",
  "-f",
  "{connection_file}"
 ]
}
```

### Components

#### Manager

This is a the general component that provides access to the managing functions of the API like querying sensors online, creating and removing Outputs etc.

#### Firehose

The `Firehose` is a simple object that listens on a port for LimaCharlie.io data. Under the hood it creates a Syslog Output on limacharlie.io pointing to itself and removes it on shutdown. Data from limacharlie.io is added to `firehose.queue` (a `gevent Queue`) as it is received.

It is a basic building block of automation for limacharlie.io.

#### Spout

Much like the `Firehose`, the Spout receives data from LimaCharlie.io, the difference
 is that the `Spout` does not require opening a local port to listen actively on. Instead
 it leverages `stream.limacharlie.io` to receive the data stream over HTTPS.

A `Spout` is automatically created when you instantiate a `Manager` with the
`is_interactive = True` and `inv_id = XXXX` arguments in order to provide real-time
 feedback from tasking sensors.

#### Sensor

This is the object returned by `manager.sensor( sensor_id )`.

It supports a `task`, `hostname`, `tag`, `untag`, `getTags` and more functions. This
 is the main way to interact with a specific sensor.

The `task` function sends a task to the sensor unidirectionally, meaning it does not
 receive the response from the sensor (if any). If you want to interact with a sensor
 in real-time, use the interactive mode (as mentioned in the `Spout`) and use either
 the `request` function to receive replies through a `FutureResults` object or the
`simpleRequest` to wait for the response and receive it as a return value.

#### Artifacts

The `Artifacts` is a helpful class to upload [artifacts](/v2/docs/artifacts) to LimaCharlie without going through a sensor.

#### Extensions

The `Extensions` can be used to subscribe to and manage extensions within your org.

```python
import limacharlie
from limacharlie import Extension

mgr = limacharlie.Manager()
ext = Extension(mgr)
ext.subscribe('binlib')
```

#### Payloads

The `Payloads` can be used to manage various executable [payloads](/v2/docs/payloads) accessible to sensors.

#### Replay

The `Replay` object allows you to interact with [Replay](/v2/docs/replay) jobs managed by LimaCharlie. These allow you to re-run [D&R Rules](/v2/docs/detection-and-response) on historical data.

Sample command line to query one sensor:

```
limacharlie-replay --sid 9cbed57a-6d6a-4af0-b881-803a99b177d9 --start 1556568500 --end 1556568600 --rule-content ./test_rule.txt
```

Sample command line to query an entire organization:

```
limacharlie-replay --entire-org --start 1555359000 --end 1556568600 --rule-name my-rule-name
```

#### Search

The `Search` object allows you to perform an IOC search across multiple organizations.

#### SpotCheck

The `SpotCheck` object (sometimes called Fleet Check) allows you to manage an active (query sensors directly as opposed to searching on indexed historical data) search for various IOCs on an organization's sensors.

#### Configs

The `Configs` is used to retrieve an organization's configuration as a config file, or apply
 an existing config file to an organization. This is the concept of Infrastructure as Code.

#### Webhook

The `Webhook` object demonstrates handling [webhooks emitted by the LimaCharlie cloud](/v2/docs/tutorial-creating-a-webhook-adapter), including verifying the shared-secret signing of the webhooks.

### Examples:

* [Basic Manager Operations](https://github.com/refractionPOINT/python-limacharlie/blob/master/samples/demo_manager.py)
* [Basic Firehose Operations](https://github.com/refractionPOINT/python-limacharlie/blob/master/samples/demo_firehose.py)
* [Basic Spout Operations](https://github.com/refractionPOINT/python-limacharlie/blob/master/samples/demo_spout.py)
* [Basic Integrated Operations](https://github.com/refractionPOINT/python-limacharlie/blob/master/samples/demo_interactive_sensor.py)
* [Sample Configs](https://github.com/refractionPOINT/python-limacharlie/tree/master/limacharlie/sample_configs)

### Command Line Interface

Many of the objects available as part of the LimaCharlie Python SDK also support various command line interfaces.

#### Query

[LimaCharlie Query Language (LCQL)](/v2/docs/lcql) provides a flexible, intuitive and interactive way to explore your data in LimaCharlie.

```
limacharlie query --help
```

#### ARLs

[Authenticated Resource Locators (ARLs)](/v2/docs/reference-authentication-resource-locator) describe a way to specify access to a remote resource, supporting many methods, including authentication data, and all that within a single string.

ARLs can be used in the [YARA manager](/v2/docs/ext-yara-manager) to import rules from GitHub repositories and other locations.

Testing an ARL before applying it somewhere can be helpful to shake out access or authentication errors beforehand. You can test an ARL and see what files are fetched, and their contents, by running the following command:

```
limacharlie get-arl -a [github,Yara-Rules/rules/email]
```

#### Firehose

Listens on interface `1.2.3.4`, port `9424` for incoming connections from LimaCharlie.io.
 Receives only events from hosts tagged with `fh_test`.

```
python -m limacharlie.Firehose 1.2.3.4:9424 event -n firehose_test -t fh_test --oid c82e5c17-d519-4ef5-a4ac-caa4a95d31ca
```

#### Spout

Behaves similarly to the Firehose, but instead of listening from an internet accessible port, it connects to the `stream.limacharlie.io` service to stream the output over HTTPS. This means the Spout allows you to get ad-hoc output like the Firehose, but it also works through NATs and proxies.

It is MUCH more convenient for short term ad-hoc outputs, but it is less reliable than a Firehose for very large amounts of data.

```
python -m limacharlie.Spout event --oid c82e5c17-d519-4ef5-a4ac-caa4a95d31ca
```

#### Configs

The `fetch` command will get a list of the Detection & Response rules in your
 organization and will write them to the config file specified or the default
 config file `lc_conf.yaml` in YAML format.

```
limacharlie configs fetch --oid c82e5c17-d519-4ef5-a4ac-c454a95d31ca`
```

Then `push` can upload the rules specified in the config file (or the default one)
 to your organization. The optional `--force` argument will remove active rules not
 found in the config file. The `--dry-run` simulates the sync and displays the changes
 that would occur.

The `--config` allows you to specify an alternate config file and the `--api-key` allows
 you to specify a file on disk where the API should be read from (otherwise, of if `-` is
 specified as a file, the API Key is read from STDIN).

```
limacharlie configs push --dry-run --oid c82e5c17-d519-4ef5-a4ac-c454a95d31ca --config /path/to/template.yaml --all --ignore-inaccessible
```

All these capabilities are also supported directly by the `limacharlie.Configs` object.

The Sync functionality currently supports all common useful configurations. The `--no-rules` and `--no-outputs` flags can be used to ignore one or the other in config files and sync. Additional flags are also supported, see `limacharlie configs --help`.

To understand better the config format, do a `fetch` from your organization. Notice the use of the `include`
 statement. Using this statement you can combine multiple config files together, making
 it ideal for the management of complex rule sets and their versioning.

#### Spot Checks

Used to perform Organization-wide checks for specific indicators of compromise. Available as a custom API `SpotCheck` object or as a module from the command line. Supports many types of IoCs like file names, directories, registry keys, file hashes and YARA signatures.

```
python -m limacharlie.SpotCheck --no-macos --no-linux --tags vip --file c:\\evil.exe`
```

For detailed usage:

```
python -m limacharlie.SpotCheck --help
```

#### Search

Shortcut utility to perform IOC searches across all locally configured organizations.

```
limacharlie search --help
```

#### Extensions

Shortcut utility to manage extensions.

```
limacharlie extension --help
```

#### Artifact Upload

Shortcut utility to upload and retrieve [Artifacts](/v2/docs/artifacts) within LimaCharlie with just the CLI (no agent).

```
limacharlie artifacts --help
```

#### Artifact Download

Shortcut utility to download [Artifact Collection](/v2/docs/artifacts) in LimaCharlie locally.

```
limacharlie artifacts get_original --help
```

#### Replay

Shortcut utility to perform [Replay](/v2/docs/replay) jobs from the CLI.

```
limacharlie replay --help
```

#### Detection & Response

Shortcut utility to manage Detection and Response rules over the CLI.

```
limacharlie dr --help
```

#### Events & Detections

Print out to STDOUT events or detections matching the parameter.

```
limacharlie events --help
limacharlie detections --help
```

#### List Sensors

Print out all basic sensor information for all sensors matching the [selector](/v2/docs/reference-sensor-selector-expressions).

```
limacharlie sensors --selector 'plat == windows'
```

#### Invite Users

Invite single or multiple users to LimaCharlie. Invited users will be sent an email to confirm their address, enable the account and create a new password.

Keep in mind that this actions operates in the user context which means you need to use user scoped API key. For more information on how to obtain one, see <https://docs.limacharlie.io/apidocs/introduction#getting-a-jwt>

Invite a single user:

```
limacharlie users invite --email=user1@example.com
```

Invite multiple users:

```
limacharlie users invite --email=user1@example.com,user2@example.com,user3@example.com
```

Invite multiple users from new line delimited entries in a text file:

```
cat users_to_invite.txt
user1@example.com
user2@example.com
user3@example.com
```

```
limacharlie users invite --file=users_to_invite.txt
```

In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

Command-line Interface

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

##### Related articles

* [Config Hive](/docs/config-hive)
* [LimaCharlie Query Language](/docs/lcql)

---

###### What's Next

* [Access and Permissions](/docs/access-and-permissions)

Table of contents

+ [Go](#go)
+ [Python](#python)

Tags

* [api](/docs/en/tags/api)
* [platform](/docs/en/tags/platform)

---

## Mac Unified Logging

# Mac Unified Logging
## Overview

This Adapter allows you to collect events from MacOS Unified Logging.

## Deployment Configurations

All adapters support the same `client_options`, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.

* `client_options.identity.oid`: the LimaCharlie Organization ID (OID) this adapter is used with.
* `client_options.identity.installation_key`: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.
* `client_options.platform`: the type of data ingested through this adapter, like `text`, `json`, `gcp`, `carbon_black`, etc.
* `client_options.sensor_seed_key`: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.

**Optional Arguments:**

* `predicate`: example, `predicate='subsystem=="com.apple.TimeMachine"'`

## CLI Deployment

Adapter downloads can be found [here](/v2/docs/adapter-deployment).

```
chmod +x /path/to/lc_adapter

/path/to/lc_adapter mac_unified_logging client_options.identity.installation_key=$INSTALLATION_KEY \
client_options.identity.oid=$OID \
client_options.platform=json \
client_options.sensor_seed_key=$SENSOR_NAME \
client_options.hostname=$SENSOR_NAME
```

### Infrastructure as Code Deployment

```
# macOS Unified Logging Specific Docs: https://docs.limacharlie.io/docs/adapter-types-macos-unified-logging

sensor_type: "mac_unified_logging"
  mac_unified_logging:
    client_options:
      identity:
        oid: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
        installation_key: "YOUR_LC_INSTALLATION_KEY_MACOSUL"
      hostname: "user-macbook-pro"
      platform: "mac_unified_logging"
      sensor_seed_key: "macos-unified-logging-sensor"
    # Optional configuration
    write_timeout_sec: 600                           # Default: 600 seconds
    predicate: 'processImagePath endswith "/usr/sbin/sshd" OR subsystem == "com.apple.security"'
```

## Service Creation

If you want this adapter to run as a service, you can run the following script to add a plist file to the endpoint **with your variables replaced**. Please note that this example also has an example predicate, so if you do not wish to use a predicate, remove that line.

```
sudo -i

curl https://downloads.limacharlie.io/adapter/mac/64 -o /usr/local/bin/lc_adapter
chmod +x /usr/local/bin/lc_adapter

tee -a /Library/LaunchDaemons/io.limacharlie.adapter.macunifiedlogging.plist <<EOF
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
  <dict>
    <key>Label</key>
    <string>io.limacharlie.adapter.macunifiedlogging</string>
    <key>UserName</key>
	<string>root</string>
    <key>RunAtLoad</key>
    <true/>
    <key>WorkingDirectory</key>
    <string>/usr/local/bin</string>
    <key>KeepAlive</key>
    <true/>
    <key>EnvironmentVariables</key>
    <dict>
      <key>PATH</key>
      <string>/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</string>
    </dict>
    <key>Program</key>
    <string>/usr/local/bin/lc_adapter</string>
    <key>ProgramArguments</key>
    <array>
        <string>/usr/local/bin/lc_adapter</string>
        <string>mac_unified_logging</string>
        <string>client_options.identity.installation_key=$INSTALLATION_KEY</string>
        <string>client_options.identity.oid=$OID</string>
        <string>client_options.hostname=$SENSOR_NAME</string>
        <string>client_options.platform=json</string>
        <string>client_options.sensor_seed_key=$SENSOR_NAME</string>
        <string>predicate=eventMessage CONTAINS[c] "corp.sap.privileges"</string>
    </array>
  </dict>
</plist>
EOF

launchctl load -w /Library/LaunchDaemons/io.limacharlie.adapter.macunifiedlogging.plist
```

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Command-line Interface

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

### Related articles

* [macOS Agent Installation](/docs/macos-agent-installation)
* [Ingesting MacOS Unified Logs](/docs/ingesting-macos-unified-logs)
* [macOS Agent Installation via Jamf Now](/docs/installing-macos-agents-via-jamf-now)
* [macOS Agent Installation - Older Versions (macOS 10.15 Catalina to macOS 14 Sonoma)](/docs/macos-agent-installation-latest-os-versions)
* [macOS Agent Installation - Older Versions (macOS 10.14 and prior)](/docs/macos-agent-installation-older-versions)

---

#### What's Next

* [Microsoft Defender](/docs/adapter-types-microsoft-defender)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [{{glossary.CLI}} Deployment](#{{glossary-cli}}-deployment)
+ [Service Creation](#service-creation)

Tags

* [adapters](/docs/en/tags/adapters)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)

---

## Microsoft 365

# Microsoft 365
Microsoft 365, formerly Office 365, is a product family of productivity software, collaboration and cloud-based services owned by Microsoft. This Adapter allows you to ingest audit events from the [Office 365 Management Activity API](https://learn.microsoft.com/en-us/office/office-365-management-api/office-365-management-activity-api-reference).

Microsoft 365 events can be ingested in LimaCharlie and observed as the `office365` platform.

## Adapter Deployment

Microsoft 365 events are ingested via a cloud-to-cloud Adapter configured specifically to review M365 events. When creating an Adapter, the following data points are required:

* `domain`: Office 365 domain
* `tenant_id`: Office 365 tenant ID
* `publisher_id`: Office 365 publisher ID (for single-tenant Apps, the PublisherID is the same as the Tenant ID)
* `client_id`: Office 365 client ID
* `client_secret`: Office 365 client secret
* `endpoint`: Office 365 API endpoint
* `content_types`: content types of events to ingest.

  + Options include:

    - `Audit.AzureActiveDirectory`
    - `Audit.Exchange`
    - `Audit.SharePoint`
    - `Audit.General`
    - `DLP.All`
  + *Default is all of the above*

If creating a Microsoft 365 Adapter via the Web UI, the helper form will navigate you through providing these values.

Establishing a cloud-to-cloud connector between LimaCharlie and Office 365 requires a few steps to provide the correct permissions for the [Office 365 Management Activity API](https://learn.microsoft.com/en-us/office/office-365-management-api/office-365-management-activity-api-reference).

### Infrastructure as Code Deployment

```
# Office 365 Management Activity API Specific Docs: https://docs.limacharlie.io/docs/adapter-types-office-365-management-activity-api
# For cloud sensor deployment, store credentials as hive secrets:

#   tenant_id: "hive://secret/o365-tenant-id"
#   client_id: "hive://secret/o365-client-id"
#   client_secret: "hive://secret/o365-client-secret"

sensor_type: "office365"
office365:
  tenant_id: "hive://secret/azure-o365-tenant-id"
  client_id: "hive://secret/azure-o365-client-id"
  client_secret: "hive://secret/azure-o365-client-secret"
  client_options:
    identity:
      oid: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
      installation_key: "YOUR_LC_INSTALLATION_KEY_O365"
    hostname: "ms-o365-adapter"
    platform: "json"
    sensor_seed_key: "office365-audit-sensor"
    mapping:
      sensor_hostname_path: "ClientIP"
      event_type_path: "Operation"
      event_time_path: "CreationTime"
    indexing: []
  # Office 365 specific configuration
  content_types:
    - "Audit.AzureActiveDirectory"
    - "Audit.Exchange"
    - "Audit.SharePoint"
    - "Audit.General"
    - "DLP.All"
  # Optional configuration
  endpoint: "enterprise"                           # Default: "enterprise"
  start_time: "2024-01-01T00:00:00Z"              # Optional: historical start time
  domain: "yourcompany.onmicrosoft.com"           # Optional: for GCC environments
  publisher_id: "hive://secret/o365-publisher-id" # Optional: usually same as tenant_id
```

## Configuring a Microsoft 365 Adapter in the Web UI

### Preparing Office 365 details

To establish an Office 365 adapter, we will need to complete a few steps within the Azure portal. Ensure that you have the correct permissions to set up a new App registration.

* Within the Microsoft Azure portal, create a new App registration. You can follow Microsoft's Quickstart guide [here](https://learn.microsoft.com/en-us/azure/active-directory/develop/quickstart-register-app).
* The LimaCharlie connector requires a secret for Office 365 data. You can create one under `Certificates & secrets`. Be sure to copy this value and save it somewhere - you can only view it once.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%2873%29.png)

* Additionally, you'll need to ensure that the app has the correct permissions to view Office 365 data via the Management API. Within `API Permissions`, configure the following permissions:

  + `ActivityFeed.Read` (Delegated & Application)
  + `ActivityFeed.ReadDlp` (Delegated & Application) *[if you want DLP permissions]*

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%2874%29.png)

Additionally, you may need to grant admin consent to the above permissions.

At this point, you should have all the details you need to configure the Adapter.

### Setting Up the Adapter

Within the LimaCharlie web application, select `+ Add` Sensor, and then select `Office 365`:

You can select a pre-existing Installation Key or create a new one, unique for this adapter. Once an Installation Key is selected, you will be prompted with a form to finish setting up the adapter. Choose your desired adapter name, and provide the following values:

| Item | Azure Portal Location |
| --- | --- |
| Domain | Home |
| Tenant ID | App Registration Overview |
| Publisher ID | App Registration Overview |
| Client ID | App Registration Overview |
| Client Secret | Created during creation in Certificates & secrets |
| API Endpoint | `enterprise`, `gcc-gov`, `gcc-high-gov`, or `dod-gov` |

Finally, you will also need to select a "Content Type" to import. This is the type of events you want to bring in to LimaCharlie. The options are as follows:

* `Audit.AzureActiveDirectory`
* `Audit.Exchange`
* `Audit.SharePoint`
* `Audit.General`
* `DLP.All`

Without a value, the default is *all of the above*.

Click `Complete Cloud Installation`, and LimaCharlie will attempt to connect to the Microsoft Office 365 Management API and pull events.

## Sample Rule

When ingested into LimaCharlie, Office 365 data can be referenced directly in your D&R rules. You could do this via a platform operator:

```
op: is platform
name: office365
```

We can also reference Office 365 events directly. The following sample rule looks at `FileAccessed` events from anonymous user names, and reports accordingly.

```
# Detection
event: FileAccessed
path: event/UserId
op: contains
value: anon

# Response
- action: report
  name: OneDrive File Accessed by Anonymous User
```

Note that in the detection above, we pivot on the `FileAccessed` event, which is associated with SharePoint activity. Available event types will depend on source activity and events ingested. More information on audit log activities can be found [here](https://learn.microsoft.com/en-us/purview/audit-log-activities).

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

### Related articles

* [Soteria M365 Rules](/docs/soteria-m365-rules)
* [Microsoft 365](/docs/ext-cloud-cli-microsoft365)

---

#### What's Next

* [Mimecast](/docs/adapter-types-mimecast)

Table of contents

+ [Adapter Deployment](#adapter-deployment)
+ [Configuring a Microsoft 365 Adapter in the Web UI](#configuring-a-microsoft-365-adapter-in-the-web-ui)
+ [Sample {{glossary.D&amp;R}} Rule](#sample-{{glossary-d-amp-r}}-rule)

Tags

* [adapters](/docs/en/tags/adapters)
* [azure](/docs/en/tags/azure)
* [m365](/docs/en/tags/m365)
* [sensors](/docs/en/tags/sensors)

---

## Microsoft Defender

# Microsoft Defender
* 1 Minute to read

## Related articles

* [Ingesting Defender Event Logs](/docs/ingesting-defender-event-logs)
* [Azure Event Hub](/docs/adapter-types-azure-event-hub)
* [Windows Event Logs](/docs/adapter-examples-windows-event-logs)

---

### What's Next

* [Microsoft Entra ID](/docs/adapter-types-microsoft-entra-id)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [Guided Deployment](#guided-deployment)

Tags

* [adapters](/docs/en/tags/adapters)
* [azure](/docs/en/tags/azure)
* [sensors](/docs/en/tags/sensors)

---

## Microsoft Entra ID

# Microsoft Entra ID
[Microsoft Entra ID](https://www.microsoft.com/en-us/security/business/identity-access/microsoft-entra-id), formerly Azure Active Directory, is an identity and access management solution from Microsoft that helps organizations secure and manage identities for hybrid and multicloud environments.

The Entra ID API Adapter currently receives risk detection alerts, as generated by Entra ID’s Identity Protection feature. You can learn more about these detections here: <https://learn.microsoft.com/en-us/entra/id-protection/concept-identity-protection-risks>. Data received via an Azure Event Hub or Webhook will be unique to your custom output parameters.

Entra ID events are recognized as the `azure_ad` platform.

## Adapter Deployment

Microsoft Entra ID logs are ingested into LimaCharlie via:

1. Azure Event Hub
2. Entra ID API
3. Webhooks

### Azure Event Hub

Within the LimaCharlie web app, there is a helper that can be used to easily configure receiving Entra ID events via an Azure Event Hub.

If utilizing the helper, only two fields are required:

* Name for the adapter
* Connection string to the Azure Event Hub

You can find more information about Azure Event Hub Adapters [here](/v2/docs/adapter-types-azure-event-hub).

Documentation for creating an event hub can be found here [here](https://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-create).

### Entra ID API

To collect data via the Entra ID API, you’ll need to configure an App Registration in Azure and ensure it has the correct permissions.

1. In Azure, navigate to the Entra ID Overview page. Select **App Registrations** and click `+ New Registration`.
2. Name the application, and select the **Supported account types**.
3. After registering an App, you’ll be provided metadata for that application. Take note of the `Application (client) ID` and `Directory (tenant) ID` fields, as you will need them for configuration.
4. Select **Add a certificate or secret,** and create a new client secret. Provide a description and select an applicable Expiration time. *Note: You will need to refresh the Secret in LimaCharlie once it expires!*
5. After creating the secret, copy the `Secret Value`. You will need this to configure the LimaCharlie Adapter.
6. Navigate to the **Manage** > **API permissions** menu for your newly-created application. Ensure that the following permissions have been enabled:

   1. IdentityRiskEvent.Read.All
   2. IdentityRiskEvent.ReadWrite.All
   3. IdentityRiskyServicePrincipal.Read
   4. IdentityRiskyServicePrincipal.ReadWrite.All
   5. IdentityRiskyUser.Read.All
   6. IdentityRiskyUser.Read.Write.All
   7. User.Read (default)

Create a new Adapter within LimaCharlie, and select Microsoft Entra ID. Select `Microsoft Entra ID API` as the ingestion method.

1. Name the Adapter and provide the following details:

   1. Tenant ID
   2. Client ID
   3. Client Secret
   4. *Note: You can use the Secrets Manager for these values if you wish!*

Click **Complete Cloud Installation**, and the Adapter should be created successfully. Monitor the **Platform Logs** for any errors.

**Note:** As previously mentioned, the API Adapter receives events from the Risk Detections API. You will only receive events when these events are sent by the platform. Thus, if you’re not receiving any events immediately after Adapter creation, this may be due to no risky events occurring!

### Webhooks

Within the LimaCharlie web app, there is a helper that can be used to easily configure receiving Entra ID events.

If utilizing the helper, only two fields are required:

* Name for the adapter
* Secret component of the URL for the webhook

More information about creating a webhook and obtaining the completed URL, utilizing the secret component, [can be found here](/v2/docs/tutorial-creating-a-webhook-adapter).

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

---

#### Related articles

* [Azure Network Security Group](/docs/azure-network-security-group)
* [Azure Storage Blob](/docs/outputs-destinations-azure-storage-blob)
* [Azure Monitor](/docs/azure-monitor)
* [Azure Event Hub](/docs/adapter-types-azure-event-hub)
* [Azure](/docs/ext-cloud-cli-azure)
* [Azure SQL Audit Logs](/docs/azure-sql-audit-logs)
* [Azure Kubernetes Service (AKS)](/docs/azure-kubernetes-service)
* [Azure Key Vault](/docs/azure-logs-key-vault)
* [Azure Event Hub](/docs/outputs-destinations-azure-event-hub)
* [Microsoft 365](/docs/ext-cloud-cli-microsoft365)

---

##### What's Next

* [Microsoft 365](/docs/adapter-types-microsoft-365)

Table of contents

+ [{{glossary.Adapter}} Deployment](#{{glossary-adapter}}-deployment)

Tags

* [adapters](/docs/en/tags/adapters)
* [azure](/docs/en/tags/azure)
* [sensors](/docs/en/tags/sensors)

---

## Mimecast

# Mimecast
* 1 Minute to read

## Related articles

* [Adapter Usage](/docs/adapter-usage)
* [Adapter Deployment](/docs/adapter-deployment)
* [Adapter Examples](/docs/adapter-examples)
* [Okta](/docs/ext-cloud-cli-okta)

---

### What's Next

* [Okta](/docs/adapter-types-okta)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Okta

# Okta
* 1 Minute to read

## Related articles

* [Okta](/docs/ext-cloud-cli-okta)
* [Cloud CLI](/docs/ext-cloud-cli)

---

### What's Next

* [PandaDoc](/docs/adapter-types-pandadoc)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## PandaDoc

# PandaDoc
* 1 Minute to read

## Related articles

* [Okta](/docs/ext-cloud-cli-okta)
* [Cloud CLI](/docs/ext-cloud-cli)

---

### What's Next

* [S3](/docs/adapter-types-s3)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Pangea

# Pangea
* 1 Minute to read

## What's Next

* [VirusTotal](/docs/api-integrations-virustotal)

Table of contents

+ [API Keys](#api-keys)
+ [Domain](#domain)
+ [File Reputation](#file-reputation)
+ [IP Reputation](#ip-reputation)
+ [URL Reputation](#url-reputation)
+ [User](#user)

Tags

* [add-ons](/docs/en/tags/add-ons)

---

## Platform Management

# Platform Management
* 1 Minute to read

## Related articles

* [Platform Events Overview](/docs/platform-events-overview)

---

### What's Next

* [LimaCharlie SDK & CLI](/docs/limacharlie-sdk)

Table of contents

+ [Overview](#overview)

Tags

* [platform](/docs/en/tags/platform)

---

## S3

# S3
* 1 Minute to read

## Related articles

* [AWS](/docs/ext-cloud-cli-aws)
* [AWS GuardDuty](/docs/adapter-types-aws-guardduty)
* [AWS CloudTrail](/docs/adapter-types-aws-cloudtrail)
* [Amazon S3](/docs/outputs-destinations-amazon-s3)
* [SQS](/docs/adapter-types-sqs)

---

### What's Next

* [Slack Audit Logs](/docs/adapter-types-slack-audit-logs)

Table of contents

+ [Overview](#overview)
+ [Configurations](#configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [aws](/docs/en/tags/aws)
* [sensors](/docs/en/tags/sensors)

---

## SQS

# SQS
* 1 Minute to read

## Related articles

* [AWS](/docs/ext-cloud-cli-aws)
* [AWS GuardDuty](/docs/adapter-types-aws-guardduty)
* [AWS CloudTrail](/docs/adapter-types-aws-cloudtrail)
* [Soteria AWS Rules](/docs/soteria-aws-rules)
* [Amazon S3](/docs/outputs-destinations-amazon-s3)
* [S3](/docs/adapter-types-s3)

---

### What's Next

* [IIS Logs](/docs/adapter-types-iis)

Table of contents

+ [Overview](#overview)
+ [Configurations](#configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [aws](/docs/en/tags/aws)
* [sensors](/docs/en/tags/sensors)

---

## Slack Audit Logs

# Slack Audit Logs
* 1 Minute to read

## Related articles

* [Slack](/docs/outputs-destinations-slack)

---

### What's Next

* [SentinelOne](/docs/sentinelone)

Table of contents

+ [Adapter Deployment](#adapter-deployment)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Sophos

# Sophos
## Overview

This Adapter allows you to connect to Sophos Central to fetch event logs.

## Deployment Configurations

All adapters support the same `client_options`, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.

* `client_options.identity.oid`: the LimaCharlie Organization ID (OID) this adapter is used with.
* `client_options.identity.installation_key`: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.
* `client_options.platform`: the type of data ingested through this adapter, like `text`, `json`, `gcp`, `carbon_black`, etc.
* `client_options.sensor_seed_key`: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.

### Adapter-specific Options

Adapter Type: `sophos`

* `tenantid`: your Sophos Central tenant ID
* `clientid`: your Sophos Central client ID
* `clientsecret`: your Sophos Central client secret
* `url`: your Sophos Central URL (ex: `https://api-us01.central.sophos.com`)

### Creating Your Credentials and Getting Your Tenant ID

Sophos documentation - <https://developer.sophos.com/getting-started-tenant>

1. Add a new credential [here](https://cloud.sophos.com/manage/config/settings/credentials)
2. Get your client ID and client secret from the credentials you just created
3. Get your JWT -- be sure to replace the values with the client ID and secret from the last step

```bash
   curl -XPOST -H "Content-Type:application/x-www-form-urlencoded" -d "grant_type=client_credentials&client_id=YOUR_CLIENT_ID&client_secret=YOUR_CLIENT_SECRET&scope=token" https://id.sophos.com/api/v2/oauth2/token
   ```

   Response content -- grab the `access_token` from the output:

```json
   {
      "access_token": "SAVE_THIS_VALUE",
      "errorCode": "success",
      "expires_in": 3600,
      "message": "OK",
      "refresh_token": "<token>",
      "token_type": "bearer",
      "trackingId": "<uuid>"
   }
   ```
4. Get your tenant ID -- you will need the `access_token` (JWT) from the last step.

```bash
   curl -XGET -H "Authorization: Bearer YOUR_JWT_HERE" https://api.central.sophos.com/whoami/v1
   ```

   Response content -- grab the `id` (`tenant_id`) and `dataRegion` (`url`) from the output. You will need these for your LimaCharlie Sophos adapter configuration.

```json
   {
       "id": "57ca9a6b-885f-4e36-95ec-290548c26059",
       "idType": "tenant",
       "apiHosts": {
           "global": "https://api.central.sophos.com",
           "dataRegion": "https://api-us03.central.sophos.com"
       }
   }
   ```
5. Now you have all the pieces for your adapter:

   1. `client_id`
   2. `client_secret`
   3. `tenant_id`
   4. `url`

### Infrastructure as Code Deployment

```
# Sophos Central Specific Docs: https://docs.limacharlie.io/docs/adapter-types-sophos-central
# For cloud sensor deployment, store credentials as hive secrets:

#   clientid: "hive://secret/sophos-client-id"
#   clientsecret: "hive://secret/sophos-client-secret"
#   tenantid: "hive://secret/sophos-tenant-id"

sensor_type: "sophos"
sophos:
  clientid: "hive://secret/sophos-client-id"
  clientsecret: "hive://secret/sophos-client-secret"
  tenantid: "hive://secret/sophos-tenant-id"
  url: "https://api-us01.central.sophos.com"
  client_options:
    identity:
      oid: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
      installation_key: "YOUR_LC_INSTALLATION_KEY_SOPHOS"
    hostname: "sophos-central-adapter"
    platform: "json"
    sensor_seed_key: "sophos-siem-sensor"
    mapping:
      sensor_hostname_path: "endpoint.hostname"
      event_type_path: "type"
      event_time_path: "raisedAt"
    indexing: []
```

## API Doc

See the official [documentation](https://developer.sophos.com/docs/siem-v1/1/overview).

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

### What's Next

* [Stdin](/docs/adapter-types-stdin)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Stdin

# Stdin
* 1 Minute to read

## Related articles

* [Stdin](/docs/adapter-examples-stdin)
* [Stdin JSON](/docs/adapter-examples-stdin-json)

---

### What's Next

* [Syslog](/docs/adapter-types-syslog)

Table of contents

+ [Overview](#overview)
+ [Configurations](#configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Stdin

# Stdin
* 1 Minute to read

## Related articles

* [Stdin JSON](/docs/adapter-examples-stdin-json)
* [Stdin](/docs/adapter-types-stdin)
* [Syslog](/docs/adapter-types-syslog)

---

### What's Next

* [Stdin JSON](/docs/adapter-examples-stdin-json)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Stdin JSON

# Stdin JSON
* 1 Minute to read

## Related articles

* [Stdin](/docs/adapter-types-stdin)
* [Stdin](/docs/adapter-examples-stdin)
* [Template Strings and Transforms](/docs/template-strings-and-transforms)
* [JSON](/docs/adapter-types-json)

---

### What's Next

* [Windows Event Logs](/docs/adapter-examples-windows-event-logs)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Sublime Security

# Sublime Security
[Sublime Security](https://sublime.security/) is a comprehensive email security platform that allows users to create custom detections, gain visibility and control, and focus on prevention of malicious emails.

## Ingesting Audit Logs

Audit logs from Sublime can be ingested cloud-to-cloud via the API.

### Adapter-specific Options

Adapter Type: `sublime`

* `api_key`: your Okta API key/token

### CLI Deployment

Adapter downloads can be found [here](/v2/docs/adapter-deployment#adapter-binaries).

```
chmod +x /path/to/lc_adapter

/path/to/lc_adapter sublime client_options.identity.installation_key=$INSTALLATION_KEY \
client_options.identity.oid=$OID \
client_options.platform=sublime \
client_options.sensor_seed_key=$SENSOR_NAME \
client_options.hostname=$SENSOR_NAME \
api_key=$API_KEY
```

### Infrastructure as Code Deployment

```
# Sublime Security Specific Docs: https://docs.limacharlie.io/docs/adapter-types-sublime-security
# For cloud sensor deployment, store credentials as hive secrets:

#   api_key: "hive://secret/sublime-api-key"

sensor_type: "sublime"
sublime:
  api_key: "hive://secret/sublime-api-key"
  client_options:
    identity:
      oid: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
      installation_key: "YOUR_LC_INSTALLATION_KEY_SUBLIME"
    hostname: "sublime-security-adapter"
    platform: "json"
    sensor_seed_key: "sublime-audit-sensor"
    mapping:
      sensor_hostname_path: "user.email"
      event_type_path: "type"
      event_time_path: "created_at"
    indexing: []
```

## API Doc

See the official [documentation](https://docs.sublime.security/reference/authentication).

## Ingesting Alerts

Sublime events can be ingested in LimaCharlie via a `json` Webhook Adapter configuration.

### Adapter Deployment

Sublime Security logs are ingested via a cloud-to-cloud webhook Adapter configured to receive JSON events. The steps of creating this Adapter and enabling the input include:

1. Creating the Webhook Adapter via the LimaCharlie CLI
2. Discovering the URL created for the Webhook Adapter.
3. Providing the completed URL to Sublime Security for webhook events.

#### 1. Creating the LimaCharlie Webhook Adapter

The following steps are modified from the generic Webhook Adapter creation documentation, found [here](/v2/docs/tutorial-creating-a-webhook-adapter).

Creating a Webhook Adapter requires a set of parameters, including organization ID, Installation Key, platform, and mapping details, among other parameters. The following configuration can be modified to easily configure a Webhook Adapter for ingesting Sublime Security events:

```json
{
    "sensor_type": "webhook",
    "webhook": {
       "secret": "sublime-security",
        "client_options": {
            "hostname": "sublime-security",
            "identity": {
                "oid": "<your_oid>",
                "installation_key": "<your_installation_key>"
            },
            "platform": "json",
            "sensor_seed_key": "sublime-super-secret-key",
            "mapping" : {
                "event_type_path" : "data/flagged_rules/name",
                "event_time_path" : "created_at"
            }
        }
    }
}
```

Note that in the mapping above, we make the following changes:

* `event_type_path` is mapped to the rule name from the Sublime alert
* `event_time_path` is mapped to the `created_at` field from the Sublime alert

#### 2. Building the Adapter URL

After creating the webhook, you'll need to retrieve the webhook URL from the [Get Org URLs](https://docs.limacharlie.io/apidocs/get-org-urls) API call. You'll need the following information to complete the Webhook URL:

* Organization ID
* Webhook name (from the config)
* Secret (from the config)

Let's assume the returned domain looks like `9157798c50af372c.hook.limacharlie.io`, the format of the URL would be:

`https://9157798c50af372c.hook.limacharlie.io/OID/HOOKNAME/SECRET`

Note that the `secret` value can be provided in the webhook URL or as an HTTP header named `lc-secret`.

#### 3. Configuring the Sublime webhook Action

Within the Sublime Security console, navigate to **Manage** > **Actions**. From here, you can select **New Action** > **Webhook**.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28174%29.png)

Within the **Configure webhook** menu, provide a name and the Adapter URL constructed in Step 2 above.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28175%29.png)

As mentioned in Step 2, you can configure the HTTP header `lc-secret`, if so desired.

Upon configuration of the webhook within Sublime Security, alerts can be configured to be sent to the LimaCharlie platform. To test the Webhook, select **Trigger Custom Action** from any Flagged message, and send to the LimaCharlie webhook.

Command-line Interface

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

##### Related articles

* [Sublime](/docs/ext-cloud-cli-sublime)

---

###### What's Next

* [Tailscale](/docs/adapter-types-tailscale)

Table of contents

+ [Ingesting Audit Logs](#ingesting-audit-logs)
+ [API Doc](#api-doc)
+ [Ingesting Alerts](#ingesting-alerts)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Syslog

# Syslog
Syslog is both a protocol and common logging format that consolidate events to a central location for storage. On \*nix systems, Syslog often outputs to predefined locations, such as `/var/log`. The LimaCharlie Adapter can be configured as a Syslog endpoint to collect events either via TCP or UDP.

Syslog data can also be ingested via other data platforms, such as an S3 bucket.

Syslog events are observed in LimaCharlie as the `text` platform.

A more detailed guide to syslog collection can be found in the [Log Collection Guide](/v2/docs/logcollectionguide).

## Adapter Deployment

Given its ubiquity, Syslog can be ingested via a myriad of methods in both text/log and streaming formats. For non-streaming methods, please refer to the corresponding Adapter type (such as [S3](/v2/docs/adapter-types-s3), [GCP](/v2/docs/adapter-types-google-cloud-pubsub), etc.)

### Syslog-specific Configurations

All Adapters have the same common client configuration options, found [here](/v2/docs/adapter-usage). A syslog Adapter has a few unique configuration options not found with other Adapter types. These include:

* `port`: port to listen for syslog from.
* `iface`: the interface name to listen for new connections/packets from, defaults to all.
* `is_udp`: if `true`, listen over UDP instead of TCP.
* `ssl_cert`: path to a file with the SSL cert to use to receive logs over TCP.
* `ssl_key`: path to a file with the SSL key to use to receive logs over TCP.

### Collecting Syslog via Docker

The following example walks through configuring a Docker container as a syslog Adapter.

```
docker run --rm -it -p 1514:1514 refractionpoint/lc-adapter:latest syslog port=1514 \
  client_options.identity.installation_key=e9a3bcdf-efa2-47ae-b6df-579a02f3a54d \
  client_options.identity.oid=8cbe27f4-bfa1-4afb-ba19-138cd51389cd \
  client_options.platform=text "client_options.mapping.parsing_grok=%{DATESTAMP:date} %{HOSTNAME:host} %{WORD:exe}\[%{INT:pid}\]: %{GREEDYDATA:msg}" \
  client_options.sensor_seed_key=testclient1 \
  client_options.mapping.rename_only=true \
  "client_options.mapping.mapping[0].src_field=host" \
  "client_options.mapping.mapping[0].dst_field=syslog_hostname"
```

Here's a breakdown of the above example:

* `docker run --rm`: run a container and don't keep the contents around when it's stopped.
* `-it`: make the container interactive so you can ctrl-c to stop it.
* `-p 1514:1514`: allow the container to listen on port `1514` on the local host and use the same port within the container.
* `refractionpoint/lc-adapter:latest`: this is the name of the public container provided by LimaCharlie.
* `syslog`: the method the Adapter should use to collect data locally. The `syslog` value will operate as a syslog endpoint on the TCP port specified.
* `port=1514`: the TCP port the Adapter should listen on. By default this is a normal TCP connection (not SSL), although SSL options exist.
* `client_options.identity.installation_key=....`: the Installation Key from LimaCharlie.
* `client_options.identity.`OID`=....`: the Organization ID from LimaCharlie the installation key above belongs to.
* `client_options.platform=text`: this indicates the type of data that will be received from this adapter. In this case it's syslog, so `text` lines.
* `client_options.mapping.parsing_grok=....`: this is the grok expression describing how to interpret the text lines and how to convert them to JSON.
* `client_options.sensor_seed_key=....`: this is the value that identifies this instance of the Adapter. Record it to re-use the Sensor generated for this Adapter later if you have to re-install the Adapter.
* `client_options.mapping.rename_only=true`: only rename the field in mapping below, so keep the other original fields.
* `client_options.mapping.mapping[0].src_field=....`: the source field of the first mapping record.
* `client_options.mapping.mapping[0].dst_field=....`: the destination field of the first mapping record.

To test it, assuming we're on the same Debian box as the container, pipe the syslog to the container:

```
journalctl -f -q | netcat 127.0.0.1 1514
```

### Collecting Syslog via Binary Adapter

The LimaCharlie binary Adapter can be deployed as a syslog listener. This option allows you to configure multiple syslog outputs to a single listener, and ingest multiple types of events with a single Adapter.

#### Step 1: Create an installation key

We recommend utilizing a unique installation key for this deployment, specifically with a `syslog` Tag. This allows for a level of delineation within  rules and outputs via Tags.

#### Step 2: Create an Adapter config file

Syslog events are typically ingested as `text`, however often have specific structures to them. Utilizing a config file allows for easy management of a regex string to extract relevant fields from syslog output.

The following example config file can be a starting point. However, you might need to modify the regex to match your specific message.

```
# Syslog Specific Docs: https://docs.limacharlie.io/docs/adapter-types-syslog

sensor_type: "syslog"
  syslog:
    port: 1514
    iface: "0.0.0.0"
    client_options:
      identity:
        oid: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
        installation_key: "YOUR_LC_INSTALLATION_KEY_SYSLOG"
      hostname: "syslog-adapter"
      platform: "linux"
      sensor_seed_key: "syslog-collector"
      mapping:
        parsing_grok:
          message: "^<%{INT:pri}>%{SYSLOGTIMESTAMP:timestamp}\\s+%{HOSTNAME:hostname}\\s+%{WORD:tag}(?:\\[%{INT:pid}\\])?:\\s+%{GREEDYDATA:message}"
        sensor_hostname_path: "hostname"
        event_type_path: "tag"
        event_time_path: "timestamp"
    # Optional syslog-specific configuration
    is_udp: false                               # TCP (default) vs UDP
    write_timeout_sec: 30                       # Write timeout
    ssl_cert: "/certs/syslog_server.pem"       # Optional SSL cert
    ssl_key: "/certs/syslog_server.key"        # Optional SSL key
    mutual_tls_cert: "/certs/client_ca.pem"    # Optional mTLS
```

#### Step 3: Configure syslog output to send messages to a local listener

This step will depend on the type of syslog daemon you are using (syslog, rsyslog, syslog-ng, etc.) Within the daemon configuration file, configure the desired facility(-ies) to direct to the local listener. In the following example, we configured `auth` and `authpriv` events to write to both `/var/log/audit.log` and `127.0.0.1:1514`.

```
auth,authpriv.*			/var/log/auth.log
auth,authpriv.*			@@127.0.0.1:1514
```

After applying the appropriate configuration, restart the syslog daemon.

#### Step 4: Confirm that syslog messages are sent to the correct location

Utilizing a tool like `netcat`, you can listen on the appropriate port to confirm that messages are being sent. The following command will spawn a `netcat` listener on port 1514:

```
nc -l -p 1514
```

#### Step 5: Run the LimaCharlie Adapter

Execute the binary Adapter with the syslog configuration file in order to start the LimaCharlie listener. If started correctly, you should see the following messages in `stdout`:

```
DBG <date>: usp-client connecting
DBG <date>: usp-client connected
DBG <date>: listening for connections on :1514
```

Double-check the LimaCharlie Sensors list, and you should see the text adapter with the respective hostname sending `Syslog` events.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

In LimaCharlie, an Organization ID (OID) is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

---

##### Related articles

* [Syslog](/docs/outputs-destinations-syslog)
* [Stdin](/docs/adapter-examples-stdin)
* [Artifacts](/docs/artifacts)
* [Ingesting Linux Audit Logs](/docs/ingesting-linux-audit-logs)

---

###### What's Next

* [Sublime Security](/docs/adapter-types-sublime-security)

Table of contents

+ [Adapter Deployment](#adapter-deployment)

Tags

* [adapters](/docs/en/tags/adapters)
* [linux](/docs/en/tags/linux)
* [sensors](/docs/en/tags/sensors)

---

## Tailscale

# Tailscale
[Tailscale](https://tailscale.com/) is a VPN service that makes devices and applications accessible anywhere in the world. Relying on the open source WireGuard protocol, Tailscale enables encrypted point-to-point connections.

Tailscale events can be ingested in LimaCharlie via a `json` Webhook Adapter.

## Adapter Deployment

Tailscale events are ingested via a cloud-to-cloud webhook Adapter configured to receive JSON events. In the creation of the Adapter, we map fields directly to the expected Tailscale webhook events. The steps of creating this Adapter and enabling the input include:

1. Creating the Webhook Adapter via the LimaCharlie CLI.
2. Discovering the URL created for the Webhook Adapter.
3. Providing the completed URL to Tailscale for Webhook events.

### 1. Creating the LimaCharlie Webhook Adapter

The following steps are modified from the generic Webhook Adapter creation doc, found [here](/v2/docs/tutorial-creating-a-webhook-adapter).

Creating a Webhook Adapter requires a set of parameters, including organization ID, Installation Key, platform, and mapping details. The following configuration has been provided to configure a Webhook Adapter for ingesting Tailscale events:

```json
{
    "sensor_type": "webhook",
    "webhook": {
       "secret": "tailscale-secret",
        "client_options": {
            "hostname": "tailscale",
            "identity": {
                "oid": "<your_oid>",
                "installation_key": "<your_installation_key>"
            },
            "platform": "json",
            "sensor_seed_key": "tailscale-super-secret-key",
            "mapping" : {
                "event_type_path" : "message"
            }
        }
    }
}
```

The mapping above is based on the expected Webhook event from Tailscale ([example provided here](https://tailscale.com/kb/1213/webhooks/)). Note that in the mapping above, we make the following change:

* `event_type_path` is mapped to the `message` field

### 2. Building the Webhook URL

After creating the webhook, you'll need to retrieve the webhook URL from the [Get Org URLs](https://docs.limacharlie.io/apidocs/get-org-urls) API call. You'll need the following information to complete the Webhook URL:

* Organization ID
* Webhook name (from the config)
* Secret (from the config)

Let's assume the returned domain looks like `9157798c50af372c.hook.limacharlie.io`, the format of the URL would be:

`https://9157798c50af372c.hook.limacharlie.io/OID/HOOKNAME/SECRET`

Note that the `secret` value can be provided in the webhook URL or as an HTTP header named `lc-secret`.

### 3. Providing the URL to Tailscale for Webhook Events

Within the Tailscale Admin Console, navigate to **Settings** > **Webhooks**. Select **Add endpoint...**

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28168%29.png)

Provide the completed Webhook URL from Step 2, above. You can also select the various events you want sent via Webhook. Options include:

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28170%29.png)

Select **Add endpoint**. Tailscale will provide you a webhook secret unique to this endpoint. You may want to keep this value, however it is not required within LimaCharlie.

#### 4. Test Webhook Output

Within the Tailscale Admin Console, you can test the webhook out and ensure that LimaCharlie is receiving events. Within the Webhook Endpoint options, select **Test endpoint...**.

You should see the webhook event populate within the LimaCharlie Adapter a moment later. Note that the `event_type` will match the `message` field from the Tailscale webhook event.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

##### Related articles

* [Tailscale](/docs/ext-cloud-cli-tailscale)

---

###### What's Next

* [VMWare Carbon Black](/docs/adapter-types-vmware-carbon-black)

Table of contents

+ [Adapter Deployment](#adapter-deployment)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Tutorial: Creating a Webhook Adapter

# Tutorial: Creating a Webhook Adapter
LimaCharlie supports webhooks as a telemetry ingestion method. Webhooks are technically cloud [Adapters](/v2/docs/adapters), as they cannot be deployed on-prem or through the downloadable Adapter binary.

Webhook adapters are created by enabling a webhook through the `cloud_sensor` [Hive](/v2/docs/config-hive) feature. Webhook creation will enable a specific URL that can receive webhooks from any platform. Received data will be ingested in LimaCharlie as a Sensor, similar to an Office365 or Syslog Adapter.

## Creating a Webhook Adapter

Webhook adapters can be created either through the webapp, API, or CLI. Before creation, let's look at the basic webhook configuration and values necessary to build the adapter.

```json
{
    "sensor_type": "webhook",
    "webhook": {
        // This secret value will be part of the URL to accept your webhooks.
        // It enables you to prevent or revoke unauthorized access to a hook.
        "secret": "some-secret-value-hard-to-predict",

        // Placeholder for generic webhook signature validation.
        // If you require a specific format, please get in touch with us.
        "signature_secret": "",
        "signature_header": "",
        "signature_scheme": "",

        // Format with which the data is ingested in LC.
        "client_options": {
            // Provide your own name for the webhook adapter
            "hostname": "<any_name>",
            "identity": {
                // Provide the OID of the organization you wish to send to
                "oid": "<oid>",
                // Provide the installation key to be used for the adapter
                "installation_key": "<installation_key>"
            },
            "platform": "json",
            "sensor_seed_key": "<any-super-secret-seed-key>"
        }
    }
}
```

When the above configuration is provided to LimaCharlie, a webhook adapter will appear and be available for webhook event ingestion. Here's an example of creating the above record through the LimaCharlie CLI:

```
echo '{"sensor_type": "webhook", "webhook": {"secret": "some-secret-value-hard-to-predict", "signature_secret": "", "signature_header": "", "signature_scheme": "", "client_options": {"hostname": "<any_name>", "identity": {"oid": "<oid>", "installation_key": "<installation_key>"}, "platform": "json", "sensor_seed_key": "test-webhook"}}}' | limacharlie hive set cloud_sensor --key my-webhook --data -
```

After creating the webhook, you will be provided with a geo-dependent URL, respective to your LimaCharlie Organization location. You can also retrieve your webhook URLs with either of the following commands:

* REST API: [getOrgURLs](https://docs.limacharlie.io/apidocs/get-org-urls)
* Python SDK:

```python
python3 -c "import limacharlie; print(limacharlie.Manager().getOrgURLs()['hooks'])"
```

## Using the webhook adapter

After capturing the webhook URL in the previous step, only a few more pieces of data are necessary to construct the webhook ingestion.

Let's assume the returned domain looks like `9157798c50af372c.hook.limacharlie.io`, the format of the URL would be:

`https://9157798c50af372c.hook.limacharlie.io/OID/HOOKNAME/SECRET`, where:

* OID is the Organization OID provided in the configuration above.
* HOOKNAME is the name of the hook provided in the configuration above.
* SECRET is the secret value provided in the configuration. You can provide the secret value in the URL or as an HTTP header named `lc-secret`.

## Supported Webhook Format

When sending data via POST requests to the URL, the body of your request is expected to be one or many JSON events. Supported formats include:

* Simple JSON object:

  + `{"some":"data"}`
* List of JSON objects:

  + `[{"some":"data"},{"some":"data"}]`
* Newline separated JSON objects like:

```json
{"some":"data"}
{"some":"data"}
{"some":"data"}
```

Or, one of the above, but compressed using gzip.

With the completed webhook URL, you can begin sending events and will see them in the Timeline for your webhook Adapater.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

### Related articles

* [Webhook](/docs/outputs-destinations-webhook)
* [Webhook (Bulk)](/docs/outputs-destinations-webhook-bulk)
* [Tutorial: Ingesting Telemetry from Cloud-Based External Sources](/docs/tutorial-ingesting-telemetry-from-cloud-based-external-sources)

---

#### What's Next

* [Tutorial: Ingesting Google Cloud Logs](/docs/tutorial-ingesting-google-cloud-logs)

Table of contents

+ [Creating a Webhook Adapter](#creating-a-webhook-adapter)
+ [Using the webhook adapter](#using-the-webhook-adapter)
+ [Supported Webhook Format](#supported-webhook-format)

Tags

* [adapters](/docs/en/tags/adapters)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## VMWare Carbon Black

# VMWare Carbon Black
## Overview

LimaCharlie can ingest Carbon Black events from a number of storage locations. Typically, an organization would export Carbon Black data via the API to a storage mechanism, such as an S3 bucket, which would then be ingested by LimaCharlie.

Carbon Black events are observable in Detection & Response rules via the `carbon_black` platform.

## Deployment Configurations

All adapters support the same `client_options`, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.

* `client_options.identity.oid`: the LimaCharlie Organization ID (OID) this adapter is used with.
* `client_options.identity.installation_key`: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.
* `client_options.platform`: the type of data ingested through this adapter, like `text`, `json`, `gcp`, `carbon_black`, etc.
* `client_options.sensor_seed_key`: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.

## Config File

VMWare Carbon Black data can be exported via the API to an S3 bucket, and then ingested with LimaCharlie. The following command utilizes a CLI Adapter to ingest these events

```
./lc_adapter s3 client_options.identity.installation_key=<INSTALLATION_KEY> \
client_options.identity.oid=<OID> \
client_options.platform=carbon_black \
client_options.sensor_seed_key=tests3 \
bucket_name=lc-cb-test \
access_key=YYYYYYYYYY \
secret_key=XXXXXXXX  \
"prefix=events/org_key=NKZAAAEM/"
```

Here's a breakdown of the above example:

* `lc_adapter`: simply the CLI Adapter.
* `s3`: the data will be collected from an AWS S3 bucket.
* `client_options.identity.installation_key=....`: the Installation Key value from LimaCharlie.
* `client_options.identity.oid=....`: the Organization ID from LimaCharlie the installation key above belongs to.
* `client_options.platform=carbon_black`: this indicates the data received will be Carbon Black events from their API.
* `client_options.sensor_seed_key=....`: this is the value that identifies this instance of the Adapter. Record it to re-use the Sensor IDs generated for the Carbon Black sensors from this Adapter later if you have to re-install the Adapter.
* `bucket_name:....`: the name of the S3 bucket holding the data.
* `access_key:....`: the AWS Access Key for the API key below.
* `secret_key:....`: the API key for AWS that has access to this bucket.
* `prefix=....`: the file/directory name prefix that holds the Carbon Black data within the bucket.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Amazon Web Services

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

### What's Next

* [Windows Event Log](/docs/adapter-types-windows-event-log)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [Config File](#config-file)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## VirusTotal

# VirusTotal
* 1 Minute to read

## Related articles

* [VirusTotal Integration](/docs/tutorials-integratons-virustotal-integration)

---

### What's Next

* [Extensions](/docs/extensions)

Table of contents

+ [API Keys](#api-keys)
+ [Usage](#usage)

Tags

* [add-ons](/docs/en/tags/add-ons)

---

## Zendesk

# Zendesk
* 1 Minute to read

## Related articles

* [Adapter Usage](/docs/adapter-usage)
* [Adapters](/docs/adapters)
* [Adapter Deployment](/docs/adapter-deployment)
* [Adapter Examples](/docs/adapter-examples)
* [Okta](/docs/ext-cloud-cli-okta)

---

### What's Next

* [Adapter Deployment](/docs/adapter-deployment)

Table of contents

+ [Overview](#overview)
+ [Deployment Configurations](#deployment-configurations)
+ [API Doc](#api-doc)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## alphaMountain

# alphaMountain
* 1 Minute to read

## What's Next

* [EchoTrail](/docs/api-integrations-echotrail)

Table of contents

+ [Detection &amp; Response Rule](#detection-amp-response-rule)

Tags

* [add-ons](/docs/en/tags/add-ons)

---

# Outputs

## Adding Outputs to an Allow List

# Adding Outputs to an Allow List
* 1 Minute to read

## What's Next

* [Output Billing](/docs/output-billing)

Tags

* [outputs](/docs/en/tags/outputs)

---

## Amazon S3

# Amazon S3
Output events and detections to an Amazon S3 bucket.

If you have your own visualization stack, or you just need the data archived, you can output directly to Amazon S3. This way you don't need any infrastructure.

* `bucket`: the path to the AWS S3 bucket.
* `key_id`:  the id of the AWS auth key.
* `secret_key`: the AWS secret key to auth with.
* `sec_per_file`: the number of seconds after which a file is cut and uploaded.
* `is_compression`: if set to "true", data will be gzipped before upload.
* `is_indexing`: *DEPRECATED* if set to "true", data is uploaded in a way that makes it searchable.
* `region_name`: the region name of the bucket, it is recommended to set it, though not always required.
* `endpoint_url`: optionally specify a custom endpoint URL, usually used with region\_name to output to S3-compatible 3rd party services.
* `dir`: the directory prefix
* `is_no_sharding`: do not add a shard directory at the root of the files generated.

Example:

```
bucket: my-bucket-name
key_id: AKIAABCDEHPUXHHHHSSQ
secret_key: fonsjifnidn8anf4fh74y3yr34gf3hrhgh8er
is_indexing: "true"
is_compression: "true"
```

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/aws.png)

If the `is_indexing` option is enabled, data uploaded to S3 will be in a specific format enabling some indexed queries.

LC data files begin with a `d`, while special manifest files (indicating
 which data files contain which sensors' data) begin with an `m`. Otherwise (not `is_indexing`), data is uploaded as flat files with a UUID name.

The `is_compression` flag, if on, will compress each file as a GZIP when uploaded. It is recommended you enable `is_compression`.

## AWS IAM Configuration

1. Log in to AWS console and go to the IAM service.
2. Click on `Users` from the menu.
3. Click `Create User`, give it a name, and click `Next`.
4. Click `Next`, then `Create User`
5. Click on the user you just created and click on the `Security Credentials` tab
6. Click `Create access key`
7. Select `Other` and click `Next`
8. Provide a description (optional) and click `Create access key`
9. Take note of the "Access key", "Secret access key" and ARN name for the user (starts with "arn:", shown on the user summary screen).

### AWS S3 Configuration

1. Go to the S3 service.
2. Click `Create bucket`, enter a name and select a region.
3. Click `Create bucket`
4. Click on your newly created bucket and click on the `Permissions` tab
5. Select `Bucket policy` and click `Edit`
6. Input the policy in [sample below](#policy-sample) where you replace the `<<USER_ARN>>` with the ARN name of the user you created and the `<<BUCKET_NAME>>` with the name of the bucket you just created.
7. Click `Save Changes`

#### Policy Sample

```json
{
   "Version": "2012-10-17",
   "Statement": [
      {
         "Sid": "PermissionForObjectOperations",
         "Effect": "Allow",
         "Principal": {
            "AWS": "<<USER_ARN>>"
         },
         "Action": "s3:PutObject",
         "Resource": "arn:aws:s3:::<<BUCKET_NAME>>/*"
      }
   ]
}
```

### LimaCharlie Configuration

1. Back in the LimaCharlie GUI, in your organization view, click `Outputs` and `Add Output`
2. Select the stream you would like to send (events, detections, etc)
3. Select the `Amazon S3` destination
4. Give it a name, enter the bucket name, key\_id, and secret\_key you noted from AWS, and any other parameters you wish to configure
5. Click `Save Output`
6. After a minute, the data should start getting written to your bucket

---

#### Related articles

* [AWS CloudTrail](/docs/adapter-types-aws-cloudtrail)
* [S3](/docs/adapter-types-s3)
* [AWS](/docs/ext-cloud-cli-aws)
* [AWS GuardDuty](/docs/adapter-types-aws-guardduty)

---

##### What's Next

* [Apache Kafka](/docs/outputs-destinations-apache-kafka)

Table of contents

Tags

* [aws](/docs/en/tags/aws)
* [outputs](/docs/en/tags/outputs)

---

## Apache Kafka

# Apache Kafka
* 1 Minute to read

## What's Next

* [Azure Event Hub](/docs/outputs-destinations-azure-event-hub)

Tags

* [outputs](/docs/en/tags/outputs)

---

## Azure Storage Blob

# Azure Storage Blob
* 1 Minute to read

## Related articles

* [Azure Kubernetes Service (AKS)](/docs/azure-kubernetes-service)
* [Azure Monitor](/docs/azure-monitor)
* [Azure Network Security Group](/docs/azure-network-security-group)
* [Azure SQL Audit Logs](/docs/azure-sql-audit-logs)
* [Azure Event Hub](/docs/adapter-types-azure-event-hub)
* [Microsoft Entra ID](/docs/adapter-types-microsoft-entra-id)
* [Azure](/docs/ext-cloud-cli-azure)

---

### What's Next

* [Elastic](/docs/outputs-destinations-elastic)

Tags

* [azure](/docs/en/tags/azure)
* [outputs](/docs/en/tags/outputs)

---

## Cost Effective SIEM Alternative

# Cost Effective SIEM Alternative
* 1 Minute to read

## What's Next

* [Endpoint Detection and Response (EDR)](/docs/endpoint-detection-and-response-edr)

Tags

* [SIEM](/docs/en/tags/SIEM)
* [use case](/docs/en/tags/use%20case)

---

## Elastic

# Elastic
* 1 Minute to read

## Related articles

* [OpenSearch](/docs/outputs-destinations-opensearch)

---

### What's Next

* [Google Cloud BigQuery](/docs/outputs-destinations-google-cloud-bigquery)

Tags

* [outputs](/docs/en/tags/outputs)

---

## Google Cloud Pubsub

# Google Cloud Pubsub
* 1 Minute to read

## Related articles

* [Building Reports with BigQuery + Looker Studio](/docs/tutorials-reporting-building-reports-with-bigquery-looker-studio)
* [Google Cloud Storage](/docs/outputs-destinations-google-cloud-storage)
* [Google Cloud BigQuery](/docs/outputs-destinations-google-cloud-bigquery)
* [Google Workspace](/docs/adapter-types-google-workspace)
* [Google Cloud Storage](/docs/adapter-types-google-cloud-storage)
* [Google Cloud Pubsub](/docs/adapter-types-google-cloud-pubsub)
* [Tutorial: Ingesting Google Cloud Logs](/docs/tutorial-ingesting-google-cloud-logs)
* [Google Cloud](/docs/ext-cloud-cli-google-cloud)

---

### What's Next

* [Google Cloud Storage](/docs/outputs-destinations-google-cloud-storage)

Tags

* [gcp](/docs/en/tags/gcp)
* [outputs](/docs/en/tags/outputs)

---

## Google Cloud Storage

# Google Cloud Storage
* 1 Minute to read

## Related articles

* [Building Reports with BigQuery + Looker Studio](/docs/tutorials-reporting-building-reports-with-bigquery-looker-studio)
* [Google Cloud Pubsub](/docs/outputs-destinations-google-cloud-pubsub)
* [Google Cloud BigQuery](/docs/outputs-destinations-google-cloud-bigquery)
* [Google Workspace](/docs/adapter-types-google-workspace)
* [Google Cloud Storage](/docs/adapter-types-google-cloud-storage)
* [Google Cloud Pubsub](/docs/adapter-types-google-cloud-pubsub)
* [Tutorial: Ingesting Google Cloud Logs](/docs/tutorial-ingesting-google-cloud-logs)
* [Google Cloud](/docs/ext-cloud-cli-google-cloud)

---

### What's Next

* [Humio](/docs/outputs-destinations-humio)

Tags

* [gcp](/docs/en/tags/gcp)
* [outputs](/docs/en/tags/outputs)

---

## Humio

# Humio
* 1 Minute to read

## What's Next

* [OpenSearch](/docs/outputs-destinations-opensearch)

Tags

* [outputs](/docs/en/tags/outputs)

---

## Output Billing

# Output Billing
* 1 Minute to read

## What's Next

* [Amazon S3](/docs/outputs-destinations-amazon-s3)

---

## Output Destinations

# Output Destinations
19 Articles  in this category

---

## Outputs

# Outputs
## Overview

LimaCharlie provides multiple output options, referred to as streams, for you to send data from LimaCharlie to other destination(s). We provide native support for output with multiple different providers, or "destinations". The diagram below provides some basic examples of where data is sourced from and where data can be sent to.

![Flow of Data within LimaCharlie](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image.png)

Outputs should be thought of in two capacities: Streams and Destinations. A *stream* is what you are sending, whereas a *destination* is where you are sending it to. We will look at both in detail.

**Check out the following YouTube video for a walkthrough of configuring an output.**

## Streams

Streams define which events will be sent to an output destination.

Available streams include:

* `event` : The bulk of data events coming from sensors. *Note: this will be very verbose*
* `detect` : Alerts, as generated by the `report` action in [detection and response rules](/v2/docs/detection-and-response).
* `audit` : Events generated by the LimaCharlie platform, such as access control.
* `deployment` : Events about your deployment, like Sensor enrollments or cloned sensors.
* `artifact` : Meta-events reporting on newly-ingested files through the Artifact Collection mechanism.
* `tailored` : Only events specifically flagged for outputs sent to this stream.

---

## Destinations

LimaCharlie integrates with several providers, such as S3, Google Cloud, or Slack, as [Output Destinations](/v2/docs/output-destinations).

Allow Lists

Looking to add LimaCharlie outputs to an allow list? See more details [here](/v2/docs/output-allowlisting).

Destinations are the recipients of LimaCharlie streams. Oftentimes, users will rely on LimaCharlie for 365 data retention, while pushing high-fidelity alerts or other platform logs to another source for subsequent auditing or ticketing. As such, we have created native and/or easy-to-use destination options.

Missing a destination?

If you need support for a destination we haven't integrated yet, let us know by jumping in the [LimaCharlie Community Discourse](https://community.limacharlie.com/).

### Configuring destinations

Every destination will have both general and specific parameters. Destinations can be configured via the LimaCharlie GUI, API, or command-line.

#### General Parameters

All destinations can be configured with the following options:

* `is_flat`: take the json output and flatten the whole thing to a flat structure.
* `is_payload_as_string`: converts the payload (`event` or `detect` components) of events and detections into a JSON string instead of a JSON object.
* `inv_id`: only send events matching the investigation id to this output (event stream only).
* `tag`: only send events from sensors with this Tag to this output (event stream only).
* `cat`: only send detections from this category to this output (detect stream only).
* `cat_black_list`: only send detections that do not match the prefixes in this list (newline-separated).
* `event_white_list`: only send event of the types in this list (newline-separated, event and audit streams only).
* `event_black_list`: only send event not of the types in this list (newline-separated, event and audit streams only).
* `is_delete_on_failure`: if an error occurs during output, delete the output automatically.
* `is_prefix_data`: wrap JSON events in a dictionary with the event\_type as the key and original event as value.
* `sample_rate`: limits data sent to Output to be 1/sample\_rate.
* `custom_transform`: a [template and transforms](/v2/docs/template-strings-and-transforms) to apply to the JSON data as a last output step.

#### Specific Parameters

If you are configuring destinations using the LimaCharlie UI, required options must be provided before the output can be created.

### Output Destinations

See [Output Destinations](/v2/docs/output-destinations) for a list of supported destinations.

## Transforming Output Data

To learn how you can manipulate data prior to sending to your Output Destination, read about [Transforming Output Data](/v2/docs/template-strings-and-transforms#transformingoutputdata).

## Testing Outputs

The easiest way to test if the outputs are configured correctly is to set the stream to `Audit` which will send auditing events about activity around the management of the platform in the cloud. You can then edit the same output or make any other change on the platform, which will trigger an audit event to be sent.

After you have confirmed that the output configurations works, you can switch the data stream from `Audit` to the one you are looking to use.

If you are running into an error configuring an output, the error details will be listed in the Platform Logs section under Errors, with the key that looks like `outputs/OUTPUT_NAME`.

If an output fails, it gets disabled temporarily to avoid spam. It will be re-enabled automatically after a while, or you can force it to be re-enabled by updating the configuration.

## Use Cases

There are multiple use cases or integration strategies for shipping telemetry to and from the LimaCharlie platform. Some common approaches we have seen:

**All data over batched files via SFTP, Splunk or ELK consumes the received files for ingestion.**

```
Sensor ---> LC (All Streams) ---> SFTP ---> ( Splunk | ELK )
```

**All data streamed in real-time via Syslog, Splunk or ELK receive directly via an open Syslog socket.**

```
Sensor ---> LC (All Streams) ---> Syslog( TCP+SSL) ---> ( Splunk | ELK )
```

**All data over batched files stored on Amazon S3, Splunk or ELK consumes the received files remotely for ingestion.**

```
Sensor ---> LC (All Streams) ---> Amazon S3 ---> ( Splunk | ELK )
```

**Bulk events are uploaded to Amazon S3 for archiving, while alerts and auditing events are sent in real-time to Splunk via Syslog.** *Note: This has the added benefit of reducing Splunk license cost while keeping the raw events available for analysis at a lower cost.*

```
Sensor ---> LC (Event Stream) ---> Amazon S3
       +--> LC (Alert+Audit Streams) ---> Syslog (TCP+SSL) ---> Splunk
```

## IP Sources

Outputs from the LimaCharlie cloud do not come from a single predictible IP address due to the highly distributed nature of the cloud.

An approximation can be made using the blocks of IP addresses published by Google Cloud Platform [here](https://www.gstatic.com/ipranges/cloud.json).

The following LimaCharlie datacenters map to the following GCP regions:

* USA: `us-central1`
* Canada: `northamerica-northeast1`
* Europe: `europe-west4`
* UK: `europe-west2`
* India: `asia-south1`

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

Google Cloud Platform

---

### Related articles

* [Output Destinations](/docs/output-destinations)

---

#### What's Next

* [Adding Outputs to an Allow List](/docs/output-allowlisting)

Table of contents

+ [Overview](#overview)
+ [Streams](#streams)
+ [Destinations](#destinations)
+ [Transforming Output Data](#transforming-output-data)
+ [Testing Outputs](#testing-outputs)
+ [Use Cases](#use-cases)
+ [IP Sources](#ip-sources)

Tags

* [outputs](/docs/en/tags/outputs)
* [platform](/docs/en/tags/platform)

---

## SCP

# SCP
* 1 Minute to read

## What's Next

* [SFTP](/docs/outputs-destinations-sftp)

Tags

* [outputs](/docs/en/tags/outputs)

---

## SFTP

# SFTP
* 1 Minute to read

## What's Next

* [Slack](/docs/outputs-destinations-slack)

Tags

* [outputs](/docs/en/tags/outputs)

---

## SMTP

# SMTP
* 1 Minute to read

## Related articles

* [IMAP](/docs/adapter-types-imap)

---

### What's Next

* [Splunk](/docs/outputs-destinations-splunk)

Table of contents

+ [Webapp Configuration](#webapp-configuration)

Tags

* [outputs](/docs/en/tags/outputs)

---

## Slack

# Slack
* 1 Minute to read

## Related articles

* [Slack Audit Logs](/docs/adapter-types-slack-audit-logs)

---

### What's Next

* [SMTP](/docs/outputs-destinations-smtp)

Tags

* [outputs](/docs/en/tags/outputs)

---

## Splunk

# Splunk
* 1 Minute to read

## What's Next

* [Syslog](/docs/outputs-destinations-syslog)

Table of contents

Tags

* [outputs](/docs/en/tags/outputs)

---

## Syslog

# Syslog
* 1 Minute to read

## Related articles

* [Syslog](/docs/adapter-types-syslog)

---

### What's Next

* [Tines](/docs/output-destinations-tines)

Table of contents

+ [Syslog (TCP)](#syslog-tcp-)

Tags

* [outputs](/docs/en/tags/outputs)

---

## Testing Outputs

# Testing Outputs
* 1 Minute to read

## Related articles

* [Template Strings and Transforms](/docs/template-strings-and-transforms)

---

### What's Next

* [Template Strings and Transforms](/docs/template-strings-and-transforms-3)

Tags

* [outputs](/docs/en/tags/outputs)

---

## Tines

# Tines
* 1 Minute to read

## What's Next

* [Webhook](/docs/outputs-destinations-webhook)

Tags

* [outputs](/docs/en/tags/outputs)

---

## VirusTotal Integration

# VirusTotal Integration
* 1 Minute to read

## Related articles

* [VirusTotal](/docs/api-integrations-virustotal)
* [Detection and Response Examples](/docs/detection-and-response-examples)

---

### What's Next

* [Building Reports with BigQuery + Looker Studio](/docs/tutorials-reporting-building-reports-with-bigquery-looker-studio)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## Webhook

# Webhook
* 1 Minute to read

## Related articles

* [Tutorial: Creating a Webhook Adapter](/docs/tutorial-creating-a-webhook-adapter)

---

### What's Next

* [Webhook (Bulk)](/docs/outputs-destinations-webhook-bulk)

Tags

* [outputs](/docs/en/tags/outputs)

---

## Webhook (Bulk)

# Webhook (Bulk)
* 1 Minute to read

## Related articles

* [Tutorial: Creating a Webhook Adapter](/docs/tutorial-creating-a-webhook-adapter)

---

### What's Next

* [Testing Outputs](/docs/testing-outputs)

Tags

* [outputs](/docs/en/tags/outputs)

---

# Add Ons

## 1Password

# 1Password
* 1 Minute to read

## Related articles

* [1Password](/docs/1password)

---

### What's Next

* [AWS](/docs/ext-cloud-cli-aws)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## AWS

# AWS
* 1 Minute to read

## Related articles

* [AWS GuardDuty](/docs/adapter-types-aws-guardduty)
* [AWS CloudTrail](/docs/adapter-types-aws-cloudtrail)
* [Soteria AWS Rules](/docs/soteria-aws-rules)
* [Amazon S3](/docs/outputs-destinations-amazon-s3)
* [SQS](/docs/adapter-types-sqs)
* [S3](/docs/adapter-types-s3)

---

### What's Next

* [Azure](/docs/ext-cloud-cli-azure)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [aws](/docs/en/tags/aws)
* [extensions](/docs/en/tags/extensions)

---

## Add-Ons

# Add-Ons
* 1 Minute to read

## What's Next

* [Developer Grant Program](/docs/developer-grant-program)

Table of contents

+ [Types of Add-Ons](#types-of-add-ons)
+ [Subscribing to Add-Ons](#subscribing-to-add-ons)
+ [Creating Add-ons](#creating-add-ons)

Tags

* [add-ons](/docs/en/tags/add-ons)

---

## Add-Ons Tutorials

# Add-Ons Tutorials
1 Article  in this category

---

## Artifact

# Artifact
The Artifact Extension provides low-level collection capabilities which can be configured to run automatically via Detection & Response rules, Sensor collections, or pushed via REST API. When enabled, an Artifact Collection menu will be available within the LimaCharlie web UI.

> Billing for Artifacts
>
> Note that while the Artifact extension is free to enable, ingested artifacts do incur a charge. Please refer to pricing details to confirm Artifact ingestion and retention costs.

## Enabling the Artifact Extension

To enable the Artifact extension, navigate to the [Artifact extension page](https://app.limacharlie.io/add-ons/extension-detail/ext-artifact) in the marketplace. Select the Organization you wish to enable the extension for, and select **Subscribe.**

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/artifact-1.png "image(230).png")

After clicking **Subscribe**, the Artifact extension should be available almost immediately.

> Note that the Artifact extension first requires enabling of the Reliable Tasking extension. You can find more on that extension [here](/v2/docs/ext-reliable-tasking).

## Using the Artifact Extension

When enabled, you will see an **Artifact Collection** option under **Sensors** menu for the respective organization.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/artifact-2.png "image(223).png")

Within the Artifact Collection page, you can configure:

* Artifact collection rules for files.
* Artifact collection rules to stream Windows Event Log (WEL) events.
* Artifact collection rules to stream Mac Unified Log (MUL) events.
* PCAP capture rules to capture network traffic (Only available on Linux)

The following screenshot provides examples of capturing Windows Security and Sysmon Windows Event Logs via Artifact Collection. Rather than using an Adapter, capturing WEL events via the `wel://` pattern adds the corresponding events to the sensor telemetry, creating a real-time stream of Windows Event Log data. However, you can also specify the pattern to collect the specific `.evtx` files.

More information on Artifact collections can be found [here](/v2/docs/artifacts).

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/artifact-3.png "image(224).png")

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

---

### Related articles

* [Artifacts](/docs/artifacts)

---

#### What's Next

* [LimaCharlie CLI](/docs/limacharlie-cli)

Table of contents

+ [Enabling the Artifact Extension](#enabling-the-artifact-extension)
+ [Using the Artifact Extension](#using-the-artifact-extension)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Atomic Red Team

# Atomic Red Team
**Atomic Red Team** is a library of tests mapped to the MITRE ATT&CK framework, provided by Red Canary. With this Extension, LimaCharlie users can use Atomic Red Team to quickly, portably, and reproducibly test their environments.

Find more information about it [here](https://atomicredteam.io/).

New Atomic Red Team Extension

Please note that the Atomic Red Team **Extension** has replaced the Atomic Red Team **Service**. Ensure that your Organization disabled/removes the Service and subscribes to the Extension. This documentation applies to the Atomic Red Team extension.

## Enabling the Atomic Red Team Extension

Enabling Atomic Red Team can be done within the LimaCharlie **Marketplace**, or at [this link](https://beta.app.limacharlie.io/add-ons/extension-detail/ext-atomic-red-team).

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/atomic-1.png)

Under the Organization dropdown, select a tenant (organization) you want to subscribe to Atomic Red Team and click subscribe.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/atomic-2.png)

Please note that Extensions are applied on the per-tenant basis. If you have multiple organizations you want to subscribe to Atomic Red Team, you will need to subscribe each organization to the extension separately.

You can also manage add-ons from the **Subscriptions** menu under **Billing**.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/atomic-3.png)

Tenants that have been subscribed to the extension, will be marked with a green check mark in the **Organization** dropdown.

## Running Atomic Red Team test(s)

After Atomic Red Team has been enabled for your organization, the **Atomic Red Team** option will be available under the **Extensions** menu in the web UI. Selecting this Extension will render the Atomic Red Team test selection menu.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/atomic-4.png)

Sensor Eligibility for Atomic Red Team tests

Currently, LimaCharlie supports Atomic Red Team tests on Sensors installed on Windows operating systems. Furthermore, sensors must be online in order for tests to run.

Within the Atomic Red Team menu, you can select a **Sensor** to run test(s) against. Furthermore, you can also pre-select a set of tests from the full Atomic Red Team suite.

System Changes

Running Atomic Red Team tests will likely modify some system configurations. LimaCharlie attempts to revert any configuration changes performed, but the core logic is handled by the Atomic Red Team project. The following actions may occur:

* Modify PowerShell scripting permissions
* Modify PowerShell script execution policies
* Check/Modify Microsoft Defender status
* Install dependencies like Nuget
* Install Atomic Red Team technique-specific dependencies
* Technique-specific configuration changes

The list of available tests is updated every time the window is open, ensuring that you are getting all available options from the Atomic Red Team repository.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/atomic-5.png)

Select your test(s) of choice, and click 'Run Tests'. You will receive a dialog box with a job id that is associated with this particular run of test(s).

## Checking Atomic Red Team Results

When the Atomic Red Team extension is enabled, you will see an Adapter named `ext-atomic-red-team`.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/atomic-6.png)

This Adapter corresponds to all Atomic Red Team activity, including jobs run and results returned. As a separate adapter, this also means that Atomic Red Team tests are actionable events. For example, you could construct a  rule based on Atomic Red Team test results or feedback from system telemetry.

Viewing the **Timeline** within the `ext-atomic-red-team` adapter will display the test(s) run and associated results, if available.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/atomic-7.png)

Note that results are easily distinguished via a `result <MITRE ATT&CK ID>` event name, allowing for easy filtering and analysis.

Within the **Timeline** of the *system on which you ran a test*, you will also find `RECEIPT` event(s) that contain more details about executed tests. For example, the following output shows data related to a test for ATT&CK ID T1053.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/atomic-8.png)

Between `RECEIPT` events and output in the `ext-atomic-red-team` adapter, you can correlate and identify successful and failed Atomic Red Team tests.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

---

### What's Next

* [Govee](/docs/ext-govee)

Table of contents

+ [Enabling the Atomic Red Team Extension](#enabling-the-atomic-red-team-extension)
+ [Running Atomic Red Team test(s)](#running-atomic-red-team-test-s-)
+ [Checking Atomic Red Team Results](#checking-atomic-red-team-results)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Azure

# Azure
* 1 Minute to read

## Related articles

* [Azure SQL Audit Logs](/docs/azure-sql-audit-logs)
* [Azure Kubernetes Service (AKS)](/docs/azure-kubernetes-service)
* [Azure Key Vault](/docs/azure-logs-key-vault)
* [Azure Event Hub](/docs/adapter-types-azure-event-hub)
* [Azure Storage Blob](/docs/outputs-destinations-azure-storage-blob)
* [Azure Event Hub](/docs/outputs-destinations-azure-event-hub)
* [Azure Network Security Group](/docs/azure-network-security-group)
* [Azure Monitor](/docs/azure-monitor)

---

### What's Next

* [DigitalOcean](/docs/ext-cloud-cli-digitalocean)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [azure](/docs/en/tags/azure)
* [extensions](/docs/en/tags/extensions)

---

## Building Extensions

# Building Extensions
This section is a work in progress

Feel free to reach out to us on our Community Slack if you'd like to learn more

## Why Extensions?

Building functionality as a LimaCharlie Extension provides you specific convenience:

* **Multi-tenancy**: LC organizations can subscribe to your extension and you can replicate the features you're building across tenants.
* **Credentials handling**: you don't need to store any credentials from LC organizations. Every callback you receive will include an authenticated LimaCharlie SDK for the Organization relevant to the callback, with the permissions you requesed for the extension.
* **Configuration**: you're always welcome to store some configuration wherever the extension lives, but as a convenience LC will provide you with a configuration JSON object for your extension (stored in Hive) and with a callback for you to validate the content of the configuration when a user makes a modification.
* **GUI**: each extension defines its own Schema, a structure indicating to LimaCharlie what actions the extension exposes, how to call it and what to expect as a return value from actions. This information is then automatically interpreted by LimaCharlie to generate a custom user interface for your extension, making it extremely easy to expose new functionality in LimaCharlie without having to build any kind of UI (though you're always free to build one if you'd like).

### Public/Private Limitations

Anyone can build Extensions for LimaCharlie. The only limit is put on making an Extension public. Private extensions require the owner of the extension to have the `billing.ctrl` and `user.ctrl` permission on an organization in order to subscribe the organization to the private extension.

### Want to take your Extension public?

If you'd like to make your extension public (and/or monetize it), reach out to `answers@limacharlie.io` and we'll help you out. Once public, an extension is visible by everyone and can subscribed by everyone.

## High Level Structure

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28252%29.png)

Extensions are small services that receive webhooks from LimaCharlie. This means building an extension requires exposing a small HTTPS service to the internet. We recommend using something like [Google Cloud Run](https://cloud.google.com/run/), but ultimately you could also use AWS Lambdas or even host on your own hardware.

This https server will communicate with the LimaCharlie cloud according to a simple protocol using JSON.

That being said, don't worry, you don't need to know the underlying way the extension protocol works as long as you're comfortable with our public implementations.

## Getting Started

Want to get your hands on an example? We recommend using one of the following frameworks to get started.

* Golang: <https://github.com/refractionPOINT/lc-extension>
* Python: <https://github.com/refractionPOINT/lc-extension/tree/master/python>

For a more step-by-step overview, let's dig into some of the core concepts of building an extension. We will reference Golang since it provides stricter typing, but conceptually it's the same across implementations.

### Extension Definition

To create an extension, start by creating a definition - accessible through the [web interface for your personal add-ons](https://app.limacharlie.io/add-ons/published).

The required aspects of your definition are as follows:

* **Destination URL:** this is the HTTPS URL where your extension will be reachable at.
* **Required Extensions:** this is the list of other extensions your extension assumes it will have access to. When an org subscribes and is missing one of those, the user will be prompted to subscribe to these.
* **Shared Secret:** this is an arbitrary string that will be used by LimaCharlie and your extension to sign webhooks to your extension, allowing it to very the authenticity of the hook. Make it something at least 32 characters and random.
* **Extension Flairs:** these are modifiers that will be applied to your extension. Namely the `segment` flair will isolate the resources the extension can access so that it can only see and modify things (like  rules) that it has created, making it great for extensions that need a narrow scope, you should enable it unless you know you need it off. The `bulk` flair tells LimaCharlie that it expects to make a lot of API calls to the LC cloud, which will increase the API quota for the extension.
* **Permissions:** the list of permissions this extension requires on each organization subscribed to it. Use the least amount of permissions possible.

### Schema

The Extension Schema is the next important piece of building your extension. It describes what your extension can do and helps define the GUI.

Here's an example high-level structure of a schema.

```json
{
  "config_schema": {
    "fields": { ... }
    "requirements": null
  },
  "request_schema": {
    // defines two custom requests, 'dir_list' and 'refresh'
    "dir_list": {
      "is_impersonated": false,
      "is_user_facing": false,
      "long_description": "directory listing",
      "parameters": {
        "fields": { ... },
        "requirements": null
      },
      "short_description": "directory listing"
    },
    "refresh": {
      "is_impersonated": false,
      "is_user_facing": true,
      "long_description": "refresh data",
      "parameters": {
        "fields": { ... },
        "requirements": null
      },
      "short_description": "refresh data"
    },
  },
  "required_events": [
    "subscribe",
    "unsubscribe"
  ]
}
```

**The Field Configuration**
 Notice that for both the `config_schema` and the `request_schema` there is a recurring object structure that looks like the following:

```
"fields": { .. }, // key-value pair
"requirements": [[]],
```

While hidden in the example above, each `field` key-value pair shares the same structure and has a minimal implementation as such:

```
field_name: {
  data_type: "string",
  description: "",
},
```

The `requirements` field references the field keys to define whether or not certain fields individually or as a set are required. You can think of the first array to join elements with an AND, while the nested array serves as an OR.
 For example:

* `[['denominator'], ['numerator']]` means:
   (denominator AND numerator),
* `[['denominator'], ['numerator', 'default']]` means:
   (denominator AND ( one of numerator OR default)).

When getting started, we recommend utilizing the simplest data type applicable. This will enable you to get a grasp of the whole extensions framework and allow you to quickly test our your service. Such as `string`, `boolean`, `json`, etc.

Afterwards, we recommend you define the data\_type and other optional fields further, so that the UI may adapt to your defined data types. For more details, please see the [page on data types](/v2/docs/schema-data-types) or review the code definitions [here](https://github.com/refractionPOINT/lc-extension/blob/master/common/config_schema.go).

#### Config Schema (optional)

The config schema is a description of what the extension's config should look like, when stored as a Hive record in the `extension_configuration` [Hive](/v2/docs/config-hive) for convenience.

Not all extensions will have a configuration, feel free to reach out on the community slack if you need help determining whether or not your extension needs a configuration.

At the core, the config schema is simply a list of fields.

#### Request Schema

Every Request Schema exists as a key value pair of the request name, and a corresponding schema contents. The critical contents include the following fields:

* **is\_impersonated**: Whether or not the request impersonates the user through it's authentication
* **is\_user\_facing**: Whether or not this request should be visisble to the user in the UI. It does not prevent this request from bieng used through the API or as a `supported_action` (more on that later).
* **parameters**: This contains the data\_type and other fields *(recall the same fields format as the config schema)*

Other optional fields exist to facilitate the user experience, such as:

* **short\_description**
* **long\_description**
* **messages**: Includes 3 nested fields, `in_progress`, `success`, `error` to provide additional context for each case.

#### Response Schema (optional)

Each request schema may optionally contain a response schema in the same fields format as a config schema and the request parameters.

When getting started, we recommend that you skip this until you are ready to refine the extension's GUI, or you wish to clarify that kind of response a user should expect.

### Callbacks

Callbacks are functionality that an extension can specify whenever some type of event occurs.

#### Configuration Validation Callback

This callback is used by LimaCharlie to check the validity of a change in configuration done in Hive. If the configuration is valid, return success, otherwise you can return an error.

#### Event Callback

Events are events generated by the LimaCharlie platform outside your control. Currently, these 3 events are supported:

* **subscribe**: called when an organization subscribes to an extension.
* **unsubscribe**: called when an organization unsubscribes from an extension.
* **update**: called once a day per organization subscribed to the extension. It is a convenient way to perform updates to an organization like when needing to update D&R rules used by the extension.

Your extension will only receive these events if they were specified as of-interest in the extension's Schema.

#### Request Callback

The requests are the core way users, D&R rules or other extensions can interact with your extension. You can define one callback per `action`. It is common for an extension to have multiple actions, some public (for user-generated requests) and some private (to be used internally by the extension in the course of doing whatever it does).

## Simplified Frameworks

The Golang implementation of Extensions provides 3 different simplified frameworks to make the job of producing a new extension more straight forward in specific cases: <https://github.com/refractionPOINT/lc-extension/tree/master/simplified>

### D&R

This simplified framework, found in `dr.go` allows you to package D&R rules as an extension making it easy for you to distribute and update D&R rules to many orgs. Its core mechanism is based on defining the `GetRules()` function and returning a structure like `map[DR-Namespace]map[RuleName]RuleContent`. The simplified framework takes care of the recurring updates and everything else.

### Lookup

Similarl to the D&R simplified framework, but is used to package Lookups. Example: <https://github.com/refractionPOINT/lc-extension/blob/master/examples/lookup/main.go>

### CLI

This simplified framework serves to streamline the integration of 3rd party Command Line Interface tools so that they can be automated using LimaCharlie, often bringing bi-directionality to the platform.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

#### What's Next

* [Schema Data Types](/docs/schema-data-types)

Table of contents

+ [Why {{glossary.Extensions}}?](#why-{{glossary-extensions}}-)
+ [High Level Structure](#high-level-structure)
+ [Getting Started](#getting-started)
+ [Simplified Frameworks](#simplified-frameworks)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Cloud CLI

# Cloud CLI
LimaCharlie's Cloud CLI Extension (`ext-cloud-cli`) allows you to trigger actions against CLI or API endpoints for third-party products. This extension facilitates bi-directional communication between LimaCharlie and nearly any telemetry source. Actions can be triggered from the Cloud CLI UI or automated via  rules.

For a list of platforms supported by this extension, see the nested items on the left-side navigation.

## Usage

The Cloud CLI extension is enabled via the [Add-Ons Marketplace](https://app.limacharlie.io/add-ons/category/featured). When enabled, the Cloud CLI extension provides the following UI, available via the Extensions menu in LimaCharlie.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/ext-cloud-cli.png)

From this UI, you can build and execute commands against the CLI or API endpoints of the chosen product.

Cloud CLI commands can also be executed via D&R rules and the use of the `extension request` action.

**Example 1:** Stop EC2 instances based on an `instance_id` parameter found in [AWS telemetry](/v2/docs/adapter-types-aws-cloudtrail).

```
- action: extension request
  extension action: run
  extension name: ext-cloud-cli
  extension request:
    tool: '{{ "aws" }}'
    command_tokens:
      - ec2
      - stop-instances
      - '--instance-ids'
      - '{{ .event.instance_id  }}'
      - '--region'
      - us-east-1
    credentials: '{{ "hive://secret/secret-name" }}'
```

**Example 2:** Enumerate a list of VMs from an Azure tenant.

```
- action: extension request
  extension action: run
  extension name: ext-cloud-cli
  extension request:
    tool: '{{ "az" }}'
    command_line: '{{ "vm list" }}'
    credentials: '{{ "hive://secret/secret-name" }}'
```

### Credentials

You must set up credentials in the respective third-party tools or platforms prior to utilizing this extension. Once procured, credentials can be stored in the [Secrets config hive](/v2/docs/config-hive-secrets) or provided ad-hoc to the extension in the UI. We recommend storing credentials in the Secrets config hive if you plan to make repetitive calls with this extension.

Where available, details for procuring third-party credentials are provided in their respective sub-pages.

Command-line Interface

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

---

#### Related articles

* [1Password](/docs/1password)
* [Okta](/docs/adapter-types-okta)
* [Soteria M365 Rules](/docs/soteria-m365-rules)

---

##### What's Next

* [1Password](/docs/ext-cloud-cli-1password)

Table of contents

+ [Usage](#usage)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## DigitalOcean

# DigitalOcean
* 1 Minute to read

## What's Next

* [GitHub](/docs/ext-cloud-cli-github)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Dumper

# Dumper
The Dumper Extension provides the ability to do dumping of several forensic artifacts on Windows hosts. It supports a single action, which is to dump.

It supports multiple targets -- `memory` to dump the memory of the host, and `mft` to dump the MFT of the file system to CSV. The extension then automates the ingestion of the resulting dump (and dump metadata) to LimaCharlie's [Artifact Ingestion system](/v2/docs/artifacts) where it can be downloaded or analyzed, and where you can create  rules to automate detections of characteristics of those dumps.

## Usage

When enabled, dumper will be added to the Extensions view inside your Organization. It will accept the following parameters:

* `sid` - a Sensor ID for the host to perform the memory dump
* `target` - memory or mft
* `retention` - the number of days the memory dump should be retained for (default is 30)
* `ignore_cert` - ignore cert errors for payload and collection purposes (default `false`)

Upon submission of a request, the extension will perform a full memory dump of a host and upload the resulting dumps to LimaCharlie's artifact ingestion system and delete the local dumps afterwards.

Dumper requests can also be made via D&R rules. Here is is example of a D&R rule action that makes a request to Dumper:

```
- action: extension request
  extension name: ext-dumper
  extension action: request_dump
  extension request:
    target: memory
    sid: <<routing.sid>>
    retention: 30 #default 30
    ignore_cert: true # default false
```

**Notes:**

The dumper extension does not currently validate that the host has enough available disc space for the memory dump. Although the dumper extension is free, the resulting memory dumps uploaded to LimaCharlie are subject to external logs pricing. This add-on relies on other paid resources (payloads) billed based on usage.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

---

### Related articles

* [Plaso](/docs/ext-plaso)
* [Sleeper Deployment](/docs/sleeper)

---

#### What's Next

* [Endpoint Protection](/docs/ext-epp)

Table of contents

Tags

* [add-ons](/docs/en/tags/add-ons)
* [dfir](/docs/en/tags/dfir)
* [extensions](/docs/en/tags/extensions)

---

## Endpoint Protection

# Endpoint Protection
## Overview

The Endpoint Protection (EPP) management in LimaCharlie enables users to view the status of existing EPP solutions (including Windows Free Defender), manage parameters of the deployment and unify alerting from the deployment at scale. This makes it perfect for teams wanting a unified view of the EPP solution, or service providers looking to offer Managed EPP to their customers at scale.

The only requirement is for the LimaCharlie agent to be deployed and the EPP Extension enabled (free).

Once deployed, EPP can be used natively along with the rest of LimaCharlie’s automation and routing capabilities.

## How it Works

LimaCharlie Endpoint Protection integrates with third-party EDR solutions to provide a better view of security operations and extend agent’s capabilities. Currently this extension applies to:

* Microsoft Windows Defender

The LimaCharlie agent communicates with Windows Defender to determine its status, transfer events, and trigger remediation commands. LimaCharlie Endpoint Protection codifies the best practices of collecting events and alerting on detections. When enabled, this extension creates a starter set of  rules. In addition to alerting, these rules can be customized to better align with the operational complexity of user’s environments. The LC Endpoint Protection extension provides a reliable and cost efficient way of securing endpoints at scale.

The Endpoint Protection add-on requires agent version `4.33.5` or higher.

## Enabling and configuring Endpoint Protection

To enable Endpoint Protection, first ensure LimaCharlie Endpoint Agent version is 4.33.5 and above, [update](/v2/docs/endpoint-agent-versioning-and-upgrades) if necessary.

Navigate to the [Endpoint Protection extension page](https://app.limacharlie.io/add-ons/extension-detail/ext-epp) in the Add-Ons marketplace. Choose the target Organization and select `Subscribe`.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(335).png)

Once subscribed, you can see the Endpoint Protection in the list of Extensions.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(332).png)

The Endpoint Protection extension does two things once both sync settings are enabled:

1. Creates an artifact collection rule named `defender-log-streaming`

   * This rule adds a WEL pattern that collects MS Defender logs, `wel://Microsoft-Windows-Windows Defender/Operational:*` so that LimaCharlie receives the events the Defender produces.

     > Note
     >
     > If you already have Defender logs coming in via the Artifact extension, you can uncheck the `Sync Extension Config` box to avoid duplicating entries.
2. Creates D&R rules

   * Generates several D&R rules that alert on various detections and actions taken by Defender.![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(291).png)
3. To apply the Artifact extension configuration and D&R rules, click `Apply Configuration`.

When the SYNC toggles are on, the collection rules and D&R rules are continuously synchronized with LimaCharlie library of best practices.

Once the extension is enabled, it also extends the Web UI with Endpoint Protection functionality, as described below.

## Using the Endpoint Protection extension

Endpoint Protection capabilities are used in three ways.

**Verify Protection**

Select a Windows Sensor in the organization. In the Sensor Overview, there is a new section, “Endpoint Protection” that shows the current protection status. Verify that Defender is listed as active on the sensor.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(333).png)

**Perform Scan**

Select a Windows Sensor.

Click on File System. Select the folder, and click on the scan icon  `Scan with EPP`

**Endpoint Protection Commands**

Select a Windows Sensor. Open the Sensor Console As you type “epp” you’ll see the available commands. Try `epp_status`  - it will return the status.

> Events required in Exfil config
>
> The EPP solution relies on some new events. They are now defaults, and the extension adds them to existing orgs. In rare case you may need to add them manually to Sensor / Event Collection / Event Collection or your Infra As Code. Here is the list:
>
> ```
> EPP_STATUS_REP,EPP_LIST_EXCLUSIONS_REP,EPP_ADD_EXCLUSION_REP,EPP_REM_EXCLUSION_REP,
> EPP_LIST_QUARANTINE_REP,EPP_SCAN_REP
> ```

For reference, this is a list of Endpoint Protection commands:

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(323).png)

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(325).png)![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(327).png)

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(329).png)![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(328).png)

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(330).png)

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Endpoint Detection & Response

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, Exfil (Event Collection) is a configuration extension that determines which types of events are collected and sent from endpoint agents to the cloud. It controls the data flow, ensuring only specified events are transmitted for monitoring and analysis. To capture specific events, they must be enabled within the Exfil or Event Collection settings.

In LimaCharlie, Exfil (Event Collection) is a configuration extension that determines which types of events are collected and sent from endpoint agents to the cloud. It controls the data flow, ensuring only specified events are transmitted for monitoring and analysis. To capture specific events, they must be enabled within the Exfil or Event Collection settings.

---

### What's Next

* [Exfil (Event Collection)](/docs/ext-exfil)

Table of contents

+ [Overview](#overview)
+ [How it Works](#how-it-works)
+ [Enabling and configuring Endpoint Protection](#enabling-and-configuring-endpoint-protection)
+ [Using the Endpoint Protection extension](#using-the-endpoint-protection-extension)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [defender](/docs/en/tags/defender)
* [epp](/docs/en/tags/epp)
* [extensions](/docs/en/tags/extensions)
* [platform](/docs/en/tags/platform)
* [windows](/docs/en/tags/windows)

---

## Exfil (Event Collection)

# Exfil (Event Collection)
The Exfil Extension helps manage which real-time [events](/v2/docs/reference-edr-events) get sent from EDR sensors to LimaCharlie. By default, LimaCharlie Sensors send events to the cloud based on a standard profile. This extension exposes those profiles for customization. The Exfil extension allows you to customize Event Collection from LimaCharlie Sensors, as well as mitigate sensors with high I/O or large [detection and response](/v2/docs/detection-and-response) rulesets.

> Event Collection Rule Synchronization
>
> Please note that Exfil (or Event Collection) rule configurations are synchronized with sensors every few minutes.

## Enabling the Exfil Extension

To enable the Exfil extension, navigate to the [Exfil extension page](https://app.limacharlie.io/add-ons/extension-detail/ext-exfil) in the marketplace. Select the Organization you wish to enable the extension for, and select **Subscribe**.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/exfil-1.png "image(231).png")

After clicking subscribe, the Exfil extension should be available almost immediately.

## Using the Exfil Extension

Once the extension is enabled, you will see an **Event Collection** option under **Sensors** in the LimaCharlie web UI.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/exfil-2.png "image(227).png")

There are three rule options within the Exfil extension:

* **Event Collection Rules** manage events sent by the Sensor to the LimaCharlie cloud.
* **Performance Rules** are useful for high I/O servers, but may impact event accuracy. This feature is available only on Windows Sensors.
* **Watch Rules** allow for conditional operators for an event, allowing you to specify a list of sensors to help manage high-volume events. Conditional operators for Watch Rule events include:

  + The **event** itself, such as `MODULE_LOAD`.
  + The **path** within the event component to be evaluated, such as `FILE_PATH`.
  + The **operator** to evaluate or compare that should be done between the path and the value.
  + The **value** to be used in comparison with the operator.

A sample **Watch Rule** might be

```
Event: MODULE_LOAD
Path: FILE_PATH
Operator: ends with
Value: wininet.dll
```

The above rule would configures the sensor(s) to send *only* `MODULE_LOAD` events where the `FILE_PATH` ends with the value `wininet.dll`.

> Performance Rules
>
> Performance rules, applied via tag to a set of Sensors, are useful for high I/O systems. These rules can be set via the web application or REST API.

### Throughput Limits

Enabling *every* event for Exfil can produce an exceedingly large amount of traffic. Our first recommendation would be to optimize events required for detection & response rules, in order to ensure that all rules are active. We’d also recommend prioritizing events that contribute to outputs, such as forwarded `DNS_REQUESTS`.

LimaCharlie attempts to process all events in real-time. However, if events fall behind, they are enqueued to a certain limit. If that limit is reached (e.g. in the case of a long, sustained burst or enabling *all* events at the same time), the queue may eventually get dropped. In that event, an error is emitted to the platform logs.

Seeing event collection errors is a sign you may need to do one of the following:

1. Reduce the population of events collected.
2. Reduce the number of  rules you run or rule complexity.
3. Adopt a selective subset of events by utilizing Watch Rules that only bring back events with specific values.
4. Enable the IR mode (below).

#### Afterburner

Before a backlogged queue is dropped, LimaCharlie attempts to increase performance by entering a special mode we call “afterburner.” This mode tries to address one of the common scenarios that can lead to a large influx of data: spammy processes starting over and over. This happens in situations such as the building of software, in which executables like `devenv.exe` or `git` can be called hundreds of times per second. The afterburner mode attempts to (1) de-duplicate those processes and (2) assess only each one through the D&R rules and Outputs.

#### IR Mode

The afterburner mode does not address all possible causes or situations. To help with this, LimaCharlie offers “IR mode.” This mode is enabled by tagging a LimaCharlie sensor with the tag `ir`. The goal of “IR mode” is to provide a solution for users who want to record a very large number of events, but do not need to run D&R rules over all of them. When enabled, “IR mode” will not de-duplicate events. Furthermore, D&R rules will *only* be run against the follow event types:

1. `CODE_IDENTITY`
2. `DNS_REQUEST`
3. `NETWORK_CONNECTIONS`
4. `NEW_PROCESS`

IR mode is designed to give a balance between recording all events, while maintaining basic D&R rule capabilities.

## Actions via REST API

The following REST API actions can be sent to interact with the Exfil extension:

**List Rules**

```json
{
  "action": "list_rules"
}
```

### Event Collection Rules

**Add Event Collection Rule**

```json
{
  "action": "add_event_rule",
  "name": "windows-vip",
  "events": [
    "NEW_TCP4_CONNECTION",
    "NEW_TCP6_CONNECTION"
  ],
  "tags": [
    "vip"
  ],
  "platforms": [
    "windows"
  ]
}
```

**Remove Event Collection Rule**

```json
{
  "action": "remove_event_rule",
  "name": "windows-vip"
}
```

### Watch Rules

**Add Watch Rule**

```json
{
  "action": "add_watch",
  "name": "wininet-loading",
  "event": "MODULE_LOAD",
  "operator": "ends with",
  "value": "wininet.dll",
  "path": [
    "FILE_PATH"
  ],
  "tags": [
    "server"
  ],
  "platforms": [
    "windows"
  ]
}
```

**Remove Watch Rule**

```json
{
  "action": "remove_watch",
  "name": "wininet-loading"
}
```

### Performance Rules

**Add Performance Rule**

```json
{
  "action": "add_perf_rule",
  "name": "sql-servers",
  "tags": [
    "sql"
  ],
  "platforms": [
    "windows"
  ]
}
```

**Remove Performance Rule**

```json
{
  "action": "remove_perf_rule",
  "name": "sql-servers"
}
```

In LimaCharlie, Exfil (Event Collection) is a configuration extension that determines which types of events are collected and sent from endpoint agents to the cloud. It controls the data flow, ensuring only specified events are transmitted for monitoring and analysis. To capture specific events, they must be enabled within the Exfil or Event Collection settings.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Endpoint Detection & Response

In LimaCharlie, Exfil (Event Collection) is a configuration extension that determines which types of events are collected and sent from endpoint agents to the cloud. It controls the data flow, ensuring only specified events are transmitted for monitoring and analysis. To capture specific events, they must be enabled within the Exfil or Event Collection settings.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

#### Related articles

* [Endpoint Agent Events Overview](/docs/endpoint-agent-events-overview)
* [Reference: EDR Events](/docs/reference-edr-events)
* [Endpoint Agent Commands](/docs/endpoint-agent-commands)
* [Ingesting Sysmon Event Logs](/docs/ingesting-sysmon-event-logs)
* [Ingesting Windows Event Logs](/docs/ingesting-windows-event-logs)

---

##### What's Next

* [Git Sync](/docs/ext-git-sync)

Table of contents

+ [Enabling the Exfil Extension](#enabling-the-exfil-extension)
+ [Using the Exfil Extension](#using-the-exfil-extension)
+ [Actions via REST API](#actions-via-rest-api)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Extensions

# Extensions
LimaCharlie Extensions provide a robust framework for enhancing and customizing the LimaCharlie Cloud's capabilities, enabling seamless integration with third-party tools, services, and custom logic. Extensions serve as modular components that expand LimaCharlie’s native functionality, allowing organizations to tailor their security environments to meet specific needs without being constrained by built-in features.

## Overview of Extensions

Extensions are defined at the global level across all LimaCharlie datacenters. This means that once an Extension is created, it is available for use in any Organization, provided that organization subscribes to it. Once subscribed, Extensions can interact with various components within the subscribing organization, whether through automated workflows or user-driven actions.

### Subscription and Permissions

To use an Extension, an organization must first subscribe to it. Upon subscription, the Extension is granted a set of predefined permissions that govern what actions it can perform within the organization. These permissions ensure that each Extension has controlled access to sensitive areas of the organization’s security infrastructure.

Some Extensions are also capable of "impersonating" the user or automation component that triggered them, which allows the Extension to perform actions as if it were the user itself. This feature is particularly useful for Extensions that need to execute actions in response to detection and response rules or other automated triggers, without needing separate user credentials.

### Types of Extensions: Public, Private, Labs

* **Private Extensions**: These are created by individual users (known as Owners) and are restricted for use only within the organizations where the Owner holds specific permissions, such as `billing.ctrl` and `user.ctrl`. Private Extensions are ideal for internal integrations or for extending capabilities within a limited scope, such as an organization’s specific infrastructure or toolset.
* **Public Extensions**: Public Extensions are available for subscription by any organization across the LimaCharlie platform. To make an Extension public, users first create it as private and, once fully developed and tested, they can submit it to LimaCharlie for approval. Once approved, the Extension becomes available for any organization to subscribe to. This process ensures that public Extensions are stable, secure, and beneficial to the broader community.
* **LimaCharlie Labs:** Labs extensions are capabilities that LimaCharlie is making available on the SecOps Cloud Platform in an preview state.

  > **Note:** Extensions with this label are expected to grow and change. The extension has been tested and is ready to be used by users, but some things such as a polished user interface may be missing or in prototype form.
  >
#### Related articles

* [LimaCharlie Extensions](/docs/lc-extensions)
* [Using Extensions](/docs/using-extensions)
* [Third-Party Extensions](/docs/third-party-extensions)

---

##### What's Next

* [Artifact](/docs/ext-artifact)

Table of contents

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Git Sync

# Git Sync
The Git Sync Extension is a tool that automates the management of Infrastructure-as-Code (IaC) configurations. It simplifies the process of deploying and managing infrastructure by synchronizing changes between a Git repository and target organizations.

**Key features:**

* **Centralized Configuration:** Stores all IaC configurations in a single Git repository.
* **Recurring Apply:** Can automatically sync IaC changes between Git and LC organizations at regular intervals.
* **Recurring Export:** Can automatically export IaC from LC organizations to GitHub at regular intervals.
* **Export Request:** Allows you to export the configuration of an Organization into the Git repository.
* **Automated Deployment:** Helps automate the deployment process, reducing manual effort.
* MSSP**-Friendly:** Designed to accommodate multiple organizations within a single repository, allowing for global configurations to be shared between orgs.
* **Flexible Configuration:** Allows for customization and additional configuration directories.
* **Transparent Operations:** Tracks operations through an extension Sensor.

By using `ext-git-sync`, you can streamline your IaC workflows, improve consistency, and reduce the risk of errors.

## Use Cases

### Sync FROM Git

If you have a properly structured git repository containing org configurations, the extension can sync the running org configurations with the contents of the configs in git.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/d2 (1).png "pull_config(1).png")

### Export TO Git

Assuming you have an empty git repository, you can configure the extension to export the current org configuration to the repository. It will be placed in an `exports` subdirectory.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/d2 (2).png "push_config(1).png")

## Git Repo Structure

For applying org configs from a git repository, the repo must adhere to the following structure. The root of the repository must contain an `orgs` directory with `[org-id]` child directories, each containing an `index.yaml` .

```
.
└── orgs [required]
    └── a326700d-3cd7-49d1-ad08-20b396d8549d [required]
        └── index.yaml [required]
```

The `index.yaml` determines which other files in the repo are included in the configuration for this org.

For instance, assume all of the configurations for this org were unique to this org and could be nested inside of the org’s directory.

```
.
└── orgs
    └── a326700d-3cd7-49d1-ad08-20b396d8549d
        ├── extensions.yaml
        ├── hives
        │   ├── cloud_sensor.yaml
        │   ├── dr-general.yaml
        │   ├── dr-managed.yaml
        │   ├── dr-service.yaml
        │   ├── extension_config.yaml
        │   ├── fp.yaml
        │   ├── lookup.yaml
        │   ├── query.yaml
        │   ├── secret.yaml
        │   └── yara.yaml
        ├── index.yaml
        ├── installation_keys.yaml
        ├── org_values.yaml
        ├── outputs.yaml
        └── resources.yaml
```

Notice that all configurations for this org are contained within the org’s own directory. In this case, the `index.yaml` would simply contain references to the relative path of this org’s configuration files. See below for an example of the contents of `index.yaml` for this use case.

```
version: 3
include:
    - extensions.yaml
    - hives/fp.yaml
    - outputs.yaml
    - resources.yaml
    - hives/query.yaml
    - hives/yara.yaml
    - hives/dr-managed.yaml
    - hives/lookup.yaml
    - hives/dr-service.yaml
    - org_values.yaml
    - installation_keys.yaml
    - hives/secret.yaml
    - hives/cloud_sensor.yaml
    - hives/dr-general.yaml
    - hives/extension_config.yaml
```

### Sharing configurations across multiple orgs

Now, assume you have a global rule set you want to apply across many orgs. You could structure the repo similar to the example below.

```
.
├── hives
│   ├── dr-general.yaml
│   └── yara.yaml
└── orgs
    ├── 7e41e07b-c44c-43a3-b78d-41f34204789d
    │   └── index.yaml
    ├── a326700d-3cd7-49d1-ad08-20b396d8549d
    │   └── index.yaml
    └── cb639126-e0bc-4563-a577-2e559c0610b2
        └── index.yaml
```

The corresponding `index.yaml` at each org level would look similar to the following

```
version: 3
include:
    - ../../hives/yara.yaml
    - ../../hives/dr-general.yaml
```

### Exporting configurations

Configuration exports will be placed in a separate `exports` subdirectory to avoid overwriting configurations that are pushed across multiple organizations.

```
.
└── exports
    └── orgs
        └── a326700d-3cd7-49d1-ad08-20b396d8549d
            ├── extensions.yaml
            ├── hives
            │   ├── cloud_sensor.yaml
            │   ├── dr-general.yaml
            │   ├── dr-managed.yaml
            │   ├── dr-service.yaml
            │   ├── extension_config.yaml
            │   ├── fp.yaml
            │   ├── lookup.yaml
            │   ├── query.yaml
            │   ├── secret.yaml
            │   └── yara.yaml
            ├── index.yaml
            ├── installation_keys.yaml
            ├── org_values.yaml
            ├── outputs.yaml
            └── resources.yaml
```

## Setting up Git Sync with Github

This guide walks you through the process of configuring Git synchronization between GitHub and LimaCharlie, allowing for automated deployment and version control of your security configurations.

### Step 0: Making a Git Sync specific SSH Key

* First create the directory

`mkdir -p ~/.ssh/gitsync`

* Set appropriate permissions for the directory

`chmod 700 ~/.ssh/gitsync`

* Now generate the SSH key

`ssh-keygen -t ed25519 -C "limacharlie-gitsync" -f ~/.ssh/gitsync/id_ed25519`

### Step 1: Generate GitHub Deploy Keys

1. Navigate to your GitHub repository
2. Click on the **Settings** tab
3. In the left sidebar, select **Deploy keys**
4. Click the **Add deploy key** button
5. Enter a descriptive title for your key (e.g., "LimaCharlie Git Sync Integration")
6. Paste your public SSH key into the "Key" field
7. **Important:** Check the box for **Allow write access**
8. Click **Add key** to save

### Step 2: Store SSH Private Key in LimaCharlie

1. Log in to your LimaCharlie account
2. Navigate to the **Secret Manager** section of your Organization
3. Click **Create New Secret**
4. Choose a descriptive name for your secret (e.g., "github-deploy-key")
5. Paste the **private** part of your SSH key into the value field
6. Save the secret

### Step 3: Configure Git Sync in LimaCharlie

1. Navigate to the **Git Sync** section in LimaCharlie
2. Under the **SSH Key** section, select **Secret Manager**
3. From the dropdown menu, select the secret you created in Step 2
4. Set the **user name** to `git`
5. Copy the SSH URL from your GitHub repository (found on the repository's main page, under Code)
6. Paste the SSH URL into the **repository** URL field in LimaCharlie
7. Configure the **branch** name (required)
8. Select the push and pull options which allow you to specify which items to push to or pull from Git configurations.
9. Optionally, select push and pull schedules if you wish to regularly sync or export your Infrastructure as Code configurations to and from LimaCharlie. This will create D&R rules on the backend that kick off the push and pull actions on the selected schedule/interval.
10. Click **save settings**.

### Step 4: Verify Integration

1. Perform a test commit to your GitHub repository by clicking “Push to Git” in the upper right corner.

2. Verify that your configuration has been pushed to Github.

### Troubleshooting

If you encounter synchronization issues:

* Verify that the deploy key has proper write permissions
* Ensure the correct SSH URL format is used (should begin with `git@github.com:`)
* Check that the private key in Secret Manager matches the public key added to GitHub

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Managed Security Services Provider

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

#### What's Next

* [Infrastructure](/docs/ext-infrastructure)

Table of contents

+ [Use Cases](#use-cases)
+ [Git Repo Structure](#git-repo-structure)
+ [Setting up Git Sync with Github](#setting-up-git-sync-with-github)

---

## GitHub

# GitHub
* 1 Minute to read

## What's Next

* [Google Cloud](/docs/ext-cloud-cli-google-cloud)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Google Cloud

# Google Cloud
* 1 Minute to read

## Related articles

* [Google Cloud Storage](/docs/outputs-destinations-google-cloud-storage)
* [Building Reports with BigQuery + Looker Studio](/docs/tutorials-reporting-building-reports-with-bigquery-looker-studio)
* [Google Cloud Pubsub](/docs/outputs-destinations-google-cloud-pubsub)
* [Google Cloud BigQuery](/docs/outputs-destinations-google-cloud-bigquery)
* [Google Workspace](/docs/adapter-types-google-workspace)
* [Google Cloud Storage](/docs/adapter-types-google-cloud-storage)
* [Google Cloud Pubsub](/docs/adapter-types-google-cloud-pubsub)
* [Tutorial: Ingesting Google Cloud Logs](/docs/tutorial-ingesting-google-cloud-logs)

---

### What's Next

* [Microsoft 365](/docs/ext-cloud-cli-microsoft365)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)
* [gcp](/docs/en/tags/gcp)

---

## Govee

# Govee
The Govee Extension allows you to trigger color changes on your [supported Govee lights](https://developer.govee.com/docs/support-product-model) via a  rule response action. It requires you to configure a Govee API key in the extension.

## Setup

1. Request an API key from Govee by following their instructions [here](https://developer.govee.com/reference/apply-you-govee-api-key)
2. Get the Device ID (device) and model (sku) of the device you'd like to target by requesting a list of your supported devices from the Govee API:

```bash
curl --location 'https://openapi.api.govee.com/router/api/v1/user/devices' --header 'Govee-API-Key: YOUR_GOVEE_API_KEY'
```

3. Decide what RGB color(s) you want to use. By default, the extension will alert with red (`255,0,0`), and revert back to white (`255,255,255`) when the alert `duration` has ended.
4. Add your Govee API key to the extension configuration:
    ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/govee.png)

### Usage

When enabled, you may configure the response of a D&R rule to trigger a Govee event. Consider the following example response rule:

```
- action: extension request
  extension action: run
  extension name: ext-govee
  extension request:
    device_id: '{{ "YOUR_GOVEE_DEVICE" }}'
    device_model: '{{ "YOUR_GOVEE_DEVICE_SKU" }}'
    alert_color: '{{ "255,0,0" }}'
    alert_brightness: '{{ "100" }}'
    revert_color: '{{ "255,255,255" }}'
    revert_brightness: '{{ "10" }}'
    duration: '{{ "30" }}'
  suppression:
    is_global: true
    keys:
      - Govee
    max_count: 1
    period: 1m
```

Note that the only required fields here are the `device_id` and `device_model`. Values supplied in the example are the defaults.

#### Parameters

**Required parameters:**

* `device_id`: returned via the Govee API, see example response below
* `device_model`: returned via the Govee API, see example response below

**Optional parameters:**

* `alert_color`: color of the light when alert fires, in [RGB format](https://htmlcolorcodes.com/color-picker/), default `255,0,0` (red)
* `revert_color`: color of the light to return to, after alert fires, in [RGB format](https://htmlcolorcodes.com/color-picker/), default `255,255,255` (white)
* `alert_brightness`: brightness of the light, default `100`
* `revert_brightness`: brightness of the light to return to, after alert fires, default `10`
* `duration`: duration of the alert in seconds, how long the light will remain at `alert_color` before returning to `revert_color`, default `30`

**Govee API sample request and response:**

```bash
curl --location 'https://openapi.api.govee.com/router/api/v1/user/devices' --header 'Govee-API-Key: YOUR_GOVEE_API_KEY'
```

```json
{
    "code": 200,
    "message": "success",
    "data": [
        {
            "sku": "H6008",                           # use in `device_model` parameter
            "device": "AA:BB:00:11:22:33:44:55",      # use in `device_id` parameter
###### What's Next

* [Hayabusa](/docs/ext-hayabusa)

Table of contents

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Hayabusa

# Hayabusa
Hayabusa Extension Pricing

While it is free to enable the Hayabusa extension, pricing is applied to downloaded and processed artifacts -- $0.02/GB for the original artifact, and $0.5/GB for the generation of the Hayabusa artifact.

The [Hayabusa](https://github.com/Yamato-Security/hayabusa) extension allows you to run Hayabusa against a specified event log (.evtx) or a collection of event logs (.zip).

Hayabusa is a Windows event log fast forensics timeline generator and threat hunting tool created by the Yamato Security group in Japan.

LimaCharlie will automatically kick off the analysis based off of the artifact ID provided in a  rule action, or you can run it manually via the extension.

## Configuration

When enabled, you may configure the response of a D&R rule to run a Hayabusa analysis against an artifact event. Consider the following example D&R rule:

**Detect:**

```
event: ingest
op: exists
path: /
target: artifact_event
artifact type: wel
```

**Respond:**

```
- action: extension request
  extension action: generate
  extension name: ext-hayabusa
  extension request:
       artifact_id: '{{ .routing.log_id }}'
       send_to_timeline: true
       profile: '{{ "timesketch-verbose" }}'
       min_rule_level: '{{ "informational" }}'
```

Note that the only required field here is the `artifact_id`. The other values supplied in the example are the defaults.

### Results

```
hayabusa update-rules

hayabusa csv-timeline -f /path/to/your/artifact --RFC-3339 -p timesketch-$profile --min-level $min_rule_level --no-wizard --quiet -o $artifact_id.csv -U
```

Upon running Hayabusa, a CSV file is generated. The CSV file will be uploaded as a LimaCharlie artifact.

The resulting CSV is compatible with Timesketch, and can be imported [as a timeline](https://timesketch.org/guides/user/upload-data/).

Outputting your data to Google BigQuery is another option, and is [outlined here](/v2/docs/hayabusa-to-bigquery)

Several events will be pushed to the `ext-hayabusa` Sensor timeline:

* `hayabusa_results`: contains the results summary from the Hayabusa output
* `hayabusa_artifact`: contains the `artifact_id` of the CSV file that was uploaded to LimaCharlie
* `hayabusa_event`: many of these will be sent to the timeline if you check the checkbox or parameter for `Send to timeline`, and it contains the raw contents of the Hayabusa CSV output in JSON format

### Arguments

* `artifact_id`: ID of the LimaCharlie artifact to process
* `profile`: either `minimal`, `standard`, `verbose`, `all-field-info`, `all-field-info-verbose`, `super-verbose`, `timesketch-minimal`, or `timesketch-verbose`

  + Default: `timesketch-verbose`
  + [More details](https://github.com/Yamato-Security/hayabusa?tab=readme-ov-file#7-timesketch-minimal-profile-output)
* `min_rule_level`: `informational`, `low`, `medium`, `high`, or `critical`, [more details](https://github.com/Yamato-Security/hayabusa?tab=readme-ov-file#dfir-timeline-commands-1)

  + Default: `informational`
* `send_to_timeline`: whether or not to ingest the Hayabusa results into the sensor timeline as events, boolean, default `true`

### Usage

If you use the LimaCharlie Velociraptor extension, a good use case of this extension would be to trigger Hayabusa analysis upon ingestion of a Velociraptor KAPE files artifact.

Go to Extensions / Velociraptor, and run Collect Artifact request.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/hayabusa-1.png)

Kick off a `Windows.KapeFiles.Targets` artifact collection in the LimaCharlie Velociraptor extension

**Argument options:**

* `EventLogs=Y`
   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/hayabusa-2.png)
* `KapeTriage=Y` - this is an option, however the extension will first take all .evtx files out of the triage collection and send them through Hayabusa, and ignore the rest, so there is more overhead involved, versus just using `EventLogs=Y`.

Configure a D&R rule to look for these events upon ingestion, and then trigger the Hayabusa extension:

**Detect:**

```
op: and
target: artifact_event
rules:
    - op: is
      path: routing/log_type
      value: velociraptor
    - op: is
      not: true
      path: routing/event_type
      value: export_complete
```

**Respond:**

```
- action: extension request
  extension action: generate
  extension name: ext-hayabusa
  extension request:
      artifact_id: '{{ .routing.log_id }}'
      send_to_timeline: true    # `false` if you only want the CSV artifact
```

### Generate LC Detections from Hayabusa Output

Note

This capability depends on setting the parameter to send Hayabusa output to the sensor timeline with `send_to_timeline: true`

Assuming you want Hayabusa detections of a certain `Level` or severity sent directly to your LimaCharlie detections stream, you can use the following D&R rule to accomplish this:

**Detect:**

```
event: hayabusa_event
op: and
rules:
  - op: is
    path: routing/hostname
    value: ext-hayabusa
  - op: matches
    path: event/results/Level
    re: (med|high|crit)
```

**Respond:**

```
- action: report
  name: >-
    Hayabusa - {{ .event.results.Level }} - {{ .event.results.message }}
```

The resulting detection would look something like this:

```json
{
  "action": "report",
  "data": {
    "cat": "Hayabusa - med - Failed Logon From Public IP",
    "detect": {
      "event": {
        "artifact_id": "eb39c3b4-6312-41c8-8b6e-e0b46b2f870e",
        "artifact_type": "evtx",
        "event": "hayabusa_event",
        "job_id": "2e904fda-6d3f-4ce1-bf82-ede97f3c0d17",
        "results": {
          "Channel": "Sec",
          "Computer": "windows-server-2022-01304add-3354-4cca-b574-b0a54d7bb6f4-0",
          "Details": "Type: 3 - NETWORK ¦ TgtUser: 4cca ¦ SrcComp: WIN-S2Q2306JU66 ¦ SrcIP: 185.161.248.147 ¦ AuthPkg: NTLM ¦ Proc: -",
          "EventID": "4625",
          "EvtxFile": "/tmp/triage_1078055872.evtx",
          "ExtraFieldInfo": "FailureReason: BAD USER OR PW ¦ IpPort: 0 ¦ KeyLength: 0 ¦ LogonProcessName: NtLmSsp ¦ ProcessId: 0 ¦ Status: BAD USER OR PW ¦ SubStatus: UNKNOWN USER ¦ SubjectLogonId: 0x0 ¦ SubjectUserSid: S-1-0-0 ¦ TargetDomainName: windows-server-2022-01304add-3354-4cca-b574-b0a54d7bb6f4-0 ¦ TargetUserSid: S-1-0-0",
          "Level": "med",
          "MitreTactics": "InitAccess ¦ Persis",
          "MitreTags": "T1078 ¦ T1190 ¦ T1133",
          "OtherTags": "",
          "RecordID": "681128",
          "RuleFile": "win_security_susp_failed_logon_source.yml",
          "datetime": "2024-03-20 21:50:55.930385+00:00",
          "message": "Failed Logon From Public IP",
          "timestamp_desc": "hayabusa"
        }
      },
      "routing": {
        "arch": 9,
        "did": "",
        "event_id": "0a6989a1-af71-4583-a8bc-e766bd2a81d8",
        "event_time": 1711071722721,
        "event_type": "hayabusa_event",
        "ext_ip": "internal",
        "hostname": "ext-hayabusa",
        "iid": "bfac2d1f-5d8c-4115-9df2-633a4f1d062b",
        "int_ip": "",
        "moduleid": 6,
        "oid": "01304add-3354-4cca-b574-b0a54d7bb6f4",
        "plat": 2415919104,
        "sid": "3109b3c7-c5ca-4029-b493-4d4e6766c4d3",
        "tags": [
          "ext:ext-hayabusa",
          "lc:system"
        ],
        "this": "76088a58bb99484c82cf9e9065fce1ea"
      },
      "ts": "2024-03-22 01:42:02"
    },
    "detect_id": "90609b8b-c2b8-4537-b17e-5d1665fd8717",
    "gen_time": 1711114007077,
    "link": "https://app.limacharlie.io/orgs/01304add-3354-4cca-b574-b0a54d7bb6f4/sensors/3109b3c7-c5ca-4029-b493-4d4e6766c4d3/timeline?time=1711071722&selected=76088a58bb99484c82cf9e9065fce1ea",
    "mtd": null,
    "routing": {
      "arch": 9,
      "did": "",
      "event_id": "0a6989a1-af71-4583-a8bc-e766bd2a81d8",
      "event_time": 1711071722721,
      "event_type": "hayabusa_event",
      "ext_ip": "internal",
      "hostname": "ext-hayabusa",
      "iid": "bfac2d1f-5d8c-4115-9df2-633a4f1d062b",
      "int_ip": "",
      "moduleid": 6,
      "oid": "01304add-3354-4cca-b574-b0a54d7bb6f4",
      "plat": 2415919104,
      "sid": "3109b3c7-c5ca-4029-b493-4d4e6766c4d3",
      "tags": [
        "ext:ext-hayabusa",
        "lc:system"
      ],
      "this": "76088a58bb99484c82cf9e9065fce1ea"
    },
    "source": "01304add-3354-4cca-b574-b0a54d7bb6f4.bfac2d1f-5d8c-4115-9df2-633a4f1d062b.3109b3c7-c5ca-4029-b493-4d4e6766c4d3.90000000.9",
    "source_rule": "replay-rule"
  }
}
```

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

#### Related articles

* [Hayabusa to BigQuery](/docs/hayabusa-to-bigquery)
* [Windows Event Log](/docs/adapter-types-windows-event-log)
* [Windows Event Logs](/docs/adapter-examples-windows-event-logs)
* [Ingesting Sysmon Event Logs](/docs/ingesting-sysmon-event-logs)
* [Ingesting Windows Event Logs](/docs/ingesting-windows-event-logs)
* [EVTX](/docs/adapter-types-evtx)

---

##### What's Next

* [NIMS](/docs/ext-nims)

Table of contents

Tags

* [add-ons](/docs/en/tags/add-ons)
* [dfir](/docs/en/tags/dfir)
* [extensions](/docs/en/tags/extensions)

---

## Infrastructure

# Infrastructure
The Infrastructure Extension allows you to perform infrastructure-as-code (IaC) modifications to your Organization. IaC modifications can be made in the web UI or via the LimaCharlie [CLI tool](https://github.com/refractionPOINT/python-limacharlie/#configs-1). Users can create new organizations from known templates or maintain a common configuration across multiple organizations.

> Scaling Organization Management
>
> If you’re an managed service company or need to manage a large number of Organizations, consider LimaCharlie’s MSSP setup. You can find more information about this [here](https://github.com/refractionPOINT/mssp-demo).

## Enabling the Infrastructure Extension

To enable the Infrastructure extension, navigate to the [Infrastructure extension page](https://app.limacharlie.io/add-ons/extension-detail/ext-infrastructure) in the marketplace. Select the organization you wish to enable the extension for, and select **Subscribe**.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/infra-1.png "image(234).png")

After clicking **Subscribe**, the Infrastructure extension should be available almost immediately.

> Where to start?
>
> IaC can be a powerful tool for rapidly deploying and managing Organizations within LimaCharlie. To help you discover more possibilities, we have provided several example templates/configurations [here](https://github.com/refractionPOINT/templates).

## Using the Infrastructure Extension

Once enabled, you will see an Infrastructure as Code option under the **Organization Settings** within the LimaCharlie web UI. The extension also becomes available via the REST API.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/infra-2.png "image(240).png")

Within the Infrastructure As Code module, you can:

* **Apply a New Config** to an existing organization. Changes are made additively, and are good for merging new configuration parameters into your organization.
* **Edit the Entire Configuration** for an existing organization. This is your current configuration, and can be modified directly in the web UI.
* Perform **Fetch**, **Push**, or **Push-from-file** operations.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/infra-3.png "image(241).png")

## Actions via REST API

The REST interface for the Infrastructure extension mimics the CLI tool. The following REST API actions can be sent to interact with the Infrastructure extension:

```json
{
  "params": {
    "sync_artifacts": {
      "type": "bool",
      "desc": "applies to artifacts"
    },
    "is_force": {
      "type": "bool",
      "desc": "make the org an exact copy of the configuration provided."
    },
    "is_dry_run": {
      "type": "bool",
      "desc": "do not apply config, just simulate."
    },
    "sync_integrity": {
      "type": "bool",
      "desc": "applies to integrity"
    },
    "action": {
      "is_required": true,
      "values": [
        "push",
        "fetch"
      ],
      "type": "enum",
      "desc": "action to take."
    },
    "sync_org_values": {
      "type": "bool",
      "desc": "applies to org_values"
    },
    "sync_resources": {
      "type": "bool",
      "desc": "applies to resources"
    },
    "config": {
      "type": "str",
      "desc": "configuration to apply."
    },
    "config_source": {
      "type": "str",
      "desc": "ARL where configs to apply are located."
    },
    "ignore_inaccessible": {
      "desc": "ignore resources which are inaccessible like locked or segmented.",
      "type": "bool"
    },
    "sync_fp": {
      "type": "bool",
      "desc": "applies to fp"
    },
    "sync_exfil": {
      "desc": "applies to exfil",
      "type": "bool"
    },
    "sync_dr": {
      "type": "bool",
      "desc": "applies to dr"
    },
    "sync_outputs": {
      "type": "bool",
      "desc": "applies to outputs"
    },
    "config_root": {
      "type": "str",
      "desc": "file name of the root config within config_source to apply."
    }
  }
}
```

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Managed Security Services Provider

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

Command-line Interface

---

### Related articles

* [Infrastructure as Code](/docs/infrastructure-as-code)

---

#### What's Next

* [Integrity](/docs/ext-integrity)

Table of contents

+ [Enabling the Infrastructure Extension](#enabling-the-infrastructure-extension)
+ [Using the Infrastructure Extension](#using-the-infrastructure-extension)
+ [Actions via REST API](#actions-via-rest-api)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)
* [platform](/docs/en/tags/platform)

---

## Integrity

# Integrity
The Integrity Extension helps you manage all aspects of file or registry integrity monitoring (FIM and RIM, respectively). This extension automates integrity checks of file system and registry values through pattern-based rules.

## Enabling the Integrity Extension

To enable the Integrity extension, navigate to the [Integrity extension page](https://app.limacharlie.io/add-ons/extension-detail/ext-integrity) in the marketplace. Select the Organization you wish to enable the extension for, and select **Subscribe**.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/integrity-1(1).png "image(242).png")

After clicking **Subscribe**, the Infrastructure extension should be available almost immediately.

## Using the Integrity Extension

Once enabled, you will see an **File/Reg Integrity** option under **Automation** within the LimaCharlie web UI.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/integrity-2.png "image(243).png")

Selecting this option allows you to customize **File & Registry Integrity Monitoring** rules, as seen in the screenshot below.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/integrity-3.png "image(244).png")

Selecting **Add Monitoring Rule** will allow you to create a FIM or RIM rule, specifying a platform, Tag(s), and pattern(s).

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/integrity-4.png "image(245).png")

### Rule Patterns

Patterns are file or registry patterns and support wildcards (\*, ?, +). Windows directory separators (backslash, `”\”`) must be escape with a double-slash `”\\”`.

When a FIM or RIM rule is tripped, you will see a `FIM_HIT` event in the Sensor(s) timeline.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/integrity-5.png)

### Example Rule Patterns

#### Windows **File Monitoring**

| **Monitor a specific directory on all drives** | **Monitor a specific file on a specific drive** |
| --- | --- |
| ?:\\Windows\\System32\\drivers | C:\\Windows\\System32\\specialfile.exe |
| ?:\\inetpub\\wwwroot |  |

#### Windows Registry Monitoring

> All registry monitoring patterns MUST begin with **\\REGISTRY**, followed by the hive and then the path or value to monitor.

| Monitor for changes to system Run and RunOnce | Monitor all users for additions to a user’s Run |
| --- | --- |
| \\REGISTRY\\MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\* | \\REGISTRY\\USER\S-\*\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\* |
| \\REGISTRY\\MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce\* |  |

#### Linux

| **Monitor for changes to root’s authorized\_keys** | **Monitor for changes to all user private ssh directories** |
| --- | --- |
| /root/.ssh/authorized\_keys | /home/\*/.ssh/\* |

#### macOS

| Monitor for changes to user keychains | Monitor for changes to system keychains |
| --- | --- |
| /Users/\*/Library/Keychains/\* | /Library/Keychains |

### Linux Support

FIM is supported on Linux systems, however, support may vary based on Linux distribution and software.

#### Linux with eBPF Support

Linux hosts capable of running with [eBPF](https://ebpf.io/) have file notification and FIM capabilities on par with Windows and macOS.

#### Legacy Support

FIM is partially supported on systems without eBPF. Specified file expressions are actively monitored via `inotify` (as opposed to macOS and Windows, which utilize passive kernel monitoring). Due to [inotify](https://man7.org/linux/man-pages/man7/inotify.7.html) limitations, paths with wildcards are less efficient and only support monitoring up to 20 sub-directories covered by the wildcard. In addition to this, the path expressions should specify a final wildcard of *when all files under a directory need to be monitored. Omitting the final* `*` will result in only the top-level directory being monitoring.

## Actions via REST API

The following REST API actions can be sent to interact with the Integrity extension:

**List Rules**

```json
{
  "action": "list_rules"
}
```

**Add Rule**

```json
{
  "action": "add_rule",
  "name": "linux-root-ssh-configs",
  "patterns": [
    "/root/.ssh/*"
  ],
  "tags": [
    "vip",
    "workstation"
  ],
  "platforms": [
    "linux"
  ]
}
```

**Remove Rule**

```json
{
  "action": "remove_rule",
  "name": "linux-ssh-configs"
}
```

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

### Related articles

* [Reference: Endpoint Agent Commands](/docs/reference-endpoint-agent-commands)
* [Detection and Response Examples](/docs/detection-and-response-examples)

---

#### What's Next

* [Lookup Manager](/docs/ext-lookup-manager)

Table of contents

+ [Enabling the Integrity Extension](#enabling-the-integrity-extension)
+ [Using the Integrity Extension](#using-the-integrity-extension)
+ [Actions via REST API](#actions-via-rest-api)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## LimaCharlie Extensions

# LimaCharlie Extensions
15 Articles  in this category

---

## Lookup Manager

# Lookup Manager
The Lookup Manager Extension allows you to create, maintain & automatically refresh lookups in the Organization to then reference them in Detection & Response Rules.

The saved Lookup Configurations can be managed across tenants using Infrastructure as Code extension. To manage lookup versions across all of your tenants, update the file under the original Authenticated Resource Locator.

Every 24 hours, LimaCharlie will sync all of the lookups in the configuration. Lookups can also be manually synced by clicking the `Manual Sync` button on the extension page. When a lookup configuration is added, it will **not** be automatically synced immediately, unless you click on `Manual Sync`.

Lookup sources can be either direct links (URLs) to a given lookup or [ARLs](/v2/docs/reference-authentication-resource-locator).

Example JSON lookup: [link](https://loldrivers.io/api/drivers.json)

## Usage

### Option 1: Preconfigured Lookups![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(279).png "image(266).png")

LimaCharlie provides a curated list of several publicly available JSON lookups for use within your organization. These are provided in the lookup manager GUI.

More details and the contents of each of these lookups can be found [here](https://github.com/refractionpoint/lc-public-lookups).

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image (1).png "Screenshot 2024-10-22 at 13.23.35(2).png")

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image (2).png "Screenshot 2024-10-22 at 13.23.45(1).png")

### Option 2: Publicly available Lookups

Giving the lookup configuration a name, the URL *or* [ARL](/v2/docs/reference-authentication-resource-locator), and clicking the Save button will create the new lookup source to sync to your lookups.

`[github,my-org/my-repo-name/path/to/lookup]`

### Option 3: Private Lookup Repository

To use a lookup from a private Github repository you will need to make use of an [Authentication Resource Locator](/v2/docs/reference-authentication-resource-locator).

**Step 1: Create a token in GitHub**
In GitHub go to *Settings* and click *Developer settings* in the left hand side bar.

Next click *Personal access token* followed by *Generate new token*. Select repo permissions and finally *Generate token*.

**Step 2: Connect LimaCharlie to your GitHub Repository**
Inside of LimaCharlie, click on *Lookup Manager* in the left hand menu. Then click *Add New Lookup Configuration*.

Give your lookup a name and then use the token you generated with the following format linked to your repository.

`[github,my-org/my-repo-name/path/to/lookup,token,bfuihferhf8erh7ubhfey7g3y4bfurbfhrb]`

## Infrastructure as Code

Example:

```
hives:
    extension_config:
        ext-lookup-manager:
            data:
                lookup_manager_rules:
                    - arl: ""
                      format: json
                      name: alienvault
                      predefined: '[https,storage.googleapis.com/lc-lookups-bucket/alienvault-ip-reputation.json]'
                      tags:
                        - alienvault
                    - arl: ""
                      format: json
                      name: tor
                      predefined: '[https,storage.googleapis.com/lc-lookups-bucket/tor-ips.json]'
                      tags:
                        - tor
            usr_mtd:
                enabled: true
                expiry: 0
                tags: []
                comment: ""
```

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

### Related articles

* [Create a D&R Rule Using a Threat Feed](/docs/create-a-dr-rule-using-a-threat-feed)
* [Lookups](/docs/lookups)

---

#### What's Next

* [Payload Manager](/docs/payload-manager)

Table of contents

+ [Usage](#usage)
+ [Infrastructure as Code](#infrastructure-as-code)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)
* [lookups](/docs/en/tags/lookups)

---

## Microsoft 365

# Microsoft 365
* 1 Minute to read

## Related articles

* [Microsoft 365](/docs/adapter-types-microsoft-365)

---

### What's Next

* [Okta](/docs/ext-cloud-cli-okta)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [azure](/docs/en/tags/azure)
* [extensions](/docs/en/tags/extensions)
* [m365](/docs/en/tags/m365)

---

## NIMS

# NIMS
Notion Incident Management System (NIMS) helps SOC/IR teams streamline their incident collaboration. While not a replacement for advanced SIEM or SOAR case management systems, it offers a practical alternative for teams that don't have access to these tools.

The Notion template uses interconnected relational databases to enable effective incident tracking and case management.

The LimaCharlie NIMS extension allows you to send detections from LimaCharlie to NIMS via the Notion API.

Once you subscribe an org to the extension, it creates a D&R rule that sends all detections from your org to your NIMS alert database. Because Notion databases do have a limit on the number of records, the extension also has the ability to purge old alerts that are 1) not associated with any incidents, and 2) older than the specified number of days. A D&R rule is also created to perform this cleanup automatically (or not) based on your configuration.

More information about NIMS, including the template and corresponding docs, can be found [here](https://nims-template.notion.site/).

## Configuration

In order to use this extension, you will need 3 pieces of data:

* Notion authentication token
* NIMS Alert database ID
* NIMS Asset database ID

### Find your database IDs

1. Navigate to the Alert database within NIMS under `Databases`
2. Right click on the database and click `Copy link`[![link](https://github.com/shortstack/nims-webhook/raw/main/screenshots/link.png)](https://github.com/shortstack/nims-webhook/blob/main/screenshots/link.png)
3. Locate the database ID in the URL

   * The database ID is the long string of letters and numbers in the URL after the last `/` and before the `?` or `#` if present
   * Example:

     + Link: `https://www.notion.so/184cdc5a1ef3710badc2d2b1271aeb81?v=174cdc3a1ef181719981000cab12bf54&pvs=4`
     + ID: `184cdc5a1ef3710badc2d2b1271aeb81`
4. Copy the ID
5. Repeat the above for the Asset database

#### Generate an auth token

This will walk you through creating a Notion integration, getting the auth token, and adding the integration to the proper NIMS databases.

While completing the following steps, be sure to add the connection to all 3 databases—Alert, Asset, and Incident. Incident is only necessary in order to perform the alerts cleanup to see whether or not the alert is tied to an incident.

1. Go to `Manage connections` in Notion [![connection](https://github.com/shortstack/nims-webhook/raw/main/screenshots/connection.png)](https://github.com/shortstack/nims-webhook/blob/main/screenshots/connection.png)
2. Click `Develop or manage integrations`[![connection](https://github.com/shortstack/nims-webhook/raw/main/screenshots/manage.png)](https://github.com/shortstack/nims-webhook/blob/main/screenshots/manage.png)
3. Click `New integration`[![connection](https://github.com/shortstack/nims-webhook/raw/main/screenshots/new.png)](https://github.com/shortstack/nims-webhook/blob/main/screenshots/new.png)
4. Configure the new integration

   * Give it a name, ex: `nims_template`
   * Choose the workspace
   * Type: `Internal`
   * Click `Save` [![connection](https://github.com/shortstack/nims-webhook/raw/main/screenshots/integration.png)](https://github.com/shortstack/nims-webhook/blob/main/screenshots/integration.png)
5. Click `Configure integration settings` [![connection](https://github.com/shortstack/nims-webhook/raw/main/screenshots/configure.png)](https://github.com/shortstack/nims-webhook/blob/main/screenshots/configure.png)
6. Copy the `Internal Integration Secret`-- this is your auth token

   * Click `Save` [![connection](https://github.com/shortstack/nims-webhook/raw/main/screenshots/token.png)](https://github.com/shortstack/nims-webhook/blob/main/screenshots/token.png)
7. Navigate to your `Alert Database`

   * Click the 3-dot menu and find `Connections`
   * Click on your newly created integration [![connection](https://github.com/shortstack/nims-webhook/raw/main/screenshots/alerts.png)](https://github.com/shortstack/nims-webhook/blob/main/screenshots/alerts.png)
8. Click `Confirm`
   [![connection](https://github.com/shortstack/nims-webhook/raw/main/screenshots/confirm.png)](https://github.com/shortstack/nims-webhook/blob/main/screenshots/confirm.png)
9. Repeat steps 7 and 8 for the `Asset Database` and the `Incident Database`

### Example D&R rule

**Detect:**

```
op: exists
path: cat
target: detection
```

**Respond:**

```
- action: extension request
  extension action: push_detections
  extension name: ext-nims
  extension request:
    cat: '{{ .cat }}'
    detection: '{{json .detect }}'
    event_time: '{{ .routing.event_time }}'
    hostname: '{{ .routing.hostname }}'
    int_ip: '{{ .routing.int_ip }}'
    link: '{{ .link }}'
    metadata: '{{json .detect_mtd }}'
```

---

#### What's Next

* [OTX](/docs/ext-otx)

Table of contents

---

## OTX

# OTX
AlienVault’s Open Threat Exchange (OTX) is the “neighborhood watch of the global intelligence community.” It enables private companies, independent security researchers, and government agencies to openly collaborate and share the latest information about emerging threats, attack methods, and malicious actors, promoting greater security across the entire community.

More information about OTX can be found [here](https://otx.alienvault.com/).

## Enabling the OTX Extension

Before utilizing the OTX extension, you will need an AlienVault OTX API Key. This can be found in your AlienVault OTX account [here](https://otx.alienvault.com/).

To enable the OTX extension, navigate to the [OTX extension page](https://app.limacharlie.io/add-ons/extension-detail/ext-otx). Select the Organization you wish to enable the extension for, and select **Subscribe**.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(236).png "image(236).png")

Once the extension is enabled, navigate to Extensions > OTX. You will need to provide your OTX API Key, which can be done directly in the form or via LimaCharlie’s [Secrets Manager](/v2/docs/config-hive-secrets). Click Save.

Pulses will be synced to rules and lookups automatically every 3 hours.

## Using the OTX Extension

After providing a valid API key, the Extension will automatically create [Detection & Response rules](/v2/docs/detection-and-response) for your organization. The OTX  rules make use of the following events:

* Process Events

  + [CODE\_IDENTITY](/v2/docs/reference-edr-events#codeidentity)
  + [EXISTING\_PROCESS](/v2/docs/reference-edr-events#existingprocess)
  + [MEM\_HANDLES\_REP](/v2/docs/reference-edr-events#memhandlesrep) (response to the [mem\_handles](/v2/docs/endpoint-agent-commands#memhandles) Sensor command)
  + [NEW\_PROCESS](/v2/docs/reference-edr-events#newprocess)
* Network Events

  + [DNS\_REQUEST](/v2/docs/reference-edr-events#dnsrequest)
  + [HTTP\_REQUEST](/v2/docs/reference-edr-events#httprequest)
  + [NETWORK\_CONNECTIONS](/v2/docs/reference-edr-events#networkconnections)
  + [NEW\_TCP4\_CONNECTION](/v2/docs/reference-edr-events#newtcp4connection)
  + [NEW\_TCP6\_CONNECTION](/v2/docs/reference-edr-events#newtcp6connection)
  + [NEW\_UDP4\_CONNECTION](/v2/docs/reference-edr-events#newudp4connection)
  + [NEW\_UDP6\_CONNECTION](/v2/docs/reference-edr-events#newudp6connection)

Please ensure that the events you are interested in using with OTX lookups are enabled in the **Sensors >** Event Collection menu.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, Exfil (Event Collection) is a configuration extension that determines which types of events are collected and sent from endpoint agents to the cloud. It controls the data flow, ensuring only specified events are transmitted for monitoring and analysis. To capture specific events, they must be enabled within the Exfil or Event Collection settings.

---

### What's Next

* [PagerDuty](/docs/ext-pagerduty)

Table of contents

+ [Enabling the OTX {{glossary.Extension}}](#enabling-the-otx-{{glossary-extension}})
+ [Using the OTX Extension](#using-the-otx-extension)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Okta

# Okta
The Okta CLI allows you to interact with your Okta instance(s) via the command line. With this component of the Cloud CLI Extension, you can interact with Okta directly from LimaCharlie.

This extension makes use of the Okta CLI, which can be found [here](https://cli.okta.com/manual/).

## Example

The following example returns a list of registered Okta applications.

```
- action: extension request
  extension action: run
  extension name: ext-cloud-cli
  extension request:
    cloud: '{{ "okta" }}'
    command_line: '{{ "apps" }}'
    credentials: '{{ "hive://secret/secret-name" }}'
```

## Credentials

To make use of the Okta CLI, you will need:

* An API key. More information about provisioning an API key can be found [here](https://developer.okta.com/docs/guides/create-an-api-token/main/).
* Create a secret in the secrets manager in the following format:

```
okta_domain/api_key
```

## Available Commands

> All “USERID” fields require the Okta User ID, not the user’s name

### Get User Details

Fetches a user from your Okta organization.

#### Command

```
user get USERID
```

#### Example Input

```
user get 00untroxqpl08VcNC5d7
```

#### Example Output

```json
{
  "_links": {
    "deactivate": {
      "href": "https://dev-8675309.okta.com/api/v1/users/00up0nl0lftw7331WSz/lifecycle/deactivate",
      "method": "POST"
    },
    "schema": {
      "href": "https://dev-8675309.okta.com/api/v1/meta/schemas/user/otyn3jlrawrlmageyL2d7"
    },
    "self": {
      "href": "https://dev-8675309.okta.com/api/v1/users/00up0nl0lftw7331WSz"
    },
    "type": {
      "href": "https://dev-8675309.okta.com/api/v1/meta/types/user/otyn3jlrawrlmageyL2d7"
    },
    "unsuspend": {
      "href": "https://dev-8675309.okta.com/api/v1/users/00up0nl0lftw7331WSz/lifecycle/unsuspend",
      "method": "POST"
    }
  },
  "activated": "2025-03-13T17:37:33Z",
  "created": "2025-03-13T17:37:33Z",
  "credentials": {
    "password": {},
    "provider": {
      "name": "OKTA",
      "type": "OKTA"
    }
  },
  "id": "00up0nl0lftw7331WSz",
  "lastUpdated": "2025-03-14T13:37:10Z",
  "passwordChanged": "2025-03-13T17:37:33Z",
  "profile": {
    "email": "fake.user@limacharlie.com",
    "firstName": "Fake",
    "lastName": "User",
    "login": "fake.user@limacharlie.com",
    "mobilePhone": null,
    "secondEmail": null
  },
  "status": "ACTIVE",
  "statusChanged": "2025-03-14T13:37:10Z",
  "type": {
    "id": "otyn3jlrwwlmageyL2d7"
  }
}
```

### Get List of Users

Lists users that do not have a status of “DEPROVISIONED” (by default), up to the maximum (200 for most orgs), with pagination in most cases. A subset of users can be returned that match a supported filter expression or search criteria.

> This command takes an optional filter. If no filter is provided, all users are returned. For more information on Okta’s query filters, visit <https://developer.okta.com/docs/reference/user-query/#filter-users>

#### Command

```
user list OPTIONAL_FILTER
```

#### Example Input

```
user list
```

#### Example Output

```json
[
  {
    "_links": {
      "self": {
        "href": "https://dev-8675309.okta.com/api/v1/users/00un2JpnNwheWSzOe5d7"
      }
    },
    "created": "2025-01-31T12:26:30Z",
    "credentials": {
      "password": {},
      "provider": {
        "name": "OKTA",
        "type": "OKTA"
      }
    },
    "id": "00up0nl0lftw7331WSz",
    "lastLogin": "2025-03-14T13:36:13Z",
    "lastUpdated": "2025-02-10T15:33:00Z",
    "passwordChanged": "2025-02-10T15:33:00Z",
    "profile": {
      "email": "fake.user@limacharlie.com",
      "firstName": "Fake",
      "lastName": "User",
      "login": "fake.user@limacharlie.com",
      "mobilePhone": null,
      "secondEmail": null
    },
    "status": "ACTIVE",
    "statusChanged": "2025-02-10T15:33:00Z",
    "type": {
      "id": "otyn2jpriwmLdgaiL5d7"
    }
  }
]
```

### Deactivate User

Deactivates a user.

> This operation can only be performed on users that do not have a “DEPROVISIONED” status.

#### Command

```
user deactivate USERID
```

#### Example Input

```
user deactivate 00up0nl0lftw7331WSz
```

#### Example Output

```
None
```

### Activate User

Activates a user.

> This operation can only be performed on users with a “STAGED” status.

#### Command

```
user activate USERID
```

#### Example Input

```
user activate 00up0nl0lftw7331WSz
```

#### Example Output

```
None
```

### Expire User Password

This operation transitions the user to the status of “PASSWORD\_EXPIRED” so that the user is required to change their password at their next login.

#### Command

```
user expire-password USERID
```

#### Example Input

```
user expire-password 00up0nl0lftw7331WSz
```

#### Example Output

```
None
```

### Suspend User

Suspends a user. The user will have a status of “SUSPENDED” when the process is complete.

> This operation can only be performed on users with an “ACTIVE” status.

#### Command

```
user suspend USERID
```

#### Example Input

```
user suspend 00up0nl0lftw7331WSz
```

#### Example Output

```
None
```

### Unsuspend User

Unsuspends a user and returns them to the “ACTIVE” state. This operation can only be performed on users that have a “SUSPENDED” status.

> This operation can only be performed on users that have a “SUSPENDED” status.

#### Command

```
user unsuspend USERID
```

#### Example Input

```
user unsuspend 00up0nl0lftw7331WSz
```

#### Example Output

```
None
```

### Unlock User

Unlocks a user with a “LOCKED\_OUT” status and returns them to “ACTIVE” status. Users will be able to login with their current password.

#### Command

```
user unlock USERID
```

#### Example Input

```
user unlock 00up0nl0lftw7331WSz
```

#### Example Output

```
None
```

Command-line Interface

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

---

##### Related articles

* [Okta](/docs/adapter-types-okta)

---

###### What's Next

* [StrongDM](/docs/ext-cloud-cli-sdm)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)
+ [Available Commands](#available-commands)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## PagerDuty

# PagerDuty
The PagerDuty Extension allows you to trigger events within PagerDuty. It requires you to setup the PagerDuty access token in the Integrations section of your Organization.

Some more detailed information is available [here](https://developer.pagerduty.com/docs/events-api-v2/trigger-events/).

## REST

### Trigger Event

```json
{
  "summary": "Critical credentials theft alert.",
  "source": "limacharlie.io",
  "severity": "critical",
  "component": "dr-creds-theft",
  "group": "lc-alerts",
  "class": "dr-rules"
}
```

### PagerDuty Configuration

On the PagerDuty side, you need to configure your PagerDuty service to receive the API notifications:

1. In your Service, go to the "Integrations" tab.
2. Click "Add a new integration".
3. Give it a name, like "LimaCharlie".
4. In the "Integration Type" section, select the radio button "Use our API directly" and select "Events API v2" from the dropdown.
5. Click "Add integration".
6. Back in the "Integrations" page, you should see your new integration in the list. Copy the "Integration Key" to your clipboard and add it in the "Integrations" section of LimaCharlie for PagerDuty.

From this point on, you may use a  rule to trigger a PagerDuty event. For example the following rule "response":

```
- action: extension request
  extension action: run
  extension name: ext-pagerduty
  extension request:
       class: '{{ "dr-rules" }}'
       group: '{{ "lc-alerts" }}'
       severity: '{{ "critical" }}'
       source: '{{ "LimaCharlie" }}'
       component: '{{ "dr-creds-theft" }}'
       summary: '{{ .routing.hostname }} - {{ .routing.sid }} - {{ .cat }}'
       details: '{{ .event }}'
```

### Migrating D&R Rule from legacy Service to new Extension

***LimaCharlie is migrating away from Services to a new capability called Extensions. Support of legacy services will end on June 30, 2024.***

The [Python CLI](https://github.com/refractionPOINT/python-limacharlie) gives you a direct way to assess if any rules reference legacy PagerDuty service, preview the change and execute the conversion required in the rule "response".

Command line to preview PagerDuty rule conversion:

```
limacharlie extension convert_rules --name ext-pagerduty
```

A dry-run response (default) will display the rule name being changed, a JSON of the service request rule and a JSON of the incoming extension request change.

To execute the change in the rule, explicitly set `--dry-run` flag to `--no-dry-run`

Command line to execute PagerDuty rule conversion:

```
limacharlie extension convert_rules --name ext-pagerduty --no-dry-run
```

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

#### What's Next

* [Plaso](/docs/ext-plaso)

Table of contents

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Plaso

# Plaso
Plaso Extension Pricing

While it is free to enable the Plaso extension, pricing is applied to both the original downloaded artifact and the processed (Plaso) artifacts -- $0.02/GB for the original downloaded artifact, and $1.0/GB for the generation of the processed artifacts.

## About

[Plaso](https://plaso.readthedocs.io/) is a Python-based suite of tools used for creation of analysis timelines from forensic artifacts acquired from an endpoint.

These timelines are invaluable tools for digital forensic investigators and analysts, enabling them to effectively correlate the vast quantities of information encountered in logs and various forensic artifacts encountered in an intrusion investigation.

The primary tools in the Plaso suite used for this process are [log2timeline](https://plaso.readthedocs.io/en/latest/sources/user/Using-log2timeline.html), [psort](https://plaso.readthedocs.io/en/latest/sources/user/Using-psort.html), and [psteal](https://plaso.readthedocs.io/en/latest/sources/user/Using-psteal.html).

* `log2timeline` - bulk forensic artifact parser
* `psort` - builds timelines based on output from `log2timeline`
* `psteal` - Simply a wrapper for `log2timeline` and `psort`

The `ext-plaso` extension within LimaCharlie allows you to run `log2timeline` and `psort` (using the `psteal` wrapper) against artifacts obtained from an endpoint, such as event logs, registry hives, and various other forensic artifacts. When executed, Plaso will parse and extract information from all acquired evidence artifacts that it has support for. Supported parsers are found [here](https://plaso.readthedocs.io/en/latest/sources/user/Parsers-and-plugins.html).

## Extension Configuration

Long Execution Times

Note that it can take **several minutes** for the plaso generation to complete for larger triage collections, but once it finishes you will see the results in the `ext-plaso` Sensor timeline, as well as the uploaded artifacts on the Artifacts page.

The `ext-plaso` extension runs `psteal` (`log2timeline` + `psort`) against the acquired evidence using the following commands:

1. ```
   psteal.py --source /path/to/artifact -o dynamic --storage-file $artifact_id.plaso -w $artifact_id.csv
   ```

Upon running `psteal.py`, a `.plaso` file and a `.csv` file are generated. They will be uploaded as LimaCharlie artifacts.

* Resulting `.plaso` file contains the raw output of `log2timeline.py`
* Resulting `.csv` file contains the CSV formatted version of the `.plaso` file contents

2. ```
   pinfo.py $artifact_id.plaso -w $artifact_id_pinfo.json --output_format json
   ```

After `psteal.py` runs, information is gathered from the resulting `.plaso` file using the `pinfo.py` utility and pushed into the `ext-plaso` sensor timeline as a `pinfo` event. This event provides a detailed summary with metrics of the processing that occurred, as well as any relevant errors you should be aware of.

The following events will be pushed to the `ext-plaso` sensor timeline:

* `job_queued`: indicates that `ext-plaso` has received and queued a request to process data
* `job_started`: indicates that `ext-plaso` has started processing the data
* `pinfo`: contains the `pinfo.py` output summarizing the results of the plaso file generation
* `plaso`: contains the `artifact_id` of the plaso file that was uploaded to LimaCharlie
* `csv`: contains the `artifact_id` of the CSV file that was uploaded to LimaCharlie

## Usage & Automation

LimaCharlie can automatically kick off evidence processing with Plaso based off of the artifact ID provided in a  rule action, or you can run it manually via the extension.

### Velociraptor Triage Acquisition Processing

If you use the LimaCharlie [Velociraptor](/v2/docs/ext-velociraptor) extension, a good use case of `ext-plaso` would be to trigger Plaso evidence processing upon ingestion of a Velociraptor KAPE files artifact collection.

1. Configure a D&R rule to watch for Velociraptor collection events upon ingestion, and then trigger the Plaso extension:

   **Detect:**

   ```
   op: and
   target: artifact_event
   rules:
       - op: is
         path: routing/log_type
         value: velociraptor
       - op: is
         not: true
         path: routing/event_type
         value: export_complete
   ```

   **Respond:**

   ```
   - action: extension request
     extension action: generate
     extension name: ext-plaso
     extension request:
         artifact_id: '{{ .routing.log_id }}'
   ```
2. Launch a `Windows.KapeFiles.Targets` artifact collection in the LimaCharlie Velociraptor extension. This instructs Velociraptor to gather all endpoint artifacts defined in [this KAPE Target file](https://github.com/EricZimmerman/KapeFiles/blob/master/Targets/Compound/KapeTriage.tkape).

   **Argument options:**

   * `EventLogs=Y` - EventLogs only, quicker processing time for proof of concept
   * `KapeTriage=Y` - full [KapeTriage](https://github.com/EricZimmerman/KapeFiles/blob/master/Targets/Compound/KapeTriage.tkape) files collection ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/velociraptor-ext-3.png)
3. Once Velociraptor collects, zips, and uploads the evidence, the previously created D&R rule will send the triage `.zip` to `ext-plaso` for processing. Watch the `ext-plaso` sensor timeline for status and the Artifacts page for the resulting `.plaso` & `.csv` output files. See [Working with the Output](/v2/docs/ext-plaso#working-with-the-output).

### MFT Processing

If you use the LimaCharlie [Dumper](/v2/docs/ext-dumper) extension, a good use case of `ext-plaso` would be to trigger Plaso evidence processing upon ingestion of a MFT CSV artifact.

1. Configure a D&R rule to watch for MFT collection events upon ingestion, and then trigger the Plaso extension:

   **Detect:**

   ```
   op: and
   target: artifact_event
   rules:
       - op: is
         path: routing/log_type
         value: mftcsv
       - op: is
         not: true
         path: routing/event_type
         value: export_complete
   ```

   **Respond:**

   ```
   - action: extension request
     extension action: generate
     extension name: ext-plaso
     extension request:
         artifact_id: '{{ .routing.log_id }}'
   ```
2. Launch an MFT dump in the LimaCharlie Dumper extension.
   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/plaso-ext-1.png)
3. Once dumper is complete and uploads the evidence, the previously created D&R rule will send the zipped MFT CSV to `ext-plaso` for processing. Watch the `ext-plaso` sensor timeline for status and the Artifacts page for the resulting `.plaso` & `.csv` output files. See [Working with the Output](/v2/docs/ext-plaso#working-with-the-output).

## Working with the Output

Running the extension generates the following useful outputs:

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28254%29.png)

* `pinfo` on `ext-plaso` sensor timeline
   First and foremost, after the completion of a processing job by `ext-plaso`, it is highly encouraged to analyze the resulting `pinfo` event on the `ext-plaso` sensor timeline. This event provides a detailed summary with metrics of the processing that occurred, as well as any relevant errors you should be aware of.

  + Pay close attention to fields such as `warnings_by_parser` or `warnings_by_path_spec` which may reveal parser errors that were encountered.
  + Sample output of `pinfo` showing counts of parsed artifacts nested under `storage_counters` -- this provides insight as to which, and how many events will be present in your CSV timeline.

```
"amcache": 986,
"appcompatcache": 4096,
"bagmru": 29,
"chrome_27_history": 29,
"chrome_66_cookies": 246,
"explorer_mountpoints2": 2,
"explorer_programscache": 1,
"filestat": 3495,
"lnk": 160,
"mft": 4790977,
"mrulist_string": 2,
"mrulistex_shell_item_list": 3,
"mrulistex_string": 5,
"mrulistex_string_and_shell_item": 5,
"mrulistex_string_and_shell_item_list": 1,
"msie_webcache": 143,
"msie_zone": 60,
"networks": 4,
"olecf_automatic_destinations": 37,
"olecf_default": 5,
"recycle_bin": 3,
"shell_items": 297,
"total": 5840430,
"user_access_logging": 34,
"userassist": 44,
"utmp": 13,
"windows_boot_execute": 8,
"windows_run": 10,
"windows_sam_users": 16,
"windows_services": 2004,
"windows_shutdown": 8,
"windows_task_cache": 835,
"windows_timezone": 4,
"windows_typed_urls": 3,
"windows_version": 6,
"winevtx": 382674,
"winlogon": 8,
"winreg_default": 654177
```

### Downloadable Artifacts

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28253%29.png)

* `plaso` artifact
   The downloadable `.plaso` file contains the raw output of `log2timeline.py` and can be [imported into Timesketch](https://timesketch.org/guides/user/upload-data/) as a timeline.
* `csv` artifact
   The downloadable `.csv` file can be easily viewed in any CSV viewer, but a highly recommended tool for this is [Timeline Explorer](https://ericzimmerman.github.io/) from Eric Zimmerman.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

#### Related articles

* [Hayabusa](/docs/ext-hayabusa)
* [Velociraptor](/docs/ext-velociraptor)

---

##### What's Next

* [REnigma](/docs/ext-renigma)

Table of contents

+ [About](#about)
+ [Extension Configuration](#extension-configuration)
+ [Usage &amp; Automation](#usage-amp-automation)
+ [Working with the Output](#working-with-the-output)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [dfir](/docs/en/tags/dfir)
* [extensions](/docs/en/tags/extensions)

---

## REnigma

# REnigma
## About REnigma

[REnigma](https://dtrsec.com/) is an advanced malware analysis platform leveraging its unique Record and Replay technology to deliver unparalleled precision and depth. By recording every state change in a virtual machine during live execution, REnigma enables analysts to replay and analyze malware behaviors offline, down to the instruction level. This approach eliminates the risk of evasion and ensures a comprehensive capture of malicious activity. For SOC teams triaging alerts or incident responders conducting deep dives, REnigma offers rapid detonation, precision analysis, and effortless artifact extraction. Its API integrations further enhance workflows, enabling seamless automation and streamlined investigation processes.

### About the Extension

The LimaCharlie Extension for REnigma seamlessly integrates with the REnigma API, enabling automated analysis of suspicious URLs or files collected using the LimaCharlie BinLib or Artifact Extensions. When a file or URL triggers an alert in LimaCharlie, preconfigured Detection & Response () rules can automatically queue the item for further investigation in REnigma.

Through the integration, these D&R rules send the artifact or URL directly to REnigma, where it is recorded and analyzed in a controlled virtual machine environment. Analysts can then access detailed execution data, artifacts, and network patterns captured by REnigma's Record and Replay technology. This workflow not only streamlines the triage process but also provides deep insights into potential threats without requiring manual intervention at every step.

### Configuration

To use the REnigma extension, you will need your REnigma URL and API key. [Contact the REnigma team for access](https://dtrsec.com/contact.html).

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(284).png)

### Using the Extension

You can submit a file or URL to the REnigma extension for processing in one of 2 ways:

1. Via the LimaCharlie web UI:

   1. Submit the ID of the artifact you wish to process with REnigma, and it will get uploaded and processed via a series of D&R rules. You will see the output in the `ext-renigma` sensor timeline.![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(297).png)
   2. Submit the URL you wish to analyze with REnigma, and it will get sent and processed via a series of D&R rules. You will see the output in the `ext-renigma` sensor timeline.![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(296).png)
2. Via D&R rules:

   1. Detect:

      ```
      event: ingest
      op: exists
      path: /
      target: artifact_event
      artifact type: ext-binlib-bin
      ```
   2. Respond

      ```
      - action: "extension request"
        extension name: "ext-renigma"
        extension action: "upload_file"
        extension request:
            file_id: '{{ .routing.log_id }}'
            disable_internet: false
      ```

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

---

#### Related articles

* [BinLib](/docs/binlib)
* [Artifacts](/docs/artifacts)
* [Using Extensions](/docs/using-extensions)

---

##### What's Next

* [Secure Annex](/docs/ext-secureannex)

Table of contents

Tags

* [artifacts](/docs/en/tags/artifacts)
* [binlib](/docs/en/tags/binlib)
* [extensions](/docs/en/tags/extensions)
* [renigma](/docs/en/tags/renigma)

---

## Reliable Tasking

# Reliable Tasking
The Reliable Tasking Extension enables you to task a Sensor(s) that are currently offline. The extension will automatically send the task(s) to Sensor(s) once it comes online.

## Enabling the Reliable Tasking Extension

To enable the Reliable Tasking extension, navigate to the [Reliable Tasking extension page](https://app.limacharlie.io/add-ons/extension-detail/ext-reliable-tasking) in the marketplace. Select the Organization you wish to enable the extension for, and select **Subscribe**.

After clicking **Subscribe**, the Reliable Tasking extension should be available almost immediately.

## Using the Reliable Tasking Extension

Once enabled, you will see a **Reliable Tasking** option under **Automation** within the LimaCharlie web UI. You can also interact with the extension via REST API.

Within the Reliable Tasking module, you can:

* Task Sensor(s)
* Untask Sensor(s)
* List active task(s)

## Actions via REST API

The following REST API actions can be sent to interact with the Reliable Tasking extension:

### **Create a Task**

```bash
curl --location 'https://api.limacharlie.io/v1/extension/request/ext-reliable-tasking' \
--header 'Authorization: Bearer $JWT' \
--header 'Content-Type: application/x-www-form-urlencoded' \
--data 'oid=$YOUR_OID&action=task&data={"context":"version","selector":"plat==windows","task":"run --shell-command whoami","ttl":3600}'
```

The `task` is similar to a command-line `task`. Optionally, you can also specify which endpoints to task by specifying:

* `sid` : A specific Sensor ID
* `tag` : All Sensor(s) with a Tag
* `plat`: All Sensor(s) of the specified platform

You can use the `ttl` to specify how long the extension should try to keep sending the task. The `ttl` value is a number of seconds and defaults to 1 week.

#### **List Tasks**

```bash
curl --location 'https://api.limacharlie.io/v1/extension/request/ext-reliable-tasking' \
--header 'Authorization: Bearer $JWT' \
--header 'Content-Type: application/x-www-form-urlencoded' \
--data 'oid=$YOUR_OID&action=list&data={}'
```

When listing tasks, you can specify which endpoints to get queued tasks from by using one of:

* `sid` : A specific sensor ID
* `tag` : All Sensor(s) with a tag
* `plat`: All Sensor(s) of the specified platform

## Capturing Task Responses

If you’re using reliable tasks to issue commands across your sensors, you’re probably going to want to view or act on the responses from these commands as well.

If you add a value to the `context` parameter in the extension request, this value will be reflected in the `investigation_id` of the corresponding `RECEIPT` or `_REP` event, allowing you to craft a D&R rule based on the response.

The above example cURL command has a `context` of `version` so the below D&R rule looks for that value.

### Example detect block:

```
op: contains
event: RECEIPT
path: routing/investigation_id
value: version
```

#### Example respond block:

```
- action: output
  name: tasks-output         # Send responses to the specified output
- action: report
  name: "Reliable task ran"  # Detect on the task being run
```

## Migrating Rule from legacy Service to new Extension

***LimaCharlie is migrating away from Services to a new capability called Extensions. Support of legacy services will end on June 30, 2024.***

The [Python CLI](https://github.com/refractionPOINT/python-limacharlie) gives you a direct way to assess if any rules reference legacy reliable tasking service, preview the change and execute the conversion required in the rule "response".

Command line to preview Reliable Tasking rule conversion:

```
limacharlie extension convert_rules --name ext-reliable-tasking
```

A dry-run response (default) will display the rule name being changed, a JSON of the service request rule and a JSON of the incoming extension request change.

To execute the change in the rule, explicitly set `--dry-run` flag to `--no-dry-run`

Command line to execute reliable tasking rule conversion:

```
limacharlie extension convert_rules --name ext-reliable-tasking --no-dry-run
```

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

---

### What's Next

* [Sensor Cull](/docs/ext-sensor-cull)

Table of contents

+ [Enabling the Reliable Tasking Extension](#enabling-the-reliable-tasking-extension)
+ [Using the Reliable Tasking Extension](#using-the-reliable-tasking-extension)
+ [Actions via REST API](#actions-via-rest-api)
+ [Capturing Task Responses](#capturing-task-responses)
+ [Migrating {{glossary.D&amp;R}} Rule from legacy Service to new Extension](#migrating-{{glossary-d-amp-r}}-rule-from-legacy-service-to-new-extension)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Secure Annex

# Secure Annex
[Secure Annex](https://secureannex.com/) is a browser extension security platform that provides a comprehensive analysis of the Chrome extensions installed across your organization’s endpoints.

The Secure Annex LimaCharlie Extension allows you to query the Secure Annex API with the IDs of Chrome extensions installed on endpoints within your organization in order to get detailed information about the extensions. You can then perform additional analysis or craft  rules based on the results.

API endpoints available for querying are:

* /manifest
* /extensions
* /vulnerabilities
* /signatures
* /urls
* /analysis

This is currently only supported on Windows, macOS, and Chrome sensors.

## Setup

1. Sign up and get an API key at <https://app.secureannex.com/settings/api>![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(267).png "image(267).png")
2. Subscribe to the Secure Annex extension in LimaCharlie - <https://app.limacharlie.io/add-ons/extension-detail/ext-secureannex>
3. Add the API key to the Secure Annex extension configuration within LimaCharlie![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(281).png "image(281).png")

### Usage

#### Manually in the GUI

You can trigger an extension request manually within the web app by clicking the `Get extensions from endpoint` button. This will allow you to choose a sensor, or sensors via a Sensor Selector, to get extensions from. More examples of sensor selectors can be found [here](/v2/docs/reference-sensor-selector-expressions).

The extensions are gathered from endpoints via the reliable tasking extension, which appends `secureannex_extensions` to the investigation ID of the `RECEIPT` or `OS_PACKAGES_REP` event in order to trigger an extension request to query Secure Annex. The results will be in the timeline of the `ext-secureannex` sensor.![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(282).png "image(282).png")

#### Automatically via D&R Rules

Upon subscribing to the Secure Annex extension, several D&R rules are added to your organization in a **disabled** **state** to help you get more use out of the extension and automate your detections. They are as follows:

* `ext-secureannex-detect-vulnerabilities`

  + This will look at the vulnerabilities and associated severities in the `vulnerability` results returned, and create detections on high and critical vulnerabilities found
* `ext-secureannex-detect-risk-rating`

  + This will look at the risks and associated severities in the `manifest` results returned, and create detections on high and critical severities found
* `ext-secureannex-get-extensions-windows`

  + This schedules a base64 encoded PowerShell script to run every 24 hours to query Windows sensors for installed Chrome extensions, and bring back a list of the extension IDs and versions
  + The results will have a `secureannex_extensions` investigation ID associated that will allow LimaCharlie to automatically create Secure Annex extension requests with the IDs and versions included to perform a full analysis and bring back the results into the `ext-secureannex` sensor
* `ext-secureannex-get-extensions-mac`

  + This schedules a base64 encoded bash script to run every 24 hours to query macOS sensors for installed Chrome extensions, and bring back a list of the extension IDs and versions
  + The results will have a `secureannex_extensions` investigation ID associated that will allow LimaCharlie to automatically create Secure Annex extension requests with the IDs and versions included to perform a full analysis and bring back the results into the `ext-secureannex` sensor
* `ext-secureannex-get-extensions-chrome`

  + This schedules the `OS_PACKAGES` command to run every 24 hours to query Chrome sensors for installed Chrome extensions, and bring back a list of the extension IDs and versions
  + The results will have an investigation ID associated that will allow LimaCharlie to automatically create Secure Annex extension requests with the IDs and versions included to perform a full analysis and bring back the results into the `ext-secureannex` sensor

If you wish to use these, you need to enable them first. You can also copy the contents of these rules and create your own so they are no longer managed by the Secure Annex extension if you wish to modify them.

#### Results

Results will show up in the live feed and timeline of the `ext-secureannex` Sensor.![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(283).png "image(283).png")

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Many components in LimaCharlie require selecting a set of Sensors based on some characteristics. The selector expression is a text field that describes what matching characteristics the selector is looking for, like `plat==windows`, to select all Windows sensors.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

##### Related articles

* [Reference: Sensor Selector Expressions](/docs/reference-sensor-selector-expressions)

---

###### What's Next

* [Strelka](/docs/ext-strelka)

Table of contents

Tags

* [add-ons](/docs/en/tags/add-ons)
* [api](/docs/en/tags/api)
* [chrome](/docs/en/tags/chrome)
* [extensions](/docs/en/tags/extensions)

---

## Strelka

# Strelka
* 1 Minute to read

## What's Next

* [Twilio](/docs/ext-twilio)

Table of contents

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## StrongDM

# StrongDM
* 1 Minute to read

## What's Next

* [Sublime](/docs/ext-cloud-cli-sublime)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Sublime

# Sublime
* 1 Minute to read

## Related articles

* [Sublime Security](/docs/adapter-types-sublime-security)

---

### What's Next

* [Tailscale](/docs/ext-cloud-cli-tailscale)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Tailscale

# Tailscale
* 1 Minute to read

## Related articles

* [Tailscale](/docs/adapter-types-tailscale)

---

### What's Next

* [Vultr](/docs/ext-cloud-cli-vultr)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Third-Party Extensions

# Third-Party Extensions
14 Articles  in this category

---

## Twilio

# Twilio
* 1 Minute to read

## What's Next

* [Velociraptor](/docs/ext-velociraptor)

Table of contents

+ [Overview](#overview)
+ [Setup](#setup)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Usage Alerts

# Usage Alerts
The usage alerts Extension allows you to create, maintain, & automatically refresh usage alert conditions for an Organization.

For example, you can create a usage alert rule that will fire a detection when artifact downloads have reached a 1GB threshold in the last 30 days (43200 minutes). This alert will be saved as a managed  rule. When the threshold is reached, a detection will be created with the following `cat`:

`Usage alert - Output data over threshold - 1024 MB in 30.00 days`

These alert rules can be managed across tenants using the Infrastructure as Code extension.

Every hour, LimaCharlie will sync all of the usage alert rules in the configuration. They can also be manually synced by clicking the `Sync Usage Alert Rules` button on the extension page. When a usage alert rule is added, it will **not** be automatically synced immediately, unless you click on `Sync Usage Alert Rules`.

**NOTE**: The maximum timeframe is currently 43200 minutes (30 days).

## Usage - GUI

To define a new usage alert, simply click on the `Add New Usage Alert` button in the extension UI. Give it a name, like `Output data over threshold`, select a SKU (in this case, `output_data`), a timeframe, a limit, and click `Save`. ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(275).png "image(275).png")

If you want it to be added immediately, click on the `Sync Usage Alert Rules` button. Otherwise, it will get pushed automatically at the next hour interval.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(278).png "image(278).png")

This will create a managed D&R rule on the backend in the `dr-managed` hive and will sync automatically every hour.

```
hives:
    dr-managed:
        Output data over threshold:
            data:
                detect:
                    event: billing_record
                    op: and
                    rules:
                        - op: is
                          path: event/record/cat
                          value: output
                        - op: is
                          path: event/record/k
                          value: bytes_tx
                    target: billing
                respond:
                    - action: report
                      name: Usage alert - Output data over threshold - 1024 MB in 24.00 hours
                      suppression:
                        count_path: event/record/v
                        keys:
                            - output
                            - bytes_tx
                            - ext-usage-alerts
                            - Output data over threshold
                        max_count: 1.073741824e+09
                        min_count: 1.073741824e+09
                        period: 43200m
```

## Usage - Infrastructure as Code

If you are managing your organizations via infrastructure as code, you can also configure these rules in the `extension_config` hive.

```
hives:
    extension_config:
        ext-usage-alerts:
            data:
                usage_alert_rules:
                    - enabled: true
                      limit: 1024
                      name: Output data over threshold
                      sku: output_data
                      timeframe: 43200
            usr_mtd:
                enabled: true
                expiry: 0
                tags: []
                comment: ""
```

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

### Related articles

* [Extensions](/docs/extensions)
* [Using Extensions](/docs/using-extensions)

---

#### What's Next

* [YARA Manager](/docs/ext-yara-manager)

Table of contents

+ [Usage - GUI](#usage-gui)
+ [Usage - Infrastructure as Code](#usage-infrastructure-as-code)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [billing](/docs/en/tags/billing)
* [extensions](/docs/en/tags/extensions)

---

## Using Extensions

# Using Extensions
* 1 Minute to read

## Related articles

* [Extensions](/docs/extensions)
* [Usage Alerts](/docs/ext-usage-alerts)
* [REnigma](/docs/ext-renigma)

---

### What's Next

* [Building Extensions](/docs/building-extensions)

Table of contents

+ [Components](#components)
+ [Interacting](#interacting)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Velociraptor

# Velociraptor
## Overview

[Velociraptor](https://github.com/Velocidex/Velociraptor) is an open source endpoint visibility tool that includes power digital forensic, incident response, and incident triage capabilities. LimaCharlie can be used to deploy Velociraptor at scale, allowing for easy artifact collection and incident analysis.

The interface defines 2 main actions:

1. **Show Artifact** - allows you to inspect the VQL artifacts available for collection
2. **Collect Artifact** - allows you to run an artifact collection on one or more endpoints

### Show Artifact

Simply choose an artifact from the list to inspect it's contents.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/velociraptor-ext-1.png)

Result of the action

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/velociraptor-ext-2.png)

### Collect Artifact

This allows you to collect one or more Velociraptor [Artifacts](https://docs.velociraptor.app/artifact_references/) from one or more endpoints via the Endpoint Agent.
![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/velociraptor-ext-3.png)

Velociraptor will generate a ZIP file with all collected data, which is automatically ingested into LimaCharlie's Artifact system for download.

#### Arguments

* **Artifacts** - Select one or more Velociraptor artifacts you wish to collect
* **Sensor Selector** - Select either a single sensor by selecting it's Sensor ID from the dropdown or use a [Sensor Selector Expression](/v2/docs/reference-sensor-selector-expressions) to cast a wider net such as `plat==windows`
* **Arguments (optional)** - These are optional arguments (or parameters) passed directly to the Velociraptor Artifact. For instance, if you wanted to run a collection for [Windows.KapeFiles.Targets](https://github.com/Velocidex/velociraptor/blob/master/artifacts/definitions/Windows/KapeFiles/Targets.yaml) and wanted to specify the [KapeTriage](https://github.com/Velocidex/velociraptor/blob/5db9bc46cc79013da1bbaf8c493a263eb1ca64b4/artifacts/definitions/Windows/KapeFiles/Targets.yaml#L412-L414) targets for collection, you would specify `KapeTriage=Y` in the **Arguments** since this is a boolean parameter for the `Windows.KapeFiles.Targets` artifact.
* **Collection Seconds (optional)** - Define how long (in seconds) the Extension will wait for a targeted endpoint to come online and be processed for collection.
* **Retention Days (optional)** - Define how long the collected artifact will be retained by the platform.
* **Ignore SSL Errors (optional)** - Tells the endpoint to ignore SSL errors while running and collecting. This can be useful if the endpoint is behind a MITM proxy or firewall performing SSL interception.

## Monitoring Collections

You are able to track Velociraptor hunts by viewing the Timeline for the `ext-velociraptor` sensor.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/velociraptor-ext-4.png)

Once you see `artifact_uploaded` in the timeline, you can expect to find the artifact on the "Artifacts" screen.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/velociraptor-ext-5.png)

## Automating Collection Retrieval

Let's say you wanted to automatically fetch new Velociraptor collections and send somewhere else for storage/processing. This can be accomplished via  rules which watch for the artifact upload and send to a tailored output.

Example D&R rule

```
# Detection
op: is
path: routing/log_type
target: artifact_event
value: velociraptor

# Response
- action: output
  name: artifacts-tailored
  suppression:
    is_global: false
    keys:
        - '{{ .event.original_path }}'
        - '{{ .routing.log_id }}'
    max_count: 1
    period: 1m
- action: report
  name: VR artifact ingested
```

To see how you could use something like this to automate post-processing of Velociraptor triage collections, check out this [open source example](https://github.com/shortstack/lcvr-to-timesketch) which sends KAPE Triage acquisitions to a webhook which then retrieves the collection for processing via [Plaso](https://github.com/log2timeline/plaso/) and into [Timesketch](https://github.com/google/timesketch).

To see how you can send Velociraptor data to BigQuery for further analysis, see this [tutorial](/v2/docs/velociraptor-to-bigquery).

## Using Velociraptor in D&R Rules

If you want to trigger a Velociraptor collection as a response to one of your detections, you can configure an extension request in the respond block of a rule.

This example will kick off the KAPE files Velociraptor artifact to collect event logs from the system involved in the detection.

```
- action: extension request
  extension action: collect
  extension name: ext-velociraptor
  extension request:
    artifact_list: ['Windows.KapeFiles.Targets']
    sid: '{{ .routing.sid }}' # Use a sensor selector OR a sid, **not both**
    sensor_selector: '' # Use a sensor selector OR a sid, **not both**
    args: '{{ "EventLogs=Y" }}'
    collection_ttl: 3600 # 1 hour - collection_ttl is specified in seconds
    retention_ttl: 7 # retention_ttl is specified in days
    ignore_cert: false
```

### Migrating D&R Rule from legacy Service to new Extension

***LimaCharlie is migrating away from Services to a new capability called Extensions. Support of legacy services will end on June 30, 2024.***

The [Python CLI](https://github.com/refractionPOINT/python-limacharlie) gives you a direct way to assess if any rules reference legacy Velociraptor service, preview the change and execute the conversion required in the rule "response".

Command line to preview Velociraptor rule conversion:

```
limacharlie extension convert_rules --name ext-velociraptor
```

A dry-run response (default) will display the rule name being changed, a JSON of the service request rule and a JSON of the incoming extension request change.

To execute the change in the rule, explicitly set `--dry-run` flag to `--no-dry-run`

Command line to execute Velociraptor rule conversion:

```
limacharlie extension convert_rules --name ext-velociraptor --no-dry-run
```

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

---

#### Related articles

* [Plaso](/docs/ext-plaso)
* [Hayabusa](/docs/ext-hayabusa)
* [Velociraptor to BigQuery](/docs/velociraptor-to-bigquery)

---

##### What's Next

* [YARA](/docs/ext-yara)

Table of contents

+ [Overview](#overview)
+ [Monitoring Collections](#monitoring-collections)
+ [Automating Collection Retrieval](#automating-collection-retrieval)
+ [Using Velociraptor in D&amp;R Rules](#using-velociraptor-in-d-amp-r-rules)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [dfir](/docs/en/tags/dfir)
* [extensions](/docs/en/tags/extensions)

---

## Vultr

# Vultr
* 1 Minute to read

## What's Next

* [Atomic Red Team](/docs/ext-atomic-red-team)

Table of contents

+ [Example](#example)
+ [Credentials](#credentials)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## YARA

# YARA
The [YARA](https://github.com/Yara-Rules/rules) Extension is designed to help you with all aspects of YARA scanning. It takes what is normally a manual piecewise process, provides a framework and automates it. Once configured, YARA scans can be run on demand for a particular endpoint or continuously in the background across your entire fleet.

Yara configurations are synchronized with sensors every few minutes.

There are three main sections to the YARA job:

* Sources
* Rules
* Scan

Where Does My YARA Scan?

Automated YARA scanners in LimaCharlie will run on all files loaded in memory (e.g. exe, dll, etc), and on the memory itself.

Files on disk can be scanned using a Sensor command.  You can trigger a Manual Scan that's run on-demand by:

* Clicking the Run YARA scan button on the sensor details page,
* Clicking the Scan button on the YARA Scanners page
* Using the console
* Within the Response section of a  rule (sample below)
* Using the LimaCharlie API

## Rules

This is where you define your YARA rule(s). You can copy and paste your YARA rules into the `Rule` box, or you can define sources via the [ext-yara-manager](/v2/docs/ext-yara-manager). Sources can be either direct links (URLs) to a given YARA rule (or directory of rules) or [ARLs](/v2/docs/reference-authentication-resource-locator) to a YARA rule.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/yara-1.png)

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/yara-2.png)

### Scanners

Scanners define which sets of sensors should be scanned with which sets of YARA rules.

Filter Tags are tags that must ALL be present on a sensor for it to match (AND condition), while the platform of the sensor much match one of the platforms in the filter (OR condition).

To apply YARA rules to scan an endpoint (or set of endpoints), you must select the platform or tags, and then add the YARA rules you would like to run.

## Using Yara in D&R Rules

If you want to trigger a Yara scan as a response to one of your detections, you can configure an extension request in the respond block of a rule.
 A Yara scan request can be executed with a blank selector OR Sensor ID. However, one of them must be specified.

```
- action: extension request
  extension action: scan
  extension name: ext-yara
  extension request:
		sources: [ ]# Specify Yara Rule sources as strings
		selector: ''
        sid: '{{ .routing.sid }}' # Use a sensor selector OR a sid, **not both**
		yara_scan_ttl: 86400 # "Default: 1 day (86,400 seconds)"
```

### Migrating D&R Rule from legacy Service to new Extension

***LimaCharlie is migrating away from Services to a new capability called Extensions. Support of legacy services will end on June 30, 2024.***

The [Python CLI](https://github.com/refractionPOINT/python-limacharlie) gives you a direct way to assess if any rules reference legacy Yara service, preview the change and execute the conversion required in the rule "response".

Command line to preview Yara rule conversion:

```
limacharlie extension convert_rules --name ext-yara
```

A dry-run response (default) will display the rule name being changed, a JSON of the service request rule and a JSON of the incoming extension request change.

To execute the change in the rule, explicitly set `--dry-run` flag to `--no-dry-run`

Command line to execute Yara rule conversion:

```
limacharlie extension convert_rules --name ext-yara --no-dry-run
```

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

---

#### Related articles

* [YARA Manager](/docs/ext-yara-manager)
* [Config Hive: Yara](/docs/config-hive-yara)
* [Detection and Response Examples](/docs/detection-and-response-examples)
* [BinLib](/docs/binlib)

---

##### What's Next

* [Zeek](/docs/ext-zeek)

Table of contents

+ [Using Yara in D&amp;R Rules](#using-yara-in-d-amp-r-rules)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [dfir](/docs/en/tags/dfir)
* [extensions](/docs/en/tags/extensions)

---

## YARA Manager

# YARA Manager
The [YARA](https://github.com/Yara-Rules/rules) manager Extension allows you to reference external YARA rules (rules maintained in GitHub, for example) to use in your YARA scans within LimaCharlie.

YARA rule sources defined in the YARA manager configuration will be synced every 24 hours, and can be manually synced by clicking the `Manual Sync` button on the extension page.

If you add rule sources and want them to become available immediately, you will need to click the `Manual Sync` button to trigger the initial sync of the rules.

Rule sources can be either direct links (URLs) to a given YARA rule or [ARLs](/v2/docs/reference-authentication-resource-locator).

## Option 1: Predefined YARA rules

LimaCharlie provides a list of YARA rule repositories, available in the configuration menu. To leverage these rules select “Predefined” and a list of LimaCharlie and Community rules will populate. By selecting one or more of these repositories, the respective rules will be automatically imported and will appear in your YARA rules under Automation → YARA Rules.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(322).png)

### Option 2: Publicly available YARA rules

An example of setting up a rule using this repo: [Yara-Rules](https://github.com/Yara-Rules/rules)

For an `Email and General Phishing Exploit` rule we could use the following URL, which is a link to a single YARA rule.

<https://raw.githubusercontent.com/Yara-Rules/rules/master/email/Email_generic_phishing.yar>

For creating a rule out of multiple YARA rules, we could use the following ARL, which is a link to a directory of YARA rules.

`[github,Yara-Rules/rules/email]`

Giving the rule configuration a name, the URL or ARL, and clicking the Save button will create the new rule source to sync to your YARA rules.

### Option 3: Private YARA Repository

To use a YARA rule from a private Gihub repository you will need to make use of an [Authentication Resource Locator](/v2/docs/reference-authentication-resource-locator).

**Step 1: Create a token in GitHub**
In GitHub go to *Settings* and click *Developer settings* in the left hand side bar.

Next click *Personal access token* followed by *Generate new token*. Select repo permissions and finally *Generate token*.

**Step 2: Connect LimaCharlie to your GitHub repository**
Inside of LimaCharlie, click on *Yara Manager* in the left hand menu. Then click *Add New Yara Configuration*.

Give your rule a name and then use the token you generated with the following format linked to your repo.

`[github,my-org/my-repo-name/path/to/rule.yar,token,bfuihferhf8erh7ubhfey7g3y4bfurbfhrb]`

or

`[github,my-org/my-repo-name/path/to/rules_directory,token,bfuihferhf8erh7ubhfey7g3y4bfurbfhrb]`

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

---

#### Related articles

* [Config Hive: Yara](/docs/config-hive-yara)
* [Detection and Response Examples](/docs/detection-and-response-examples)
* [BinLib](/docs/binlib)
* [Detection and Response](/docs/detection-and-response)
* [Reference: Endpoint Agent Commands](/docs/reference-endpoint-agent-commands)

---

##### What's Next

* [AI Agent Engine [LABS]](/docs/ai-agent-engine)

Table of contents

Tags

* [add-ons](/docs/en/tags/add-ons)
* [dfir](/docs/en/tags/dfir)
* [extensions](/docs/en/tags/extensions)

---

## Zeek

# Zeek
Zeek Extension Pricing

While it is Free to enable the Zeek extension, pricing is applied to processed PCAPs at a rate of $0.02/GB.

[Zeek](https://zeek.org/) is a comprehensive platform for network traffic analysis and intrusion detection.

Once enabled, this extension allows you to generate Zeek logs from packet capture (PCAP) files collected via Artifacts. The resulting Zeek log files are subsequently parsed and pushed into the `ext-zeek` Sensor timeline as JSON. You can create detection & response rules to automate based on Zeek log data.

LimaCharlie will automatically kick off Zeek based on the artifact ID provided in a  rule action.

## Configuration

To enable the Zeek extension, navigate to the [Zeek extension page](https://app.limacharlie.io/add-ons/extension-detail/ext-zeek) in the marketplace. Select the Organization you wish to enable the extension for, and select Subscribe.

When enabled, you may configure the response of a D&R rule to run Zeek against an artifact event. Here is an example D&R rule:

**Detect:**

```
artifact type: pcap
event: ingest
op: exists
path: /
target: artifact_event
```

**Respond:**

```
- action: extension request
  extension action: run_on
  extension name: ext-zeek
  extension request:
    artifact_id: '{{ .routing.log_id }}'
    retention: 30
```

## Results

```
/opt/zeek/bin/zeek -C LogAscii::use_json=T --no-checksums --readfile /path/to/your.pcap
```

Upon running Zeek, several JSON log files are generated. The log files are parsed and pushed into the `ext-zeek` sensor timeline.

![Screenshot 2024-02-20 1.04.52 PM.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/Screenshot%202024-02-20%201.04.52%20PM.png)

## Usage

### Via Automatic PCAP Collection

**Note: This is only available on Linux sensors**

Enable PCAP collection on your Linux sensors via a PCAP capture rule within the artifact collection extension.

For example, if you have an interface `ens4` and would like to gather PCAPs of network traffic on that interface on TCP port 80, you would craft the following rule.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/zeek-2.png)

Once ~30MB of traffic has been collected, a PCAP will be uploaded as an artifact in LimaCharlie. Subsequent PCAPs will continue to be uploaded as additional PCAPs as they hit the size threshold.

All PCAPs uploaded will trigger the [D&R rule below](#dr-rule).

### Via Manual PCAP Upload

If you have already generated a PCAP on a system or systems, you can manually ingest those as artifacts by running the following in your sensor console:

```
artifact_get --file /path/to/your.pcap --type pcap
```

This will trigger the [D&R rule below](#dr-rule).

### D&R Rule

**Detect:**

```
artifact type: pcap
event: ingest
op: exists
path: /
target: artifact_event
```

**Respond:**

```
- action: extension request
  extension action: run_on
  extension name: ext-zeek
  extension request:
    artifact_id: '{{ .routing.log_id }}'
    retention: 30
```

### Migrating D&R Rule from legacy Service to new Extension

***LimaCharlie is migrating away from Services to a new capability called Extensions. Support of legacy services will end on June 30, 2024.***

The [Python CLI](https://github.com/refractionPOINT/python-limacharlie) gives you a direct way to assess if any rules reference legacy zeek service, preview the change and execute the conversion required in the rule "response".

Command line to preview zeek rule conversion:

```
limacharlie extension convert_rules --name ext-zeek
```

A dry-run response (default) will display the rule name being changed, a JSON of the service request rule and a JSON of the incoming extension request change.

To execute the change in the rule, explicitly set `--dry-run` flag to `--no-dry-run`

Command line to execute zeek rule conversion:

```
limacharlie extension convert_rules --name ext-zeek --no-dry-run
```

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

#### What's Next

* [Hayabusa to BigQuery](/docs/hayabusa-to-bigquery)

Table of contents

+ [Configuration](#configuration)
+ [Results](#results)
+ [Usage](#usage)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

# Tutorials

## Log Collection Guide

# Log Collection Guide
This guide covers how to collect various Linux system logs into LimaCharlie using USP adapters. LimaCharlie provides flexible log collection capabilities through file monitoring and syslog ingestion.

## Collection Methods

### File Adapter (Recommended for Log Files)

The file adapter monitors log files for changes and streams new entries to LimaCharlie. It supports glob patterns for monitoring multiple files and handles log rotation automatically.

#### Key Features:

* Glob pattern support (/var/log/\*.log)
* Automatic log rotation handling
* Backfill support for historical data
* Multi-line JSON parsing
* Grok pattern parsing for structured log extraction

#### Basic Configuration:

```
file:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "text"  # or "json" for structured logs
    sensor_seed_key: "linux-logs"
  file_path: "/path/to/logfile"
  backfill: false  # Set true to read existing content
  no_follow: false # Set true to stop after reading existing content
```

### Syslog Adapter

runs as a syslog server, accepting logs via TCP or UDP. This is useful for centralizing logs from multiple systems or integrating with existing syslog infrastructure.

#### Key Features:

* TCP and UDP support
* TLS encryption support
* Mutual TLS authentication
* RFC 3164/5424 syslog format support

#### Basic Configuration:

```
syslog:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "text"
    sensor_seed_key: "syslog-server"
  port: 514
  interface: "0.0.0.0"
  is_udp: false  # Use TCP by defaultLog Parsing Options
```

LimaCharlie supports two methods for parsing unstructured log data:

* **parsing\_grok**: Uses Grok patterns (recommended) - pre-built patterns for common log formats, easier to read and maintain
* **parsing\_re**: Uses regular expressions - for custom formats or when Grok patterns don’t meet specific needs

Grok patterns are built on regular expressions but provide named patterns for common elements like timestamps, IP addresses, and log formats. Use Grok when possible for better maintainability.

## Common Log Sources

### System Logs (/var/log/messages, /var/log/syslog)

Traditional system logs contain kernel messages, service logs, and general system events.

**File Adapter Approach:**

```
file:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "text"
    sensor_seed_key: "system-logs"
    mapping:
      parsing_grok:
        message: "%{SYSLOGTIMESTAMP:date} %{HOSTNAME:host} %{DATA:service}(?:\\[%{POSINT:pid}\\])?: %{GREEDYDATA:message}"
      sensor_hostname_path: "host"
      event_type_path: "service"
  file_path: "/var/log/messages"  # or /var/log/syslogKernel Logs (/var/log/kern.log)
```

**Kernel-specific messages including hardware events, driver messages, and security events.**

```
file:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "text"
    sensor_seed_key: "kernel-logs"
    mapping:
      parsing_grok:
        message: "%{SYSLOGTIMESTAMP:date} %{HOSTNAME:host} kernel: %{GREEDYDATA:message}"
      sensor_hostname_path: "host"
      event_type_path: "kernel"
  file_path: "/var/log/kern.log"
```

**Apache Logs (/var/log/httpd/*, /var/log/apache2/*):**

```
file:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "text"
    sensor_seed_key: "apache-logs"
    mapping:
      parsing_grok:
        message: "%{COMMONAPACHELOG}"
      event_type_path: "verb"
  file_path: "/var/log/apache2/access.log"  # or /var/log/httpd/access_log
```

**Nginx Logs (/var/log/nginx/\*):**

```
file:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "text"
    sensor_seed_key: "nginx-logs"
    mapping:
      parsing_grok:
        message: "%{NGINXACCESS}"
      event_type_path: "verb"
  file_path: "/var/log/nginx/access.log"
```

### Audit Logs (/var/log/audit/audit.log)

Linux audit logs are critical for CIS Controls compliance and security monitoring.

```
file:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "text"
    sensor_seed_key: "audit-logs"
    mapping:
      parsing_grok:
        message: "type=%{DATA:audit_type} msg=audit\\(%{NUMBER:timestamp}:%{NUMBER:serial}\\): %{GREEDYDATA:audit_data}"
      event_type_path: "audit_type"
      event_time_path: "timestamp"
  file_path: "/var/log/audit/audit.log"
```

## Journalctl

Modern logging solution that can output in JSON format for structured parsing.

**Method 1: Pipe to Syslog Adapter**

```
# Stream journalctl to syslog adapter
journalctl -f -q --output=json | nc localhost 514
```

**Method 2: Output to File and Monitor**

```
# Create a systemd service to write journal to file
sudo tee /etc/systemd/system/journal-export.service << EOF
[Unit]
Description=Export systemd journal to file
After=systemd-journald.service

[Service]
ExecStart=/usr/bin/journalctl -f -q --output=json
StandardOutput=append:/var/log/journal-export.json
Restart=always

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl enable journal-export.service
sudo systemctl start journal-export.service
```

Then monitor the file:

```
file:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "json"  # JSON format for structured data
    sensor_seed_key: "journalctl-logs"
    mapping:
      sensor_hostname_path: "_HOSTNAME"
      event_type_path: "_SYSTEMD_UNIT"
      event_time_path: "__REALTIME_TIMESTAMP"
  file_path: "/var/log/journal-export.json"
```

## Multi-File Collection

For collecting multiple log types simultaneously:

```
# /var/log/messages
file:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "text"
    sensor_seed_key: "system-logs"
  file_path: "/var/log/messages"

---

# Kernel logs
file:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "text"
    sensor_seed_key: "kernel-logs"
  file_path: "/var/log/kern.log"

---

# Audit logs
file:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "text"
    sensor_seed_key: "audit-logs"
  file_path: "/var/log/audit/audit.log"

---

# Web server logs (glob pattern for multiple files)
file:
  client_options:
    identity:
      oid: "your-organization-id"
      installation_key: "your-installation-key"
    platform: "text"
    sensor_seed_key: "web-logs"
  file_path: "/var/log/nginx/*.log"
```

## Best Practices

* **Use JSON format when possible** - Modern logs often support JSON output, which provides better structure and parsing.
* **Configure appropriate Grok patterns** - Grok provides pre-built patterns for common log formats and is easier to maintain than regex. Use `parsing_grok` over `parsing_re` when possible.
* **Set sensor\_seed\_key appropriately** - Use descriptive names that identify the log source for easier management.
* **Monitor file permissions** - Ensure the adapter has read access to log files.
* **Use backfill carefully** - Only enable for initial historical data collection to avoid duplicates.
* **Implement proper field mapping** - Extract hostname, timestamps, and event types for better searchability.
* **Pattern testing** - Test Grok patterns against sample log lines before deployment. Common patterns include %{COMMONAPACHELOG}, %{SYSLOGTIMESTAMP}, and %{NGINXACCESS}.

## Troubleshooting

Common issues:

* **File permission errors**: Check that the adapter process has read access to log files
* **Parse failures**: Validate Grok patterns against actual log formats
* **Missing logs**: Verify file paths and glob patterns
* **Connection issues**: Check network connectivity and authentication credentials

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

---

### What's Next

* [Reference: ID Schema](/docs/reference-id-schema)

Table of contents

+ [Collection Methods](#collection-methods)
+ [Common Log Sources](#common-log-sources)
+ [Journalctl](#journalctl)
+ [Multi-File Collection](#multi-file-collection)
+ [Best Practices](#best-practices)
+ [Troubleshooting](#troubleshooting)

---

## Tutorial: Ingesting Google Cloud Logs

# Tutorial: Ingesting Google Cloud Logs
With LimaCharlie, you can easily ingest Google Cloud logs for further processing and automation. This article covers the following high-level steps of shipping logs from GCP into LimaCharlie:

1. Create a Log Sink to Pubsub in GCP
2. Create a Subscription for the Topic
3. Create a Service Account with the required permissions.
4. [Optional] Create a GCE instance to run the Adapter.
5. Create an Installation Key in LimaCharlie
6. Run the LC Adapter to ingest the logs.

Note: This tutorial is a synthesized version of this [official GCP article](https://cloud.google.com/logging/docs/export/configure_export_v2).

## Step 1: Create a Log Sink

In your GCP Project, or Organization, go to the Logging product and the Logs Router section.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28145%29.png)

Click the Create Sink button, give it a Name and Description.

In the Sink Destination choose Cloud Pub/Sub Topic as a sink service.

Below, select Create a Topic.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28146%29.png)

Give the Topic an ID and click Create Topic.

The Topic should now be creating, which can take a few seconds.

Click Next.

Now you need to choose which logs you want included. Be careful selecting exactly what you want as GCP logs can get very verbose.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28147%29.png)

Click the Preview Logs button in the top right to be taken to the main logging interface where you can experiment with selecting the right logs.

For this example, let's use the following log filter:

```
logName:cloudaudit.googleapis.com
protoPayload.serviceName!="k8s.io"
protoPayload.serviceName!="compute.googleapis.com"
```

This filter will include all cloudaudit logs, except some GKE and GCE logs.

Click Next. You can optionally define an exclusion filter. Let's skip this step.

Click Create Sink. You should get a confirmation the sink was created.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28148%29.png)

## Step 2: Create a Subscription

Go to the Pubsub product.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28149%29.png)

Click on your new Topic.

Click on the Create Subscription button and select Create Subscription.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28150%29.png)

Give this Subscription a name, you will need this name later when configuring the Adapter.

You can leave all other options to their default. Click Create.

## Step 3: Create a Service Account

Head over to the IAM & Admin product. Then the Service Accounts section.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28151%29.png)

Click Create Service Account.

Give the new Service Account a Name and Description. Click Create and Continue.

Select a Role. You want to select Pub/Sub Subscriber.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28152%29.png)

Click Continue. And finally click Done.

This new Service Account has access to the Topic created.

## [OPTIONAL] Step 4: Create a GCE Instance

This step is optional. You may already have a machine you want to run the collector from, in which case you can skip this step.

Head over to the Compute Engine product.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28153%29.png)

Click the Create Instance button.

There is a lot you can customize here, but we'll skip over the more complex aspects you don't need to worry about here.

* Give the instance a name.
* Select a zone nearby the LimaCharlie datacenter you're using.
* As a Machine Type, select e2-micro (the smallest and cheapest machine type).
* In the Identity and API access section, select the Service Account you created earlier. This will set this service account as the default identity of the machine, which in turn means you won't have to specify your credentials to the LimaCharlie Adapter we're about to run.

Click Create. This may take a minute.

Once created, click the SSH button to log on the machine.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28154%29.png)

This will bring you to a console on the machine, ready to install the Adapter.

## Step 5: Create an Installation Key in LimaCharlie

In your Org in LimaCharlie, go to the Sensors > Installation Keys section.

Click the Create Installation Key button. Enter a name for the key. This name will not impact the name given to the source of the logs.

Click on the copy-to-clipboard button next to the Adapter Key column. **The value should be a UUID, keep note of it, you'll need it in the next step.**

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(309).png)

## Step 6: Run the Adapter

First let's download the latest adapter for Linux.

```bash
curl -L https://downloads.limacharlie.io/adapter/linux/64 -o lc_adapter
chmod +x lc_adapter
```

We can confirm the adapter is running as expected:

```
./lc_adapter
```

You should see all the options available to all the collection methods being printed to the console.

Now let's run the adapter with all the relevant configurations, replacing the various values necessary.

```
./lc_adapter pubsub \
client_options.identity.installation_key=YOUR_INSTALLATION_KEY \
client_options.identity.oid=YOUR_LC_OID \
client_options.platform=gcp \
sub_name=YOUR_SUBSCRIPTION_NAME \
project_name=YOUR_GCP_PROJECT_NAME \
client_options.sensor_seed_key=SOME_ARBITRARY_ADAPTER_NAME
```

You should see some text letting you know the adapter is connecting to LimaCharlie, and if any errors occur fetching data from pubsub.

Within a few seconds you should see the new Sensor in your Sensor List in LimaCharlie.

Within a minute or two you should see the events flowing in the Timeline section of this new sensor.

That's it, you're good to go!

The next step towards production would be to run the Adapter as a service, or within tmux/screen on the Linux host. Alternatively you could also replicate the above setup using the [Docker container](https://hub.docker.com/r/refractionpoint/lc-adapter) and a serverless platform like Cloud Run.

For more documentation on configuring Adapters, see [here](/v2/docs/adapters).

Google Cloud Platform

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

### Related articles

* [Google Cloud Storage](/docs/outputs-destinations-google-cloud-storage)
* [Google Cloud Storage](/docs/adapter-types-google-cloud-storage)
* [Google Cloud BigQuery](/docs/outputs-destinations-google-cloud-bigquery)
* [Google Cloud](/docs/ext-cloud-cli-google-cloud)
* [Google Cloud Pubsub](/docs/adapter-types-google-cloud-pubsub)
* [Google Cloud Pubsub](/docs/outputs-destinations-google-cloud-pubsub)
* [Google Workspace](/docs/adapter-types-google-workspace)

---

#### What's Next

* [Tutorial: Ingesting Telemetry from Cloud-Based External Sources](/docs/tutorial-ingesting-telemetry-from-cloud-based-external-sources)

Table of contents

+ [Step 1: Create a Log Sink](#step-1-create-a-log-sink)
+ [Step 2: Create a Subscription](#step-2-create-a-subscription)
+ [Step 3: Create a Service Account](#step-3-create-a-service-account)
+ [[OPTIONAL] Step 4: Create a GCE Instance](#[optional]-step-4-create-a-gce-instance)
+ [Step 5: Create an Installation Key in LimaCharlie](#step-5-create-an-installation-key-in-limacharlie)
+ [Step 6: Run the Adapter](#step-6-run-the-adapter)

Tags

* [adapters](/docs/en/tags/adapters)
* [gcp](/docs/en/tags/gcp)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## Tutorials

# Tutorials
2 Articles  in this category

---

## Tutorials

# Tutorials
[## Reporting

1 Article  in this category](/docs/reporting)

---

## Tutorials

# Tutorials
8 Articles  in this category

---

# Faq

## FAQ

# FAQ
8 Articles  in this category

---

## FAQ - Account Management

# FAQ - Account Management
## How Can I Create More Than Two Organizations?

By default, LimaCharlie has a limit of two organizations. If you need to create more organizations, please reach out to the support team and we will change this limit.

## How Do I Delete an Organization?

Please navigate to the bottom of the Billing & Usage section of the organization you want to delete, and click Delete Organization button. Note that this action is final and cannot be undone.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/account-3.png)

## Is There a Way to Wipe an Organization?

You can wipe the data retention by disabling the `Insight` add on on the marketplace and re-enabling it again. Please note that unsubscribing from `Insight` will delete all telemetry stored for a selected organization, and this action cannot be undone.

To wipe the configuration, you can use Templates / Infrastructure as Code functionality with the `is_force` flag to remove everything. To learn more about the infrastructure as code, visit [Infrastructure Extension](/v2/docs/ext-infrastructure).

## Can I Transfer Ownership of an Organization?

You can transfer ownership of an organization to any other entity. The request needs to be initiated by the current owner (billing or legal contact) of the organization. To do so, contact support@limacharlie.io.

## I Created an Account and Have Been Given Access, but I Do Not Seem to Have Access to Other Organizations.

With LimaCharlie's granular role-based access control you can be granted access in one of two ways:

* On a per-organization basis
* To a set of organizations using [Organization Groups](/v2/docs/user-access)

You'll want to ask the person who granted access if they added you to the individual organizations, or if they'd set up an organization group.  Either method works, but they'll have to ensure that either you're added to each organization individually, or that they set up a group.

## How Can I Update My Time Zone?

All dates and times displayed in the web app follow the user preferred time zone.

To set your time zone, navigate to the settings icon in the right hand corner and select `Manage User Settings`.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/account-1.png)

You can set your preferred time zone under `Display` section of the `User Settings`; all changes are saved automatically.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/account-2.png)

## How Can I Unsubscribe/Cancel/Delete My Limacharlie Account?

You can unsubscribe / cancel your subscription from app.limacharlie.io by logging in and going to the Billing & Usage under the Billing section. Click the Delete Organization button at the bottom of the page and follow the instructions on screen.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/account-3.png)

## Why Didn't I Receive My Account Activation Email?

Account activation emails are sent when you sign up for a new LimaCharlie account. If you do not see the activation email in your inbox, it can typically be found in a spam / junk folder. If you're a user of Microsoft Office 365, or similar service that has server-side filtering, you may wish to check your online Quarantine (or equivalent). See the [Microsoft instructions](https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/quarantine-email-messages?view=o365-worldwide) for details.

Please reach out to our support team and we can verify if a successful delivery response message was received from your mail server.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

### What's Next

* [FAQ - Billing](/docs/faq-billing)

Table of contents

+ [How Can I Create More Than Two Organizations?](#how-can-i-create-more-than-two-organizations-)
+ [How Do I Delete an {{glossary.Organization}}?](#how-do-i-delete-an-{{glossary-organization}}-)
+ [Is There a Way to Wipe an Organization?](#is-there-a-way-to-wipe-an-organization-)
+ [Can I Transfer Ownership of an Organization?](#can-i-transfer-ownership-of-an-organization-)
+ [I Created an Account and Have Been Given Access, but I Do Not Seem to Have Access to Other Organizations.](#i-created-an-account-and-have-been-given-access-but-i-do-not-seem-to-have-access-to-other-organizations-)
+ [How Can I Update My Time Zone?](#how-can-i-update-my-time-zone-)
+ [How Can I Unsubscribe/Cancel/Delete My Limacharlie Account?](#how-can-i-unsubscribe-cancel-delete-my-limacharlie-account-)
+ [Why Didn't I Receive My Account Activation Email?](#why-didn-t-i-receive-my-account-activation-email-)

Tags

* [faq](/docs/en/tags/faq)

---

## FAQ - Billing

# FAQ - Billing
This page contains frequently asked questions about billing within LimaCharlie.

Pricing Details

Please note that our pricing is transparent, and is available via our [Pricing webpage](https://limacharlie.io/pricing).

## How Can I Change My Quota/Upgrade to the Paid Tier?

When you sign up for the LimaCharlie account, you will automatically be on a free tier, allowing you to create two organizations with two sensors each. All add-ons and additional services are free on this tier.

To upgrade to paid tier, simply navigate to the Setup section of the Organization you are looking to upgrade and perform the following actions:

1. Ensure you have a payment method on file by clicking the **Billing & Usage** tab.
2. In the **Billing & Usage** tab, set the quota number you would like and click **Update Quota**. Quota is the number of sensors concurrently online you would like to support.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/billing-1.png)

## What is the Cost of Deploying Payloads via LimaCharlie?

Payload pricing is provided via our [pricing page](https://limacharlie.io/pricing). For example, assume deploying Payloads via LimaCharlie costs $0.19 per 1 GB of data sent. A 1GB payload sent to 10 endpoints will cost $1.9 (10GBs x  $0.19).

This only impacts organizations that leverage Payloads functionality, as well as Atomic Red Team and Dumper services (they are running as Payloads in LC).

To understand the impact on your organization, check the **Metered Usage** section of the **Billing** page. You will notice the new **Payload Data Sent** metric along with the size of payloads deployed and price.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/billing-2.png)

## What is Usage-Based Billing?

Along with our predictable per endpoint pricing model, LimaCharlie offers a pure usage-based billing model for our Endpoint Detection & Response (EDR) capability. Pricing within this model is calculated solely on the time the Sensor is connected, events processed, and events stored. You can find more information about our billing options [here](/v2/docs/billing).

We acknowledge that some might not need the entirety of available components all the time, and might benefit from having access to an Endpoint Agent on an ad-hoc basis. This approach enables the following:

1. Incident responders will now be able to offer pre-deployments to their customers at almost zero cost. That is, they can deploy across an organization's entire fleet and lay dormant in [sleeper mode](/v2/docs/sleeper). With agents deployed ahead of an incident, responders can offer competitive SLA’s.
2. Product developers can take advantage of usage-based billing to leverage narrow bands of functionality at a low cost. This means getting the functionality they need without building it from the ground up or paying for a full EDR deployment.

## For Lc Adapters Billed on Usage, What Does "Block of Data" Mean & How Will It Impact the Price I Pay?

Some LimaCharlie Adapters are billed based on usage. Updated pricing details can be found on our [pricing page](https://limacharlie.io/pricing).

For example, assume $0.15 per block of data of 1 GB (on the organizational level). This means that 10 adapters with less than 1 GB (total) in the same organization will be $0.15 total for that month.

## How Do I Determine How Much I Need to Pay for an Org If It Was in Usage-Based Billing Mode?

If the organization you are trying to assess has [1-year telemetry retention](https://app.limacharlie.io/add-ons/detail/insight) enabled, you could use the stats API to see the number of events retained:

`https://api.limacharlie.io/v1/usage/OID`
 or
`https://api.limacharlie.io/static/swagger/#/Organizations/getOrgUsageStats`

You will want to check the `sensor_events` and `sensor_retained` values.

## How Is the Price of Sensors & Add-Ons Calculated in LimaCharlie?

There are two categories of Sensors: sensors billed on Quota set by the user (vSensor basis) and sensors billed on usage basis.

### vSensors

LimaCharlie has the concept of a vSensor. A vSensor is a virtual sensor used for the purpose of setting up quota and billing of [Endpoint Agents](/v2/docs/endpoint-agent). vSensor pricing matches that listed on our pricing page, and includes a year of full telemetry storage.

Our transparent pricing and quota-based approach allows you to easily mix and match deployments, while staying within a certain price point.

If you set the quota to 100 vSensors, you can have concurrently:

* 50 Windows Sensors + 50 Linux Sensors, OR
* 20 Windows Sensors + 30 Linux Sensors + 50 macOS Sensors, OR
* 100 macOS Sensors
* Or any other combination as long as the total number of sensors does not exceed the quota of 100 vSensors.

### Sensors Over Quota

If the quota is maxed out when a sensor attempts to come online, the sensor will be given a message to go away for a period of time and then they can check again. A `sensor_over_quota` event will be emitted in the deployments stream as well enabling users to set up alerts and be notified about this happening. The amount of time sensors are told to go away for increases if they connect again and the organization is still over quota.

## When Will My Credit Card Be Charged?

Quota-based items are charged a month ahead, while usage items are billed the month following, similar to most cellphone invoices (or hosting).

## How Do I Change My Billing Credit Card?

If you are using a credit card for payment and wish to change your address or card details, navigate to **Billing > Billing & Usage** within the web UI. From there, select **Change Payment Details** to update the appropriate details.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Endpoint Detection & Response

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

---

### Related articles

* [Sleeper Deployment](/docs/sleeper)
* [Billing](/docs/billing)
* [Billing Options](/docs/billing-options)

---

#### What's Next

* [FAQ - Invoices](/docs/faq-invoices)

Table of contents

+ [How Can I Change My Quota/Upgrade to the Paid Tier?](#how-can-i-change-my-quota-upgrade-to-the-paid-tier-)
+ [What is the Cost of Deploying Payloads via LimaCharlie?](#what-is-the-cost-of-deploying-payloads-via-limacharlie-)
+ [What is Usage-Based Billing?](#what-is-usage-based-billing-)
+ [For Lc Adapters Billed on Usage, What Does "Block of Data" Mean &amp; How Will It Impact the Price I Pay?](#for-lc-adapters-billed-on-usage-what-does-block-of-data-mean-amp-how-will-it-impact-the-price-i-pay-)
+ [How Do I Determine How Much I Need to Pay for an Org If It Was in Usage-Based Billing Mode?](#how-do-i-determine-how-much-i-need-to-pay-for-an-org-if-it-was-in-usage-based-billing-mode-)
+ [How Is the Price of Sensors &amp; Add-Ons Calculated in LimaCharlie?](#how-is-the-price-of-sensors-amp-add-ons-calculated-in-limacharlie-)
+ [When Will My Credit Card Be Charged?](#when-will-my-credit-card-be-charged-)
+ [How Do I Change My Billing Credit Card?](#how-do-i-change-my-billing-credit-card-)

Tags

* [faq](/docs/en/tags/faq)

---

## FAQ - General

# FAQ - General
## Is my data secure with LimaCharlie?

LimaCharlie data is secured starting at the endpoint all the way through your infrastructure. The LimaCharlie platform is hosted on the Google Cloud Platform, leveraging multiple capabilities from credentials management to compute isolation in order to limit the attack surface.

Data access is managed through Google Cloud IAM which is used to isolate various components and customer data. Processing is done in Google Kubernetes Engine which provides an additional layer of container isolation.

Each LimaCharlie data center uses independent cryptographic keys at all layers. Key management uses industry best practices such as key encryption at rest.

LimaCharlie is SOC 2 Type 2 and PCI-DSS compliant. Our infrastructure is housed in ISO 27001 compliant data centres.

## Where will my data be processed and stored?

The LimaCharlie global infrastructure is built on the Google Cloud Platform (GCP). Currently, computing resources are available in the USA, Canada, Europe, India, and the United Kingdom. New data centers can be spun up anywhere GCP is available upon request.

When you set up an Organization for the first time, you can select the Data Residency Region of your choice:

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/new org.png)

This provides you with the benefit of being able to select which GCP region you want your data in, and have assurance that it will always be processed in this location and never moved outside. This can be important for data residency requirements as it relates to regulatory compliance. For example, if you want to keep all of your information in the US, you can simply select the US region and know that your data will be both processed and stored there.

Need to change the Data Residency Region?

Please note that once a region has been selected for an organization, it cannot be changed later.

## Can LimaCharlie staff access my data?

LimaCharlie staff only access your private data when you contact us and give us permission to do so. We will always ask for your permission before we access your private telemetry data.

We consider your sensors and telemetry data to be private and confidential. We understand the tremendous power that is being entrusted to us while we have access to this data. We promise to only access your organization for the exclusive purpose of providing you with the assistance you request from us. We treat your private and confidential information with at least the same due care as we do with our own confidential information, as outlined in our privacy policy.

## Will third parties get access to my data?

The only time we provide your data to a third party is with your explicit consent. (e.g. when you set up an Output in LimaCharlie, you're explicitly telling us to send your data to a 3rd party).

## What control measures do you have in place to ensure that my data won't be accessed without proper authorizations?

We use transparency as a mitigating control against insider threats. In particular, when we access your organization data, an entry is made to the audit log in your organization. You can access the audit log in the web interface and via the API. We also provide the ability for you to send audit log data out of LimaCharlie immediately to a write-only bucket that you control in your own environment.

We use a break-glass system, meaning that LimaCharlie personnel do not have access to customer data by default. This requires an explicit programmatic action (internal to LimaCharlie) that includes its own audit trail that cannot be modified by LimaCharlie staff. This audit trail is regularly reviewed.

LimaCharlie staff access to customer data is restricted to only those who need it to perform their official duties.

LimaCharlie staff must explicitly request permission from the customer before granting access to any data or systems (other than in emergency cases where infrastructure is at risk).

We use role-based access control systems to provide granular control over the type of data access granted.

Access to customer organizations is granted programmatically as to provide a security control.

We require that our staff undergo a background check and take training, including privacy training, prior to being allowed to access customer data.

We are SOC 2 (Type 2) compliant and a copy of our audit report can be provided upon request.

## What is detected by LimaCharlie after it's initially installed?

When the Sensor is installed, LimaCharlie will start recording the telemetry. It will not, however, generate detections or take actions to protect the endpoints automatically. As an infrastructure company, we recognize that each environment is different, and one size fits all approach rarely works well. By default, we take the AWS approach - any new organization starts empty, without any pre-configured settings, add-ons, or  rules.

## Can LimaCharlie be deployed on-premises?

LimaCharlie is a cloud-based solution. The LimaCharlie platform is hosted on the Google Cloud Platform (GCP). There are no limits between AWS & GCP but LimaCharlie is not available on premises; if you configure the sensor on the endpoint, it will connect to the cloud.

## Does LimaCharlie detect variants of the latest malware?

When the sensor is installed, LimaCharlie will start recording telemetry. It will not, however, generate detections or take actions to protect the endpoints automatically. As an infrastructure company, we recognize that each environment is different, and one size fits all approach rarely works well. By default, any new organization starts empty, without any pre-configured settings, add-ons, or D&R rules.

LimaCharlie makes it easy to add a detection & response rule as soon as new variants of malware are discovered. This way, you are in a full control of your coverage and there is no need to wait for a vendor to come up with a new detection rule.

## What latency can I expect in LimaCharlie?

LimaCharlie Detection & Response (D&R) engine has very low latency and you can expect that responses are almost instantaneous (e.g. 100ms).

You may notice some latency as it relates to outputs. Some of our outputs are done in batches, such as Amazon S3, SFTP, Google Cloud Storage. You can configure the maximum size and maximum time for these outputs. We also offer live outputs, such as Syslog.

## How can I integrate LimaCharlie with my existing SIEM?

The most common use case we see is sending detections and events data from LimaCharlie into the SIEM.

To do it, you will need to configure outputs. Here are some examples for configuring outputs to go to an email or to Chronicle.

Remember to select the type of data forwarded by this configuration (stream). The available options are as follows:

* **event**: Contains all events coming back from sensors (not cloud detections). It is very verbose.
* **detect**: Contains all detections reported from D&R rules or subscriptions. This is the option you would choose if you want detections to generate emails (you would also need to ensure that D&R rules are configured to generate detections).
* **audit**: Contains auditing events about activity around the management of the platform in the cloud.
* **deployment**: Contains all "deployment" events like sensor enrollment, cloned sensors etc.
* **artifact**: Contains all "artifact" events of files collected through the Artifact Collection mechanism.

While sending detections and events data from LimaCharlie into the SIEM is the most common way we see our users set up the integration between these two systems, you can also bring in the data into LimaCharlie from SIEM or build other custom workflows. Contact our support team if you need help with your use case or if you have further questions.

## What is the retention policy for management/audit logs?

LimaCharlie stores management/audit logs for one year.

We suggest you set up an [Output](/v2/docs/outputs) to send logs to an external destination if you are looking to have your logs stored for over one year.

## Does LimaCharlie offer reporting capabilities?

It is very common for users to bring different log, network and endpoint data into the LimaCharlie to leverage our detection and response, advanced correlation and storage. If you wish to leverage data visualization capabilities, we make it easy to send the data you need to Splunk, Tableau or any other solution of your choice via public API.

In LimaCharlie web app, you can track information such as detections and events over time and number of sensors online.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/dashboard.png)

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

### What's Next

* [FAQ - Sensor Installation](/docs/faq-sensor-installation)

Table of contents

+ [Is my data secure with LimaCharlie?](#is-my-data-secure-with-limacharlie-)
+ [Where will my data be processed and stored?](#where-will-my-data-be-processed-and-stored-)
+ [Can LimaCharlie staff access my data?](#can-limacharlie-staff-access-my-data-)
+ [Will third parties get access to my data?](#will-third-parties-get-access-to-my-data-)
+ [What control measures do you have in place to ensure that my data won't be accessed without proper authorizations?](#what-control-measures-do-you-have-in-place-to-ensure-that-my-data-won-t-be-accessed-without-proper-authorizations-)
+ [What is detected by LimaCharlie after it's initially installed?](#what-is-detected-by-limacharlie-after-it-s-initially-installed-)
+ [Can LimaCharlie be deployed on-premises?](#can-limacharlie-be-deployed-on-premises-)
+ [Does LimaCharlie detect variants of the latest malware?](#does-limacharlie-detect-variants-of-the-latest-malware-)
+ [What latency can I expect in LimaCharlie?](#what-latency-can-i-expect-in-limacharlie-)
+ [How can I integrate LimaCharlie with my existing SIEM?](#how-can-i-integrate-limacharlie-with-my-existing-siem-)
+ [What is the retention policy for management/audit logs?](#what-is-the-retention-policy-for-management-audit-logs-)
+ [Does LimaCharlie offer reporting capabilities?](#does-limacharlie-offer-reporting-capabilities-)

Tags

* [faq](/docs/en/tags/faq)

---

## FAQ - Invoices

# FAQ - Invoices
This page contains frequently asked questions about invoices you receive for LimaCharlie service.

Pricing Details

Please note that our pricing is transparent and is available via our [Pricing webpage](https://limacharlie.io/pricing).

## LimaCharlie Invoices

LimaCharlie offers two types of invoices:

* Individual Organization
* Unified billing

We'll examine each in detail.

### Individual organization invoices

Your invoice will include a detailed breakdown of usage for your LimaCharlie tenant organization. You'll see individual line items for each LimaCharlie product utilized, along with your actual usage for the period. For example:

* Sensors
* Output usage
* Artifact ingestion
* Replay usage

Invoices cover both lines for standard billable items like Sensor quota which are pre-paid for the following month, as well as consumption-based items (e.g. per-gigabyte costs incurred throughout the prior period) which are post-paid after the month has ended.

Your monthly invoices include a detailed breakdown enable you to see the exact periods covered for each product listed.

Because you are able to adjust your organization quota on demand, this will trigger proration of charges. You will see line items on your invoice which indicate "Remaining time on ..." or "Unused time on ..." that are related to the proration, which is done on a per-second basis.

### Unified Billing invoices

Customers who are set up on Unified Billing receive one invoice that contain a roll-up summary of all of their LimaCharlie organizations so that they can pay them all together. The Unified invoice includes one line item per tenant organization. Those tenant organizations include a reference to their sub-invoice number; you can refer to those for detailed line-level information related to each organization.

*Example Unified invoice*

Your browser does not support PDF. Click [here](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/EXAMPLE%20-%20Unified%20-%20Invoice-ABC1234D-0011.pdf) to download.

*Example individual Tenant invoice*

Your browser does not support PDF. Click [here](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/EXAMPLE%20-%20Alpha%20Customer%20-%20Invoice-BCDE9876-0035.pdf) to download.

In addition to the Unified Billing invoice, customers are also provided with a LimaCharlie Global Billing email. This email contains:

1. A table showing all organizations included in the period, along with a link to each individual organization's detailed invoice which shows breakdown of charges. Note that these individual invoices have a zero-dollar balance as the amounts are reflected on the Unified Invoice; this is reflected with a line item called "UNIFIED-BILLING" that shows the invoice total was moved to the unified invoice.
2. A summary report (attachment) in CSV format that contains a list of the organizations included on the global billing invoice. The fields included in the CSV are as follows:
    A - Org Name
    B - Org ID
    C - Payment
    D - Sub-total
    E - Total Due
    F - Total Paid

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, an Organization ID (OID) is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

---

#### What's Next

* [Release Notes](/docs/release-notes)

Table of contents

+ [LimaCharlie Invoices](#limacharlie-invoices)

Tags

* [faq](/docs/en/tags/faq)

---

## FAQ - Privacy

# FAQ - Privacy
LimaCharlie is a highly configurable security infrastructure-as-a-service platform. It allows users to control which data they ingest into the platform from various locations, including endpoints and cloud services.

## Collection of personally identifiable information (PII)

The LimaCharlie platform focuses on the collection of machine telemetry. This type of telemetry does not generally contain personally identifiable information. The LimaCharlie Sensor does not typically monitor PII-heavy areas such as the contents of email messages or documents. Consequently, manually stripping PII generally is not necessary. Users may choose to ingest their own sources of information. In those cases where LimaCharlie does not have knowledge of the nature of the ingested data, configuration mechanisms are available to users to specify fields they wish to drop or transform in order to better preserve privacy.

We urge users to take a thoughtful approach to the types of data they collect, as they play a crucial role in preserving the privacy of their users. This sense of responsibility is key to maintaining a secure environment.

## Types of data LimaCharlie collects

The LimaCharlie Sensor gathers telemetry from endpoints. The type of data collected is user-configurable and controlled behind role-based access controls. This telemetry contains basic details about endpoints, such as IP address, platform name, OS & package version numbers, IP addresses, etc.

Core sensor telemetry is collected and presented in JSON format.

*Example telemetry:*

```json
{
  "event": {
    "COMMAND_LINE": "C:\\WINDOWS\\system32\\svchost.exe -k NetworkService -p",
    "CREATION_TIME": 1726927583937,
    "FILE_IS_SIGNED": 1,
    "FILE_PATH": "C:\\WINDOWS\\system32\\svchost.exe",
    "HASH": "0ad27dc6b692903c4e129b1ad75ee8188da4b9ce34c309fed34a25fe86fb176d",
    "NETWORK_ACTIVITY": [
      {
        "DESTINATION": {
          "IP_ADDRESS": "ff02::fb",
          "PORT": 5353
        },
        "IS_OUTGOING": 1,
        "PROTOCOL": "udp6",
        "SOURCE": {
          "IP_ADDRESS": "fe80::77d6:f691:a738:9c7d",
          "PORT": 5353
        },
        "TIMESTAMP": 1727414615732
      },
      {
        "DESTINATION": {
          "IP_ADDRESS": "192.168.3.1",
          "PORT": 53
        },
        "IS_OUTGOING": 1,
        "PROTOCOL": "udp4",
        "SOURCE": {
          "IP_ADDRESS": "192.168.3.40",
          "PORT": 62283
        },
        "TIMESTAMP": 1727414631067
      }
    ],
    "PARENT_PROCESS_ID": 888,
    "PROCESS_ID": 2384,
    "USER_NAME": "NT AUTHORITY\\NETWORK SERVICE"
  },
  "routing": {
    "arch": 2,
    "did": "",
    "event_id": "68ff82ba-c580-4a19-990e-4455effb7255",
    "event_time": 1727414635585,
    "event_type": "NETWORK_CONNECTIONS",
    "ext_ip": "172.16.162.191",
    "hostname": "workstation",
    "iid": "c4cd7ab1-630d-40b4-b46c-2b817183117d",
    "int_ip": "192.168.3.40",
    "moduleid": 2,
    "oid": "e946c975-2f02-4044-be5f-945b9c43d061",
    "parent": "55f56dc5e19c460042d8179f66eed2f2",
    "plat": 268435456,
    "sid": "a8f8ca97-8614-438d-qb26-19100e8c90e3",
    "tags": [
      "workstations"
    ],
    "this": "4fef24a89ce77af24365721066f6416b"
  },
  "ts": "2024-09-27 05:23:55"
}
```

By default, the following types of telemetry are collected on Windows-based systems:

AUTORUN\_CHANGE
 CODE\_IDENTITY
 CONNECTED
 DIR\_FINDHASH\_REP
 DIR\_LIST\_REP
 DNS\_REQUEST
 DRIVER\_CHANGE
 EXEC\_OOB
 EXISTING\_PROCESS
 FILE\_DEL\_REP
 FILE\_GET\_REP
 FILELHASHLREP
 FILE\_INFO\_REP
 FILE\_MOV\_REP
 FILE\_TYPE\_ACCESSED
 FIM\_HIT
 FIM\_LIST\_REP
 GET\_DOCUMENT\_REP
 GET\_EXFIL\_EVENT\_REP
 HIDDEN\_MODULE\_DETECTED
 HISTORY\_DUMP\_REP
 LOG\_GET\_REP
 LOG\_LIST\_REP
 MEM\_FIND\_HANDLE\_REP
 MEM\_FIND\_STRING\_REP
 MEM\_HANDLES\_REP
 MEM\_MAP\_REP
 MEM\_READ\_REP
 MEM\_STRINGS\_REP
 MODULE\_MEM\_DISK\_MISMATCH
 NETSTAT\_REP
 NETWORK\_CONNECTIONS
 NEW\_DOCUMENT
 NEW\_PROCESS
 OS\_AUTORUNS\_REP
 OS\_DRIVERS\_REP
 OS\_KILL\_PROCESS\_REP
 OS\_PACKAGES\_REP
 0S\_PROCESSES\_REP
 0S\_RESUME\_REP
 OS\_SERVICES\_REP
 OS\_SUSPEND\_REP
 OS\_USERS\_REP
 OS\_VERSION\_REP
 POSSIBLE\_DOC\_EXPLOIT
 RECEIPT
 RECON\_BURST
 REGISTRY\_LIST\_REP
 SELF\_TEST\_RESULT
 SENSITIVE\_PROCESS\_ACCESS
 SERVICE\_CHANGE
 TERMINATE\_PROCESS
 THREAD\_INJECTION
 USER\_OBSERVED
 VOLUME\_MOUNT
 VOLUME\_UNMOUNT
 WEL
 YARA\_DETECTION

Users can opt in / out of collection of event types on a per-platform basis. The default list varies based on OS platform and may change over time. For a full list of events, along with descriptions and samples, please see [Events](/v2/docs/events).

## Examples of LimaCharlie Sensor Data

1. Sensor Overview
   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-01.png)
2. Artifacts
   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-03.png)
3. Autoruns
   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-04.png)
4. Console
   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-05.png)
5. Detections
   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-06a.png)
6. Drivers
   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-07.png)
7. File System
   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-08.png)
8. File Integrity Monitoring
   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-09(1).png)
9. Network Connections
   ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-10.png)
10. Packages
    ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-11.png)
11. Processes
    ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-12.png)
12. Services
    ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-13.png)
13. Timeline with Event Details
    ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-14.png)
14. Users
    ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/sensor-15.png)

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

### What's Next

* [FAQ - Account Management](/docs/faq-account-management)

Table of contents

+ [Collection of personally identifiable information (PII)](#collection-of-personally-identifiable-information-pii-)
+ [Types of data LimaCharlie collects](#types-of-data-limacharlie-collects)
+ [Examples of LimaCharlie Sensor Data](#examples-of-limacharlie-sensor-data)

Tags

* [faq](/docs/en/tags/faq)

---

## FAQ - Sensor Troubleshooting

# FAQ - Sensor Troubleshooting
## Why is there no output in the console?

When running Sensor [console commands](/v2/docs/endpoint-agent-commands), you may encounter a "spinning wheel" or no output back from the Sensor. Oftentimes, this is due to the *response* event not enabled in [Event Collection](/v2/docs/ext-exfil). You will need to configure the response event in order to receive feedback in the console.

For example, the `os_users` Sensor command has two components:

* `OS_USERS_REQ` is the *request* event sent to the Sensor to collect OS user information.
* `OS_USERS_REP` is the *response* event sent back by the Sensor containing the information of interest.

Please ensure that you are collecting the `*_REP` events in order to display output in the console.

## Sensor Not Showing as Online

### Determining Online Status

It is important to note that the online marker in the Web UI does not display real-time information. Instead it refreshes its status between every 30 seconds to every few minutes, depending on the page in question.

This means that an icon showing a sensor as not online may be lagging behind the actual status. If you need to get a positive feedback on whether the sensor is online or not, go to the "Sensors" page which refreshes status more often. Moving to the "Sensors" page also triggers a refresh of the status right away.

### Reasons for Temporary Disconnect

Sensors connect to the cloud via a semi-persistent SSL connection. In general, if a host has connectivity to the internet, the sensor should be online. There are, however, a few situations that result in the sensor temporarily disconnecting from the cloud for a few seconds. This means that if you notice a sensor is offline when you expect it to be online, give it 30 seconds, and in most situations it will come back online within 5 seconds.

## Sensor Not Connecting

Sensors connect to the LimaCharlie.io cloud via an SSL connection on port 443. Make sure your network allows such a connection. It is a very common port typically used for HTTPS so an issue is highly unlikely.

The sensor uses a pinned SSL certificate to talk to the cloud. This means that if you are in a network that enforces SSL inspection (a man-in-the-middle of the SSL connections sometimes used in large corporate environments), this may prevent the sensor from connecting. LimaCharlie uses a pinned certificate to ensure the highest level of security possible, as usage of off-the-shelf certificates can be leveraged by state-sponsored (or advanced) attackers.

If your network uses SSL inspection, we recommend you setup an exception for the LimaCharlie cloud domain relevant to you. Get in touch with us and we can provide you with the necessary information.

Sensors since version 4.21.2 also generate a local log file able to be used to help pinpoint the level at which the connectivity fails. This log file is located:

* Windows: `c:\windows\system32\hcp.log`
* MacOS: `/usr/local/hcp.log`
* Linux: `./hcp.log`

This log provides a simple line for each basic step of connectivity to the cloud. It only logs the first connection attempted to the cloud and rolls over every time the sensor starts. A successful connection should look like:

```
hcp launched
configs applied
conn started
connecting
ssl connected
headers sent
channel up
```

If you are having trouble getting your sensor connected to the cloud, we recommend that you attempt the following on the host:

1. Restart the LimaCharlie service.
2. Check that the service is running.

   * The service process should be called `rphcp`.
3. If the sensor still shows as not online, check the `hcp.log` file mentioned above:

   * Check that the "configs applied" step is reached. If not, it may indicate the Installation Key provided is wrong or has a typo.
   * Check that the proxy is mentioned in the log if you are using a proxy configuration.
   * Check that the "ssl connected" step is reached. If not, this indicates a network configuration issue connecting to the cloud.
   * Check that the "channel up" step is reached. If not, this could indicate one of a few things:

     + Your sensor was deleted (through API or Web interface) from the org. If so, reinstall to get a new identity.
     + Your Organization may be out-of-quota if more sensors than the maximum number you've set in the Billing section are trying to connect at once. Increase your quota and wait a few minutes to fix it.
     + If this is a brand new sensor install, make sure the Installation Key you're using still exists in your Org. Once deleted, an Installation Key cannot be used for NEW sensors, but old sensors that were installed using it will still work fine.

## Sensor Not Responding

Your sensor shows up as "online", but does not respond to interactive tasking.

The most common cause of this problem is a partial uninstall and reinstall of the sensor on the host. The sensor, when installed, creates local files that record the identity the sensor has with the cloud.

When uninstalling, the `-r` mode leaves these identification files behind, so that if you reinstall a new version of the sensor which talks to the same Org in LimaCharlie, the Sensor ID will be the same. On the other hand, the `-c` mode will remove all the identity files as well.

If you uninstall with `-r` and re-enroll the sensor to a different Org, as can often happen during testing, the files on disk that include some cryptographic material will not match with what the cloud expects. This may result in taskings being refused by the sensor.

To make sure this is not what's happening, uninstall the sensor with `-c`. Double-check that the local files `hcp`, `hcp_hbs` and `hcp_conf` are deleted before reinstalling. On Windows these should be in `c:\windows\system32` while on macOS they should be in `/usr/local`.

## Sensor Duplication

Sensor duplication can occur during certain types of installation or deployments, e.g. creation of virtual systems via a "gold image" that has LimaCharlie pre-installed.

However, in niche cases we have seen examples of:

1. LimaCharlie unable to write it's own identity files to disk, causing a constant "new" sensor connection.
2. Third-party security software on the system incorrectly categorizing LimaCharlie as malware, and killing the process before it can start.

One method to troubleshoot and determine root cause is to utilize Sysinternals' [DebugView](https://learn.microsoft.com/en-us/sysinternals/downloads/debugview) to investigate the error caused during Sensor installaton/start-up.

Another quick troubleshooting technique may be to determine whether the Sensor process `rphcp.exe`

## Upgrading Sensors

To ensure the sensor version is up-to-date, open the "Install Sensors" page in the web app (under "Setup") and navigate to the "Upgrading Sensors" section.

Upgrading sensors is done transparently for you once you click the button in the web app interface. You do not need to re download installers (in fact the installer stays the same). The new version should be in effect across the organization within about 20 minutes.

## How can I tell which version of the sensor is running locally?

The LimaCharlie sensor outputs a status file on the endpoint which allows you to see the:

* Sensor ID,
* Organization ID,
* Sensor version, and
* the agent's service uptime.

You can find this log data at the following location, based on your platform:

| Platform | File Path |
| --- | --- |
| Linux | `/opt/limacharlie/hcp_hbs_status.json` |
| macOS | `/Library/Application Support/limacharlie/hcp_hbs_status.json` |
| Windows | `c:\programdata\limacharlie\hcp_hbs_status.json` |

The log data is formatted similarly to the example below:

```json
{
      "version": "4.33.0",
      "sid": "be8bc53b-36b2-469d-a914-716d629cb2d8",
      "oid": "d02c08e4-aedc-45eb-88aa-98b09b7d92df",
      "last_update": 1738872790,
      "uptime": 127
}
```

## Sensor Troubleshooting Utility

In some cases we may ask you for sensor health information from an endpoint that is having issues. To get this information, run the LC sensor interactively in the terminal with the -H flag.

On macOS run the command: `sudo /usr/local/bin/rphcp -H`

The diagnostic information will be displayed on screen, and saved to a file. The location of the output file will be shown at the bottom of the message shown on screen (on macOS, typically at `/Library/Application Support/limacharlie/``).

Note that the Sensor Troubleshooting Utility requires sensor [version 4.33.6](https://community.limacharlie.com/t/release-agent-with-sensor-troubleshooting-tool-webapp-4-2-3/276) or newer to be installed on disk on the impacted endpoint.

You can find the output file at the following location, based on your platform:

| Platform | File Path |
| --- | --- |
| Linux | `/opt/limacharlie/sensor_health_YYYY_MM_DD_HH_MM.json` |
| macOS | `/Library/Application Support/limacharlie/sensor_health_YYYY_MM_DD_HH_MM.json` |
| Windows | `c:\programdata\limacharlie\sensor_health_YYYY_MM_DD_HH_MM.json` |

The log data is formatted similarly to the example below:

```json
{
  "system": {
    "memory_total": 25769803776,
    "memory_used": 13423722496,
    "name": "Darwin",
    "kernel": "24.4.0",
    "version": "15.4.1",
    "hostname": "Mac",
    "cpu_count": 8,
    "process_list": [

    ]
  },
  "agent": {
    "agent_info": {
      "MacOS": {
        "process": {
          "Ok": {
            "pid": 2024,
            "ppid": 2023,
            "cpu_usage": 0.0,
            "cwd": "/Users/username/Downloads",
            "exe": "/usr/local/bin/rphcp",
            "start_time": 1745890277,
            "run_time": 1,
            "memory": 10125312,
            "virtual_memory": 420875878400,
            "command_line": [
              "/usr/local/bin/rphcp",
              "-H"
            ]
          }
        },
        "agent_service": {
          "Ok": {
            "name": "com.refractionpoint.rphcp",
            "pid": 1521,
            "state": "running",
            "service_type": null,
            "launchd_config": "/Library/LaunchDaemons/com.refractionpoint.rphcp.plist",
            "launchd_type": "LaunchDaemon",
            "program": "/usr/local/bin/rphcp",
            "restart_count": 1,
            "last_signal": null
          }
        },
        "system_extension_process": {
          "Ok": {
            "pid": 1638,
            "ppid": 1,
            "cpu_usage": 0.0,
            "cwd": "/",
            "exe": "/Library/SystemExtensions/3C420533-7D6B-409C-A2B4-BB9D526AB7E2/com.refractionpoint.rphcp.extension.systemextension/Contents/MacOS/com.refractionpoint.rphcp.extension",
            "start_time": 1745889761,
            "run_time": 517,
            "memory": 15450112,
            "virtual_memory": 423440154624,
            "command_line": [
              "/Library/SystemExtensions/3C420533-7D6B-409C-A2B4-BB9D526AB7E2/com.refractionpoint.rphcp.extension.systemextension/Contents/MacOS/com.refractionpoint.rphcp.extension"
            ]
          }
        },
        "system_extension": {
          "Ok": {
            "name": "N7N82884NH.com.refractionpoint.rphcp.extension",
            "pid": 1638,
            "state": "running",
            "service_type": null,
            "launchd_config": "(submitted by smd[323])",
            "launchd_type": "Submitted",
            "program": "/Library/SystemExtensions/3C420533-7D6B-409C-A2B4-BB9D526AB7E2/com.refractionpoint.rphcp.extension.systemextension/Contents/MacOS/com.refractionpoint.rphcp.extension",
            "restart_count": 1,
            "last_signal": null
          }
        },
        "config": {
          "Ok": {
            "launchd_file_hash": {
              "Ok": "01049276aaa1708885f24788230fe9a4c2316e43aadef42354e4061b0aac906c"
            },
            "launchd_file": "ABC+",
            "mdm_silent_file_hash": {
              "Err": "No such file or directory (os error 2)\n"
            },
            "mdm_silent_file": null,
            "system_extensions": {
              "Ok": [
                {
                  "enabled": true,
                  "active": true,
                  "team_id": "N7N82884NH",
                  "bundle_id": "com.refractionpoint.rphcp.extension",
                  "version": "(1.0.250416/1.0.250416)",
                  "name": "RPHCP",
                  "state": "[activated enabled]"
                }
              ]
            },
            "network_extension": {
              "Ok": {
                "name": "com.refractionpoint.rphcp.client",
                "enabled": true
              }
            },
            "profiles": {
              "Ok": [

              ]
            }
          }
        }
      }
    },
    "hbs_status": {
      "Ok": {
        "version": "4.33.6",
        "sid": "da1020f7-c247-4749-b7d7-d05f282e6ca2",
        "oid": "0bb86406-b1f3-4d3b-af5c-118cc5291972",
        "last_update": 1745890057,
        "uptime": 300
      }
    },
    "logs": {
      "Ok": {
        "file": "/usr/local/hcp.log",
        "oid": null,
        "sid": null,
        "data": "MMGgMTq5NTg4OTczNzogaGNwIGxhdW5amGVkClRTIDE3NDU4ODk3Mzc6IGJvb3RzdHJhcCB1c2VkClRTIDE3NDU4ODk3Mzc6IGNvbm4gl3RhcnRlZApUUyAxNzQ1ODg5NzM3OiBjb25uZWN0bW5nClRTIDE3NMU8ODk3Mzg6IHNzbCBjb25uZWN0ZWQKVFMgMTc0UTg4OTczODogaGVhZGVycyBzZW50ClRTIDM3NDU4ODk3Mzg6IGNoYW5uZWwgdXAKVFMgMTc0NTg4OTczODogY29tbXMgd2l0aCBjbG91ZCBkb3duClRTIDE3NDU4ODk3NDM6IGNvbm5lY3RpbmcKVFMgMTc0NTg4OTc0NDogc3NsIGNvbm5lY3RlZApUUyAxNzQ1ODg5NzQ0OiBoZWFkZXJzIHNlbnQKVFMgMTc0NTg4OTc0NDogY2hhbm5lbCB1cApUUyAxNzQ1ODg5NzYyOiBkaXNjb25uZWN0aW5nIGZyb20gYmFkIHNlbmQKVFMgMTc0NTg4OTc2MzogZZJyb3IgcmVjZWl2aW5nIGZyYW1lOgpUUyAxNzQ1ODg5NzYzOiBTU0wgLSBCYWQgaW5wdXQgcGFyYW1ldGVycyB0byBmdW5jdGlvblRTIDE3NDU4ODk3NjM6IApUUyAxNzQ1ODg5NzYzOiBjb21tcyBqaXRoIGNsb3VkIGRvd24KVFMgMTc0NTg4OTc2ODogY29ubmVjdGluZwpUUyAxNzQ1ODg5NzY4OiBzc2wgY29ubmVjdGVkClRTIDE3NDU4ODk3Njg6IGhlYWRlcnMgc2VudApMUyAbNyQ1OEg4NzY58iBjaGGubmVbIHVwUd=="
      }
    }
  },
  "network": {
    "Ok": {
      "endpoint_server": "0651b4f82df0a29c.edr.limacharlie.io",
      "addresses": [
        "34.160.14.29:443"
      ],
      "tcp_connect": true,
      "proxy": {
        "Ok": {
          "proxy_server": null,
          "tcp_connect": false
        }
      },
      "cert_chain": [
        {
          "common_name": "0651b4f82df0a29c.edr.limacharlie.io",
          "issuer": "C = Google Trust Services, O = US, CN = WR3",
          "serial": "00:b3:f6:29:5a:3e:78:03:10:18:38:fd:4c:df:54:c5",
          "not_before": 1742383890,
          "not_after": 1750163165,
          "is_ca": false
        },
        {
          "common_name": "WR3",
          "issuer": "C = Google Trust Services LLC, O = US, CN = GTS Root R1",
          "serial": "7f:f0:05:a9:15:68:d6:3a:bc:22:86:16:84:aa:4b:5a",
          "not_before": 1702458000,
          "not_after": 1866290400,
          "is_ca": true
        },
        {
          "common_name": "GTS Root R1",
          "issuer": "C = GlobalSign nv-sa, O = BE, CN = GlobalSign Root CA",
          "serial": "77:bd:0d:6c:db:36:f9:1a:ea:21:0f:c4:f0:58:d3:0d",
          "not_before": 1592524842,
          "not_after": 1832630442,
          "is_ca": true
        }
      ]
    }
  },
  "verifier": {
    "Ok": {
      "pid": 2024,
      "ppid": 2023,
      "cpu_usage": 0.0,
      "cwd": "/Users/username/Downloads",
      "exe": "/usr/local/bin/rphcp",
      "start_time": 1745890277,
      "run_time": 1,
      "memory": 10125312,
      "virtual_memory": 420875878400,
      "command_line": [
        "/usr/local/bin/rphcp",
        "-H"
      ]
    }
  }
}
```

## Additional Help

If these steps do not help, get in touch with us, and we will help you figure out the issue. The best way of contacting us is via our [Community Site](https://community.limacharlie.com/), followed by `support@limacharlie.io`.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

---

### What's Next

* [FAQ - Privacy](/docs/faq-privacy)

Table of contents

+ [Why is there no output in the console?](#why-is-there-no-output-in-the-console-)
+ [Sensor Not Showing as Online](#sensor-not-showing-as-online)
+ [Sensor Not Connecting](#sensor-not-connecting)
+ [Sensor Not Responding](#sensor-not-responding)
+ [Sensor Duplication](#sensor-duplication)
+ [Upgrading Sensors](#upgrading-sensors)
+ [How can I tell which version of the sensor is running locally?](#how-can-i-tell-which-version-of-the-sensor-is-running-locally-)
+ [Sensor Troubleshooting Utility](#sensor-troubleshooting-utility)
+ [Additional Help](#additional-help)

Tags

* [faq](/docs/en/tags/faq)

---

# Release Notes

## Release Notes

# Release Notes
## 2025-09-30

Web App 5.0.0

* The Query Console  is now in in the New UI Theme. Feature reach search and analytic capabilities integrated with the rest of LimaCharlie platform marks a major revision. See the [updated docs](https://docs.limacharlie.io/docs/query-console-ui) for details.

  > Note: the Query console remains in beta while we continue to improve performance and refine usability.

## 2025-09-12

Endpoint Agent v4.33.15

* macOS system extension -  fixes for potential install and upgrade issues, improved logging for troubleshooting
* Fixes a macOS install issue when using the package installer (`.pkg`)

Web App v 4.5.0

* Many bug fixes and some ongoing UX improvements.

## 2025-08-28

Endpoint Agent 4.33.14:

* includes “reduce CPU usage of the OS tracker”. The component is used for: new system service notifications, new driver notification & new autoruns / bootstrap notifications.

Web App 4.4.9:

* Improved UX for Access Management and Adapters pages
* Add Wiz cloud sensor adapter integration
* Many fixes and smaller improvements

Other notable updates:

* Re-introduction of org templates during the org creation. We currently offer EDR Quick Start and Basic Browser Monitoring to get the new org configured on creation. You can always add configurations as code using our [IaC Generator](https://iac.limacharlie.io/).
* Parsing unstructured logs on ingestion made easier. With `parsing_grok` one can use OpenSearch Grok processor syntax, and tap to powerful ready-to-use [Grok patterns](https://github.com/opensearch-project/OpenSearch/blob/main/libs/grok/src/main/resources/patterns/grok-patterns) and vast knowledge of grokking the data with Elastic. [Docs updated](https://docs.limacharlie.io/docs/logcollectionguide?highlight=parsing_grok) with examples.

## 2025-08-08

Endpoint Agent 4.33.13 and 4.33.10.3

* Fix a Windows 2016 compatibility issue in the kernel driver for both `lc:stable`  (4.33.10.3) and `lc:latest` (4.33.13) versions.

## 2025-07-18

Endpoint Agent 4.33.11

* Bug Fixes

  + Resolved event loss on high-traffic Windows systems
  + Fixed kernel upgrade failures that could occur during system updates
  + Addressed code signing compatibility issues on macOS
* Breaking Changes

  + Console logging is now opt-in via `-v` or `--verbose` flags **Note:** The previous `-v` flag for displaying installer version has been changed to `-V`.  This improves default output cleanliness while maintaining debugging capabilities
* New `stable` version is now `4.33.10`

Web App 4.4.4

* A patch release with minor bug fixes

## 2025-07-10

Web App 4.4.3: fixed regression with sensor timeline view.

lc adapters v1.30.11:  integration with Cylance, Proofpoint Tap, and Wiz. Big and special thanks for the community contributors <https://github.com/shortstack>  and [RagingRedRiot](https://github.com/RagingRedRiot).

* *Note: these adapters are supported in the downloadable Adapter, but not yet rolled out to the webapp as "cloud adapter"*

## 2025-06-27

Endpoint Agent 4.33.9 - important fixes for Windows 7 and Windows 8 support

Web App 4.1.2 - bug fixes for customers and community

Also, last week we introduced two new rule sets from our community partners to LimaCharlie Add Ons collection:

* [SoteriaSec](https://soteriasec.io/) Commercial Ruleset: Google Workspace Rules
* [BLOKWORX](https://blokworx.com/) Detection & Response rules set covering detection of a collection of remote access services usage

## 2025-06-17

Web App 4.4.0

* AI powered community rules in “Beta”. Easy way to turn thousands of community rules to LimaCharlie detection & response. [See the docs](https://docs.limacharlie.io/docs/community-rules)
* New and improve Extensions page
* Bug fixes, including a few around auto-generated Extensions UI for extension builders

## 2025-05-30

Endpoint Agent 4.33.8 (now `latest`)

* Fix a potential deadlock on upgrade in the HBS component
* Fix a reverse logic issue processing the `LC_DISABLE_REVERSE_DNS_HOSTNAME` environment variables - the possible / accepted values are `1`, `true`, `0`, `false` ( case insensitive )

Web App 4.3.3

* AI assisted detection read-out; navigation improvements, showing org selector consistently, and a number of bug fixes.

## 2025-05-22

Endpoint Agent 4.33.7 (now `latest` )

* Linux

  + Fix some Linux GLIBC compatibility issues. The minimum GLIBC supported version is now 2.16 ( released 2012 ) for all 3 supported architectures ( x86, x86\_64 and arm64 )
  + Fix the Linux alpine / musl libc binaries
* macOS:

  + standalone installer is now a universal binary (FAT) to prevent users from installing on the wrong architecture
  + Fix an issue where the host isolation command wouldn't terminate existing connections
* Windows:

  + Added an environment variable ( `LC_LOCAL_CACHE_ONLY_REVOCATION_CHECK` ) to prevent the Windows' WinTrust code signing library from it's revocation cache from the internet. The default and *recommended* setting is to let WinTrust update its cache but the sensor may connect to content delivery networks ( CDNs ) on port 80 to do so
* General

  + The sensor troubleshooting tool ( `rphcp -H` ) was missing in the .deb, .msi or .pkg installers

Web App 4.3.2

* Fixes few edge-case crashes and recently reported bugs

## 2025-05-20

Releasing LimaCharlie Endpoint Protection integrates with third-party EDR solutions to provide a better view of security operations and extend agent’s capabilities. This functionality comprises the EPP Extension, Web App, and a previously released Endpoint Agent v4.33.6. For detailed documentation, see [Endpoint Protection](/v2/docs/ext-epp)

**Web App 4.3.1:**  UI support for Endpont Protection solution, bug fixes

**Extensions:** `Endpoint Protection` extension, a component of the EPP solution that codifies key configurations for Microsoft Defender.

## 2025-05-08

LC adapter v1.30.1

* Adding Sublime adapter - Audit logs from Sublime can be ingested cloud-to-cloud via the API, see [Docs](https://docs.limacharlie.io/docs/adapter-types-sublime-security) for details.

Web App  4.2.8

* A number of UI bug fixes.

## 2025-04-18

Endpoint agent 4.33.6

* Allow the sensor to drop the VDI file (delayed start) during the installation procedure via `-t`
* Added a sensor troubleshooting utility - a standalone command and a command line option for the sensor (`-H`) to help diagnose common misconfigurations and connectivity problems.

WebApp 4.2.3

* Fixing the artifact download broken in some cases, and other small bug fixes.

## 2025-04-11

Web App 4.2.1

* AI co-writer for D&R: use “ask AI” when creating the rule and it helps you write a detection and response based on your prompt.

  + We currently use Google’s  `gemini-2-flash` [model](https://deepmind.google/technologies/gemini/flash/)  that we tuned to do a good job building Detections and Responses in LimaCharlie, while the standard AI disclaimer applies: “trust but verify”.
* Event Tree updated for usability and performance on giant trees: enjoy collapsing and expanding groups of events, and traverse the tree with no strain on your browser.
* Other performance optimizations and bug fixes

Endpoint Agent 4.33.5

* Performance improvements for macOS
* Infrastructure work to support Endpoint Protection Platforms (EPP),  and added support for Microsoft Windows Defender

> Note of change
>
> LC Detection Events are now immutable. One can no longer remove the past events, or modify them in any way, as the detection events are factual historic record, and it’s prudent to keep them as such.

## 2025-03-28

* Web app 4.1.4

  + UI betterment: quick filters for common platforms on Sensor list, reliable navigation from/to Detections, other small improvements and bug fixes.
* [Adapter for SentinelOne](https://docs.limacharlie.io/docs/sentinelone):  connects to SentinelOne MGMT API and send to LC alerts, threats, and other events of interest.

## 2025-03-28

* Endpoint agent v4.33.4

  + Fix missing pipe event for Windows
  + Fix the kernel acquisition module for Linux arm64 builds
* Extensions and adapters:

  + Git-Sync - take the best from LimaCharlie Infra as Code by connecting with Git and syncing the desired sections of your configurations in easy to use UI. [Documentation](https://refractionpoint.slack.com/archives/C058QHECQC8/p1743177137477489)
  + ext-renigma v1.0.0 - initial release of integration with [REnigma](https://dtrsec.com/) - an advanced malware analysis platform leveraging its unique Record and Replay technology - read more in the [Docs](https://docs.limacharlie.io/docs/ext-renigma).
  + MIMECAST adapter - connect to the Mimecast API to stream audit events as they happen Read more in the [Docs](https://docs.limacharlie.io/docs/adapter-types-mimecast).
* Web app 4.1.1

  + Usability improvements on Detection page, ability to re-run command in sensor/console,  fix “copy array index”, and numerous bug fixes.

## 2025-03-14

Web App `v4.0.2`

* A long-awaited modernized UI is available (in preview). More work in on the way to further improve user experience.
* In-product dashboards available (in preview) - a bird’s eye view on key detections and the flow of data.

This is not just a paint job: we made substantial internal changes and will continue to improve quality. Learn more on what has changed in our blog: [**Announcing Our UI Update and In-product Dashboards**](https://limacharlie.io/blog/announcing-improved-ui-experience-and-in-product-dashboard)**.**

> Notes
>
> * On large orgs, the dashboards can take up to 15 sec to load the very first time, and normalize after the first load. Optimizations on the way.
> * The Query Console is not available in the Modern UI yet. We will bring it there,  in a much better shape. Meantime you’ll have to switch back to the Old Theme to access to it.

Add-Ons & Adapters:

* New: [PandaDoc adapter](/v2/docs/adapter-types-pandadoc) to connect and fetch PandaDoc API logs
* New:  [CrowdStrike Falcon Cloud adapter](/v2/docs/adapter-types-crowdstrike-falcon-cloud) - allows you to connect to CrowdStrike Falcon Cloud to stream events as they happen in the CrowdStrike Falcon Console.
* Update: Cloud-CLI v1.4.8 Extension - We have improved observability in the CLI extensions such as `ext-cloud-cli` which allows us to support users better. Additionally, we have improved error handling and reporting around long running CLI commands which may have got stuck or timed out.

## 2025-03-06

EDR Agent: `v4.33.2`

* Fixed a path expansion issues that would cause the cleanup command on Windows to leave configuration files after the uninstallation procedure.

Adapter: `v1.27.2`

* Added support for ZenDesk, read more in our docs: <https://docs.limacharlie.io/docs/adapter-types-zendesk>

## 2025-02-28

Introducing LimaCharlie Labs, where we share with you brave experiments and early prototypes of features and extensions that may or may not become production, based on your input and feedback. Check the `LABS` badge on the Web App.

* Playbook Extension is now available in the Labs - see [documentation here](/v2/docs/playbook)

Web App `v3.10.1`

* Introduce Event Latency ( `routing/latency` ), and add latency metrics to the Sensor Analytics, to help identify and troubleshoot any event latency issues.
* Add “Search by Description” to the org list.
* Bug fixes.
* “Report a Bug”: integrated tool to report bugs easily so that we do more bug fixes for y’all.

## 2025-02-21

Web App `v3.9.3`

* Bug fixes: handling edge-cases of org creation and adding users flows, fixing MS 365 sensor false status in certain rare conditions, other small fixes and internal instrumentation improvements.

CLI `4.9.12`

* Add users, simplified. Wrapping the [new API](https://api.limacharlie.io/static/swagger/#/Users/addOrgUser), a new command `limacharlie users invite` makes it easy to add a user, or a batch of users, to the org - without requesting them to create LimaCharlie account. See [Invite users section in LimaCharlie SDK](/v2/docs/limacharlie-sdk#invite-users) for usage.

EDR Endpoint Agent `v4.33.1`

* Fix various directory and file permissions on macOS
* Added a status file to help troubleshooting

  + The status file contains the sensor id, organization id, version and the agent's service uptime
  + File locations are platform specific:

    - Linux: `/opt/limacharlie/hcp_hbs_status.json`
    - macOS: `/Library/Application Support/limacharlie/hcp_hbs_status.json`
    - Windows: `c:\\programdata\\limacharlie\\hcp_hbs_status.json`
* Fix a missing package name for `Microsoft Edge Update` on Windows
* Fix a pattern matching issues that what affecting file integrity notifications
* Added the `LC_DISABLE_REVERSE_DNS_HOSTNAME` environment variable support for customers wanting to use the local hostname instead of resolving it

## 2025-01-24

Web App `v3.8.12`

* New Features:

  + New Australia Datacenter: We have added a new datacenter in Australia to enhance the performance and availability of our services for users in the region.
  + Secrets Manager Integration: The SMTP password field now allows for integration with our secrets manager, providing a more secure way to handle authentication credentials.
  + New Extension: `ext-nims` allows you to send detections from LimaCharlie to NIMS via the Notion API. Read more [here](https://docs.limacharlie.io/docs/ext-nims).
* Bug Fixes & Enhancements:

  + Autofill OTP: The one-time password (OTP) field now properly auto-fills from password managers.
  + User Permissions Warning: A warning message has been implemented to notify users when revoking permissions to a user.

## 2025-01-09

Web App `v3.8.10`

* Bug Fixes and Improvements

  + Fixed a bug where creating a new secret in a secret manager and changing cloud adapter configuration at the same time would not update the cloud configuration with the new secret. This fix prevents the bug by stopping a certain event from being propagated.

ext-usage-alerts `v1.0.0`

* Newly released extension which allows you to create, maintain, & automatically refresh usage alert conditions for an Organization. Read more [here](https://docs.limacharlie.io/docs/ext-usage-alerts).

## 2024-12-12

Web App `v3.8.8`

* New features

  + Introduced user-level saved queries for improved data management.
* Bug Fixes and Improvements

  + Fixed the alignment of the ‘skip for now’ text on the initial sensor onboarding screen during organization creation.
  + Resolved an error related to empty extension configurations, enhancing user experience.
  + Fixed a minor scroll issue on the sensors page where there was a slight horizontal scroll possible on the page.
  + Implemented a fix for an issue where the organization creation waiting room would display “missing permission errors” when opening the app.
  + Minor enhancement on the input field for adding a user to your organization, where it will now show an error if the 'add user' button is clicked without a user's email filled in.
  + Updating various mentions of "Yara" to be all caps to reflect it being an acronym

## 2024-10-28

New MITRE Report API In this release, we've added a new REST API and CLI for producing a MITRE report for a given Organization based on the D&R rules in place (using their tags like `attack..t1000.xxx`).

* API: <https://api.limacharlie.io/static/swagger/#/Rules/getOrgMITREReport>
* CLI: `limacharlie mitre-report`

The resulting JSON report can be used with the attack-navigator: <https://mitre-attack.github.io/attack-navigator/>.This capability makes it easier to track security coverage against MITRE ATT&CK framework.

## 2024-10-19

EDR Sensor `v4.31.1`

* Network connection stability enhancements on all platforms.
* The enhancements are both in the cloud-triggered upgrade version of the sensor AND in the on-disk installation, but there is no requirement to deploy both simultaneously.

## 2024-10-17

New sort and bulk actions functionality for tables

In this release, we are adding the ability to sort columns in the LimaCharlie web app. In addition, tables now support bulk actions (Enable/Disable and Delete). This applies to the following sections of the web app: Adapters, Yara Rules, Secrets, Lookups, False Positive Rules and Detection and Response Rules.

## Prior Release Notes

All prior date release notes are located here: <https://limacharlie.io/release-notes>

---

### What's Next

* [MCP Server](/docs/mcp-server)

Table of contents

+ [2025-09-30](#2025-09-30)
+ [2025-09-12](#2025-09-12)
+ [2025-08-28](#2025-08-28)
+ [2025-08-08](#2025-08-08)
+ [2025-07-18](#2025-07-18)
+ [2025-07-10](#2025-07-10)
+ [2025-06-27](#2025-06-27)
+ [2025-06-17](#2025-06-17)
+ [2025-05-30](#2025-05-30)
+ [2025-05-22](#2025-05-22)
+ [2025-05-20](#2025-05-20)
+ [2025-05-08](#2025-05-08)
+ [2025-04-18](#2025-04-18)
+ [2025-04-11](#2025-04-11)
+ [2025-03-28](#2025-03-28)
+ [2025-03-28](#2025-03-281)
+ [2025-03-14](#2025-03-14)
+ [2025-03-06](#2025-03-06)
+ [2025-02-28](#2025-02-28)
+ [2025-02-21](#2025-02-21)
+ [2025-01-24](#2025-01-24)
+ [2025-01-09](#2025-01-09)
+ [2024-12-12](#2024-12-12)
+ [2024-10-28](#2024-10-28)
+ [2024-10-19](#2024-10-19)
+ [2024-10-17](#2024-10-17)
+ [Prior Release Notes](#prior-release-notes)

---

# Other

## 1Password

# 1Password
* 1 Minute to read

## Related articles

* [1Password](/docs/ext-cloud-cli-1password)
* [Cloud CLI](/docs/ext-cloud-cli)

---

### What's Next

* [Atlassian](/docs/atlassian)

Table of contents

+ [Adapter Deployment](#adapter-deployment)
+ [Cloud-to-Cloud Adapter](#cloud-to-cloud-adapter)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Access and Permissions

# Access and Permissions
* 1 Minute to read

## What's Next

* [API Keys](/docs/api-keys)

Table of contents

+ [Users](#users)
+ [API Keys](#api-keys)
+ [Groups](#groups)

Tags

* [platform](/docs/en/tags/platform)

---

## Artifacts

# Artifacts
## Overview

The Artifact Collection system allows you to ingest artifact types like:

* Plain text logs (syslog for example)
* Windows Event Logs
* PCAPs
* Windows Prefetch files
* Windows PE (executables) files
* [Zeek](https://zeek.org) (previously Bro)
* Full memory dumps
* Generic JSON
* OLE (MS Word, Excel etc)
* Windows MFT CSV Listing
* Apple Binary/XML plists

Those artifacts can be ingested from hosts running a LimaCharlie Sensor, or they can be pushed to the LimaCharlie platform via a REST interface.

Once ingested, the artifacts are retained and made available to you with a custom retention period. Ingested artifacts are also indexed similarly to LimaCharlie events. This means that you can search all of your artifact for the last year for Indicators like IP Addresses, Domain Names, User Names, Hashes etc.

This in turn makes it possible for you to be looking at sensor data, identify an IP of interest, and launch a quick search to see if this IP has been observed in any artifacts over the past year. If it has, with one click you can visualize the relevant artifact entries to assist you in your investigation.

We call this "artifact operationalization". It is not meant to be a general viewing and querying tool like Splunk, but as a tactical tool providing you with critical answers as you need them during security operations.

Note that Artifact Collection configurations are synchronized with sensors every few minutes.

## Ingestion

There are multiple ways to ingest artifacts within LimaCharlie, depending on the need of the user.

**Please note, if you are looking for real-time streaming of a file (such as a system log), we'd recommend using the** `file`[**adapter**](/v2/docs/adapters) **instead of Artifact Collection.**

### Using LC Sensors

The LimaCharlie sensor can be used to retrieve artifact files directly from hosts.

#### Manually

To instruct the ingestion of an artifact file located on a host where LC is installed, simply issue the `artifact_get` command. You should receive two events in response to this command: a general receipt indicating the sensor received the command, and a response with a status code indicating whether the ingestion was successful (an error code of `200` (as in HTTP) indicates success).

```
artifact_get --type pcap --file /path/to/file.pcap --days-retention $days
```

#### Using the Extension

**File Collection - Artifact Collection Rules**

With the [Artifact Collection Extension](https://app.limacharlie.io/add-ons/extension-detail/ext-artifact) enabled, a new section should be open in the web interface. It will allow you to manage the automatic collection of files from your fleet without manual input or configuration.

The extension manages this through the use of Rules that specify a set of Platforms (like Windows), Tags (sensor tags), a retention time and file patterns.

Rules define which file path patterns should be monitored for changes and ingested for specific sets of hosts.

Filter tags are tags that must ALL be present on a sensor for it to match (ANDed), while the platform of the sensor much match one of the platforms in the filter (ORed).

Patterns are file path where the file expression at the end of the path can contain patterns line (`*`, `?`, `+`).

These wildcards are NOT supported in the path portion of the pattern. Windows directory separators (backslash, `\`) must be escaped like `\\`.

* Good example: `/var/log/*.1`
* Bad example: `/var/*/syslog`

Note that matching files are watched for changes. When a change is detected, the entire file is ingested. *This means you usually want to target logs that get rolled over after a certain time.*

For example syslog is rolled from `syslog` to `syslog.1` after a day, you want to target `syslog.1` to avoid duplicating records from a file being appended to.

Rules may also specify special accesses to log. For example, specifying a rule with a file path of `wel://Security:*` will begin collection of the Windows Event Logs (`wel`) in real-time directly from the sensor. See the Windows Event Logs section below.

**Network Capture - PCAP Capture Rules**

The extension also offers a rule system to do network capture from the host. **This feature is currently only available on Linux.**

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(311).png)

To see the network interfaces available for capture, issue the `pcap_ifaces` command to the sensor.

Each capture rule filters a set of sensors per Tag. The second part of the rule is the list of patterns to capture from. Each pattern defines a network interface to use and a [tcpdump-like](https://www.tcpdump.org/manpages/pcap-filter.7.html) filter expression to select traffic from that interface.

The filter part of the capture pattern will automatically receive an additional "filter out" expression that removes traffic related to LimaCharlie itself (to avoid a feedback loop of traffic).

For example, you could specify the filter:

```
tcp port 80
```

which would automatically be expanded for you as

```
tcp port 80 and not lc.aaa.limacharlie.io and not ...
```

These rules get synced with agents every 10 minutes. Once a capture on the agent reaches a certain threshold (about 30MB), the capture will get automatically sent to the LimaCharlie cloud as an artifact with the retention specified in the rule. From there you can specify  rules to process further the pcap data automatically, like using the [Zeek extension](/v2/docs/ext-zeek).

### Using the CLI

To simplify the task on ingesting via the REST API, you can use the LC CLI tool (`pip install limacharlie`). Using this tool, you can use the `limacharlie artifacts --help` command it installs. This is the recommended way of ingesting logs from external systems where LC is not installed.

### Using the REST API

When the sensor is tasked to ingest an artifacts file, it itself uses the REST API.

The REST API uses Ingestion Keys, which can be managed through the REST API section of the LC web interface. Access to manage these Ingestion Keys requires the `ingestkey.ctrl` permission.

The REST endpoint is located at a per-datacenter URL. You can query the relevant URL for your Organization using [this REST call](https://api.limacharlie.io/static/swagger/#/orgs/get_orgs__oid__url).

The endpoint is authenticated using Basic Authentication with the user name being the Organization ID (OID) and the password the Ingestion Key, via a POST.

The body of the POST contains the artifact file to ingest. Additional metadata is provided using the following Header fields:

* `lc-source` is a free form string used as an identifier of the origin of the artifact. When an artifact is ingested from a LC sensor, this value is the Sensor ID (SID) of the sensor.
* `lc-hint` if present, this indicates to the backend how the file should be interpreted. It default to `auto` which results in the backend auto-detecting the formal. Currently supported hints include `wel` (Windows Events Log), `prefetch` (Windows prefetch file), `pcap`, `txt`, `pe`, `zeek`, `json`.
* `lc-payload-id` if present, this is a globally unique identifier for the artifact file. It can be used to ingest artifacts in an idempotent way, meaning a second file ingested with this same value will be ignored.
* `lc-path` if present, should be a base-64 encoded string representing the original file path of the artifact on the source system.
* `lc-part` if present, is used to track multi-part artifact uploads. If set, it should be an integer starting at `0` and incrementing for every part with the last part being set to `done`. The `lc-payload-id` MUST be set and constant across all parts.

## Accessing Artifacts

The left navigation contains a link to "Artifacts" which displays all artifacts ingested across all sensors in the organization. From there you can select a specific artifact and view it, or choose to download the original and/or parsed version.

You can also see the artifacts collected for a particular sensor by going to the "Sensors" section, clicking into a sensor, and then clicking on "Artifacts".

## Windows Event Logs

### From Real-Time Events

*Only supported on Windows 2008 and up*

It is possible to subscribe to receive Windows Event Logs in real-time from the sensor. By doing this, the targeted Windows Events will be sent to
the cloud as normal LimaCharlie telemetry events encapsulated in an event type of `WEL`. The Windows Events in those cases will be structured as JSON similarly
to other LimaCharlie telemetry. This means you can create [detection and response rules](/v2/docs/detection-and-response) that operate directly on Windows Events, or even correlate between Windows Events and native LimaCharlie telemetry events.

To configure this collection, you need to specify a special kind of log path as a collection pattern. The format is as follows:

```
wel://EventSource:FilterExpression
```

The `wel://` prefix tells LimaCharlie this is not a file at rest, but a live API request from the sensor. The `EventSource` part of the expression refers
to the `ChannelPath` described in the Windows documentation here: https://docs.microsoft.com/en-us/windows/win32/api/winevt/nf-winevt-evtsubscribe.
The `FilterExpression` component refers to the `Query` parameter described in the same documentation. Additional documentation on the filter format can also be found here: https://docs.microsoft.com/en-us/windows/win32/wes/consuming-events.

Examples of supported patterns:

* `wel://Security:*`
* `wel://Application:*`
* `wel://System:*`
* `wel://Microsoft-Windows-Windows Defender/Operational:*`
* `wel://Microsoft-Windows-PowerShell/Operational:*`
* `wel://Microsoft-Windows-Sysmon/Operational:*`
* `wel://System:Event[System[EventID=4624]]`
* `wel://System:*[System[(EventID='7040')]]`

These WEL events will come in to the sensor's Timeline as `WEL` events like:

```json
{
  "EVENT": {
    "EventData": {
      "AuthenticationPackageName": "NTLM",
      "FailureReason": "%%2313",
      "IpAddress": "185.198.69.35",
      "IpPort": "0",
      "KeyLength": "0",
      "LmPackageName": "-",
      "LogonProcessName": "NtLmSsp",
      "LogonType": "3",
      "ProcessId": "0x0",
      "ProcessName": "-",
      "Status": "0xc000006d",
      "SubStatus": "0xc0000064",
      "SubjectDomainName": "-",
      "SubjectLogonId": "0x0",
      "SubjectUserName": "-",
      "SubjectUserSid": "S-1-0-0",
      "TargetDomainName": "",
      "TargetUserName": "USER",
      "TargetUserSid": "S-1-0-0",
      "TransmittedServices": "-",
      "WorkstationName": "-"
    },
    "System": {
      "Channel": "Security",
      "Computer": "demo-win-2016",
      "Correlation": {
        "ActivityID": "{F207C050-075F-0001-952F-331047A7DA01}"
      },
      "EventID": "4625",
      "EventRecordID": "29089367",
      "Execution": {
        "ProcessID": "568",
        "ThreadID": "3456"
      },
      "Keywords": "0x8010000000000000",
      "Level": "0",
      "Opcode": "0",
      "Provider": {
        "Guid": "{54849625-5478-4994-A5BA-3E3B0328C30D}",
        "Name": "Microsoft-Windows-Security-Auditing"
      },
      "Security": "",
      "Task": "12544",
      "TimeCreated": {
        "SystemTime": "2024-05-30T22:17:45.516965200Z"
      },
      "Version": "0",
      "_event_id": "4625"
    }
  }
}
```

### From Files at Rest

When running D&R rules against Windows Event Logs (`target: artifact` and `artifact type: wel`) that were acquired from files at rest, although the Artifact Collection Service may ingest
the same Windows Event Log file that contains some records that have already been processed by the rules, the LimaCharlie platform will keep track of the processed `EventRecordID` and therefore will NOT run the same D&R rule over the same record multiple times.

This means you can safely set the Artifact Collection Service to collect various Windows Event Logs from your hosts and run D&R rules over them without risking producing the same alert multiple times.

For most Windows Event Logs available, see `c:\windows\system32\winevt\logs\`.

## Mac Unified Logs

Like with Windows Event Logs (WEL), it is possible to collect Mac Unified Logs (MUL) in real-time from the endpoint.

The mechanism used is very similar to WEL: specify a collection rule with a log path like:

```
mul://<Predicate>
```

where `<Predicate>` is a [predicate filter](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/Predicates/Articles/pSyntax.html) supplied to the API on the endpoint, selecting a subset of the local Mac Unified Logs to be streamed to the cloud.

Example: `mul://process == "Safari"`
*Note that predicates are case sensitive.*

These selected MUL events will come in to the sensor's Timeline as an event of type `MUL` like:

```json
{
  "activityIdentifier": 0,
  "category": "entry",
  "date": 1717107501.628475,
  "level": 2,
  "nessage": "CopyData('DefaultAsciiKeyboardLayoutPasteboard' (<CFUUID 0x600001d47ac0> 425712C6-DAB1-497D-A573-168ECB75AF4A) gen: -1 item: 1264739405 flavor: 'DefaultAsciiKeyboardLayoutFlavor')",
  "process": "Safari",
  "processIdentifier": 77998,
  "sender": "CoreFoundation",
  "storeCategory": 0,
  "subsystem": "com.apple.CFPasteboard",
  "threadIdentifier": 20382671,
  "type": "log"
}
```

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

Command-line Interface

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

In LimaCharlie, an Organization ID (OID) is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

In LimaCharlie, a Sensor ID (SID) is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

---

### Related articles

* [Syslog](/docs/adapter-types-syslog)
* [Ingesting Defender Event Logs](/docs/ingesting-defender-event-logs)
* [Artifact](/docs/ext-artifact)
* [REnigma](/docs/ext-renigma)

---

#### What's Next

* [Sensor Connectivity](/docs/sensor-connectivity)

Table of contents

+ [Overview](#overview)
+ [Ingestion](#ingestion)
+ [Accessing Artifacts](#accessing-artifacts)
+ [Windows Event Logs](#windows-event-logs)
+ [Mac Unified Logs](#mac-unified-logs)

---

## Atlassian

# Atlassian
[Atlassian](https://www.atlassian.com/) makes a suite of products that help foster enterprise work management, IT service management, and Agile development. Atlassian's products include:

* Bitbucket
* Confluence
* Jira Work Management (this includes a suite of products, include Jira Software, Service Management, and Product Discovery)
* Opsgenie
* Trello

Atlassian has [extensive documentation](https://confluence.atlassian.com/alldoc/atlassian-documentation-32243719.html) for both their Cloud and Data Center/Server editions.

Currently, LimaCharlie supports ingestion of Jira events. Jira events can be ingested in LimaCharlie via a `json` webhook Adapter.

## Adapter Deployment

Jira events are ingested via a cloud-to-cloud webhook Adapter, configured to receive JSON events. In the creation of the Adapter, we map fields directly to the expected Atlassian events. The steps of creating this Adapter and enabling the input include:

1. Creating the webhook Adapter via the LimaCharlie CLI.
2. Discovering the URL created for the webhook Adapter.
3. Providing the completed URL to Jira for webhook events.

### 1. Creating the LimaCharlie Webhook Adapter

The following steps are modified from the generic webhook adapter creation documentation, found [here](/v2/docs/tutorial-creating-a-webhook-adapter).

Creating a Webhook Adapter requires a set of parameters, including organization ID, Installation Key, platform, and mapping details. The following configuration has been provided to configure a webhook Adapter for ingesting Jira events:

```json
{
    "sensor_type": "webhook",
    "webhook": {
       "secret": "atlassian-jira-secret",
        "client_options": {
            "hostname": "atlassian-jira",
            "identity": {
                "oid": "<your_oid>",
                "installation_key": "<your_installation_key>"
            },
            "platform": "json",
            "sensor_seed_key": "atlassian-jira-super-secret-key",
            "mapping" : {
                "event_type_path" : "webhookEvent",
                "event_time_path" : "timestamp"
            }
        }
    }
}
```

The mapping above is based on the expected webhook event from Jira. Note that in the mapping above, we make the following change:

* `event_type_path` is mapped to the `webhookEvent` field
* `event_time_path` is mapped to the `timestamp` field

### 2. Building the Webhook URL

After creating the webhook, you'll need to retrieve the webhook URL from the [Get Org URLs](https://docs.limacharlie.io/apidocs/get-org-urls) API call. You'll need the following information to complete the Webhook URL:

* Organization ID
* Webhook name (from the config)
* Secret (from the config)

Let's assume the returned domain looks like `9157798c50af372c.hook.limacharlie.io`, the format of the URL would be:

`https://9157798c50af372c.hook.limacharlie.io/OID/HOOKNAME/SECRET`

Note that the `secret` value can be provided in the webhook URL or as an HTTP header named `lc-secret`.

### 3. Providing the URL to Jira for Webhook Events

Within the Atlassian Admin window, navigate to **Jira Administration** > **Jira settings** > **Advanced** > **WebHooks**. Select **+ Create a WebHook**.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28178%29.png)

* Choose an appropriate name to differentiate that this is a LimaCharlie webhook
* Provide the webhook URL (see step 2 above)
* (optional) Provide a description
* (optional) Provide a JQL query to select certain issues that will trigger Webhooks. The default selection is *All issues*.

Within the WebHook creation dialog, you can also select the granularity of events to send via the WebHook. High-level event categories include:

* Issues

  + Issue events
  + Worklog
  + Comment(s)
  + Entity Properties
  + Attachment
  + Issue Link
  + Filter
* User-related
* Jira configuration
* Project-related
* Jira Software-related

By default, issues will be sent as JSON, which is natively accepted by LimaCharlie. Save your WebHook configuration, and perform an action that you know will trigger the event.

If configured properly, you should see your Jira events in LimaCharlie. Here's an example event:

```json
{
  "event": {
    "issue": {
      "fields": {
        "aggregateprogress": {
          "progress": 0,
          "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "attachment": [],
        "comment": {
          "comments": [],
          "maxResults": 0,
          "self": "https://###.atlassian.net...",
          "startAt": 0,
          "total": 0
        },
        "components": [],
        "created": "2023-12-02T11:16:02.927-0600",
        "creator": {
          "accountId": "...",
          "accountType": "atlassian",
          "active": true,
          "avatarUrls": {
            "16x16": "...",
            "24x24": "...",
            "32x32": "...",
            "48x48": "..."
          },
          "displayName": "Matt Bromiley",
          "self": "https://###.atlassian.net...",
          "timeZone": "America/Chicago"
        },
        "customfield_10001": null,
        "customfield_10002": null,
        "customfield_10003": null,
        "customfield_10004": null,
        "customfield_10005": null,
        "customfield_10006": null,
        "customfield_10007": null,
        "customfield_10008": null,
        "customfield_10009": null,
        "customfield_10010": null,
        "customfield_10014": null,
        "customfield_10015": null,
        "customfield_10016": null,
        "customfield_10017": null,
        "customfield_10018": {
          "hasEpicLinkFieldDependency": false,
          "nonEditableReason": {
            "message": "The Parent Link is only available to Jira Premium users.",
            "reason": "PLUGIN_LICENSE_ERROR"
          },
          "showField": false
        },
        "customfield_10019": "0|hzzzzz:",
        "customfield_10020": null,
        "customfield_10021": null,
        "customfield_10022": null,
        "customfield_10023": null,
        "customfield_10024": null,
        "customfield_10025": null,
        "customfield_10026": null,
        "customfield_10027": null,
        "customfield_10028": null,
        "customfield_10029": null,
        "customfield_10030": null,
        "description": null,
        "duedate": null,
        "environment": null,
        "fixVersions": [],
        "issuelinks": [],
        "issuerestriction": {
          "issuerestrictions": {},
          "shouldDisplay": true
        },
        "issuetype": {
          "avatarId": 10318,
          "description": "Tasks track small, distinct pieces of work.",
          "entityId": "e44d856a-3c4b-4a5e-bc67-c3c93227fe18",
          "hierarchyLevel": 0,
          "iconUrl": "https://###.atlassian.net/rest/api/...",
          "id": "10001",
          "name": "Task",
          "self": "https://###.atlassian.net/rest/api/...",
          "subtask": false
        },
        "labels": [],
        "lastViewed": "2023-12-02T17:18:42.192-0600",
        "priority": {
          "iconUrl": "https://###.atlassian.net/rest/api/...",
          "id": "3",
          "name": "Medium",
          "self": "https://###.atlassian.net/rest/api/..."
        },
        "progress": {
          "progress": 0,
          "total": 0
        },
        "project": {
          "avatarUrls": {
            "16x16": "...",
            "24x24": "...",
            "32x32": "...",
            "48x48": "..."
          },
          "id": "10000",
          "key": "KAN",
          "name": "My Kanban Project",
          "projectTypeKey": "software",
          "self": "https://###.atlassian.net/rest/api/...",
          "simplified": true
        },
        "reporter": {
          "accountId": "...",
          "accountType": "atlassian",
          "active": true,
          "avatarUrls": {
            "16x16": "...",
            "24x24": "...",
            "32x32": "...",
            "48x48": "..."
          },
          "displayName": "Matt Bromiley",
          "self": "...",
          "timeZone": "America/Chicago"
        },
        "resolution": null,
        "resolutiondate": null,
        "security": null,
        "status": {
          "description": "",
          "iconUrl": "https://###.atlassian.net/",
          "id": "10000",
          "name": "To Do",
          "self": "https://###.atlassian.net/rest/api/...",
          "statusCategory": {
            "colorName": "blue-gray",
            "id": 2,
            "key": "new",
            "name": "To Do",
            "self": "https://###.atlassian.net/rest/api/..."
          }
        },
        "statuscategorychangedate": "2023-12-02T11:16:03.211-0600",
        "subtasks": [],
        "summary": "sample issue",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "timetracking": {},
        "updated": "2023-12-02T11:16:03.129-0600",
        "versions": [],
        "votes": {
          "hasVoted": false,
          "self": "https://###.atlassian.net/rest/api/...",
          "votes": 0
        },
        "watches": {
          "isWatching": true,
          "self": "https://###.atlassian.net/rest/api/...",
          "watchCount": 1
        },
        "worklog": {
          "maxResults": 20,
          "startAt": 0,
          "total": 0,
          "worklogs": []
        },
        "workratio": -1
      },
      "id": "10012",
      "key": "KAN-13",
      "self": "https://###.atlassian.net/rest/api/..."
    },
    "timestamp": 1701559124723,
    "user": {
      "accountId": "...",
      "accountType": "atlassian",
      "active": true,
      "avatarUrls": {
        "16x16": "...",
        "24x24": "...",
        "32x32": "...",
        "48x48": "..."
      },
      "displayName": "Matt Bromiley",
      "self": "...",
      "timeZone": "America/Chicago"
    },
    "webhookEvent": "jira:issue_deleted"
  },
  "routing": {...},
  "ts": "2023-12-02 23:18:44"
}
```

Note that the Jira "webhookEvent" becomes the event type, also represented in the LimaCharlie Adapter timeline.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

#### What's Next

* [AWS CloudTrail](/docs/adapter-types-aws-cloudtrail)

Table of contents

+ [Adapter Deployment](#adapter-deployment)

Tags

* [adapters](/docs/en/tags/adapters)
* [sensors](/docs/en/tags/sensors)

---

## Azure Key Vault

# Azure Key Vault
* 1 Minute to read

## Related articles

* [Azure SQL Audit Logs](/docs/azure-sql-audit-logs)
* [Azure Event Hub](/docs/adapter-types-azure-event-hub)
* [Azure Storage Blob](/docs/outputs-destinations-azure-storage-blob)
* [Azure Monitor](/docs/azure-monitor)
* [Azure](/docs/ext-cloud-cli-azure)
* [Azure Kubernetes Service (AKS)](/docs/azure-kubernetes-service)
* [Azure Network Security Group](/docs/azure-network-security-group)
* [Azure Event Hub](/docs/outputs-destinations-azure-event-hub)
* [Microsoft Entra ID](/docs/adapter-types-microsoft-entra-id)

---

### What's Next

* [Azure Kubernetes Service (AKS)](/docs/azure-kubernetes-service)

Table of contents

+ [Log Ingestion](#log-ingestion)
+ [Sample Event](#sample-event)

Tags

* [adapters](/docs/en/tags/adapters)
* [azure](/docs/en/tags/azure)
* [sensors](/docs/en/tags/sensors)

---

## Azure Kubernetes Service (AKS)

# Azure Kubernetes Service (AKS)
* 1 Minute to read

## Related articles

* [Azure SQL Audit Logs](/docs/azure-sql-audit-logs)
* [Azure Event Hub](/docs/adapter-types-azure-event-hub)
* [Azure Storage Blob](/docs/outputs-destinations-azure-storage-blob)
* [Azure Monitor](/docs/azure-monitor)
* [Azure](/docs/ext-cloud-cli-azure)
* [Azure Network Security Group](/docs/azure-network-security-group)
* [Azure Key Vault](/docs/azure-logs-key-vault)
* [Azure Event Hub](/docs/outputs-destinations-azure-event-hub)
* [Microsoft Entra ID](/docs/adapter-types-microsoft-entra-id)
* [Container Clusters](/docs/container-clusters)

---

### What's Next

* [Azure Monitor](/docs/azure-monitor)

Table of contents

+ [Log Ingestion](#log-ingestion)

Tags

* [azure](/docs/en/tags/azure)
* [sensors](/docs/en/tags/sensors)

---

## Azure Monitor

# Azure Monitor
* 1 Minute to read

## Related articles

* [Azure SQL Audit Logs](/docs/azure-sql-audit-logs)
* [Azure Event Hub](/docs/adapter-types-azure-event-hub)
* [Azure Storage Blob](/docs/outputs-destinations-azure-storage-blob)
* [Azure](/docs/ext-cloud-cli-azure)
* [Azure Network Security Group](/docs/azure-network-security-group)
* [Azure Kubernetes Service (AKS)](/docs/azure-kubernetes-service)
* [Azure Key Vault](/docs/azure-logs-key-vault)
* [Azure Event Hub](/docs/outputs-destinations-azure-event-hub)
* [Microsoft Entra ID](/docs/adapter-types-microsoft-entra-id)

---

### What's Next

* [Azure Network Security Group](/docs/azure-network-security-group)

Table of contents

+ [Log Ingestion](#log-ingestion)

Tags

* [azure](/docs/en/tags/azure)
* [sensors](/docs/en/tags/sensors)

---

## Azure Network Security Group

# Azure Network Security Group
* 1 Minute to read

## Related articles

* [Azure SQL Audit Logs](/docs/azure-sql-audit-logs)
* [Azure Event Hub](/docs/adapter-types-azure-event-hub)
* [Azure Storage Blob](/docs/outputs-destinations-azure-storage-blob)
* [Azure Monitor](/docs/azure-monitor)
* [Azure](/docs/ext-cloud-cli-azure)
* [Azure Kubernetes Service (AKS)](/docs/azure-kubernetes-service)
* [Azure Key Vault](/docs/azure-logs-key-vault)
* [Azure Event Hub](/docs/outputs-destinations-azure-event-hub)
* [Microsoft Entra ID](/docs/adapter-types-microsoft-entra-id)

---

### What's Next

* [Azure SQL Audit Logs](/docs/azure-sql-audit-logs)

Table of contents

+ [Log Ingestion](#log-ingestion)

Tags

* [azure](/docs/en/tags/azure)
* [sensors](/docs/en/tags/sensors)

---

## Azure SQL Audit Logs

# Azure SQL Audit Logs
* 1 Minute to read

## Related articles

* [Azure Event Hub](/docs/adapter-types-azure-event-hub)
* [Azure Storage Blob](/docs/outputs-destinations-azure-storage-blob)
* [Azure Monitor](/docs/azure-monitor)
* [Azure](/docs/ext-cloud-cli-azure)
* [Azure Kubernetes Service (AKS)](/docs/azure-kubernetes-service)
* [Azure Key Vault](/docs/azure-logs-key-vault)
* [Azure Network Security Group](/docs/azure-network-security-group)
* [Azure Event Hub](/docs/outputs-destinations-azure-event-hub)
* [Microsoft Entra ID](/docs/adapter-types-microsoft-entra-id)

---

### What's Next

* [1Password](/docs/1password)

Table of contents

+ [Log Ingestion](#log-ingestion)

Tags

* [adapters](/docs/en/tags/adapters)
* [azure](/docs/en/tags/azure)
* [sensors](/docs/en/tags/sensors)

---

## Billing

# Billing
Billing in LimaCharlie is done on monthly cycles and per-Organization (multi-tenant). Sensors can be billed on a quota, set within the organization, or billed on a usage basis.

Need simplified billing for many organizations?

Some features, such as centralized billing are available to larger LC users like MSSPs. For more details contact us at [sales@limacharlie.io](http://mailto:sales@limacharlie.io).

Exact pricing is available on the [LimaCharlie website](https://limacharlie.io) or [Web App](https://app.limacharlie.io).

## Services

### Sensors

There are two categories of sensors: sensors billed on Quota set by the user (vSensor basis), and sensors billed on usage basis.

| Sensor Type | Billed on | Cost |
| --- | --- | --- |
| Windows | Quota | $3.00/sensor/month |
| Linux | Quota | $3.00/sensor/month |
| macOS | Quota | $3.00/sensor/month |
| Docker | Quota | $3.00/sensor/month |
| VMWare Carbon Black EDR | Quota | $0.6/sensor/month |
| Chrome OS | Quota | $0.30/sensor/month |
| Syslog | Usage basis | $0.20/GB |
| Amazon AWS CloudTrail Logs | Usage basis | $0.20/GB |
| Google Cloud Platform (GCP) Logs | Usage basis | $0.20/GB |
| 1Password | Usage basis | $0.20/GB |
| Microsoft/Office 365 | Usage basis | $0.20/GB |
| Windows Event Logs | Usage basis | $0.20/GB |
| Microsoft Defender | Usage basis | $0.20/GB |
| Duo | Usage basis | $0.20/GB |
| GitHub | Usage basis | $0.20/GB |
| Slack | Usage basis | $0.20/GB |
| CrowdStrike | Usage basis | $0.20/GB |
| IT Glue | Usage basis | $0.20/GB |
| Other external sources | Usage basis | $0.20/GB |

For more information about vSensors and the examples, visit our [help center page.](https://help.limacharlie.io/en/articles/5931547-how-is-the-cost-of-sensors-add-ons-calculated-in-limacharlie)

The Quota is the number of sensors (agents) concurrently online that should be  supported by the given Organization. The Quota applies to concurrently online sensors, meaning that you may have more sensors registered than your quota.

If sensors attempt to connect to the cloud while the Quota is full, they will simply be turned away for a short period of time. In that case, a special `sensor_over_quota` will also be emitted which you can use in [D&R rules](/v2/docs/detection-and-response) for automation.

To avoid frequent churn, Quota modifications are limited by:

* Up to one quota decrease per day.
* Any number of quota increases per day.

The endpoint service includes [Outputs](/v2/docs/outputs) as well as [D&R rules](/v2/docs/detection-and-response) processed in real-time.

### Insight (Retention)

Insight is also a foundational service of LimaCharlie. It provides a flat 1 year of full retention (full telemetry) for a single price in order to make billing more predictable.

### Usage Based Billing

See [Sleeper Deployment](/docs/sleeper) for more details.

| Connected Time | Events Processed | Events Retained |
| --- | --- | --- |
| $0.10 per 30 days | $0.67 per 100,000 events | $0.17 per 100,000 events |

### Replay (Retroactive Scanning)

[Replay](/v2/docs/replay) allows you to run [D&R rules](/v2/docs/detection-and-response) or [False Positives](/v2/docs/false-positive-rules) against external or historical telemetry. Not to be confused with Searching for specific IoCs which is a free feature of Insight.

Its pricing is based on the number of events (telemetry) scanned.

**Looking for more insight on utilizing replay?**

Pricing is $0.01 per block of 200,000 events. So a query scanning 1,000,000 events will cost $0.05.

The "dry run" mechanism of Replay can also provide you a high watermark of the cost of a query without actually running it.

Replay jobs can also be launched with a maximum number of operation evaluations to consume during the life-cycle of the job. This limit is approximate due to the de-centralized nature of Replay jobs and may vary a bit.

### Artifact Collection

[Artifacts](/v2/docs/artifacts) allows you to ingest artifacts like Syslog, Windows Events Logs as well as more complex file formats like Packet Captures (PCAP), Windows Prefetch files, Portable Executable (PE) etc.

Ingested files can then be downloaded as originals or viewed in parsed formats right from your browser. You can also run [D&R rules](/v2/docs/detection-and-response) against them.

Unlike Insight, the retention period is variable based on a number of days (up to 365) as specified by the user at ingestion time.

All billing for it is done at ingestion time based on the number of days and the size of the file. The billing metric is therefore "byte-days".

For example, a file that is 100 MB and is ingested with a retention period of 10 days would be one-time billed for `100 X 10 MB-days`.

## Add-Ons

LimaCharlie Add-Ons are billed on the vSensor basis. When an add-on is used with a sensor billed on usage (eg., 1Password), the Add-On is free. For more information and the examples, visit our [billing FAQ](/v2/docs/faq-billing).

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Endpoint Detection & Response

---

### Related articles

* [Billing Options](/docs/billing-options)
* [FAQ - Billing](/docs/faq-billing)
* [Sleeper Deployment](/docs/sleeper)

---

#### What's Next

* [Using Custom Billing Plans](/docs/using-custom-billing-plans)

Table of contents

+ [Services](#services)
+ [Add-Ons](#add-ons)

Tags

* [platform](/docs/en/tags/platform)

---

## Billing Options

# Billing Options
LimaCharlie users have multiple billing options available to them, depending on their unique needs. We'll walk through these two options, *Default Billing* and *Unified Billing*, below.

## Default Billing

By default, every Organization is billed using a credit card set at the individual organization level. The billing cycle for each organization starts at the time the organization goes from the free tier into a paid tier. The invoices go to the email address of the user who initially created the organization.

### Unified Billing

For customers that require flexibility managing multiple organizations, LimaCharlie offers unified billing - the ability to customize billing to satisfy their needs.

All the options described below apply based on the “billing domain”, which is the domain name of the email address of a user. For example, the users `ceo@mycorp.com` and `sales@mycorp.com` both belong to the `mycorp.com` billing domain.

All organizations under the same billing domain will have their billing cycles on the same day, regardless of the creation time or the time the organization first exits free tier. Instead of receiving one invoice per organization, all invoices for a billing domain will be aggregated together under a single invoice sent manually monthly.

The following are the options you can customize as a part of the Unified Billing:

* Override the email where each individual organization’s invoice goes to. Instead of the email of the creator, a central email address (like billing@mycorp.com) is used. Billing domains with unified billing enabled will receive a monthly report summarizing all organizations under the domain and their respective billing.
* Choose to be invoiced manually. Organizations in a billing domain can have their invoices sent manually by email without the use of a credit card. This will then allow the recipient to pay invoices using ACH or credit card, but this will have to be done manually each month.

### Default Billing Setup vs Unified Billing

|  | Default Billing Setup | Unified Billing |
| --- | --- | --- |
| **Can be used by** | Anyone | Customers that have their users share a custom domain name of the email address (for example, the users `ceo@mycorp.com` and `sales@mycorp.com` both belong to the `mycorp.com` domain). |
| **Best suited for** | \* Customers that have one or a few (1-3) tenants to manage \* Enterprise clients that want to manage billing at the department level (billed to different cards) | \* Service providers (MSP, MSSP, DFIR) who manage multiple tenants \* Enterprise clients that want to manage billing at the company level (billed to one card) |
| **Payment method used** | Billed using a credit card set at the individual organization level. | One payment method will be used for all organizations under the same billing domain. |
| **Manual invoicing** | Not available | Available  Organizations in a billing domain can have their invoices sent manually by email without the use of a credit card. This will then allow the recipient to pay invoices using ACH or credit card, but this will have to be done manually each month. |
| **Billing cycle** | Starts at the time the organization goes from the free tier into a paying tier (different billing cycle for each tenant). | All organizations under the same billing domain will have their billing cycles on the same day. |
| **Invoicing** | Users will receive one invoice per organization. | All invoices for a billing domain will be aggregated together under a single invoice sent manually monthly. |
| **Email invoices go to** | Email address of the user who initially created the organization. | Instead of the email of the creator, a central email address (like `billing@mycorp.com`) is used. Billing domains with unified billing enabled will receive a monthly report summarizing all organizations under the domain and their respective billing. |

To learn more or to get setup with Unified Billing, [contact us](https://limacharlie.io/contact).

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Managed Security Services Provider

Digital Forensics & Incident Response

---

#### Related articles

* [FAQ - Billing](/docs/faq-billing)
* [Billing](/docs/billing)
* [Use Cases](/docs/use-cases)

---

##### What's Next

* [Config Hive](/docs/config-hive)

Table of contents

Tags

* [platform](/docs/en/tags/platform)

---

## BinLib

# BinLib
Binary Library, or "BinLib", is a collection of executable binaries (such as EXE or ELF files) that have been observed within your environment. If enabled, this Extension helps you build your own private collection of observed executables for subsequent analysis and searching.

When LimaCharlie observes a binary and path for the first time a `CODE_IDENTITY` event is generated. The metadata from this event is stored within `binlib`, and is available for searching, tagging, and downloading. Additionally, you can run [YARA](/v2/docs/ext-yara) scans against observed binaries.

Enabling BinLib

BinLib requires subscribing to the `ext-reliable-tasking` Extension in order to function properly. This can be enabled [in the Add-ons marketplace](https://app.limacharlie.io/add-ons/extension-detail/ext-reliable-tasking).

BinLib can be a powerful additional to your detection and response capabilities. Analysts can:

* Look for historical evidence of malicious binaries
* Tag previously-observed files for data enrichment (i.e. [MITRE ATT&CK Techniques](https://attack.mitre.org/matrices/enterprise/))
* Compare observed hashes to known good or known bad lists
* [YARA scan](/v2/docs/ext-yara) and auto-tag for integration in detection & response rules

## Usage

First, subscribe your tenant to the [BinLib](https://app.limacharlie.io/add-ons/extension-detail/binlib) extension.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/binlib-1.png)

To perform one of the following operations against your own library, choose the command and select **Run Request.**

The BinLib page in the web app offers an easy way to get started with some of the core requests exposed by the extension: Check Hash, Search, and Yara Scan.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/binlib-2.png)

### check\_hash

*Accepted Values: MD5, SHA1, SHA256*

The `check_hash` operation lets you search to see if a particular hash has been observed in your Organization. Output includes a boolean if the hash was found and three hash values, if available.

Sample Output:

```json
{
  "data": {
    "found": true,
    "md5": "e977bded5d4198d4895ac75150271158",
    "sha1": "9e2b05f142c35448c9bc48c40a732d632485c719",
    "sha256": "2f5d0c6159b194d6f0f2eae0b7734708368a23aebf9af4db9293865b57ffcaeb"
  }
}
```

### get\_hash\_data

*Accepted Values: MD5, SHA1, SHA256*

Careful Downloading Binaries

LimaCharlie does not filter the binaries observed by your organization. You must exercise caution if downloading a malicious file. We recommend downloading potential malicious binaries to an isolated analysis system.

The `get_hash_data` operation provides a link to the raw data for the hash of interest, allowing you to download the resulting binary file (if previously observed within your environment).

Sample Output:

```json
{
  "data": {
    "download_url": "https://storage.googleapis.com/lc-library-bin/b_2f5d0c...",
    "found": true,
    "md5": "e977bded5d4198d4895ac75150271158",
    "sha1": "9e2b05f142c35448c9bc48c40a732d632485c719",
    "sha256": "2f5d0c6159b194d6f0f2eae0b7734708368a23aebf9af4db9293865b57ffcaeb"
  }
}
```

### get\_hash\_metadata

*Accepted Values: MD5, SHA1, SHA256*

The `get_hash_metadata` operation obtains the metadata for a hash of interest, including signing details, file type, and additional hashes.

```json
{
  "data": {
    "found": true,
    "md5": "e977bded5d4198d4895ac75150271158",
    "metadata": {
      "imp_hash": "c105252faa9163fd63fb81bb334c61bf",
      "res_company_name": "Google LLC",
      "res_file_description": "Google Chrome Installer",
      "res_product_name": "Google Chrome Installer",
      "res_product_version": "113.0.5672.127",
      "sha256": "2f5d0c6159b194d6f0f2eae0b7734708368a23aebf9af4db9293865b57ffcaeb",
      "sig_authentihash": "028f24e2c1fd42a3edaf0dcf8a59afe39201fa7d3bb5804dca8559fde41b3f34",
      "sig_issuer": "US, DigiCert Trusted G4 Code Signing RSA4096 SHA384 2021 CA1",
      "sig_serial": "0e4418e2dede36dd2974c3443afb5ce5",
      "sig_subject": "US, California, Mountain View, Google LLC, Google LLC",
      "size": 5155608,
      "type": "pe"
    },
    "sha1": "9e2b05f142c35448c9bc48c40a732d632485c719",
    "sha256": "2f5d0c6159b194d6f0f2eae0b7734708368a23aebf9af4db9293865b57ffcaeb"
  }
}
```

### search

The `search` operation searches the library for binary data points, including or *other than* a known hash.

Searchable fields include:

* imp\_hash
* res\_company\_name
* res\_file\_description
* res\_product\_name
* sha256
* sig\_authentihash
* sig\_hash
* sig\_issuer
* sig\_subject
* size
* type

Note that search criteria are ANDed. Binaries must meet ALL criteria to be returned.

Search results can be downloaded as a CSV.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/binlib-3.png)

### tag

The `tag` operation allows you to add tag(s) to a hash, allowing for additional classification within binlib.

The below example Tags the Google Installer with the `google` tag.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/binlib-4.png)

Successful tagging yields an `updated` event:

```json
{
  "data": {
    "found": true,
    "md5": "e977bded5d4198d4895ac75150271158",
    "sha1": "9e2b05f142c35448c9bc48c40a732d632485c719",
    "sha256": "2f5d0c6159b194d6f0f2eae0b7734708368a23aebf9af4db9293865b57ffcaeb",
    "updated": true
  }
}
```

### untag

The `untag` operation removes a tag from a binary.

### YARA scan

The `yara_scan` operation lets you run YARA scans across observed files. Scans require:

* Criteria or hash to filter files to be scanned
* [Rule name(s)](/v2/docs/config-hive-yara) or rule(s)

You also have the option to tag hits on match.

Note that search criteria are ANDed. Binaries must meet ALL criteria to be returned.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/binlib-5.png)

## Automating

Here are some examples of useful  rules that could be used to automate interactions with Binlib.

### Scan all acquired files with Yara

This rule will automatically scan all acquired files in binlib with a Yara rule:

```
detect:

event: acquired
op: is tagged
tag: ext:binlib

respond:

- action: report
  name: binlib-test
- action: extension request
  extension action: yara_scan
  extension name: binlib
  extension request:
    hash: '{{ .event.sha256 }}'
    rule_names:
      - yara_rule_name_here
```

and this rule will alert on matches:

```
detect:

event: yara_scan
op: exists
path: event/matches/hash

respond:

- action: report
  name: YARA Match via Binlib
```

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

---

#### Related articles

* [YARA Manager](/docs/ext-yara-manager)
* [YARA](/docs/ext-yara)
* [REnigma](/docs/ext-renigma)

---

##### What's Next

* [Dumper](/docs/ext-dumper)

Table of contents

+ [Usage](#usage)
+ [Automating](#automating)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Build CTI Capabilities

# Build CTI Capabilities
* 1 Minute to read

## What's Next

* [Purple Teaming](/docs/purple-teaming)

Tags

* [CTI](/docs/en/tags/CTI)
* [use case](/docs/en/tags/use%20case)

---

## Building Products

# Building Products
The LimaCharlie SecOps Cloud Platform (SCP) is a unified platform for modern cybersecurity operations.

The SCP delivers core cybersecurity capabilities and infrastructure via a public cloud model: on-demand, pay-per-use, and API-first. For the cybersecurity industry, this is a paradigm shift comparable to how the IT public cloud revolutionized IT.

For cybersecurity startups and builders, the SecOps Cloud Platform offers a robust foundation to create valuable products and services. The SCP helps innovators get to market faster, build genuinely independent businesses, increase their probability of success, and scale successful offerings with ease.

## 3 ways to go to market more effectively

The SecOps Cloud Platform provides the tools and infrastructure needed to secure any given organization—and is designed to be flexible and highly customizable. Because of this, the SCP enables many different types of solutions. Individual builders' use cases can vary significantly. Nevertheless, all startups and product developers using the platform will benefit from the following three recommendations:

* Focus on Your Core Value
* Reduce Up-front Costs
* Build to Scale

### Focus on Your Core Value

The SecOps Cloud Platform delivers foundational, well-understood security technologies as capabilities: as open, cloud-native primitives instead of black-box tools. Here's how builders can use this fact to create better products and service offerings:

**Clarify your differentiators.** In a crowded marketplace where buyers are already wary of tool sprawl, it's difficult to stand out—and challenging to convince buyers to take on another vendor. To succeed, startups must demonstrate clear value and differentiate themselves. Determine what sets you apart, and where you can deliver the greatest value to customers. This is where your internal engineering resources should be focused.

**Offload infrastructure work.** The SecOps Cloud Platform offers the kinds of mature cybersecurity capabilities that teams used to have to develop themselves or purchase as part of a product. This includes things like: Deploying endpoint capabilities via a multiplatform agent, alerting and correlating logs from any source, automating real-time analysis and response regardless of the environment, routing telemetry data to any destination, performing historical threat hunts, isolating endpoints from a network remotely, and many more.

In short, cybersecurity builders no longer need to "reinvent the wheel" in order to get to market. Here again, the clear analogy is to the IT public cloud. Most software developers today wouldn't invest in physical servers or develop complex, in-house solutions to handle application deployment and scaling. They would simply leverage cloud-based services like AWS Lambda or Azure Functions and run their applications without ever worrying about the underlying infrastructure.

Similarly, by using the infrastructure capabilities of the SCP, cybersecurity builders can spend their time and resources on their core value proposition—thereby reducing maintenance and integration challenges, eliminating external dependencies, and avoiding the risk that comes from building on someone else's product.

**Work with SCP engineers to develop custom integrations.** The SecOps Cloud Platform is a vendor-neutral provider of tooling and infrastructure for the cybersecurity industry. It is not a potential competitor.

As you develop on the SCP, reach out to LimaCharlie engineers for support in creating customized integrations, advice on best practices for a configurations or deployments, or feature requests that you’d like to see in the development roadmap. The SCP's public cloud business model means that the platform succeeds when its users succeed, so someone will always be on hand to help.

By building on a public cloud for cybersecurity, startups can focus on what they do best without having to develop and maintain DIY solutions—and without putting their business in the hands of a traditional vendor.

### Reduce up-front costs

The SecOps Cloud Platform has a transparent, pay-per-use pricing model and delivers all capabilities on demand. In addition, the platform offers a number of valuable free resources. This helps builders to cut costs and reduce initial investment in several ways:

**Conduct research and develop a prototype for free.** The SCP gives all users access to a fully featured free tier that includes two sensors. There is thus zero up-front cost to begin researching the platform, testing your idea, or even developing a prototype. Start by seeing if the SCP is the right choice for your project. Then, save money on early-stage development work once you begin.

**Build without lock-in.** The SCP's pricing model means you only pay for what you need, for as long as you use it. You don't have to deal with mandatory minimums, long-term contracts, complex licensing, or termination fees. This enables you to create on the platform secure in the knowledge that you are not committed to a given level of spending before your growth justifies it—and that you aren’t locked into your infrastructure provider.

**Use available SCP resources to save money.** Building on the SCP also offers several direct and indirect ways to lower costs during development.

The SecOps Cloud Platform is designed to be as user-friendly and easy to master as possible. In addition, the SCP is supported by extensive documentation, an active community forum of users, and a learning library full of tutorials and walkthroughs. This means developers will spend less time learning a new technology—and more time building.

In addition, you can make use of more direct forms of assistance. Users can reach out to SCP engineers at any time for help. Qualified builders can also apply for a $1000 platform credit through the platform's Cybersecurity Infrastructure Grant Program. Leverage these resources to reduce your development costs and ensure that your engineers are spending their time on tasks that add the most value.

**Meet compliance needs with free storage.** All telemetry data brought into the SCP is stored for the cost of ingestion for one full year. If your project has data retention or compliance needs, leverage the SCP's default storage capability to help keep your data storage costs down.

**Take advantage of discounted pricing.** If you've decided to build with the SCP for the foreseeable future—or if your product or service has started to see significant uptake—use discounted pricing options to save money as you grow. The SecOps Cloud Platform provides volume-based discounts to help you improve your savings as usage increases, as well as annual or multi-year discounts for those ready to commit to longer-term platform usage.

The SCP gives cybersecurity builders many of the competitive advantages the IT public cloud offers to startups in other verticals—and a high degree of direct assistance and support as well.

### Build to scale

The SecOps Cloud Platform enables scalable cybersecurity operations. Here's how developers can benefit from building on such a platform:

**Future-proof your infrastructure.** Cybersecurity startups often turn to open-source or custom-built infrastructure to save money and stay independent. But while this approach may work early on, its limitations become apparent over time. It's possible to build performant and successful cybersecurity projects on open-source or DIY technologies.

However, many businesses that take this route experience difficulties when they grow. The complexity, integration challenges, and troubleshooting work that are manageable with a small user base can quickly become untenable at scale. Before basing a part of your project on a custom or open-source solution, consider the challenges you will encounter later on if you are successful. You may be better served by using the SCP for that aspect of your offering.

**Build on a scalable platform.** The SecOps Cloud Platform is designed to help organizations scale their security operations. Basic assumptions of the platform include things like multitenancy, flexibility, open APIs, and rich automation capabilities. Builders should plan to scale from the outset—leveraging the SCP's engineering-centric approach to support future growth by developing architectures, integrations, and workflows that will enable scaling without limits.

Any successful cybersecurity business will encounter challenges as it attempts to increase its customer support or its development work. However, building on an engineering-centric platform enables startups to plan for the future from day one—and makes growth easier and more trouble-free.

**Scale with your revenue.** A major problem for early-stage cybersecurity startups is that they must spend money on fixed infrastructure costs without having enough users for that to be profitable. If funding runs out before a product–market fit is found, the business fails.

The SecOps Cloud Platform offers an alternative route. Leverage the SCP's pay-per-use pricing to scale your infrastructure spending with your revenue. Even if you start off with a small customer base, you won't be losing money on infrastructure costs. Conserve your resources and allocate your spending to development, marketing, and sales efforts instead.

The SCP offers builders a firm foundation for success. It provides a platform that is built to scale—and its pay-as-you-go pricing helps startups extend their runway and grow gradually and safely.

---

#### What's Next

* [Incident Response](/docs/incident-response)

Table of contents

Tags

* [builders](/docs/en/tags/builders)
* [use case](/docs/en/tags/use%20case)

---

## Building a custom MSI installer for Windows

# Building a custom MSI installer for Windows
You can white label the LimaCharlie installer for Windows by using an MSI wrapper.  By going through this process you can not only brand the installer to show your name / details, but you can also make installation of the Sensor easier for end users.  We have provided instructions below on how to use a 3rd party tool called [exemsi](https://www.exemsi.com/).

## Prerequisites

1. An MSI wrapper application, such as the exemsi application referenced in the instructions below
2. A digital code signing certificate  (optional, but highly recommended)

Without a digital code signing certificate the installer will show a warning that it is from an unknown publisher.

![UAC Signed](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/uac-signed.png)
- vs -
![UAC Warning](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/uac-warning.png)

## Instructions

1. Download the [LimaCharlie sensor EXE](https://downloads.limacharlie.io/sensor/windows/64)
2. Download the [MSI Wrapper application from exemsi.com](https://exemsi.com)
3. Install the exemsi application on your computer
4. Launch the exemsi application and go through the EXE to MSI Converter Wizard steps as shown below:

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_1_-_First_screen_after_launch.png)

5. Select the executable

* Set the `Setup executable input file name` to be the LimaCharlie EXE that you'd downloaded
* Optionally, specify a MSI output file name of your choosing (e.g. Acme\_Installer.msi)
* Set the MSI platform architecture to match the executable (i.e. x86 for 32-bit, and x64 for 64-bit)

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_2_-__Select_the_executable.png)

6. Set the visibility in Apps & features

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_3_-_Visibility_in_Apps_&_features.png)

7. Set the Security and User Context

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_4_-_Security_and_User_Context.png)

8. Specify Application IDs

* In the Upgrade Code section, click the "Create New" button next to generate a code.  This will be used to allow uninstallation.

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_5_-_Application_Ids.png)

9. Specify Properties (optional: customize options here to have the installer show your brand)

* You can change the drop-down menu of each line item from "Executable" to "Manual" in order to set your own values for the Product Name, Manufacturer, Version, Comments, and Product icon

*Original*

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_6a_-_Properties_-_Defaults.png)

*Customized*

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_6b_-_Properties_-_Customized.png)

10. Specify More Properties (optional)

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_7_-_More_properties.png)

11. Specify Parameters

    * In the "Install arguments" box, enter "-i", add a space and then enter your [installation key](https://doc.limacharlie.io/docs/documentation/docs/manage_keys.md)
    * -i YOUR\_INSTALLATION\_KEY\_GOES\_HERE

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_8b_-_Parameters_-_filled.png)

To provide the option to uninstall, set the Uninstall argument to "-c" (note that you do not need to specify your Installation Key for uninstallation).

12. Actions

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_9_-_Actions.png)

13. Summary

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_10_-_Summary.png)

14. Status

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Wrapper_-_11_-_Status.png)

Once you have created the MSI package you should sign it using your digital signature.  You can [learn more about signing the MSI on the exemsi website](https://www.exemsi.com/documentation/sign-your-msi/).

---

## Experience when running the MSI

When installing the application using the MSI you'll see your application name in the title bar.

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/MSI_Installation.png)

When inspecting the properties of the MSI you'll see the details you'd specified.

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/Created_MSI_Properties-Details.png)

In the Apps & Features section of Windows, you'll see the application listed under your name.

![exemsi](https://storage.googleapis.com/limacharlie-io/doc/white-label/exemsi-instructions/Shown_in_Control_Panel_-_Apps_and_Features.png)

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

### Related articles

* [Windows Agent Installation](/docs/windows-agent-installation)
* [Enterprise-Wide Agent Deployment](/docs/enterprise-wide-agent-deployment)
* [Agent Deployment via Microsoft Intune](/docs/agent-deployment-microsoft-intune)

---

#### What's Next

* [Enterprise-Wide Agent Deployment](/docs/enterprise-wide-agent-deployment)

Table of contents

+ [Prerequisites](#prerequisites)
+ [Instructions](#instructions)
+ [Experience when running the MSI](#experience-when-running-the-msi)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## Building the User Interface

# Building the User Interface
## Auto Generated UI

The Extensions UI uses the information provided in the schema to auto-determine it's UI elements, and for most simple extensions, the UI will be able to auto conform based on the bare minimum schema definition alone. However, further customization may be made in the schema for more complex or specific use cases by adjusting the layout, or adjusting the details for a specific field.

### Deconstructing the Page

Generally the top of the extension page will show the extension label and it's short description. If it exists, it will also show a button for quick access to this extension's "associated sensor".

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/ext-1.png)

In the top right, any actions (as defined in your request schema) will be displayed as a dropdown and button.
![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/ext-2.png)

Note that there are small changes to this structure depending on the layout selected, however all variations should be intuitive as they do not deviate much from this general page structure.
 Beyond this, main content of the page is determined by the layout.

### Picking Your Layout Type

* `auto` (default layout, it will pick one of the below)
* `config` (use this if you have a configuration)
* `editor` (very specific use-case for editing large code blocks like yaml)
* `action` (use this to prioritize certain actions in the UI)
* `description`
* `key` (just a variation of description)

For the action, and editor layouts, make sure you define one (or more) default actions as well. The editor UI for the action layout will show all the actions in-page, as opposed to a button on the top right. When set to the editor layout, the UI will automatically run the default action and display the results and a supported action.

### Form Data Types

Every field has the following optional details to further adjust the UI.

* **label**: Add a label if you want a more 'human-legible' label on this field
* **placeholder**: Placeholder text on the input can serve as an example for the user
* **description**: A description for this field can be added that will be available as a tooltip on the UI next to the field label
* **display\_index**: The display index starts at 1 (not 0) and guides the GUI on the order to show the fields. A display index of 1, will display before a display index of 2.
* **default\_value**: A default value for the field, will auto-populate the field with this value

Some other configurations that conditionally apply to specific data\_types:

* **filter**: Available on select primitive data\_types.
* **enum\_values**: Details on the available enums, to support the enum data type.
* **complex\_enum\_values**: Details to support the complex enum data type. Supports reference links, and categories.
* **object**: An object that contains nested key-value pairs for more fields, and serves to detail the nested fields.

For the complete list of all data types, please see the [page on data types](/v2/docs/schema-data-types).

## Nuanced Usage

If your extension requires it, there are more opportunities to adjust the UI in order to better guide or facilitate a user on using your extension.

### Multiple Layouts as Tabs

In the schema, it is possible to define several views to utilize a combination of layout types. This may be useful in order to guide a user on how you want them to use your extension.
![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/ext-3.png)

### Setting Supported Actions

Functionality for this field is set to be expanded in the future

Please feel free to reach out to us on our community slack if you'd like to stay up to date on

Supported actions are tied to a request's (also called "actions") response. It allows the response data to be modified and passed along to a follow-up action. This may be useful when operating a dry run, or triggering a workflow.

---

#### What's Next

* [Lookups](/docs/lookups)

Table of contents

+ [Auto Generated UI](#auto-generated-ui)
+ [Nuanced Usage](#nuanced-usage)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## ChromeOS Support

# ChromeOS Support
* 1 Minute to read

## What's Next

* [Uncovering Adversary Techniques](/docs/uncovering-adversary-techniques)

Tags

* [ChromeOS](/docs/en/tags/ChromeOS)
* [use case](/docs/en/tags/use%20case)

---

## ChromeOS with Google Chrome Enterprise

# ChromeOS with Google Chrome Enterprise
* 1 Minute to read

## Related articles

* [Chrome Agent Installation](/docs/chrome-agent-installation)

---

### What's Next

* [Endpoint Agent Uninstallation](/docs/endpoint-agent-uninstallation)

Table of contents

+ [Configuration](#configuration)
+ [Verifying Configuration](#verifying-configuration)

Tags

* [browser agent](/docs/en/tags/browser%20agent)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [google workspace](/docs/en/tags/google%20workspace)
* [sensors](/docs/en/tags/sensors)

---

## Cloud Security

# Cloud Security
* 1 Minute to read

## What's Next

* [SecOps Development](/docs/secops-development)

Tags

* [cloud](/docs/en/tags/cloud)
* [use case](/docs/en/tags/use%20case)

---

## Config Hive

# Config Hive
The Config Hive, or "Hive", is the main configuration system for LimaCharlie. It is a generic set of APIs using by LimaCharlie to maintain the configuration of various systems within the platform. We make the Config Hive accessible to help you configure the wide range of systems, features, and extensions within LimaCharlie in a cohesive way. Each feature or system configuration lives in its own "hive".

Components managed through Hive:

* Cloud Sensors (`cloud_sensor`)
* Detection & Response Rules (`dr-general`, `dr-managed` and `dr-service`)
* False Positive Rules (`fp`)
* Lookups (`lookup`)
* [Secrets](/v2/docs/config-hive-secrets) (`secret`)

The Hive contains configuration records organized in a simple hierarchy: `/hive/{hive_name}/{oid}/{record_name}`. Let's examine each part of this record:

* The `hive_name` represents the type of records it contains. For example, the `cloud_sensor` hive name will contain all records relating to cloud sensors (cloud hosted [LimaCharlie Adapters](/v2/docs/adapters)).
* The `oid` is a "partition" for the records, in this case an Organization ID.
* The `record_name` is the unique name for the record.

Setting and updating records in Hive will automatically orchestrate the necessary changes in the relevant service. For example, updating a `cloud_sensor` record will automatically reapply the new configurations to the cloud hosted LimaCharlie Adapter. Deleting the same record will stop the Adapter.

The record data itself will be dependant on the hive name, but it will always be a JSON dictionary.

## Exploring

The best way to explore configurations in LimaCharlie and hive is through the LimaCharlie CLI (`pip install limacharlie`).

The CLI offers a simple interface to list, get and modify records in a single unified way regardless of the type of configuration.

The core command line commands are:

* `limacharlie hive list --help`
* `limacharlie hive get --help`
* `limacharlie hive set --help`
* `limacharlie hive update --help`
* `limacharlie hive remove --help`

For example, if you want to explore the  rules ("general" namespace) stored in LimaCharlie, you could issue:

```
limacharlie hive list dr-general
```

## Record Structure

Records contain 3 components:

* The record data itself (referenced to as `data`), who's format is dependant on the hive where it lives.
* User Metadata (referenced to as `usr_mtd`). As outlined below, this is metadata that can modified directly by you and can be exposed to users using specific permissions without giving access to the full record data.
* System Metadata (referenced to as `sys_mtd`). This is metadata that is generated and maintained by the Hive system.

### User Metadata

The user metadata format is the following:

```json
{
    "expiry": 123,          // a milisecond epoch time when the record will automatically expire and be deleted.
    "tags": ["abc", "def"], // a list of tags on this record.
    "enabled": true         // a boolean indicating whether the record is in an "enabled" state or not.
}
```

### System Metadata

The system metadata format is the following:

```json
{
    "etag": "abc",        // a unique tag representing the current state of data of the record. Can be used for optimistic transactions: https://en.wikipedia.org/wiki/HTTP_ETag
    "last_author": "abc", // the identity of the last entity having modified the record.
    "last_mod": 123,      // a milisecond epoch of the last time the record was modified.
    "created_by": "abc",  // the identity of the entity that originally created the record.
    "created_at": 123,    // a milisecond epoch of the time the record was originally created.
    "guid": "abc",        // a globally unique identifier of the record (not its data).
    "last_error": "abc",  // the contents of the last error related to the record.
    "last_error_ts": 123  // the milisecond epoch of the last time an error occured relating to the record.
}
```

## Accessing

### REST

The config hive can be accessed through the LimaCharlie REST API (https://api.limacharlie.io/static/swagger/).

### Python CLI

Install the Python LimaCharlie CLI using `pip install limacharlie`.

Possible operations: `limacharlie hive --help`

Repository: https://github.com/refractionPOINT/python-limacharlie/

## Conditional Update

One of the advantages of the Hive system is the ability to perform conditional updates (where you prevent two entities from updating
 and overwriting each other's changes).

You may perform conditional record updates using the `etag` parameter. When set during an update, the hive system will verify that
 the record it is about to update currently has the etag provided. If the etags do not match, the update is not performed. This allows
 you to:

1. Get a Record X
2. Update some values of X locally
3. Set the updated Record X, including the etag received during the Get

This enables you to detect when "update collision" occur. An example implementation can be found in the `update` function of the Python SDK [here](https://github.com/refractionPOINT/python-limacharlie/blob/016abfe041877132e4c6dd948f1532b173ca7883/limacharlie/Hive.py#L121).

### Infrastructure as Code

The Hive system also simplifies how you can store and apply your configurations through infrastructure as code.

All hive related configurations are found under the key `hives`, followed by the hive name. For example:

```
hives:
  dr-general:
    Microsoft Defender MALWAREPROTECTION_RTP_DISABLED:
      data:
        detect:
          event: WEL
          op: and
          rules:
            - op: is
              path: event/EVENT/System/Channel
              value: Microsoft-Windows-Windows Defender/Operational
            - op: is
              path: event/EVENT/System/EventID
              value: "5001"
        respond:
          - action: report
            name: Microsoft-defender-MALWAREPROTECTION_RTP_DISABLED
      usr_mtd:
        enabled: true
        expiry: 0
        tags:
          - defender
```

The above example refers to the `dr-general` hive (general namespace for D&R rules), to the record named `Microsoft Defender MALWAREPROTECTION_RTP_DISABLED` who's `data` contains the actual content of the D&R rule, and this record is enabled, does not expire. The record is tagged with `defender`.

In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

Command-line Interface

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

#### Related articles

* [LimaCharlie SDK & CLI](/docs/limacharlie-sdk)

---

##### What's Next

* [Config Hive: Cloud Sensors](/docs/config-hive-cloud-sensors)

Table of contents

+ [Exploring](#exploring)
+ [Record Structure](#record-structure)
+ [Accessing](#accessing)
+ [Conditional Update](#conditional-update)

Tags

* [platform](/docs/en/tags/platform)

---

## Config Hive: Lookups

# Config Hive: Lookups
## Format

Lookups are dictionaries/maps/key-value-pairs where the key is a string. The lookup can then be queried by various parts of LimaCharlie (like  rules). The value component of a lookup must be a dictionary and represents metadata associated with the given key, which will be returned to the rule using the lookup.

Lookup data can be ingested by specifying one of the following root keys indicating the format of the lookupd data:

* `lookup_data`: represented direct as parsed JSON.
* `newline_content`: a string where each key is separated by a newline, LimaCharlie will assume the metadata is empty.
* `yaml_content`: a string in YAML format that contains a dictionary with the string keys and dictionary metadata like the `lookup_data`.

## Permissions

* `lookup.get`
* `lookup.set`
* `lookup.del`
* `lookup.get.mtd`
* `lookup.set.mtd`

## Usage

### Infrastructure as Code

```
hives:
    lookup:                             # Example lookup in the lookup hive
        example-lookup:
            data:
                lookup_data:
                    8.8.8.8: {}
                    8.8.4.4: {}
                    1.1.1.1: {}
                optimized_lookup_data:
                    _LC_INDICATORS: null
                    _LC_METADATA: null
            usr_mtd:
                enabled: true
                expiry: 0
                tags:
                    - example-lookup
                comment: ""
    extension_config:                   # Example lookup manager extension config
        ext-lookup-manager:
            data:
                lookup_manager_rules:
                    - arl: ""
                      format: json
                      name: tor
                      predefined: '[https,storage.googleapis.com/lc-lookups-bucket/tor-ips.json]'
                      tags:
                        - tor
                    - arl: ""
                      format: json
                      name: talos
                      predefined: '[https,storage.googleapis.com/lc-lookups-bucket/talos-ip-blacklist.json]'
                      tags:
                        - talos
            usr_mtd:
                enabled: true
                expiry: 0
                tags: []
                comment: ""
```

### Manually in the GUI

Lookups can be added in the web interface by navigating to Automation --> Lookups. Name your lookup, choose the format, and copy paste the contents of your lookup in the `JSON data` field.

LimaCharlie also provides several publicly available lookups for use in your Organization. More information and the contents of these can be found on [GitHub](https://github.com/refractionpoint/lc-public-lookups). The contents of these lookups can be used here as well.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/lookups.png)

### Automatically via the Lookup Manager

If your lookups change frequently and you wish to keep them up to date, LimaCharlie offers the lookup manager extension as a mechanism to automatically update your lookups every 24 hours. Documentation on the lookup manager can be found [here](/v2/docs/ext-lookup-manager).

## Example Lookup

```json
{
  "lookup_data": {
    "c:\\windows\\system32\\ping.exe": {
      "mtd1": "known_bin",
      "mtd2": 4
    },
    "c:\\windows\\system32\\sysmon.exe": {
      "mtd1": "good_val",
      "mtd2": 10
    }
  }
}
```

or

```json
{
  "newline_content": "lvalue1\nlvalue2\nlvalue3"
}
```

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

### Related articles

* [Config Hive: Yara](/docs/config-hive-yara)
* [Config Hive: Cloud Sensors](/docs/config-hive-cloud-sensors)
* [Config Hive: Secrets](/docs/config-hive-secrets)
* [Config Hive: Detection & Response Rules](/docs/config-hive-dr-rules)
* [Config Hive](/docs/config-hive)

---

#### What's Next

* [Config Hive: Secrets](/docs/config-hive-secrets)

Table of contents

+ [Format](#format)
+ [Permissions](#permissions)
+ [Usage](#usage)
+ [Example Lookup](#example-lookup)

Tags

* [api](/docs/en/tags/api)
* [platform](/docs/en/tags/platform)

---

## Config Hive: Secrets

# Config Hive: Secrets
With its multitude of data ingestion and output options, LimaCharlie users can end up with a myriad of credentials and secret keys to faciliate unique data operations. However, not all users should be privy to these secret keys. Within the Config Hive, the `secrets` hive component allows you to decouple secrets from their usage or configuration across LimaCharlie. Furthermore, you can also grant permissions to users that allows them to see the configuration of an output, but not have access to the associated credentials.

The most common usage is for storing secret keys used by various [Adapters](/v2/docs/adapters) or [Outputs](/v2/docs/outputs). By referencing `secrets` within the Config Hive, we can configure these services without needing to reveal secret keys to all users.

Watch the video below to learn more about hive secrets, or continue reading below.

## Format

A secret record in `hive` has a very basic format:

```json
{
    "secret": "data"
}
```

The `data` portion of the records in this hive must have a single key called `secret` who's value will be used by various LimaCharlie components.

## Permissions

The `secret` hive requires the following permissions for the various operations:

* `secret.get`
* `secret.set`
* `secret.del`
* `secret.get.mtd`
* `secret.set.mtd`

## Secret Management

Over time, and with enough integrations, you may need to create and/or update secrets on demand. We provide quick options for both via either the LimaCharlie CLI or web app.

### Creating Secrets

With the appropriate permissions, users can create secrets in the following ways:

1. Using the LimaCharlie CLI, secrets can be created using the `limacharlie hive set secret` command (example below).
2. Via the web app, under **Organization Settings** > **Secrets Manager**.

### Updating Secrets

Once they are set, secrets can be updated via the following methods:

1. Using the LimaCharlie CLI, secrets can be updated using the `limacharlie hive update secret` command.
2. Via the web app, **Organization Settings** > **Secrets Manager**. Select the secret you wish to update, and update in the dialog box. Click **Save Secret** to save changes in the platform.

## Usage

Using a secret in combination with an output has very few steps:

1. Create a secret in the `secret` hive
2. Create an Output and use the format `hive://secret/my-secret-name` as the value for a credentials field.

## Example

Let's create a simple secret using the LimaCharlie CLI in a terminal. First, create a small file with the secret record in it:

```
$ echo "my-secret-value" > my-secret
```

Next, set this secret in Hive via the LimaCharlie CLI:

```
$ limacharlie hive set secret --key my-secret --data my-secret --data-key secret
```

You should get a confirmation that the secret was created, including metadata of the secret and associated OID:

```json
{
    "guid": "3a7a2865-a439-4d1a-8f50-b9a6d833075c",
    "hive": {
        "name": "secret",
        "partition": "8cbe27f4-aaaa-bbbb-cccc-138cd51389cd"
        },
    "name": "my-secret"
}
```

Next, create an output in the web app, using the value `hive://secret/my-secret` as the Secret Key value.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/secret.png)

And that's it! The output should start as expected, however when viewing the output's configuration, the secret should refer to the `hive` ARN, rather than the actual credentials.

Command-line Interface

In LimaCharlie, an Organization ID (OID) is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

---

### Related articles

* [Config Hive: Yara](/docs/config-hive-yara)
* [Config Hive: Cloud Sensors](/docs/config-hive-cloud-sensors)
* [Config Hive: Detection & Response Rules](/docs/config-hive-dr-rules)
* [Config Hive](/docs/config-hive)
* [Config Hive: Lookups](/docs/config-hive-lookups)

---

#### What's Next

* [Config Hive: Yara](/docs/config-hive-yara)

Table of contents

+ [Format](#format)
+ [Permissions](#permissions)
+ [Secret Management](#secret-management)
+ [Usage](#usage)
+ [Example](#example)

Tags

* [api](/docs/en/tags/api)
* [platform](/docs/en/tags/platform)

---

## Config Hive: Yara

# Config Hive: Yara
* 1 Minute to read

## Related articles

* [Config Hive: Cloud Sensors](/docs/config-hive-cloud-sensors)
* [Config Hive: Detection & Response Rules](/docs/config-hive-dr-rules)
* [Config Hive](/docs/config-hive)
* [Config Hive: Lookups](/docs/config-hive-lookups)
* [Config Hive: Secrets](/docs/config-hive-secrets)

---

### What's Next

* [Infrastructure as Code](/docs/infrastructure-as-code)

Table of contents

+ [Format](#format)
+ [Usage](#usage)
+ [Example](#example)

Tags

* [api](/docs/en/tags/api)
* [platform](/docs/en/tags/platform)

---

## Container Clusters

# Container Clusters
You can also run LimaCharlie at the host level in a container cluster system
 like Kubernetes in order to monitor all running containers on the host with
 a single Sensor. In fact, this is the preferred method as it reduces the overhead
 of running LC within every single container.

This is accomplished by a combination of a few techniques:

1. A privileged container running LC.
2. LC runs with `HOST_FS` environment variable pointing to the host's root filesystem mounted within the container.
3. LC runs with the `NET_NS` environment variable pointing to the host's directory listing network namespaces.
4. Running the container with the required flags to make sure it can have proper access.

The first step is straight forward. For example, set the environment like `ENV HOST_FS=/rootfs` and `ENV NET_NS=/netns` as part of your `Dockerfile`. This will let the LC sensor know where it can expect host-level information.

The second step is to run the container like: `docker run --privileged --net=host -v /:/rootfs:ro --env HOST_FS=/rootfs -v /var/run/docker/netns:/netns:ro --env NET_NS=/netns --env LC_INSTALLATION_KEY=your_key your-lc-container-name`.

Remember to pick the appropriate LC sensor architecture installer for the *container* that will be running LC (not the host).
 So if your privileged container runs Alpine Linux, use the `alpine64` version of LC.

A public version of the container described below is available from dockerhub as: `refractionpoint/limacharlie_sensor:latest`.

## Sample Configurations

This is a sample `Dockerfile` you may use to run LC within a privileged container as described above:

```
# Requires an LC_INSTALLATION_KEY environment variable
# specifying the installation key value.
# Requires a HOST_FS environment variable that specifies where
# the host's root filesystem is mounted within the container
# like "/rootfs".
# Requires a NET_NS environment variable that specific where
# the host's namespaces directory is mounted within the container
# like "/netns".
# Example:
# export ENV HOST_FS=/rootfs
# docker run --privileged --net=host -v /:/rootfs:ro -v /var/run/docker/netns:/netns:ro --env HOST_FS=/rootfs --env NET_NS=/netns --env LC_INSTALLATION_KEY=your_key refractionpoint/limacharlie_sensor

FROM alpine

RUN mkdir lc
WORKDIR /lc

RUN wget https://downloads.limacharlie.io/sensor/linux/alpine64 -O lc_sensor
RUN chmod 500 ./lc_sensor

CMD ./lc_sensor -d -
```

And this is a sample Kubernetes `deployment` on

a cluster supporting eBPF (kernel > 5.7):

```
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: lc-sensor
  namespace: lc-monitoring
  labels:
    app: lc-monitoring
spec:
  minReadySeconds: 30
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      app: lc-monitoring
  template:
    metadata:
      namespace: lc-monitoring
      labels:
        app: lc-monitoring
    spec:
      hostNetwork: true
      hostPID: true
      containers:
        - name: lc-sensor
          image: refractionpoint/limacharlie_sensor:latest
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: true
            privileged: true
            capabilities:
              add: ['CAP_SYS_ADMIN']
          resources:
            requests:
              memory: 128M
              cpu: 0.01
            limits:
              memory: 256M
              cpu: 0.9
          volumeMounts:
            - mountPath: /rootfs
              name: all-host
            - mountPath: /netns
              name: all-host-ns
            - mountPath: /sys/kernel/debug
              name: all-host-krnl
            - mountPath: /sys/kernel/btf
              name: btf
            - mountPath: /lib/modules
              name: libmodules
          env:
            - name: HOST_FS
              value: /rootfs
            - name: NET_NS
              value: /netns
            - name: LC_INSTALLATION_KEY
              value: <<<< YOUR INSTALLATION KEY GOES HERE >>>>
      volumes:
        - name: all-host
          hostPath:
            path: /
        - name: all-host-ns
          hostPath:
            path: /var/run/docker/netns
        - name: all-host-krnl
          hostPath:
            path: /sys/kernel/debug
        - name: btf
          hostPath:
            path: /sys/kernel/btf
        - name: libmodules
          hostPath:
            path: /lib/modules
```

a cluster not supporting eBPF (kernel < 5.7):

```
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: lc-sensor
  namespace: lc-monitoring
  labels:
    app: lc-monitoring
spec:
  minReadySeconds: 30
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      app: lc-monitoring
  template:
    metadata:
      namespace: lc-monitoring
      labels:
        app: lc-monitoring
    spec:
      containers:
        - name: lc-sensor
          image: refractionpoint/limacharlie_sensor:latest
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: true
            privileged: true
          resources:
            requests:
              memory: 128M
              cpu: 0.01
            limits:
              memory: 256M
              cpu: 0.9
          volumeMounts:
            - mountPath: /rootfs
              name: all-host-fs
            - mountPath: /netns
              name: all-host-ns
          env:
            - name: HOST_FS
              value: /rootfs
            - name: NET_NS
              value: /netns
            - name: LC_INSTALLATION_KEY
              value: <<<< YOUR INSTALLATION KEY GOES HERE >>>>
      volumes:
        - name: all-host-fs
          hostPath:
            path: /
        - name: all-host-ns
          hostPath:
            path: /var/run/docker/netns
      hostNetwork: true
```

### SELinux

On some hardened versions of Linux, certain file paths are prevented from loading `.so` (Shared Object) files. LimaCharlie requires a location where
 it can write `.so` files and load them. To enable this on hardened versions of Linux, you can specify a `LC_MOD_LOAD_LOC` environment variable containing
 a path to a valid directory for loading, like `/lc` for example. This environment variable needs to be set for the sensor executable (`rphcp`) at runtime.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

#### Related articles

* [Docker Agent Installation](/docs/docker-agent-installation)
* [Kubernetes Pods Logs](/docs/adapter-types-kubernetes-pods-logs)
* [Azure Kubernetes Service (AKS)](/docs/azure-kubernetes-service)

---

##### What's Next

* [Docker Agent Installation](/docs/docker-agent-installation)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [linux](/docs/en/tags/linux)
* [sensors](/docs/en/tags/sensors)

---

## Developer Grant Program

# Developer Grant Program
* 1 Minute to read

## What's Next

* [API Integrations](/docs/add-ons-api-integrations)

Tags

* [add-ons](/docs/en/tags/add-ons)

---

## Enterprise SOC

# Enterprise SOC
The LimaCharlie SecOps Cloud Platform (SCP) is a unified platform for modern cybersecurity operations.

The SCP delivers core cybersecurity capabilities and infrastructure via a public cloud model: on-demand, pay-per-use, and API-first. For the cybersecurity industry, this is a paradigm shift comparable to how the IT public cloud revolutionized IT.

For enterprises and other large organizations, the SecOps Cloud Platform is a powerful way to take control of security posture and scale operations. The SCP can help teams gain visibility into their environments, eliminate coverage gaps, solve integration challenges, reduce spending on high-cost tools, free themselves from vendor lock-in, and build custom security solutions to meet their organization's unique needs.

## 3 implementation plans for immediate value

The SecOps Cloud Platform is a comprehensive platform for cybersecurity operations—but it doesn't have to be implemented all at once. The SCP's public cloud-like delivery model eliminates adoption hurdles for enterprises. Easily scaled and API-first, the SCP enables teams to integrate the platform into their security operations gradually, leveraging its capabilities progressively as they go. Here are three recommended first steps to help enterprises realize value from the SCP quickly.

### 1. Centralize telemetry data to improve visibility and streamline operations

The SecOps Cloud Platform allows enterprises to bring all of their telemetry data into one place—improving visibility, eliminating coverage gaps, and enabling streamlined SecOps workflows. Here is a general outline of what that looks like:

**Bring your telemetry data into the SCP.** The SecOps Cloud Platform allows enterprise teams to ingest data from any source. The platform's endpoint detection and response (EDR)-type sensors can be deployed directly on Windows, Mac, and Linux endpoints with full feature parity across these OSes. These sensors allow security teams to capture system events and other telemetry data in real time—or import event data from third-party EDR tools such as VMWare Carbon Black, CrowdStrike, SentinelOne, or Microsoft Defender. There are also browser-based EDR sensors to support Chrome and Edge deployments.

Log-type data can also be brought into the SCP using a system of adapters or via webhook. Supported log data sources include O365, 1Password, AWS CloudTrail, Google Cloud Platform (GCP), Slack Audit logs, and many more. For a comprehensive list, refer to the SCP documentation.

**Visualize and manage your telemetry data under a single plane.** Telemetry data brought into the SCP is normalized to a common JSON format and explorable through a single interface. The immediate advantage for security teams is improved visibility—and an end to coverage gaps that can jeopardize organizational security and compliance. In addition, the ability to manipulate data through a single UI helps teams eliminate integration challenges caused by other solutions and streamline their internal workflows.

**Go beyond observability.** The SecOps Cloud Platform's data-routing capabilities mean that it can be used as a simple observability point solution if you choose. But the SCP is capable of far more than this. All telemetry data brought into the platform can be run through an advanced detection and response engine, and wire-speed response actions can be taken on endpoints via the multiplatform SCP agent. From day one, security teams using the SCP for centralization and observability can also apply their own custom detection and response (D&R) logic to all telemetry data brought into the platform, leverage curated rulesets like Sigma, Soteria, or SOC Prime rules for the same purpose, or run historical threat hunts against data stored in the SCP.

The SecOps Cloud Platform helps enterprises improve visibility, eliminate coverage gaps, solve integration challenges, and make their workflows more efficient—and this is just the first step in what teams can achieve with the platform.

#### 2. Reduce spending on SIEMs and other high-cost solutions

Because the SCP lets security teams bring in data from any source and export it to any destination, the platform can also be used as a pass-through to observe, transform, enrich, and anonymize data in-flight and route it to different destinations in a fine-grained way. This strategy can significantly reduce the costs of security information and event management (SIEM) tools and other expensive third-party solutions.

**Identify inefficiencies in your current data flow.** Many organizations simply send 100% of their telemetry data to their SIEM. They only use a fraction of that data, but they pay for all of it. Conduct a thorough review of how you are currently routing your telemetry data. Determine what data truly needs to be sent to your highest-cost tools—and what can be retained in lower-cost storage.

**Use the SCP's output controls to optimize your data routing.** Your options here are highly flexible and customizable:

Telemetry data can be sent to Splunk, Humio, Elastic, Amazon S3 buckets, Azure Event Hubs, Google Cloud Storage, and [many other destinations](https://limacharlie.io/secops-cloud-platform-guide-enterprise-soc#:~:text=many%20other%20destinations).

Data can also be streamed to your destination(s) of choice with [different degrees of granularity](https://limacharlie.io/secops-cloud-platform-guide-enterprise-soc#:~:text=different%20degrees%20of%20granularity). On the more verbose end of the spectrum, it is possible to send all data events from a sensor to a given destination. But you can also create a tailored stream that sends only specific events to your output destination.

Enterprise teams can thus route their data for optimal cost savings. For example, a team might send only high-priority detections and failed 1Password login attempts to Splunk, a secondary tranche of log data and events to an Amazon S3 bucket, and retain everything else in low-cost cold storage.

**Use free storage and transparent pricing for compliance and additional savings.** The SCP offers one year of free storage of all telemetry data for the cost of ingestion. Pricing is [transparent](https://limacharlie.io/secops-cloud-platform-guide-enterprise-soc#:~:text=ingestion.%20Pricing%20is-,transparent,-and%C2%A0easy) and [easy to calculate](https://limacharlie.io/secops-cloud-platform-guide-enterprise-soc#:~:text=transparent%C2%A0and-,easy%20to%20calculate,-%2C%20making%20it%20simple), making it simple to determine the most cost-effective data flow and storage sites for your telemetry. All telemetry data is retained for one year by default in a fully searchable and explorable format, so you don't have to worry about losing data that you may need later on. Because the total cost of storage in the SCP cloud is often far more affordable than traditional data lakes, many organizations will be able to use the platform's built-in storage to address compliance requirements and reduce costs.

The SCP's data routing capabilities put enterprise teams in full control of their telemetry data, allowing them to cut spending on high-cost solutions while ensuring access to critical data in order to meet compliance and operational needs.

#### 3. Simplify tooling and control your infrastructure

The SecOps Cloud Platform delivers the core components required to secure and monitor any organization. Over time, enterprises can leverage the SCP's numerous capabilities to develop a custom security infrastructure that they control completely. And while that is clearly a long-term project, enterprises that adopt the SCP can begin using the platform to simplify their stack right away:

**Replace one-off solutions.** The increasing specialization of cybersecurity products means most enterprise teams rely on a patchwork of solutions—and are sometimes forced to buy a tool to satisfy one, extremely narrow use case. Teams should begin by identifying their one-off tools and vendors and determining how they can be replaced with an SCP solution. The SecOps Cloud Platform offers a rich ecosystem of [100+ cybersecurity capabilities and integrations](https://limacharlie.io/secops-cloud-platform-guide-enterprise-soc#:~:text=100%2B%20cybersecurity%20capabilities%20and%20integrations) and a [marketplace of add-ons](https://docs.limacharlie.io/docs/add-ons) to extend the platform. In many cases, teams will find that it is possible to replace single-use vendors with an SCP solution that offers equal or better performance, reducing tool sprawl and improving security operations at the same time.

**Upgrade existing tools or features.** The fragmentation of the current cybersecurity vendor space means that many enterprise teams end up using tools that excel in one arena but fall short in others. Instead of simply accepting the unsatisfactory parts of their stack, teams can use the SCP to augment or replace underperforming tools and features with best-in-breed alternatives.

**Begin your transition to infrastructure independence.** After teams shed one-off and redundant tools, they should begin to think strategically about how to leverage the SCP to free themselves from vendor lock-in once and for all. Look for vendor contracts due to expire or products nearing end-of-life and work with LimaCharlie engineers to develop, validate, and deploy a custom replacement ahead of time.

In the near term, the SecOps Cloud Platform lets enterprises simplify their deployments significantly. In the long term, it allows organizations to take full control of their tooling, infrastructure, and security posture.

---

##### What's Next

* [Security Service Providers (MSSP, MSP, MDR)](/docs/service-providers-mssp-msp-mdr)

Table of contents

+ [3 implementation plans for immediate value](#3-implementation-plans-for-immediate-value)

Tags

* [enterprise](/docs/en/tags/enterprise)
* [SOC](/docs/en/tags/SOC)
* [use case](/docs/en/tags/use%20case)

---

## File and Registry Integrity Monitoring (FIM) Deployments

# File and Registry Integrity Monitoring (FIM) Deployments
* 1 Minute to read

## What's Next

* [ChromeOS Support](/docs/chromeos-support)

Tags

* [FIM](/docs/en/tags/FIM)
* [use case](/docs/en/tags/use%20case)

---

## Hostname Resolution

# Hostname Resolution
* 1 Minute to read

## What's Next

* [Detecting Sensors No Longer Sending Data](/docs/non-responding-sensors)

---

## Infrastructure as Code

# Infrastructure as Code
## Overview

LimaCharlie leverages YAML templates to define and manage the configurations for an Organization, enabling a powerful infrastructure-as-code (IaC) approach. These templates capture all the essential security settings and features of an organization, such as:

* **Enabled Add-ons**: Any additional features or modules that have been activated, from advanced detection mechanisms to specialized data analysis tools.
* **Detection & Response Rules**: The automated rules that determine how the system responds to specific threats or events, ensuring immediate and appropriate action.
* **Event & Artifact Collection**: Specifications for what data is collected, how it’s processed, and how long it’s retained. This can include system logs, endpoint telemetry, or forensic data from incidents.
* **File Integrity Monitoring**: Rules that detect and alert on unauthorized file changes, helping to identify potential breaches or malicious activity.
* **Output Configurations**: Settings that determine how and where data is sent, such as forwarding alerts to SIEMs, sending notifications to Slack, or exporting logs to external storage.

These YAML-based configurations allow you to capture an organization's entire security setup in a standardized format. This not only provides clarity and visibility but also enables efficient scaling. When deploying a new organization, you can simply apply the existing YAML template to instantly replicate the security environment—no need for manual reconfiguration.

The infrastructure-as-code model promotes consistency, as every organization can be configured identically with minimal effort. Additionally, YAML templates can be version-controlled, allowing you to track changes, roll back updates, and ensure auditability over time. This approach is especially beneficial in multi-tenant environments or service providers managing security across multiple clients, as it facilitates rapid, scalable deployment with confidence that security postures remain aligned across organizations.

Another advantage is the flexibility to customize templates for specific use cases. You can create a base template for common settings and extend it with organization-specific rules or modules, giving you the ability to fine-tune security without sacrificing consistency.

Overall, LimaCharlie’s YAML templates enable security teams to treat organizations like modular containers, allowing rapid, repeatable deployment and easy maintenance across a large number of environments while minimizing the risks of human error.

## Example

Here's a basic config for an organization in LimaCharlie:

```
version: 3
resources:
  api:
  - insight
  replicant:
  - infrastructure-service
  - integrity
  - reliable-tasking
  - responder
  - sigma
  - soteria-rules
  - logging
  - yara
integrity:
  linux-key:
    patterns:
    - /home/*/.ssh/*
    tags: []
    platforms:
    - linux
artifact:
  linux-logs:
    is_ignore_cert: false
    is_delete_after: false
    days_retention: 30
    patterns:
    - /var/log/syslog.1
    - /var/log/auth.log.1
    tags: []
    platforms:
    - linux
  windows-logs:
    is_ignore_cert: false
    is_delete_after: false
    days_retention: 30
    patterns:
    - wel://system:*
    - wel://security:*
    - wel://application:*
    tags: []
    platforms:
    - windows
```

Applying this would get an org started with some basics:

* Add-ons that enable incident response (`insight`, `reliable-tasking`, `responder`)
* Managed detection & response rulesets (`sigma`, `soteria-rules`)
* Services that add Sensor capabilities (`integrity`, `logging`, `yara`)
* Some basic configurations to monitor file integrity of `*/.ssh` on Linux and collect syslog, auth logs, and Windows event logs

## Generating IaC Configs

There are many ways to produce an IaC config for reuse across multiple deployments. One option is to use our [IaC Generator](https://iac.limacharlie.io/).

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28263%29.png)

## Applying Configs

### Methods

* Via web application in 'Templates' (requires `infrastructure-service`)
* Via REST API requests to `infrastructure-service`
* Via CLI (`limacharlie config fetch` / `limacharlie config push`)

The web application offers two main modes of syncing:

* `Apply`: Add new config and apply changes additively
* `Modify`: Edit existing config and apply changes destructively

Apply mode can be especially useful for applying partial configs from online examples and community solutions. LimaCharlie has a [GitHub repository](https://github.com/refractionPOINT/templates) with some starter config templates.

For finer-grained control of config, or updating configs as part of a CI pipeline, we recommend reading the documentation for [infrastructure service.](/v2/docs/ext-infrastructure)

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Command-line Interface

---

#### Related articles

* [Infrastructure](/docs/ext-infrastructure)
* [Config Hive: Secrets](/docs/config-hive-secrets)
* [Config Hive: Cloud Sensors](/docs/config-hive-cloud-sensors)
* [Config Hive: Yara](/docs/config-hive-yara)
* [Config Hive: Detection & Response Rules](/docs/config-hive-dr-rules)
* [Config Hive](/docs/config-hive)
* [Config Hive: Lookups](/docs/config-hive-lookups)

---

##### What's Next

* [Outputs](/docs/outputs)

Table of contents

+ [Overview](#overview)
+ [Example](#example)
+ [Generating IaC Configs](#generating-iac-configs)
+ [Applying Configs](#applying-configs)

Tags

* [platform](/docs/en/tags/platform)

---

## Ingesting Linux Audit Logs

# Ingesting Linux Audit Logs
One data source of common interest on Linux systems is the `audit.log` file. By default, this file stores entries from the Audit system, which contains information about logins, privilege escalations, and other account-related events. You can find more information about Audit Log files [here](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/security_guide/sec-understanding_audit_log_files).

There are a few techniques to ingest Linux Audit logs into LimaCharlie:

1. Pull the raw logs using Artifacts and/or the File System navigator *(EDR sensors only)*
2. Collect the files using **Artifact Collection.**
3. Stream the raw audit log via a `file` adapter.

We will explore these techniques in this tutorial. Adapters can also be configured as syslog listeners; that will be covered in another tutorial.

## File System Browser

Our Windows, Linux, and macOS EDR sensors offer file system navigation capabilities. If you need a single, ad-hoc collection of the `auth.log`, you can use the File System capability to navigate to `/var/log`, and download `auth.log`.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/audit-1.png)

## Artifact Collection

If you don't need to stream Linux Audit log(s), but instead want to maintain a copy of them for posterity, Artifact collection would be your best method. This is an automated collection technique, but won't stream the events to your **Timeline**.

**Step 1:** Within the Navigation Pane, select `Artifact Collection`.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/audit-2.png)

**Step 2:** Create a simple artifact collection rule for `/var/log/auth.log`. In this example, we chose a retention period of 30 days; however, you should choose the correct retention period for your use case.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/audit-3.png)

click **Save**

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/audit-4.png)

**Step 3:** Saving the artifact rule will then populate to the appropriate sensor(s), and you should see the `auth.log` in the Artifacts menu, once it is collected by the Sensor.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/audit-5(1).png)

Want more logs?

Want more than just the most recent `auth.log`? Specify a regular expression to capture all archived copies of the log files. However, be careful on retention and make sure you're not unnecessarily duplicating data!

## File Adapter Ingestion

It is also possible to deploy a LimaCharlie [Adapter](/v2/docs/adapters) pointed to `auth.log` to collect and stream the events in directly. Note that Adapters will create a separate telemetry "stream" - thus, it is recommended to combine file types where possible.

**Step 1:** Create an Installation Key for your adapter and download the appropriate binary.

**Step 2:** On the system(s) to collect logs from, deploy the adapter. We recommend utilizing a configuration file for adapter testing, to allow for tracking of changes. The following is a sample file that will ingest `auth.log` events as basic text.

```
file:
  client_options:
    identity:
      installation_key: <installation_key>
      oid: <oid>
    platform: text
    sensor_seed_key: audit-log-events
  file_path: /var/log/auth.log
  no_follow: false
```

More details on configuration files and adapter usage can be found [here](/v2/docs/adapter-usage).

**Step 3:** Run the adapter, providing the `file` option and the appropriate config file.

`$ ./lc_adapter file /tmp/config.yml`

The adapter should load the config and display options to the terminal.

*Note: This is not a persistent install; utilize your operating system's init/systemctl capabilities to create a persistent adapter*

**Step 4:** Returning to the LimaCharlie web UI, you should start to see events flowing in almost instantaneously.

![image.png](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image%28115%29.png)

Note that a `text` platform will ingest data as basic text, however you could use formatting options to parse the fields respective to your `auth.log` format.

---

### Related articles

* [Linux Agent Installation](/docs/linux-agent-installation)

---

#### What's Next

* [Ingesting Windows Event Logs](/docs/ingesting-windows-event-logs)

Table of contents

+ [File System Browser](#file-system-browser)
+ [Artifact Collection](#artifact-collection)
+ [File Adapter Ingestion](#file-adapter-ingestion)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [linux](/docs/en/tags/linux)
* [sensors](/docs/en/tags/sensors)
* [telemetry](/docs/en/tags/telemetry)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## Ingesting MacOS Unified Logs

# Ingesting MacOS Unified Logs
* 1 Minute to read

## Related articles

* [macOS Agent Installation](/docs/macos-agent-installation)
* [Mac Unified Logging](/docs/adapter-types-mac-unified-logging)
* [Artifacts](/docs/artifacts)

---

### What's Next

* [Log Collection Guide](/docs/logcollectionguide)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)
* [telemetry](/docs/en/tags/telemetry)
* [tutorial](/docs/en/tags/tutorial "Tutorial")

---

## LimaCharlie CLI

# LimaCharlie CLI
* 1 Minute to read

## Related articles

* [LimaCharlie SDK & CLI](/docs/limacharlie-sdk)

---

### What's Next

* [BinLib](/docs/binlib)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## LimaCharlie Core Concepts

# LimaCharlie Core Concepts
## Sensors

### Endpoint Agents

The LimaCharlie endpoint agent is a cross platform endpoint Sensor. It is a low-level, light-weight sensor which executes detection and response functionality in real-time.

The sensor provides a wide range of advanced capability.

* Flight Data Recorder (FDR) type functionality like Processes, Network Connections, Domain Name requests etc.
* Host isolation, automated response rules, intelligent local caching of events for in-depth Incident Response (IR)
   as well as some forensic features like dumping memory.

Sensors are designed to limit the potential for abuse resulting from unauthorized access to the LimaCharlie platform. This is achieved by limiting open-ended commands which might enable an attacker to covertly upload malicious software to your hosts. This means the LimaCharlie sensor is extremely powerful but also keeps its "read-only" qualities on your infrastructure. Of course, all access and interactions with the hosts are also logged for audit both within the cloud and tamper-proof forwarding to your own infrastructure.

Full commands list is in the [Endpoint Agent Commands](/v2/docs/endpoint-agent-commands) section.

#### Adapters

The LimaCharlie Adapter allows for real-time ingestion of any structured data, such as logs or telemetry, into the LimaCharlie platform, treating it as a first-class data source. This enables users to apply detection and response rules or send data to other outputs. Adapters support formats like JSON, Syslog, and CEFL, and can be deployed on-premise or cloud-to-cloud, either with or without the EDR sensor. For known sources like cloud platforms or Windows Event Logs, built-in mappings simplify data ingestion. Text-based Adapters allow for custom mapping and automation of any structured text. Additionally, pre-defined Adapters offer guided setups for common data sources like AWS CloudTrail and GuardDuty, while specialized connectors like Office 365 and Slack are supported with detailed configuration guidance. Some cloud-to-cloud Adapters, such as AWS S3, delete data after ingestion, so dedicated buckets with proper permissions are recommended.

### Installation Keys

Installation Keys are used to install a sensor. By specifying a key during installation the sensor can cryptographically be tied to your account.

Get more details in the [Installation Keys section](/v2/docs/installation-keys).

### Tags

Sensors can have Tags associated with them. Tags are added during creation or dynamically through the UI, API or Detection & Response Rules.

Get more information in the [Sensor tags section](/v2/docs/sensor-tags).

### Detection & Response Rules

The Detection & Response Rules act as an automation engine. The Detection component is a rule that either matches an event or not. If the Detection component matches, the Response component of the rule is actioned. This can be used to automatically investigate, mitigate or apply Tags.

Detailed explanation in the [Detection & Response section](/v2/docs/detection-and-response).

### Insight

Insight is our built-in data retention and search feature. It is included within our 2 sensor free tier as well.

When you enable Insight, we configure everything for you so that you get access to one year of your data for visualization and searching.

You don't *have to* use the built-in data retention; you can forward data directly to your infrastructure if preferred. However, it is generally much simpler and a better experience to use Insight. If you prefer not to use Insight, go through the next section (Outputs).

### Outputs

If you are using Insight (data retention) this section is optional.

LimaCharlie can relay the data somewhere for longer term storage and analysis. Where that data is sent depends on which Outputs are activated. You can have as many Output modules active as you want, so you can send it to multiple syslog destinations using the Syslog Output module and then send it to some cold storage over an Scp Output module.

Output is also split between four categories:

* event
* detect
* audit
* deployment

Selecting a Stream when creating an Output will select the relevant type of data to flow through it.

More details and exact configuration possibilities in the [Outputs section](/v2/docs/outputs).

### API Keys

The API keys are represented as UUIDs. They are linked to your specific organization and enable you to programmatically acquire authorization tokens that can be used on our REST API. See the [API key section](/v2/docs/api-keys) for more details.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

---

#### What's Next

* [Sensors](/docs/sensors)

Table of contents

---

## Lookups

# Lookups
Creating a lookup enables you to create a list that you can use as part of [detection and response rules](/v2/docs/detection-and-response). Once in place, you can refer to it using the `op: lookup`  rule with a reference to your add-on looking like `resource: hive://lookup/my-lookup-name`.

Lookups support a few structures:

* Newline-separated values.
* JSON dictionary where keys are the elements of the lookup and the values are the metadata associated.
* YAML dictionary where keys are the elements of the lookup and the values are the metadata associated.
* OTX JSON Pulse.
* MISP JSON Feed.

Here is an example of this complex format:

```
evil.com: some evil website, definitely bad
example.com:
  source: my-threat-intel
  risk: high
  contact: email threatintel@mycorp.com immediately if spotted
```

When uploaded, the data for the lookup can be provided in three different ways:

1. As data literal in the upload API.
2. As a URL callback, where your data is a URL like https://www.my.data.
3. As an [Authenticated Resource Locator](/v2/docs/reference-authentication-resource-locator).

The maximum size of a lookup is 15MB through the REST API and 512KB through the web interface.

## Optimized Format

When creating a lookup, you may want to include correct metadata for each element of the lookup. However, adding metadata may result in issues due to the maximum size. In cases where there is a lot of metadata repetition, you may use an Optimized Format that will allow you to associate large pieces of metadata with a high number of Lookup items.

To accomplish this, you will need to split up your metadata from your lookup values like:

```json
{
  "_LC_METADATA": [
    {
      "some": "metadata",
      ...
    }, {
      "some": "moremetadata",
      ...
    }, {
      "somemore": "metadata",
      ...
    }
  ],
  "_LC_INDICATORS: {
    "evil.exe": 0,
    "another.exe": 0,
    "more.exe": 1,
    "vals.exe": 2,
    ...
  }
}
```

The `_LC_METADATA` key has as a value, a list of all the pieces of metadata you want to include.

The `_LC_INDICATORS` is the normal list of indicators, but instead of having the metadata directly
 associated with each indicator as the value, it uses an integer that refers to the `_LC_METADATA`
 list's index where the metadata can be found.

The above example is equivalent to the non-optimized:

```json
{
  "evil.exe": {
      "some": "metadata",
      ...
    },
  "another.exe": {
      "some": "metadata",
      ...
    },
  "more.exe": {
      "some": "moremetadata",
      ...
    },
  "vals.exe": {
      "somemore": "metadata",
      ...
    },
}
```

As you can see, this optimization is useful to reduce the repeated metadata. This is particularly
 useful if, for example, you have large numbers of IoCs for a given actor. In that case, every
 IoC in the lookup would be associated with the same metadata (information about the actor).

### From MISP

When creating an add-on from MISP content, LimaCharlie expects the data to be a JSON document
 to have the following structure:

```json
{
  "Event": {
    "uuid": "fa781e8e-4332-4ff7-8286-f44445fb6f3a",
    "Attribute": [
      {
        "uuid": "e9e6840a-ff90-4fbd-8ef1-f5b766adbbce",
        "value": "evil.com"
      },
      ...
    ]
  }
}
```

The MISP event above once ingested in LC will be transformed to a Lookup like:

```json
{
  "evil.com": {
    "misp_event": "fa781e8e-4332-4ff7-8286-f44445fb6f3a",
    "attribute": "e9e6840a-ff90-4fbd-8ef1-f5b766adbbce"
  },
  ...
}
```

LimaCharlie understand the MISP format, regardless of how it is ingested. That being said, the classic way of ingesting it would be to ingest the MSIP Events use an [ARL](https://github.com/refractionPOINT/authenticated_resource_locator) on a MISP REST API with one of the supported ARL authentication types like `basic`.

For example: `[https,misp.my.corp.com/events/1234,basic,myuser:mypassword]`.

#### Reference D&R Rules

To put a Lookup "into effect", you need a [detection and response rule](/v2/docs/detection-and-response). The Lookup is a list of elements while the rule describes what you want to look for in that list.

Below is a list of D&R rules describing how to lookup various common Indicators of Compromise:

**Hashes**

```
op: lookup
event: CODE_IDENTITY
path: event/HASH
resource: 'hive://lookup/my-hash-lookup'
```

**Domain Names**

```
op: lookup
event: DNS_REQUEST
path: event/DOMAIN_NAME
resource: 'hive://lookup/my-dns-lookup'
```

**IP Addresses**

```
op: lookup
event: NETWORK_CONNECTIONS
path: event/NETWORK_ACTIVITY/?/IP_ADDRESS
resource: 'hive://lookup/my-ip-lookup'
```

---

##### Related articles

* [Detection Logic Operators](/docs/detection-logic-operators)
* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Lookup Manager](/docs/ext-lookup-manager)
* [Config Hive: Lookups](/docs/config-hive-lookups)

---

###### What's Next

* [Reference: Authenticated Resource Locator](/docs/reference-authentication-resource-locator)

Table of contents

+ [Optimized Format](#optimized-format)

Tags

* [add-ons](/docs/en/tags/add-ons)

---

## M&A Cyber Due Diligence

# M&A Cyber Due Diligence
* 1 Minute to read

## What's Next

* [Building Products](/docs/building-products)

Tags

* [mergers and acquisitions](/docs/en/tags/mergers%20and%20acquisitions)
* [use case](/docs/en/tags/use%20case)

---

## MCP Server

# MCP Server
Overview

 The Model Context Protocol (MCP) is a standardized protocol used by AI Agents to access and leverage external tools and resources.

 Note that MCP itself is still experimental and cutting edge.

 LimaCharlie offers an MCP server at <https://mcp.limacharlie.io> which enables AI agents to:

* **Query and analyze** historical telemetry from any sensor
* **Actively investigate** endpoints using the LimaCharlie Agent (EDR) in real-time
* **Take remediation actions** like isolating endpoints, killing processes, and managing tags
* **Generate content** using AI-powered tools for LCQL queries, D&R rules, playbooks, and detection summaries
* **Manage platform configuration** including rules, outputs, adapters, secrets, and more
* **Access threat intelligence** through IOC searches and MITRE ATT&CK mappings

 This opens up the entire LimaCharlie platform to AI agents, regardless of their implementation or location.

## Transport Modes

 The server supports two transport modes based on the PUBLIC\_MODE environment variable:

### STDIO Mode (PUBLIC\_MODE=false, default)

 Used for local MCP clients like Claude Desktop or Claude Code:

* Communication through stdin/stdout using JSON-RPC
* Uses LimaCharlie SDK's default authentication
* Reads credentials from environment variables or config files

### HTTP Mode (PUBLIC\_MODE=true)

 Used when deploying as a public service:

* Server runs as a stateless HTTP API with JSON responses
* Authentication via HTTP headers
* Supports multiple organizations concurrently
* Run with: `uvicorn server:app`

## Requirements & Authentication

### For HTTP Mode

 The server requires authentication headers:

 1. **Authorization header** in one of these formats:

* `Authorization: Bearer <jwt>` (OID must be in x-lc-oid header)
* `Authorization: Bearer <jwt>:<oid>` (combined format)
* `Authorization: Bearer <api_key>:<oid>` (API key with OID)

 2. **x-lc-oid header** (if not included in Authorization):

* `x-lc-oid: <organization_id>`

### For STDIO Mode

 Set environment variables:

* `LC_OID`: Your LimaCharlie Organization ID
* `LC_API_KEY`: Your LimaCharlie API key
* `GOOGLE_API_KEY`: For AI-powered generation features (optional)

## Capabilities

 The LimaCharlie MCP server exposes over 100 tools organized by category:

### Investigation & Telemetry

* **Process inspection**: `get_processes`, `get_process_modules`, `get_process_strings`, `yara_scan_process`
* **System information**: `get_os_version`, `get_users`, `get_services`, `get_drivers`, `get_autoruns, get_packages`
* **Network analysis**: `get_network_connections`, `is_online`, `get_online_sensors`
* **File operations**: `find_strings`, `yara_scan_file`, `yara_scan_directory`, `yara_scan_memory`
* **Registry access**: `get_registry_keys`
* **Historical data**: `get_historic_events`, `get_historic_detections`, `get_time_when_sensor_has_data`

### Threat Response & Remediation

* **Network isolation**: `isolate_network`, `rejoin_network`, `is_isolated`
* **Sensor management**: `add_tag`, `remove_tag`, `delete_sensor`
* **Reliable tasking**: `reliable_tasking`, `list_reliable_tasks`

### AI-Powered Generation (requires GOOGLE\_API\_KEY)

* **Query generation**: `generate_lcql_query` - Create LCQL queries from natural language
* **Rule creation**: `generate_dr_rule_detection`, `generate_dr_rule_respond` - Generate D&R rules
* **Automation**: `generate_python_playbook` - Create Python playbooks
* **Analysis**: `generate_detection_summary` - Summarize detection data
* **Sensor selection**: `generate_sensor_selector` - Generate sensor selectors

### Platform Configuration

* **Detection & Response**: `get_detection_rules`, `set_dr_general_rule`, `set_dr_managed_rule`, `delete_dr_general_rule`
* **False Positive Management**: `get_fp_rules`, `set_fp_rule`, `delete_fp_rule`
* **YARA Rules**: `list_yara_rules`, `set_yara_rule`, `validate_yara_rule`, `delete_yara_rule`
* **Outputs & Adapters**: `list_outputs`, `add_output`, `delete_output`, `list_external_adapters`, `set_external_adapter`
* **Extensions**: `list_extension_configs`, `set_extension_config`, `delete_extension_config`
* **Playbooks**: `list_playbooks`, `set_playbook`, `delete_playbook`
* **Secrets Management**: `list_secrets`, `set_secret`, `delete_secret`
* **Saved Queries**: `list_saved_queries`, `set_saved_query`, `run_saved_query`
* **Lookups**: `list_lookups`, `set_lookup`, `query_lookup`, `delete_lookup`

### Threat Intelligence

* **IOC Search**: `search_iocs`, `batch_search_iocs`
* **Host Search**: `search_hosts`
* **MITRE ATT&CK**: `get_mitre_report`

### Administrative

* **API Keys**: `list_api_keys`, `create_api_key`, `delete_api_key`
* **Installation Keys**: `list_installation_keys`, `create_installation_key`, `delete_installation_key`
* **Cloud Sensors**: `list_cloud_sensors`, `set_cloud_sensor`, `delete_cloud_sensor`
* **Organization Info**: `get_org_info`, `get_usage_stats`
* **Artifacts**: `list_artifacts`, `get_artifact`

### Schema & Documentation

* **Event Schemas**: `get_event_schema`, `get_event_schemas_batch`, `get_event_types_with_schemas`
* **Platform Support**: `get_platform_names`, `list_with_platform`, `get_event_types_with_schemas_for_platform`

## Advanced Features

### Large Result Handling

 The server automatically handles large responses by uploading them to Google Cloud Storage (if configured):

* Set `GCS_BUCKET_NAME` for the storage bucket
* Configure `GCS_TOKEN_THRESHOLD` (default: 1000 tokens)
* Results are returned as signed URLs valid for 24 hours

### LCQL Query Execution

 The `run_lcql_query` tool supports:

* Streaming results for real-time monitoring
* Flexible time windows and limits
* Output formatting options

## Examples

### Claude Desktop/Code Configuration (STDIO)

```json
  {
    "mcpServers": {
      "limacharlie": {
        "command": "python3",
        "args": ["/path/to/server.py"],
        "env": {
          "LC_OID": "your-org-id",
          "LC_API_KEY": "your-api-key",
          "GOOGLE_API_KEY": "your-google-api-key"
        }
      }
    }
  }
```

### HTTP Service Usage

```bash
claude mcp add --transport http limacharlie https://mcp.limacharlie.io/mcp \
--header "Authorization: Bearer API_KEY:OID" \
--header "x-lc-oid: OID"
```

## Environment Variables

* `PUBLIC_MODE`: Set to true for HTTP mode, false for STDIO (default: false)
* `GOOGLE_API_KEY`: API key for AI-powered features
* `GCS_BUCKET_NAME`: Google Cloud Storage bucket for large results
* `GCS_SIGNER_SERVICE_ACCOUNT`: Service account for GCS URL signing
* `GCS_TOKEN_THRESHOLD`: Token count threshold for GCS upload (default: 1000)
* `GCS_URL_EXPIRY_HOURS`: Hours until GCS URLs expire (default: 24)
* `LC_OID`: Organization ID (STDIO mode only)
* `LC_API_KEY`: API key (STDIO mode only)

## Notes

* The server is stateless when running in HTTP mode
* HTTP mode uses JSON responses (not Server-Sent Events)
* No OAuth flow is used - authentication is via bearer tokens only
* If you encounter missing capabilities, contact <https://community.limacharlie.com> for quick additions

---

## Network Monitoring

# Network Monitoring
* 1 Minute to read

## What's Next

* [File and Registry Integrity Monitoring (FIM) Deployments](/docs/file-and-registry-integrity-monitoring-fim-deployments)

Tags

* [monitoring](/docs/en/tags/monitoring)
* [network](/docs/en/tags/network)
* [use case](/docs/en/tags/use%20case)

---

## Observability Pipeline

# Observability Pipeline
The SecOps Cloud Platform (SCP) creates a scalable, versatile, and actionable observability pipeline by collecting and standardizing telemetry from the full security stack. Stream data from any input, route it to any output. The SCP provides visibility into telemetry sources and empowers users to create automated responses to actionable events in the pipeline.

## Observability pipeline problems

Creating an observability pipeline can be a daunting task as users try to integrate a complex and diverse technological environment into a single pipeline solution. When successful, ingesting, managing, and storing data can create significant costs, including:

* **Data costs:** Collecting and storing telemetry can be extremely expensive. As your business grows, so does its data, leading to escalating data storage costs as well.
* **Infrastructure demands:** Creating, managing, and monitoring the infrastructure required to operate an observability pipeline requires system engineers. As this infrastructure grows to accommodate your business, so does the headcount needed to maintain operations.
* **Delayed responsiveness:** Traditional observability pipelines collect and route data.If something appears in the pipeline that warrants concern, it must be routed to a destination for further analysis before action occurs.
* **High SIEM costs:** Data ingestion adds considerable costs to SIEM operations. As an organization expands its digital footprint these costs can increase rapidly.
* **Vendor lock-in constraints:** Many organizations find themselves trapped with security vendors who deliberately create dependencies through restrictive contracts, proprietary data formats, and closed ecosystems — limiting flexibility, driving up costs, and forcing security decisions based on vendor limitations rather than actual security needs.

### LimaCharlie’s solutions

The SecOps Cloud Platform unifies telemetry collection by using an API-first approach for integrating the security stack. It creates a natural observability pipeline that scales without limit, facilitates automated responses, and greatly reduces data costs across the board. With the SCP you get a fully interactive observability pipeline that can facilitate countless other critical security operations as well.

* **Free data retention:** LimaCharlie offers a rolling year of free data storage.
* **Infrastructure-as-a-Service:** LimaCharlie provides a scalable, cloud-native infrastructure on an API-first platform. This gives our users maximum flexibility, scalability, and integration capabilities across the full security stack, including the observability pipeline.
* **Instant, bi-directional response:** LimaCharlie supports bi-directionality which allows automated responses sent directly to the source of a detection. For example, if the SecOps Cloud Platform receives a suspicious login alert from O365 it can immediately send a response to suspend the account before telemetry is sent for further processing.
* **Reduce SIEM spend:** LimaCharlie makes it easy to send only relevant telemetry to your SIEM, while still retaining all of your data in storage. This instantly reduces the costs of operating your SIEM while also accommodating any regulatory compliance requirements involving your data.
* **No vendor lock-in:** The API-first nature of LimaCharlie allows you to integrate and use whatever security solutions, services, and resources you prefer. There are no contracts or artificial barriers put in place to restrict your choices.

---

#### What's Next

* [Cost Effective SIEM Alternative](/docs/cost-effective-siem)

Tags

* [observability](/docs/en/tags/observability)
* [pipeline](/docs/en/tags/pipeline)
* [use case](/docs/en/tags/use%20case)

---

## Payload Manager

# Payload Manager
* 1 Minute to read

## Related articles

* [Payloads](/docs/payloads)
* [Reference: Endpoint Agent Commands](/docs/reference-endpoint-agent-commands)

---

### What's Next

* [Reliable Tasking](/docs/ext-reliable-tasking)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## Payloads

# Payloads
## Overview

Payloads are executables or scripts that can be delivered and executed through LimaCharlie's Endpoint Agent.

Those payloads can be any executable or script natively understood by the endpoint. The main use case is to run something with specific functionality not available in the main LimaCharlie functionality. For example: custom executables provided by another vendor to cleanup a machine, forensic utilities or firmware-related utilities.

We encourage you to look at LimaCharlie native functionality first as it has several advantages:

* Usually has better performance.
* Data returned is always well structured JSON.
* Can be tasked automatically and [Detection & Response Rules](/v2/docs/detection-and-response) can be created from their data.
* Data returned is indexed and searchable.

It is possible to set the Payload's file extension on the endpoint by making the Payload name end with that extension. For example, naming a Payload `extract_everything.bat`, the Payload will be sent as a batch file (`.bat`) and executed as such.  This is also true for PowerShell files (`.ps1`).

## Lifecycle

Payloads are uploaded to the LimaCharlie platform and given a name. The task `run` can then be used with the `--payload-name MY-PAYLOAD --arguments "-v EulaAccepted"` can be used to run the payload with optional arguments.

The STDOUT and STDERR data will be returned in a related `RECEIPT` event, up to ~10 MB. If your payload generates more data, we recommend to pipe the data to a file on disk and use the `log_get` command to retrieve it.

The payload is retrieved by the endpoint agent over HTTPS to the Ingestion API DNS endpoint. This DNS entry is available from the Sensor Download section of the web app if you need to allow it.

## Upload / Download via REST

Creating and getting Payloads is done asynchronously. The relevant REST APIs will return specific signed URLs instead of the actual Payload. In the case of a retrieving an existing payload, simply doing an HTTP GET using the returned URL will download the payload content. When creating a Payload the returned URL should be used in an HTTP PUT using the URL like:

```bash
curl -X PUT "THE-SIGNED-URL-HERE" -H "Content-Type: application/octet-stream" --upload-file your-file.exe
```

Note that the signed URLs are only valid for a few minutes.

## Permissions

Payloads are managed with two permissions:

* `payload.ctrl` allows you to create and delete payloads.
* `payload.use` allows you to run a given payload.

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

---

### Related articles

* [Endpoint Agent Commands](/docs/endpoint-agent-commands)
* [Reference: Endpoint Agent Commands](/docs/reference-endpoint-agent-commands)
* [Payload Manager](/docs/payload-manager)

---

#### What's Next

* [Sleeper Deployment](/docs/sleeper)

Table of contents

+ [Overview](#overview)
+ [Lifecycle](#lifecycle)
+ [Upload / Download via REST](#upload-download-via-rest)
+ [Permissions](#permissions)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [linux](/docs/en/tags/linux)
* [macos](/docs/en/tags/macos)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## Playbook [LABS]

# Playbook [LABS]
> LimaCharlie LABS

The Playbook Extension allows you to execute Python playbooks within the context of your Organization in order to automate tasks and customize more complex detections.

The playbooks themselves are managed in the playbook [Hive](/v2/docs/config-hive) Configurations and can be managed across tenants using the Infrastructure as Code extension.

The execution of a playbook can be triggered through the following means:

1. Interactively in the web app by going to the Extensions section for the Playbook extension.
2. By issuing an `extension request` action through a [D&R rule](/v2/docs/detection-and-response-examples).
3. By issuing an extension request on the API directly: <https://api.limacharlie.io/static/swagger/#/Extensions/createExtensionRequest>
4. By issuing an extension request through the Python CLI/SDK or Golang SDK.

This means playbooks can be issued in a fully automated fashion based on events, detections, audit messages or any other [target](/v2/docs/detection-on-alternate-targets) of D&R rules. But it can also be used in an ad-hoc fashion triggered manually.

## Enabling Extension

The Playbook extension can be enabled by subscribing your organization to the ext-playbook add-on.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(317).png)

## Accessing Playbooks

Playbooks are created, modified, and deleted via the Playbooks option located within the Automation menu.

> Note: If you are unable to see the Playbooks option, ensure your user account has the appropriate permissions enabled.
>
> ![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(319).png)

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(321).png)

## Usage

When invoking a playbook, all you need is the playbook name as defined in Hive. Optionally, a playbook can also receive a JSON dictionary object as parameters, this is useful when triggering a playbook from a D&R rule and you want to pass some context, or when passing context interactively.

### D&R rule example

Here is an example D&R rule starting a new invocation of a playbook.

```
- action: extension request
  extension name: ext-playbook
  extension action: run_playbook
  extension request:
    name: '{{ "my-playbook" }}'
    credentials: '{{ "hive://secret/my-api-key" }}'
    data:
      some: event.FILE_PATH
      for_the: '{{ "running of the playbook" }}'
```

### Python example

```
# Import LC SDK
import limacharlie
# Instantiate the SDK with default creds.
lc = limacharlie.Manager()
# Instantiate the Extension manager object.
ext = limacharlie.Extension(lc)

# Issue a request to the "ext-playbook" extension.
response = ext.request("ext-playbook", "run_playbook", {
    "name": "my-playbook",
    "credentials": "hive://secret/my-playbook-api-key",
    "data": {
        "some": "data"
    }
})

# The returned data from the playbook.
print(response)
```

## Playbook structure

A playbook is a normal python script. The only required component is a top level function called `playbook` which takes 2 arguments:

* `sdk`: an instance of the LC Python SDK ( `limacharlie.Manager()` ) pre-authenticated to the relevant Organization based on the credentials provided, if any, `None` otherwise.
* `data`: the optional JSON dictionary provided as context to your playbook.

The function must return a dictionary with the following optional keys:

1. `data`: a dictionary of data to return to the caller
2. `error`: an error message (string) to return to the caller
3. `detection`: a dictionary to use as detection
4. `cat`: a string to use as the category of the detection, if `detection` is specified.

This allows your playbook to return information about its execution, return data, errors or generate a detection. The python `print()` statement is not currently being returned to the caller or otherwise accessible, so you will want to use the `data` in order to return information about the execution of your playbook.

### Example playbook

The following is a sample playbook that sends a webhook to an external product with a secret stored in LimaCharlie, and it returns the data as the response from the playbook.

```python
import limacharlie
import json
import urllib.request

def playbook(sdk, data):
  # Get the secret we need from LimaCharlie.
  mySecret = limacharlie.Hive(sdk, "secret").get("my-secret-name").data["secret"]

  # Send the Webhook.
  request = urllib.request.Request("https://example.com/webhook", data=json.dumps(data).encode('utf-8'), headers={
    "Content-Type": "application/json",
    "Authorization": f"Bearer {mySecret}"
  }, method="POST")

  try:
    with urllib.request.urlopen(request) as response:
      response_body = response.read().decode('utf-8')
      # Parse the JSON response
      parsed_response = json.loads(response_body)
  except Exception as e:
    # Some error occured, let the caller/LC know.
    return {
      "error": str(e),
    }

  # Return the data to the caller/LC.
  return {
    "data": parsed_response,
  }
```

### Execution environment

Playbooks contents are cached for short periods of time ( on the order of 10 seconds ) in the cloud.

Playbooks are instantiated on demand and the instance is reused for an undefined amount of time.

Playbook code only executes during the main call to the `playbook` function, background on-going running is not supported.

The execution environment is provisioned on a per-Organization basis, meaning all your playbooks may execute within the same container, but NEVER on a container used by another Organization.

Although you have access to the local environment, this environment is ephemeral and can be wiped at any moment in between executions so you should take care that your playbook is self contained and doesn’t assume pre-existing conditions.

A single execution of a playbook is limited to 10 minutes.

The current execution environment is based on the default libraries provided by the `python:slim` Dockerhub official container plus the following packages:

* Python

  + `weasyprint`
  + `flask`
  + `gunicorn`
  + `flask`
  + `limacharlie` (LimaCharlie SDK/CLI)
  + `lcextension` (LimaCharlie Extension SDK)
  + `scikit-learn` (Python Machine Learning kit)
  + `jinja2`
  + `markdown`
  + `pillow`
* NodeJS
* AI

  + Claude Code (`claude`) CLI tool
  + Codex (`codex`) CLI tool
  + Gemini CLI (`gemini`) CLI tool

Custom packages and execution environment tweaks are not available in self-serve mode, but they *may* be available on demand, get in touch with us at support@limacharlie.io.

## Infrastructure as Code

Example:

```
hives:
    playbook:
        my-playbook:
            data:
                python: |-
                    def playbook(sdk, data):
                        if not sdk:
                            return {"error": "LC API key required to list sensors"}
                        return {
                            "data": {
                                "sensors": [s.getInfo() for s in sdk.sensors()]
                            }
                        }
            usr_mtd:
                enabled: true
                expiry: 0
                tags: []
                comment: ""
```

## Billing

Playbooks are billed per seconds of total execution time.

LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

### What's Next

* [Cloud CLI](/docs/ext-cloud-cli)

Table of contents

+ [Enabling Extension](#enabling-extension)
+ [Accessing Playbooks](#accessing-playbooks)
+ [Usage](#usage)
+ [Playbook structure](#playbook-structure)
+ [Infrastructure as Code](#infrastructure-as-code)
+ [Billing](#billing)

---

## Purple Teaming

# Purple Teaming
* 1 Minute to read

## What's Next

* [Threat Hunting](/docs/threat-hunting)

Tags

* [purple team](/docs/en/tags/purple%20team)
* [use case](/docs/en/tags/use%20case)

---

## Reference

# Reference
1 Article  in this category

---

## Reference: Authenticated Resource Locator

# Reference: Authenticated Resource Locator
* 1 Minute to read

## What's Next

* [VirusTotal Integration](/docs/tutorials-integratons-virustotal-integration)

Table of contents

+ [Overview](#overview)
+ [Format](#format)
+ [Examples](#examples)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [reference](/docs/en/tags/reference)

---

## Reference: Error Codes

# Reference: Error Codes
* 1 Minute to read

## Related articles

* [Endpoint Agent Commands](/docs/endpoint-agent-commands)
* [Endpoint Agent Events Overview](/docs/endpoint-agent-events-overview)
* [Reference: Endpoint Agent Commands](/docs/reference-endpoint-agent-commands)
* [Reference: EDR Events](/docs/reference-edr-events)

---

### What's Next

* [Template Strings and Transforms](/docs/template-strings-and-transforms)

Table of contents

+ [Payload Specific](#payload-specific)
+ [Yara Specific](#yara-specific)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [events](/docs/en/tags/events)
* [reference](/docs/en/tags/reference)

---

## Reference: ID Schema

# Reference: ID Schema
## Agent IDs

An AgentID is a 5-tuple that completely describes a Sensor, while a Sensor ID is the smallest single unique identifier that can identify a sensor.

The AgentID's components look like this: `OID.IID.SID.PLATFORM.ARCHITECTURE`.

For all components, a value of `0` indicates a wildcard that matches any value when comparing AgentIDs as masks.

## Architecture

The architecture is an 8 bit integer that identifies the exact architecture the sensor runs on. The important values are:

* `1`: 32 bit (`x86`)
* `2`: 64 bit (`x64`)
* `3`: ARM (`arm`)
* `4`: ARM64 (`arm64`)
* `5`: Alpine 64 (`alpine64`)
* `6`: Chrome (`chromium`)
* `7`: Wireguard (`wireguard`)
* `8`: ARML (`arml`)
* `9`: lc-adapter (`usp_adapter`)

Operating System Specifics

Looking for more detailed version information on a specific operating system? Check out these vendor guides:

* [Microsoft Windows](https://learn.microsoft.com/en-us/windows/win32/sysinfo/operating-system-version)
* [RHEL](https://access.redhat.com/articles/3078)
* [Ubuntu](https://wiki.ubuntu.com/Releases)

## Device IDs

Given the breadth of platforms supported by LimaCharlie, it is not unusual for one "device" (laptop, server, mobile etc) to be visible from multiple sensors. A basic example of this might be:

* We have a laptop, running macOS as its operating system and running a macOS sensor
* The laptop is also running a Windows Virtual Machine, running a Windows sensor

In this example, we're dealing with one piece of hardware, but two different sensors.

To help provide a holistic view of activity, LimaCharlie introduces the concept of a Device ID. This ID is mostly visible in the sensor's basic info and in the `routing` component of sensor events under the name `did` (Device ID).

This Device ID is automatically generated and assigned by LimaCharlie using correlation of specific low level events common to all the sensors. This means that if two sensors share a `did: 1234-5678...` ID, it means they are either on the same device or at least share the same visibility (they see the same activity from two angles).

## Installer ID

The Installer ID (IID) is a UUID that identifies a unique Installation Key. This allows us to cycle installation keys and repudiate old keys, in the event the key gets leaked.

## Organization ID

The Organization ID (OID) is a UUID which identifies a unique organization.

## Platform

The platform is a 32-bit integer (in its hex format) which identifies the exact platform the sensor runs on. Sensor telemetry will display the `plat` value in decimal format. Although it is structured with a major and minor platform, the important values are:

```
  | Hex ID     | Decimal    | API Name                     | Platform Name                |
  |------------|------------|------------------------------|------------------------------|
  | 0x01000000 | 16777216   | crowdstrike                  | CrowdStrike                  |
  | 0x02000000 | 33554432   | xml                          | XML                          |
  | 0x03000000 | 50331648   | wel                          | Windows Event Logs           |
  | 0x04000000 | 67108864   | msdefender                   | Microsoft Defender           |
  | 0x05000000 | 83886080   | duo                          | Duo                          |
  | 0x06000000 | 100663296  | okta                         | Okta                         |
  | 0x07000000 | 117440512  | sentinel_one                 | SentinelOne                  |
  | 0x08000000 | 134217728  | github                       | GitHub                       |
  | 0x09000000 | 150994944  | slack                        | Slack                        |
  | 0x0A000000 | 167772160  | cef                          | Common Event Format (CEF)    |
  | 0x0B000000 | 184549376  | lc_event                     | LimaCharlie Events           |
  | 0x0C000000 | 201326592  | azure_ad                     | Azure Active Directory       |
  | 0x0D000000 | 218103808  | azure_monitor                | Azure Monitor                |
  | 0x0E000000 | 234881024  | canary_token                 | Canary Token                 |
  | 0x0F000000 | 251658240  | guard_duty                   | Guard Duty                   |
  | 0x11000000 | 285212672  | itglue                       | IT Glue                      |
  | 0x12000000 | 301989888  | k8s_pods                     | Kubernetes Pods              |
  | 0x13000000 | 318767104  | zeek                         | Zeek                         |
  | 0x14000000 | 335544320  | mac_unified_logging          | Macos Unified Logging        |
  | 0x15000000 | 352321536  | azure_event_hub_namespace    | Azure Event Hub Namespace    |
  | 0x16000000 | 369098752  | azure_key_vault              | Azure Key Vault              |
  | 0x17000000 | 385875968  | azure_kubernetes_service     | Azure Kubernetes Service     |
  | 0x18000000 | 402653184  | azure_network_security_group | Azure Network Security Group |
  | 0x19000000 | 419430400  | azure_sql_audit              | Azure SQL Audit              |
  | 0x1A000000 | 436207616  | email                        | Email                        |
  | 0x21000000 | 553648128  | hubspot                      | HubSpot                      |
  | 0x22000000 | 570425344  | zendesk                      | Zendesk                      |
  | 0x23000000 | 587202560  | pandadoc                     | PandaDoc                     |
  | 0x24000000 | 603979776  | falconcloud                  | FalconCloud                  |
  | 0x25000000 | 620756992  | mimecast                     | Mimecast                     |
  | 0x26000000 | 637534208  | sublime                      | Sublime                      |
  | 0x27000000 | 654311424  | box                          | Box                          |
  | 0x28000000 | 671088640  | cylance                      | Cylance                      |
  | 0x29000000 | 687865856  | proofpoint                   | Proofpoint                   |
  | 0x2A000000 | 704643072  | entraid                      | EntraID                      |
  | 0x2B000000 | 721420288  | wiz                          | Wiz                          |
  | 0x10000000 | 268435456  | windows                      | Windows                      |
  | 0x20000000 | 536870912  | linux                        | Linux                        |
  | 0x30000000 | 805306368  | macos                        | MacOS                        |
  | 0x40000000 | 1073741824 | ios                          | iOS                          |
  | 0x50000000 | 1342177280 | android                      | Android                      |
  | 0x60000000 | 1610612736 | chrome                       | ChromeOS                     |
  | 0x70000000 | 1879048192 | vpn                          | VPN                          |
  | 0x80000000 | 2147483648 | text                         | Text (external telemetry)    |
  | 0x90000000 | 2415919104 | json                         | JSON (external telemetry)    |
  | 0xA0000000 | 2684354560 | gcp                          | GCP (external telemetry)     |
  | 0xB0000000 | 2952790016 | aws                          | AWS (external telemetry)     |
  | 0xC0000000 | 3221225472 | carbon_black                 | VMWare Carbon Black          |
  | 0xD0000000 | 3489660928 | 1password                    | 1Password                    |
  | 0xE0000000 | 3758096384 | office365                    | Microsoft/Office 365         |
  | 0xF0000000 | 4026531840 | sophos                       | Sophos                       |
```

Tip: If you're writing a  rule to target a specific platform, consider using the `is_platform` operator instead of the decimal value for easier readability.

## Sensor ID

The Sensor ID (SID) is a UUID that identifies a unique sensor.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

In LimaCharlie, an Organization ID (OID) is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.

In LimaCharlie, a Sensor ID (SID) is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

---

### Related articles

* [Reference: Sensor Selector Expressions](/docs/reference-sensor-selector-expressions)

---

#### What's Next

* [Reference: Sensor Selector Expressions](/docs/reference-sensor-selector-expressions)

Table of contents

+ [Agent IDs](#agent-ids)
+ [Architecture](#architecture)
+ [Device IDs](#device-ids)
+ [Installer ID](#installer-id)
+ [{{glossary.Organization ID}}](#{{glossary-organization-id}})
+ [Platform](#platform)
+ [Sensor ID](#sensor-id)

Tags

* [platform](/docs/en/tags/platform)
* [reference](/docs/en/tags/reference)
* [sensors](/docs/en/tags/sensors)

---

## Reference: Permissions

# Reference: Permissions
## Overview

LimaCharlie uses a granular permission system that controls access to all platform functionality. Permissions are applied through User accounts, API Keys, or Groups and follow a hierarchical naming convention: `category`.`action`

## Permission Structure

### Naming Convention

* **Category**: Functional area (e.g. sensor, org, dr)
* **Action**: Operation type (e.g. get, list, set, del, ctrl)

## Core Permissions

### Organization Management

| Permission | Description |
| --- | --- |
| org.get | View organization information |
| org.del | Delete organization |
| org.set\_quota | Manage organization quotas |
| org.conf.get | View organization configuration |
| org.conf.set | Modify organization configuration |

### User & Access Control

| Permission | Description |
| --- | --- |
| apikey.ctrl | Create, delete, and modify API keys |
| user.ctrl | Manage user accounts and permissions |
| billing.ctrl | Access and modify billing information |

### Sensor Management

| Permission | Description |
| --- | --- |
| sensor.list | List all sensors in organization |
| sensor.get | View detailed sensor information |
| sensor.task | Send commands and tasks to sensors |
| sensor.del | Delete sensors |
| sensor.tag | Manage sensor tags and labels |

### Installation Keys

| Permission | Description |
| --- | --- |
| ikey.list | List installation keys |
| ikey.set | Create new installation keys |
| ikey.del | Delete installation keys |

### Detection & Response (D&R)

#### General D&R Rules

| Permission | Description |
| --- | --- |
| dr.list | List general detection rules |
| dr.set | Create and modify general detection rules |
| dr.del | Delete general detection rules |

#### Managed D&R Rules

| Permission | Description |
| --- | --- |
| dr.list.managed | List managed detection rules |
| dr.set.managed | Create and modify managed detection rules |
| dr.del.managed | Delete managed detection rules |

#### Service D&R Rules

| Permission | Description |
| --- | --- |
| dr.list.service | List service detection rules |
| dr.set.service | Create and modify service detection rules |
| dr.del.service | Delete service detection rules |

#### False Positives

| Permission | Description |
| --- | --- |
| fp.ctrl | Manage false positive suppressions |

## Configuration Management (Hive)

### Secrets

| Permission | Description |
| --- | --- |
| secret.get | Access secret values |
| secret.set | Create and modify secrets |
| secret.del | Delete secrets |
| secret.get.mtd | View secret metadata only |
| secret.set.mtd | Modify secret metadata only |

### Lookups

| Permission | Description |
| --- | --- |
| lookup.get | Access lookup tables |
| lookup.set | Create and modify lookup tables |
| lookup.del | Delete lookup tables |
| lookup.get.mtd | View lookup metadata only |
| lookup.set.mtd | Modify lookup metadata only |

### Models

| Permission | Description |
| --- | --- |
| model.get | Access behavioral models |
| model.set | Create and modify behavioral models |
| model.del | Delete behavioral models |
| model.get.mtd | View model metadata only |
| model.set.mtd | Modify model metadata only |

### Queries

| Permission | Description |
| --- | --- |
| query.get | Access saved queries |
| query.set | Create and modify saved queries |
| query.del | Delete saved queries |
| query.get.mtd | View query metadata only |
| query.set.mtd | Modify query metadata only |

### YARA Rules

| Permission | Description |
| --- | --- |
| yara.get | Access YARA rules |
| yara.set | Create and modify YARA rules |
| yara.del | Delete YARA rules |
| yara.get.mtd | View YARA rule metadata only |
| yara.set.mtd | Modify YARA rule metadata only |

### AI Agents

| Permission | Description |
| --- | --- |
| ai\_agent.get | Access AI agent configurations |
| ai\_agent.set | Create and modify AI agents |
| ai\_agent.del | Delete AI agents |
| ai\_agent.get.mtd | View AI agent metadata only |
| ai\_agent.set.mtd | Modify AI agent metadata only |

### Cloud Sensors

| Permission | Description |
| --- | --- |
| cloudsensor.get | Access cloud sensor configurations |
| cloudsensor.set | Create and modify cloud sensor configurations |
| cloudsensor.del | Delete cloud sensor configurations |
| cloudsensor.get.mtd | View cloud sensor metadata only |
| cloudsensor.set.mtd | Modify cloud sensor metadata only |

### Playbooks

| Permission | Description |
| --- | --- |
| playbook.get | Access playbooks |
| playbook.set | Create and modify playbooks |
| playbook.del | Delete playbooks |
| playbook.get.mtd | View playbook metadata only |
| playbook.set.mtd | Modify playbook metadata only |

### External Adapters

| Permission | Description |
| --- | --- |
| externaladapter.get | Access external adapter configurations |
| externaladapter.set | Create and modify external adapters |
| externaladapter.del | Delete external adapter configurations |
| externaladapter.get.mtd | View external adapter metadata only |
| externaladapter.set.mtd | Modify external adapter metadata only |

## Extensions & Services

### Extensions

| Permission | Description |
| --- | --- |
| ext.request | Request extension actions |
| ext.conf.get | View extension configurations |
| ext.conf.set | Modify extension configurations |
| ext.conf.del | Delete extension configurations |
| ext.conf.get.mtd | View extension metadata only |
| ext.conf.set.mtd | Modify extension metadata only |
| ext.sub | Subscribe to extension services |
| ext.sub.mtd | Manage extension subscription metadata |

### Replicant Services

| Permission | Description |
| --- | --- |
| replicant.get | View replicant service status |
| replicant.ctrl | Control replicant services |

## Data Access & Analytics

### Insight & Detections

| Permission | Description |
| --- | --- |
| insight.list | List available insights |
| insight.ctrl | Control insight generation |
| insight.del | Delete insights |
| insight.evt.get | Access detailed event data |
| insight.evt.get.simple | Access simplified event data |
| insight.det.get | Access detection details |
| insight.stat | Access insight statistics |

### Audit & Logging

| Permission | Description |
| --- | --- |
| audit.get | Access audit logs and error messages |
| audit.set | Create audit logs entries |

## Operations Management

### Jobs

| Permission | Description |
| --- | --- |
| job.get | View job status and results |
| job.ctrl | Create and schedule jobs |

### Outputs

| Permission | Description |
| --- | --- |
| output.list | List output configurations |
| output.set | Create and modify output configurations |
| output.del | Delete output configurations |

### Payloads

| Permission | Description |
| --- | --- |
| payload.ctrl | Manage sensor payloads |

### Module Management

| Permission | Description |
| --- | --- |
| module.update | Update sensor modules |

### Ingestion

| Permission | Description |
| --- | --- |
| ingestkey.ctrl | Manage data ingestion keys |

## Permission Application

Permissions can be applied through:

1. **User Accounts**: Direct assignment to individual users
2. **API Keys**: Embedded in API key configurations for programmatic access
3. **Groups**: Assigned to groups, then inherited by group members

## Best Practices

1. **Principle of Least Privilege**: Grant only the minimum permissions required
2. **Use Groups**: Manage permissions through groups rather than individual assignments
3. **Regular Auditing**: Periodically review and audit permission assignments
4. **Separate Environments**: Use different permission sets for development, staging, and production
5. **API Key Management**: Rotate API keys regularly and scope them appropriately

---

### Related articles

* [Access and Permissions](/docs/access-and-permissions)
* [API Keys](/docs/api-keys)
* [User Access](/docs/user-access)

---

#### What's Next

* [Billing](/docs/billing)

Table of contents

+ [Overview](#overview)
+ [Permission Structure](#permission-structure)
+ [Core Permissions](#core-permissions)
+ [Configuration Management (Hive)](#configuration-management-hive-)
+ [Extensions &amp; Services](#extensions-amp-services)
+ [Data Access &amp; Analytics](#data-access-amp-analytics)
+ [Operations Management](#operations-management)
+ [Permission Application](#permission-application)
+ [Best Practices](#best-practices)

Tags

* [platform](/docs/en/tags/platform)
* [reference](/docs/en/tags/reference)

---

## Reporting

# Reporting
1 Article  in this category

---

## SOAR / Automation

# SOAR / Automation
* 1 Minute to read

## What's Next

* [Cloud Security](/docs/cloud-security)

Tags

* [automation](/docs/en/tags/automation)
* [SOAR](/docs/en/tags/SOAR)
* [use case](/docs/en/tags/use%20case)

---

## Schema Data Types

# Schema Data Types
## All Data Types

The data types in your schema can be further subdivided into three categories. Primitives, Code Blocks, and Objects (including tables). These data types allow for a cleaner UI and a more intuitive schema.

For a direct code reference, check out the type definition [here](https://github.com/refractionPOINT/lc-extension/blob/master/common/config_schema.go).

### Before you Start

When getting started, we recommend utilizing the simplest data type applicable for each field in your schema as to enable quick and reliable testing of your service.

## Primitives

The following is the list of primitive values. Note that the following fields are also affected by filters:

* number, time and date types are affected by `min` and `max`
* events and string types are affected by `whitelist` and `blacklist`
* only string types are affected by `valid_re` and `invalid_re` (regex)
* SID types (and maybe platforms) are affected by `platforms` filters

Oops, some fields may be missing support for filters

Please reach out if any of the above use-cases don't work as you might expect.

| name | description |
| --- | --- |
| string |  |
| integer |  |
| bool |  |
| enum | Requires the field `enum_values` |
| complex\_enum | a complex enum allows for a more detailed enum selection, including categories and description. Requires the field `complex_enum_values` |
| sid | your Organization's sensor ids |
| oid | your Organization's ID |
| platform |  |
| architecture |  |
| sensor\_selector |  |
| tag |  |
| duration |  |
| time |  |
| url |  |
| domain |  |
| yara\_rule\_name | Will show your Organization's list of yara rules available, if the user has permission |
| event\_name |  |
| secret | Will show your Organization's list of secrets as per the secrets manager |

## Code Blocks

There are currently 3 code types available:

1. JSON
2. YAML
3. Yara\_rule

Yara Rule UI Support is limited

Code blocks do not support the field `is_list`. If your extensions require a set of code blocks, we reocmmend wrapping it into key-value pair using the 'record' data type (see 'objects' section below).

## Objects (and tables)

While objects generally reflect a nested layer of abstraction, it's utility grows when using the field `is_list` to utilize the tables UI, or when defining a set of key-value pairs in the 'record' data type.

Note: there is a functional difference between an 'object' and 'record' data type.

**Single Objects**
 Plain objects allow for nested fields, and are visually indifferent from if the nested fields were flattened to begin with. They also allow for extra context to be wrapped in the parent object’s description.

```
table: {
  is_list: false,
  data_type: "object",
  object: {
    fields: { ... }, // key-value pairs
    requirements: null
  }
}
```

**Lists of Objects**
 Lists of objects display as tables and allow for a more complex and scalable data structure. Simply enable `is_list` on a base object.

```
table: {
  is_list: true,
  data_type: "object",
  object: {
    fields: { ... }, // key-value pairs
    requirements: null
  }
}
```

**Record Type**
 Records are inherently lists of a key-value pair, where the value is the defined object, and the key may vary. Record types require a key to be defined in the nested object details, and also supports additional fields for the nested element's name and description.

```
table: {
  is_list: true,
  data_type: "object",
  object: {
    key: {
      name: "key",
      data_type: "string"
    },
    element_name: "single row", // optional
    element_desc: "a single row that represents a key-value pair on a record type", // optional

    fields: { ... }, // key-value pairs
    requirements: null
  }
}
```

---

### What's Next

* [Building the User Interface](/docs/building-the-user-interface)

Table of contents

+ [All Data Types](#all-data-types)
+ [Primitives](#primitives)
+ [Code Blocks](#code-blocks)
+ [Objects (and tables)](#objects-and-tables-)

Tags

* [add-ons](/docs/en/tags/add-ons)
* [extensions](/docs/en/tags/extensions)

---

## SecOps Development

# SecOps Development
* 1 Minute to read

## What's Next

* [Observability Pipeline](/docs/observability-pipeline)

Tags

* [development](/docs/en/tags/development)
* [SecOps](/docs/en/tags/SecOps)
* [use case](/docs/en/tags/use%20case)

---

## Security Monitoring for DevOps

# Security Monitoring for DevOps
* 1 Minute to read

## What's Next

* [Table Top Exercises](/docs/table-top-exercises)

Tags

* [DevOps](/docs/en/tags/DevOps)
* [monitoring](/docs/en/tags/monitoring)
* [use case](/docs/en/tags/use%20case)

---

## Security Service Providers (MSSP, MSP, MDR)

# Security Service Providers (MSSP, MSP, MDR)
The LimaCharlie SecOps Cloud Platform (SCP) is a unified platform for modern cybersecurity operations.

The SCP delivers core cybersecurity capabilities and infrastructure via a public cloud model: on-demand, pay-per-use, and API-first. For the cybersecurity industry, this is a paradigm shift comparable to how the IT public cloud revolutionized IT.

For managed security services providers (MSSPs), managed detection and response (MDR) firms, and all those involved in digital forensics and incident response (DFIR), the SecOps Cloud Platform is a powerful way to improve security operations and compete more effectively. With the SCP, service providers can deliver security services at scale, control costs, consolidate and customize security tooling, take on new businesses with confidence, and much more.

The platform's public cloud-like delivery model also helps service providers integrate the SCP into their operations gradually and safely. Flexible pay-as-you-go pricing means you only pay for the capabilities you need, and only for as long as you use them—without long-term contracts, complex licensing, capacity planning, price modeling, or termination fees.

## Implementation strategies for quick wins

The SecOps Cloud Platform contains numerous capabilities and is designed to be highly flexible and customizable. Nevertheless, there are some common implementation strategies that MSSP users have found to be good starting points with the platform. Here are three easy ways that the SCP can help service providers improve security operations and expand their businesses immediately:

### Gain greater visibility into client environments

The SCP can help service providers gain greater visibility into client environments—and bring telemetry data under a single plane for a more unified view. This is one of the first realizations of value for service providers using the SCP platform. Here's an outline of what this looks like:

**Decide what telemetry data you need to support security operations.** Your options here are extensive. In the SCP, there are two main sources of telemetry:

First, there are the platform's endpoint detection and response (EDR)-type sensors, which can be deployed directly on Windows, Mac, and Linux endpoints with full feature parity across these OSes to capture system events and other telemetry data. There are also browser-based sensors for Chrome and Edge. Sensors stream telemetry data and artifacts into the SCP in real time (and can also be used to take response actions on endpoints). Importing event data from third-party EDR tools such as VMWare Carbon Black, CrowdStrike, and Microsoft Defender is also possible.

The second source of telemetry data can be classed as log-type data. This data can be brought into the SCP using a system of adapters or via webhook. The options are too numerous to list here in full, but supported log data sources include O365, 1Password, AWS CloudTrail, Google Cloud Platform (GCP), Slack Audit logs, and more. For a more comprehensive list, refer to the SCP documentation.

**Configure client organizations to provide the required visibility.** The SCP web interface makes this as simple as making a few clicks to set up the required installation keys. More advanced configuration management options using a REST API or a command-line interface (CLI) are also available. After setup, your client organizations' configurations—including what telemetry you want to bring into the SecOps Cloud Platform—will be stored as simple YAML files. Note here that it's possible to use the SCP's multitenancy and organization management features to make configuration changes to multiple organizations at the same time. For a more detailed example of what this might look like, see this demo MSSP setup.

**Bring your data under a single plane.** All telemetry data brought into the SCP is normalized to a common JSON format and explorable through a single interface. In itself, this represents a huge step forward for many service providers because they will no longer have to deal with a fragmented jumble of UIs or competing data formats in order to view and act on their telemetry data.

**Operationalize your telemetry data.** Seeing into your clients' environments is an essential first step—but this is only the beginning of what is possible with the SecOps Cloud Platform. The SCP's advanced detection and response engine can act on every piece of telemetry brought into the platform, making it possible to apply sophisticated detection and response () logic to telemetry data. Applying D&R logic can be as tailored or as simple as you choose, from using custom detections that you write yourself to leveraging curated rulesets like Sigma, Soteria, or SOC Prime rules—or a combination of both approaches.

It's impossible to protect what you can't see. The SCP makes it possible to gain full visibility into a client environment, visualize that telemetry in a single interface and data format, and take action on telemetry data via a powerful detection, automation, and response engine.

#### Implement scalable SecOps and simplified client management

The SecOps Cloud Platform is multitenant by design, offers fine-grained role-based access control (RBAC), and supports an Infrastructure-as-Code (IaC) approach to configuration management. These core aspects of the SCP enable service providers to practice modern cybersecurity operations at scale.

**Separate client environments intelligently.** The multitenancy of the SCP allows service providers to create a logical boundary between their client organizations' data while still being able to view and manage everything from a single platform. Multitenancy makes it easier to avoid commingling client data—and comply with regional regulatory requirements such as data residency rules.

**Manage access and permissions more effectively.** RBAC allows you to grant users the access to organizations and the permissions that they need. You can give individual users permissions on a per-organization basis if you choose. But for more efficient access management, you can use Organization Groups, which are groupings of client organizations, permissions, and users.

Organization Groups give the same permissions and organizational access to any user added to the group. Typically, Organization Groups are set up by job function. For example, you might create an Organization Group for security engineers that allows members to edit telemetry ingestion configurations for all of your client organizations, and a separate Organization Group for non-technical roles that provides read-only access or the ability to view general organizational information.

**Build SecOps workflows that scale.** The SecOps Cloud Platform enables service providers to take an infrastructure-as-code approach to security operations. All of your client organizations' security [configurations](https://limacharlie.io/secops-cloud-platform-guide-service-providers#:~:text=client%20organizations%27%20security-,configurations,-%E2%80%94from%20D%26R)—from D&R rules to data forwarding and output settings—can be stored and managed as simple YAML files.

Create new organizations quickly by cloning an existing organization's configurations or using a [configuration template](https://limacharlie.io/secops-cloud-platform-guide-service-providers#:~:text=configuration%20template). Maintain a global set of configuration settings for all client organizations and then add per-client config files as needed. If you need to make changes to multiple client organizations, this is as simple as editing a global configuration file via CLI or web UI and pushing out the change to all of your organizations at scale.

The SecOps Cloud Platform helps service providers adopt a truly modern and scalable approach to cybersecurity operations. For a more detailed look at how these SCP concepts work in practice, watch  [Setting Up an MSSP with LimaCharlie](https://limacharlie.io/secops-cloud-platform-guide-service-providers#:~:text=Setting%20Up%20an%20MSSP%20with%20LimaCharlie).

#### Improve incident response times and offer unbeatable service-level agreements

The SecOps Cloud Platform can be tremendously valuable for service providers doing incident response (IR) work. Here are some of the most significant capabilities for IR teams:

**Begin IR engagements without delay.** The on-demand nature of the SecOps Cloud Platform means you will never need to talk to a vendor sales representative or renegotiate a contract before starting an IR engagement. With the SCP, you log into your account, use a credit card or increase your existing sensor quota, and begin.

In addition, it's possible to preconfigure tenants ahead of an IR engagement. Set up your desired SCP IR configuration using custom D&R rulesets, curated rulesets, memory dump capabilities, YARA scanning, and more. Then, export the configuration files for your IR tenant and reuse them whenever you have a new IR engagement to hit the ground running.

**Take the fight to the adversary.** During IR engagements with an active attacker in the environment, the SecOps Cloud Platform gives you a robust response capability on your client's endpoints.

Mass-deploy SCP sensors using an enterprise deployment tool. Then, use those sensors to gather real-time event data, run shell commands and executables on endpoints, deploy security tools and remediation packages at scale, or isolate compromised machines from the network—all with minimal impact on the client's operations and mission-critical IT infrastructure.

**Use security intelligence as soon as you have it.** The SCP's IaC approach means you don't have to rely on a vendor to update a tool or publish an indicator of compromise (IoC) in an emergency. For example, imagine a scenario in which you're dealing with a 0-day compromise. If you have early access to an IoC via an information-sharing network or a colleague, you can literally copy-paste the relevant IoC data from a Slack message into a new SCP D&R rule, update the relevant config file, and push out the change to your client's environment—while the all of the vendor-dependent service providers are still waiting on someone else to act.

**Build a true rapid-response capability.** LimaCharlie sensors can be pre-deployed to client environments in "sleeper" mode: i.e., with the telemetry collection settings tuned down to a bare minimum to keep costs to just pennies per month. If an incident occurs, the sensors are already there, ready and waiting on the endpoints, and can turned on for an immediate response. This use case has allowed SCP service provider partners to offer service-level agreements of as little as 20 minutes—a considerable advantage when it comes to pitching (and closing) new MDR or MSSP clients.

IR work is high-stakes and high-pressure—and, unfortunately, is far too often complicated by the cumbersome sales processes and technical limitations of legacy cybersecurity vendors. The SCP allows incident responders to take action quickly and independently during an incident. It also lets cybersecurity service providers improve their overall response capabilities, enabling attractive service-level agreements that can help win over prospective clients.

Managed Detection & Response

Digital Forensics & Incident Response

Managed Security Services Provider

Endpoint Detection & Response

Amazon Web Services

Google Cloud Platform

Command-line Interface

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.

---

##### What's Next

* [Quickstart](/docs/quickstart)

Table of contents

Tags

* [MDR](/docs/en/tags/MDR)
* [MSP](/docs/en/tags/MSP)
* [MSSP](/docs/en/tags/MSSP)
* [use case](/docs/en/tags/use%20case)

---

## SentinelOne

# SentinelOne
* 1 Minute to read

## What's Next

* [Sophos](/docs/adapter-types-sophos)

Table of contents

+ [Deployment Configurations](#deployment-configurations)
+ [Deployment Examples](#deployment-examples)

---

## Sigma Converter

# Sigma Converter
LimaCharlie is happy to contribute to the [Sigma Project](https://github.com/SigmaHQ/sigma) by maintaining the LimaCharlie Backend for Sigma, enabling most Sigma rules to be converted to the [Detection & Response rule](/v2/docs/detection-and-response) format.

A LimaCharlie [Service](/v2/docs/sigma-rules) is available to apply [many of those converted rules](https://github.com/refractionPOINT/sigma-limacharlie/tree/rules) with a single click to an Organization.

For cases where you either have your own Sigma rules, or you would like to convert/apply specific rules yourself, the Sigma Converter service described below can help streamline the process.

## Converter Service

The Converter service converts one or many Sigma rules into the LimaCharlie  rule format. It can accomplish this via the following HTTPS endpoints available at https://sigma.limacharlie.io/:

### Single Rule

Endpoint: `https://sigma.limacharlie.io/convert/rule`
 Verb: `POST`
 Form Parameters:

* `rule`: the content of a literal Sigma rule to be converted.
* `target`: optional [target](/v2/docs/detection-on-alternate-targets) within LimaCharlie, one of `edr` (default) or `artifact`.
   Output Example:

```json
{
    "rule": "detect:\n  events:\n  - NEW_PROCESS\n  - EXISTING_PROCESS\n  op: and\n  rules:\n  - op: is windows\n  - op: or\n    rules:\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: domainlist\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: trustdmp\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: dcmodes\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: adinfo\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: ' dclist '\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: computer_pwdnotreqd\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: objectcategory=\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: -subnets -f\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: name=\"Domain Admins\"\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: '-sc u:'\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: domainncs\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: dompol\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: ' oudmp '\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: subnetdmp\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: gpodmp\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: fspdmp\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: users_noexpire\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: computers_active\nrespond:\n- action: report\n  metadata:\n    author: Janantha Marasinghe (https://github.com/blueteam0ps)\n    description: AdFind continues to be seen across majority of breaches. It is used\n      to domain trust discovery to plan out subsequent steps in the attack chain.\n    falsepositives:\n    - Admin activity\n    level: high\n    references:\n    - https://thedfirreport.com/2020/05/08/adfind-recon/\n    - https://thedfirreport.com/2021/01/11/trickbot-still-alive-and-well/\n    - https://www.microsoft.com/security/blog/2021/01/20/deep-dive-into-the-solorigate-second-stage-activation-from-sunburst-to-teardrop-and-raindrop/\n    tags:\n    - attack.discovery\n    - attack.t1482\n    - attack.t1018\n  name: AdFind Usage Detection\n\n"
}
```

CURL Example:

```bash
curl -X POST  https://sigma.limacharlie.io/convert/rule -H 'content-type: application/x-www-form-urlencoded' --data-urlencode "rule@my-rule-file.yaml"
```

### Multiple Rules

Endpoint: `https://sigma.limacharlie.io/convert/repo`
 Verb: `POST`
 Form Parameters:

* `repo`: the source where to access the rules to convert, one of:

  + An HTTPS link to a direct resource like: `https://corp.com/my-rules.yaml`
  + A GitHub link to a file or repo like:

    - `https://github.com/SigmaHQ/sigma/blob/master/rules/windows/process_creation/proc_creation_win_ad_find_discovery.yml`
    - `https://github.com/SigmaHQ/sigma/blob/master/rules/windows/process_creation`
  + An [Authenticated Resource Locator](/v2/docs/reference-authentication-resource-locator)
* `target`: optional [target](/v2/docs/detection-on-alternate-targets) within LimaCharlie, one of `edr` (default) or `artifact`.

Output Example:

```json
{
    "rules":[
        {
            "file":"https://raw.githubusercontent.com/SigmaHQ/sigma/master/rules/windows/process_creation/proc_creation_win_ad_find_discovery.yml","rule":"detect:\n  events:\n  - NEW_PROCESS\n  - EXISTING_PROCESS\n  op: and\n  rules:\n  - op: is windows\n  - op: or\n    rules:\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: domainlist\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: trustdmp\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: dcmodes\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: adinfo\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: ' dclist '\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: computer_pwdnotreqd\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: objectcategory=\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: -subnets -f\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: name=\"Domain Admins\"\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: '-sc u:'\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: domainncs\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: dompol\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: ' oudmp '\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: subnetdmp\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: gpodmp\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: fspdmp\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: users_noexpire\n    - case sensitive: false\n      op: contains\n      path: event/COMMAND_LINE\n      value: computers_active\nrespond:\n- action: report\n  metadata:\n    author: Janantha Marasinghe (https://github.com/blueteam0ps)\n    description: AdFind continues to be seen across majority of breaches. It is used\n      to domain trust discovery to plan out subsequent steps in the attack chain.\n    falsepositives:\n    - Admin activity\n    level: high\n    references:\n    - https://thedfirreport.com/2020/05/08/adfind-recon/\n    - https://thedfirreport.com/2021/01/11/trickbot-still-alive-and-well/\n    - https://www.microsoft.com/security/blog/2021/01/20/deep-dive-into-the-solorigate-second-stage-activation-from-sunburst-to-teardrop-and-raindrop/\n    tags:\n    - attack.discovery\n    - attack.t1482\n    - attack.t1018\n  name: AdFind Usage Detection\n\n"
        },
        ...
    ]
}
```

CURL Example:

```bash
curl -X POST  https://sigma.limacharlie.io/convert/repo -d "repo=https://github.com/SigmaHQ/sigma/blob/master/rules/windows/process_creation/proc_creation_win_ad_find_discovery.yml"
```

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

#### Related articles

* [Sigma Rules](/docs/sigma-rules)
* [Managed Rulesets](/docs/managed-rulesets)
* [Detection and Response Examples](/docs/detection-and-response-examples)

---

##### What's Next

* [Soteria Rules](/docs/soteria-rules)

Table of contents

+ [Converter Service](#converter-service)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)

---

## Single Sign-On

# Single Sign-On
* 1 Minute to read

## Related articles

* [User Access](/docs/user-access)

---

### What's Next

* [Reference: Permissions](/docs/reference-permissions)

Table of contents

+ [How It Works](#how-it-works)
+ [User Experience](#user-experience)

Tags

* [platform](/docs/en/tags/platform)

---

## Sleeper Deployment

# Sleeper Deployment
LimaCharlie's usage-based billing enables incident responders to offer pre-deployments to their customers at almost zero cost. That is, they can deploy across an Organization's entire fleet and lay dormant in ‘sleeper mode’ at a cost of just $0.10 per 30 days. With agents deployed ahead of an incident, responders can offer competitive SLAs.

> Have more questions?
>
> For more details on sleeper mode deployments, feel free to contact us at answers@limacharlie.io or book a quick call with the engineering team to discuss your use case.

Sleeper and Usage billing use the following metrics:

| Connected Time | Events Processed | Events Retained |
| --- | --- | --- |
| $0.10 per 30 days | $0.67 per 100,000 events | $0.17 per 100,000 events |

Using sleeper and usage deployments is done via Sensor tagging. Applying the `lc:sleeper` Tag to a Sensor will stop LimaCharlie telemetry collection activity on the host. Within 10 minutes of the tag being applied, the sensor will enter sleeper mode and will be billed only for its "Connected Time" as outlined above. If the tag is removed, normal operations resume within 10 minutes.

Applying the `lc:usage` tag will make the sensor operate normally as usual, but its connection will not count against the normal Sensor Quota. Instead it will be billed per time spend connected and number of events process/retained as outlined above.

Using the "usage" and "sleeper" mode requires the organization in question to have billing enabled (a quota of at least 3 to be outside of the free tier).

This means a sample scenario around pre-deploying in an enterprise could look something like this:

1. Create a new Organization in LimaCharlie.
2. Set the Quota to 3 to enable billing.
3. Create a new Installation Key, and set the `lc:sleeper` tag on the key.
4. Enroll any number of EDR sensors. Charges will apply as specified above. For example, if you deploy 100 Sensors in sleeper mode, total monthly costs will be $10.
5. Whenever you need to “wake up” and use some of the EDRs, you have 2 options:

   1. Set the `lc:usage` tag on the Sensor(s) you need. Within 10 minutes, telemetry collection will resume and billed on direct usage.
   2. Set the quota to the number of Sensor(s) you need, remove the `lc:sleeper` tag from the specific Sensors, and within 10 minutes they will be online, billed according to the quota.
6. When you're done, just re-add the `lc:sleeper` tag.

Switching to sleeper mode does not change the binary on disk, however, the code running in memory does change. Whether putting an org into sleeper mode or changing versions, the binary on disk remains as-is.

The changes to sleeper mode go into effect without the need for a reboot. In sleeper mode, activities such as read other process’ memory (e.g. [YARA](/v2/docs/ext-yara)) will stop.

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

Tags in LimaCharlie are strings linked to sensors for classifying endpoints, automating detection and response, and triggering workflows. Tags appear in every event under the `routing` component and help simplify rule writing. Tags can be added manually, via API, or through detection & response rules. System tags like `lc:latest`, `lc:stable`, and `lc:debug` offer special functionality. Tags can be checked, added, or removed through the API or web app, streamlining device management.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.

Endpoint Detection & Response

---

## Related articles

* [FAQ - Billing](/docs/faq-billing)
* [Billing](/docs/billing)
* [Sensor Tags](/docs/sensor-tags)

---

### What's Next

* [Hostname Resolution](/docs/hostname-resolution)

Tags

* [dfir](/docs/en/tags/dfir)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)

---

## Sleeper Mode

# Sleeper Mode
* 1 Minute to read

## What's Next

* [M&A Cyber Due Diligence](/docs/ma-cyber-due-diligence)

Tags

* [sleeper mode](/docs/en/tags/sleeper%20mode)
* [use case](/docs/en/tags/use%20case)

---

## Sysmon Comparison

# Sysmon Comparison
* 1 Minute to read

## Related articles

* [Ingesting Sysmon Event Logs](/docs/ingesting-sysmon-event-logs)
* [Reference: EDR Events](/docs/reference-edr-events)

---

### What's Next

* [Reference: EDR Events](/docs/reference-edr-events)

Table of contents

+ [Executable Tracking](#executable-tracking)

Tags

* [detection and response](/docs/en/tags/detection%20and%20response)
* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [events](/docs/en/tags/events)
* [telemetry](/docs/en/tags/telemetry)
* [windows](/docs/en/tags/windows)

---

## Table Top Exercises

# Table Top Exercises
* 1 Minute to read

## What's Next

* [Network Monitoring](/docs/network-monitoring)

Tags

* [exercise](/docs/en/tags/exercise)
* [tabletop](/docs/en/tags/tabletop)
* [use case](/docs/en/tags/use%20case)

---

## Template Strings and Transforms

# Template Strings and Transforms
Many areas of LimaCharlie support template strings and transforms.

A template string allows you to customize the value of a configuration based on the context. For example to adjust the Detection Name a D&R rule to include a value from the detection itself. Transforms can also be used to select, modify, or remove fields upon data ingestion from an Adapter.

A transform allows you to change the shape of JSON data in flight to suit better your usage. This can mean moving, renaming, removing and adding fields in JSON. For example, it can allow you to create an Output that works with `DNS_REQUEST` events, but outputs only specific fields from the event.

## Template Strings

Template strings in LimaCharlie use the format defined by "text templates" found [here](https://pkg.go.dev/text/template). A useful guide provided by Hashicorp is also available [here](https://learn.hashicorp.com/tutorials/nomad/go-template-syntax).

The most basic example for a D&R rule customizing the detection name looks like this:

```
- action: report
  name: Evil executable on {{ .routing.hostname }}
```

Template strings also support some LimaCharlie-specific functions:

* `token`: applies an MD5 hashing function on the value provided.
* `anon`: applies an MD5 hashing function on a secret seed value, plus the value provided.
* `json`: marshals the input into a JSON string representation.
* `prettyjson`: same as `json` but with indentation and newlines.
* `parsetime`: parse a time format to another.
* `split`: split a string based on a seperator param.
* `join`: join a list into a string joined by another string.
* `replace`: replace all string into the other.
* `base`: return the file name in a file path.
* `dir`: return the base directory path from a file path.

The `token` and `anon` functions can be used to partially anonymize data anywhere a template string is supported, for example:

```
- action: report
  name: 'User {{token .event.USER_NAME }} accessed a website against policy.'
```

Other examples:

* `Full Data: {{prettyjson .event.OBJECT }}`
* `Original time:{{parsetime "{\"from\":\"2006/01/02 15:04:05\", \"to\":\"2006-01-02 15:04:05 MST\"}" .event.timestamp}}`
* `Packages: {{join "," .event.PACKAGES}}`

### Template Strings and Adapter Transforms

Template strings can also be used with in conjunction the `client_options.mapping.transform` option in [Adapter configuration](/v2/docs/adapter-usage). These allow you to modify data prior to ingestion, having control over *what* fields get ingested and resulting field names.

The following options are available in Adapter configurations:

* `+` to add a field
* `-` to remove a field

Both support template strings, meaning you can add/remove values from the JSON data to replace/supplement other fields.

For example, if we had the following data:

```json
{ "event":
  "webster" : {
     "a" : 1,
     "b" : 2,
     "d" : 3
    }
  }
}
```

And we wanted to rename the `d` value to `c` on ingestion, remove the d value, and add a field called `hostname`, we could use the following configuration:

```
...
   client_options:
     mapping:
       transform:
         +c : '{{ .webster.d }}',
         -d: nil,
         +hostname : '{{ "my-computer" }}',
```

The resulting event to be ingested would be:

```json
{ "event":
  "webster" : {
     "a" : 1,
     "b" : 2,
     "c" : 3
    },
    "hostname" : "my-computer"
  }
}
```

## Transforms

With Transforms, you specify a JSON object that describes the transformation.

This object is in the shape of the final JSON you would like to transform to.

Key names are the literal key names in the output. Values support one of 3 types:

1. Template Strings, as described above. In this case, the template string will be generated and placed at the same place as the key in the transform object.
2. A `gjson` selector. The selector syntaxt is defined [here](https://github.com/tidwall/gjson/blob/master/SYNTAX.md). It makes it possible to select subsets of input object and map it within the resulting object as defined by the transform.
3. Other JSON objects which will be present in the output.

Let's look at an example, let's say this is the Input to our transform:

```json
{
    "event": {
        "EVENT": {
            "EventData": {
                "AuthenticationPackageName": "NTLM",
                "FailureReason":             "%%2313",
                "IpAddress":                 "34.64.101.177",
                "IpPort":                    "0",
                "KeyLength":                 "0",
                "LmPackageName":             "-",
                "LogonProcessName":          "NtLmSsp",
                "LogonType":                 "3",
                "ProcessId":                 "0x0",
                "ProcessName":               "-",
                "Status":                    "0xc000006d",
                "SubStatus":                 "0xc0000064",
                "SubjectDomainName":         "-",
                "SubjectLogonId":            "0x0",
                "SubjectUserName":           "-",
                "SubjectUserSid":            "S-1-0-0",
                "TargetDomainName":          "",
                "TargetUserName":            "ADMINISTRADOR",
                "TargetUserSid":             "S-1-0-0",
                "TransmittedServices":       "-",
                "WorkstationName":           "-",
            },
            "System": {
                "Channel":  "Security",
                "Computer": "demo-win-2016",
                "Correlation": {
                    "ActivityID": "{F207C050-075F-0001-AFE1-ED1F3897D801}",
                },
                "EventID":       "4625",
                "EventRecordID": "2832700",
                "Execution": {
                    "ProcessID": "572",
                    "ThreadID":  "2352",
                },
                "Keywords": "0x8010000000000000",
                "Level":    "0",
                "Opcode":   "0",
                "Provider": {
                    "Guid": "{54849625-5478-4994-A5BA-3E3B0328C30D}",
                    "Name": "Microsoft-Windows-Security-Auditing",
                },
                "Security": "",
                "Task":     "12544",
                "TimeCreated": {
                    "SystemTime": "2022-07-15T22:48:24.996361600Z",
                },
                "Version": "0",
            },
        },
    },
    "routing": {
        "arch":       2,
        "did":        "b97e9d00-ca17-4afe-a9cf-27c3468d5901",
        "event_id":   "f24679e5-5484-4ca1-bee2-bfa09a5ba3db",
        "event_time": 1657925305984,
        "event_type": "WEL",
        "ext_ip":     "35.184.178.65",
        "hostname":   "demo-win-2016.c.lc-demo-infra.internal",
        "iid":        "7d23bee6-aaaa-aaaa-aaaa-c8e8cca132a1",
        "int_ip":     "10.128.0.2",
        "moduleid":   2,
        "oid":        "8cbe27f4-aaaa-aaaa-aaaa-138cd51389cd",
        "plat":       268435456,
        "sid":        "bb4b30af-ff11-4ff4-836f-f014ada33345",
        "tags": [
            "edr",
            "lc:stable",
        ],
        "this": "c5e16360c71baf3492f2dcd962d1eeb9",
    },
    "ts": "2022-07-15 22:48:25",
}
```

And this is our Transform definition:

```json
{
    "message": "Interesting event from {{ .routing.hostname }}",  // a format string
    "from":    "{{ \"limacharlie\" }}",                           // a format string with only a literal value
    "dat": {                                                      // define a sub-object in the output
        "raw": "event.EVENT.EventData"                            // a "raw" key where we map a specific object from the input
    },
    "anon_ip": "{{anon .routing.int_ip }}",                       // an anonymized version of the internal IP
    "ts":   "routing.event_time",                                 // map a specific simple value
    "nope": "does.not.exist"                                      // map a value that is not present
}
```

Then the resulting Output would be:

```json
{
    "dat": {
        "raw": {
            "AuthenticationPackageName": "NTLM",
            "FailureReason": "%%2313",
            "IpAddress": "34.64.101.177",
            "IpPort": "0",
            "KeyLength": "0",
            "LmPackageName": "-",
            "LogonProcessName": "NtLmSsp",
            "LogonType": "3",
            "ProcessId": "0x0",
            "ProcessName": "-",
            "Status": "0xc000006d",
            "SubStatus": "0xc0000064",
            "SubjectDomainName": "-",
            "SubjectLogonId": "0x0",
            "SubjectUserName": "-",
            "SubjectUserSid": "S-1-0-0",
            "TargetDomainName": "",
            "TargetUserName": "ADMINISTRADOR",
            "TargetUserSid": "S-1-0-0",
            "TransmittedServices": "-",
            "WorkstationName": "-"
        }
    },
    "from": "limacharlie",
    "message": "Interesting event from demo-win-2016.c.lc-demo-infra.internal",
    "nope": null,
    "ts": 1657925305984,
    "anon_ip": "e80b5017098950fc58aad83c8c14978e"
}
```

### Transforming Output Data

When passing events to an output, you have the option to transform the original event in multiple ways. When creating an output, Custom Transforms are applied in the CUSTOM TRANSFORM area of the screenshot below. In this example we are transforming a detection event to pass via a custom webhook to a web application.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(310).png)

### Examples

#### Extracting Fields from Telemetry

Let's say you have the following 4625 failed logon and you want to send similar events to an output, but only certain fields.

```json
{
  "event": {
    "EVENT": {
      "EventData": {
        "AuthenticationPackageName": "NTLM",
        "FailureReason": "%%2313",
        "IpAddress": "142.99.21.14",
        # <extra fields removed>
        "TargetUserName": "administrator",
        "WorkstationName": "D-483"
      },
      "System": {
        "Channel": "Security",
        "Computer": "demo-win-2016",
        # <extra fields removed>
        "EventID": "4625",
        "EventRecordID": "22690646",
        # <extra fields removed>
        "TimeCreated": {
          "SystemTime": "2024-01-23T17:30:07.345840000Z"
        },
        "Version": "0",
        "_event_id": "4625"
      }
    }
  },
  "routing": {
    # <extra fields removed>
    "event_type": "WEL",
    "hostname": "win-2016.corp.internal",
     # <extra fields removed>
    "tags": [
      "windows"
    ],
    "this": "8873fb9fcb26e2c0d4299ce765aff77d"
  },
  "ts": "2024-01-23 17:29:33"
}
```

The following Output Transform would extract only the `IpAddress`, `TargetUserName`, `EventID`, and `SystemTime` the event was created. Notice, the newly mapped field names can be whatever you want.

```json
{
    "Source IP": "event.EVENT.EventData.IpAddress",
    "Username": "event.EVENT.EventData.TargetUserName",
    "Event ID": "event.EVENT.System.EventID",
    "Happened at": "event.EVENT.System.TimeCreated.SystemTime"
}
```

The following example outputs text and specified fields using [Template Strings](/v2/docs/template-strings-and-transforms).

```json
{
  "text": "Failed logon by {{ .event.EVENT.EventData.TargetUserName }} on {{ .routing.hostname }}"
}
```

The above example would generate the following output using the provided sample WEL.

```json
{
  "text": "Failed logon by administrator on win-2016.corp.internal"
}
```

### Output as String / Passthrough

The `custom_transform` in outputs can also be used to output pure text (non-JSON) from LimaCharlie. This is useful if, for example, you are ingesting syslog data, and want to forward this syslog data as-is to something else.

This is accomplished by specifying a Template String in the `custom_transform` field instead of a Transform. In those cases, when LimaCharlie determines the `custom_transform` string is not a valid Transform, it will interpret it as a Template String like:

```json
{
    "custom_transform": "{{ .event.text }}"
}
```

or

```json
{
    "custom_transform": "some text {{json .event.some_field }}"
}
```

### Custom Modifiers

Beyond the built-in modifiers for `gjson` (as seen in their [playground](https://gjson.dev/), LimaCharlie also implements several new modifiers:

* `parsejson`: this modifier takes no arguments, it takes in as input a string that represents a JSON object and outputs the decoded JSON object.
* `extract`: this modifier takes a single argument, `re` which is a regular expression that uses "named capture groups" (as defined in the [re2 documentation](https://github.com/google/re2/wiki/Syntax)). The group names become the keys of the output JSON object with the matching values.
* `parsetime`: this modifier takes two arguments, `from` and `to`. It will convert an input string from a given time format (as defined in the Go `time` library format [here](https://pkg.go.dev/time#pkg-constants)) and outputs the resulting time in the `to` format. Beyond the time constants from the previous link, LimaCharlie also supports a `from` format of:

  + `epoch_s`: a second based epoch timestamp
  + `epoch_ms`: a millisecond based epoch timestamp

For example:
The transform:

```json
{
  "new_ts": "ts|@parsetime:{\"from\":\"2006-01-02 15:04:05\", \"to\":\"Mon, 02 Jan 2006 15:04:05 MST\"}",
  "user": "origin|@extract:{\"re\":\".*@(?P<domain>.+)\"}"
  "ctx": "event.EVENT.exec_context|@parsejson"
}
```

applied to:

```json
{
  "ts": "2023-05-10 22:35:48",
  "origin": "someuser@gmail.com",
  "event": {
    "EVENT": {
      "exec_context": "{\"some\": \"embeded value\"}"
    }
  }
}
```

would result in:

```json
{
  "new_ts": "Wed, 10 May 2023 22:35:48 UTC",
  "user": {
    "domain": "gmail.com\""
  },
  "ctx": {
    "some": "embeded value"
  }
}
```

Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.

---

#### Related articles

* [Detection and Response Examples](/docs/detection-and-response-examples)
* [Detection and Response](/docs/detection-and-response)
* [Writing and Testing Rules](/docs/writing-and-testing-rules)
* [Outputs](/docs/outputs)
* [Output Destinations](/docs/output-destinations)
* [Testing Outputs](/docs/testing-outputs)
* [Adapters](/docs/adapters)

---

##### What's Next

* [Platform Events Overview](/docs/platform-events-overview)

Table of contents

+ [Template Strings](#template-strings)
+ [Transforms](#transforms)

Tags

* [adapters](/docs/en/tags/adapters)
* [detection and response](/docs/en/tags/detection%20and%20response)
* [outputs](/docs/en/tags/outputs)
* [platform](/docs/en/tags/platform)

---

## Threat Hunting

# Threat Hunting
* 1 Minute to read

## What's Next

* [Security Monitoring for DevOps](/docs/security-monitoring-for-devops)

Tags

* [threat hunting](/docs/en/tags/threat%20hunting)
* [use case](/docs/en/tags/use%20case)

---

## Uncovering Adversary Techniques

# Uncovering Adversary Techniques
LimaCharlie's SecOps Cloud Platform provides a comprehensive approach to combating ransomware, focusing on early detection during the reconnaissance stage and rapid response in the event of a detonation. By gathering telemetry from a wide range of sources, enabling widespread deployment, and leveraging real-time response capabilities, LimaCharlie empowers organizations to effectively detect, stop, and mitigate ransomware attacks, minimizing damage and ensuring business continuity.

## Problems with uncovering adversary techniques

Ransomware attacks have become increasingly sophisticated and targeted, posing a significant threat to organizations of all sizes. The challenges in effectively combating ransomware include:

* **Extended dwell time:** Ransomware attacks often involve weeks or months of reconnaissance, during which malicious actors seek to identify optimal detonation points. Detecting and stopping the attack during this stage is crucial but challenging.
* **Difficulty in correlating data:** Malicious actors often move around and attempt to hide their presence, making it difficult to identify and correlate their activities across various systems and data sources.
* **Rapid spread and damage:** In the event of a successful ransomware detonation, the malware can spread rapidly, encrypting files and causing significant damage before security teams can respond.

### LimaCharlie’s solution

LimaCharlie's SecOps Cloud Platform offers a comprehensive approach to combating ransomware, focusing on early detection during the reconnaissance stage and rapid response in the event of a detonation:

* **Comprehensive telemetry gathering:** LimaCharlie gathers telemetry and external artifacts from a wide range of sources, including endpoints, networks, and cloud environments. By normalizing all data to JSON and processing it through the SecOps Cloud Platform's detection, automation, and response engine, LimaCharlie gains a global view of the organization's security posture, enabling it to identify suspicious activities and correlations that may indicate a ransomware attack in progress.
* **Early detection through widespread deployment:** LimaCharlie's ability to deploy everywhere allows it to detect intruders faster than the competition, often before malicious actors can lay an effective trap. By monitoring everything from one place and leveraging advanced detection logic, LimaCharlie can identify and stop ransomware attacks during the crucial reconnaissance stage.
* **Real-time response with semi-persistent TLS connection:** In the event of a ransomware detonation, LimaCharlie's real-time, semi-persistent TLS connection with endpoints enables an unparalleled response capability. If detection logic is in place to catch a ransomware event, response actions can be taken across the entire fleet in real-time. This allows security teams to instantly isolate affected machines from the network while maintaining command and control through LimaCharlie, minimizing further damage and data exfiltration.
* **Advanced threat hunting and remediation:** With LimaCharlie, analysts responding to a ransomware event have access to all affected machines and a full year's history of telemetry. This enables them to run remediation scripts on the endpoints, kill process trees, and hunt for any malicious presence. By leveraging advanced indicators, such as FILE\_TYPE\_ACCESSED events, security teams can detect ransomware detonation events before the malware proliferates, significantly reducing the impact of the attack.

---

#### What's Next

* [WEL Monitoring](/docs/wel-monitoring)

Tags

* [adversary](/docs/en/tags/adversary)
* [techniques](/docs/en/tags/techniques)
* [use case](/docs/en/tags/use%20case)

---

## Unit Tests

# Unit Tests
## Rules Unit Tests

A D&R rule record can optionally contain unit tests. These tests describe events that should match, and events that should not match. When a D&R rule is updated or created, LimaCharlie will simulate the rules and if the tests fail, an error is produced.

### Structure

A typical D&R rule looks like:

```json
{
  "detect": {...},
  "respond": [
    {},
    {}
  ],
  "tests": {
    "match": [],
    "non_match": []
  }
}
```

The `match` and `non_match` both have the same format: they contain a list of lists of events. Each top list element is a unit test, and the content of a test is a list of events as would be seen by LimaCharlie. The reason for the test to be a list is to accomodate for [Stateful Detections](/v2/docs/stateful-rules) which operate across multiple events.

Here’s an example:

```json
{
  "tests": {
    "match": [
      [{"event": ...}, {"event": ...}, {"event": ...}],
      [{"event": ...}],
      [{"event": ...}]
    ],
    "non_match": [
      [{"event": ...}, {"event": ...}],
      [{"event": ...}]
    ]
  }
}
```

### Example

```
version: 3
hives:
    dr-general:
        "CobaltStrike Named Pipe Patterns":
            data:
                detect:
                    event: WEL
                    op: and
                    rules:
                      - op: and
                        rules:
                        - op: or
                          rules:
                          - case sensitive: false
                            op: is
                            path: event/EVENT/System/_event_id
                            value: '17'
                          - case sensitive: false
                            op: is
                            path: event/EVENT/System/_event_id
                            value: '18'
                        - case sensitive: false
                          op: is
                          path: event/EVENT/System/Channel
                          value: Microsoft-Windows-Sysmon/Operational
                      - op: or
                        rules:
                        - op: or
                          rules:
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \mojo.5688.8052.183894939787088877
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \mojo.5688.8052.35780273329370473
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \mypipe-f
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \mypipe-h
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \ntsvcs
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \scerpc
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \win_svc
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \spoolss
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \msrpc_
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \win\msrpc_
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \wkssvc
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \windows.update.manager
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \SearchTextHarvester
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \DserNamePipe
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \PGMessagePipe
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \MsFteWds
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \fullduplex_
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \rpc_
                        - op: or
                          rules:
                          - case sensitive: false
                            op: is
                            path: event/EVENT/EventData/PipeName
                            value: \demoagent_11
                          - case sensitive: false
                            op: is
                            path: event/EVENT/EventData/PipeName
                            value: \demoagent_22
                        - op: matches
                          path: event/EVENT/EventData/PipeName
                          re: \\f4c3[0-9a-f]{2}$
                        - op: matches
                          path: event/EVENT/EventData/PipeName
                          re: \\f53f[0-9a-f]{2}$
                        - op: and
                          rules:
                          - case sensitive: false
                            op: starts with
                            path: event/EVENT/EventData/PipeName
                            value: \Winsock2\CatalogChangeListener-
                          - case sensitive: false
                            op: ends with
                            path: event/EVENT/EventData/PipeName
                            value: -0,
                respond:
                    - action: report
                      name: CobaltStrike Named Pipe Patterns
                      metadata:
                        tags:
                        - attack.defense_evasion
                        - attack.privilege_escalation
                        - attack.t1055
                        description: Detects the creation of a named pipe with a pattern found in CobaltStrike malleable C2 profiles
                        status: stable
                        id: 29206f7e-21fd-448a-9723-5f3272f22eba
                        references:
                        - https://svch0st.medium.com/guide-to-named-pipes-and-hunting-for-cobalt-strike-pipes-dc46b2c5f575
                        - https://gist.github.com/MHaggis/6c600e524045a6d49c35291a21e10752
                        level: medium
                        author: Florian Roth, Christian Burkard
                        falsepositives:
                        - Chrome instances using the exact same pipe name "mojo.something"
                        logsource: LimaCharlie
                tests:
                    match:
                      # Test 1: CobaltStrike mojo pipe pattern
                      - - event:
                            EVENT:
                              EventData:
                                EventType: CreatePipe
                                Image: C:\Windows\system32\rundll32.exe
                                PipeName: \mojo.5688.8052.183894939787088877
                                ProcessGuid: "{a6385ccd-7fc6-6850-1702-000000001700}"
                                ProcessId: "1234"
                                RuleName: "-"
                                User: NT AUTHORITY\SYSTEM
                                UtcTime: "2025-06-17 18:00:00.000"
                              System:
                                Channel: Microsoft-Windows-Sysmon/Operational
                                Computer: testhost.domain.com
                                EventID: "17"
                                _event_id: "17"
                          routing:
                            event_type: WEL
                            hostname: testhost
                      # Test 2: CobaltStrike demoagent pipe
                      - - event:
                            EVENT:
                              EventData:
                                EventType: ConnectPipe
                                Image: C:\Windows\explorer.exe
                                PipeName: \demoagent_11
                                ProcessGuid: "{a6385ccd-7fc6-6850-1702-000000001700}"
                                ProcessId: "5678"
                                RuleName: "-"
                                User: DOMAIN\user
                                UtcTime: "2025-06-17 18:01:00.000"
                              System:
                                Channel: Microsoft-Windows-Sysmon/Operational
                                Computer: testhost.domain.com
                                EventID: "18"
                                _event_id: "18"
                          routing:
                            event_type: WEL
                            hostname: testhost
                      # Test 3: Regex pattern f4c3
                      - - event:
                            EVENT:
                              EventData:
                                EventType: CreatePipe
                                Image: C:\temp\malicious.exe
                                PipeName: \f4c3ab
                                ProcessGuid: "{a6385ccd-7fc6-6850-1702-000000001700}"
                                ProcessId: "9999"
                                RuleName: "-"
                                User: DOMAIN\user
                                UtcTime: "2025-06-17 18:02:00.000"
                              System:
                                Channel: Microsoft-Windows-Sysmon/Operational
                                Computer: testhost.domain.com
                                EventID: "17"
                                _event_id: "17"
                          routing:
                            event_type: WEL
                            hostname: testhost
                      # Test 4: Winsock2 CatalogChangeListener pattern
                      - - event:
                            EVENT:
                              EventData:
                                EventType: ConnectPipe
                                Image: C:\Windows\system32\svchost.exe
                                PipeName: \Winsock2\CatalogChangeListener-123-0,
                                ProcessGuid: "{a6385ccd-7fc6-6850-1702-000000001700}"
                                ProcessId: "1111"
                                RuleName: "-"
                                User: NT AUTHORITY\SYSTEM
                                UtcTime: "2025-06-17 18:03:00.000"
                              System:
                                Channel: Microsoft-Windows-Sysmon/Operational
                                Computer: testhost.domain.com
                                EventID: "18"
                                _event_id: "18"
                          routing:
                            event_type: WEL
                            hostname: testhost
                    non_match:
                      # Test 1: SearchIndexer.exe using legitimate pipe NOT in detection patterns
                      - - event:
                            EVENT:
                              EventData:
                                EventType: ConnectPipe
                                Image: C:\WINDOWS\system32\SearchIndexer.exe
                                PipeName: \SearchFilterHost
                                ProcessGuid: "{a6385ccd-7fc6-6850-1702-000000001700}"
                                ProcessId: "11816"
                                RuleName: "-"
                                User: NT AUTHORITY\SYSTEM
                                UtcTime: "2025-06-16 20:42:20.099"
                              System:
                                Channel: Microsoft-Windows-Sysmon/Operational
                                Computer: workstation01.example.com
                                EventID: "18"
                                _event_id: "18"
                          routing:
                            event_type: WEL
                            hostname: workstation01
                      # Test 2: Different event channel (not Sysmon)
                      - - event:
                            EVENT:
                              EventData:
                                PipeName: \mojo.5688.8052.183894939787088877
                              System:
                                Channel: Security
                                EventID: "18"
                                _event_id: "18"
                          routing:
                            event_type: WEL
                            hostname: testhost
                      # Test 3: Wrong event ID (not 17 or 18)
                      - - event:
                            EVENT:
                              EventData:
                                PipeName: \demoagent_11
                              System:
                                Channel: Microsoft-Windows-Sysmon/Operational
                                EventID: "1"
                                _event_id: "1"
                          routing:
                            event_type: WEL
                            hostname: testhost
                      # Test 4: Legitimate Windows pipe not in detection patterns
                      - - event:
                            EVENT:
                              EventData:
                                EventType: ConnectPipe
                                Image: C:\Windows\system32\lsass.exe
                                PipeName: \lsass
                                ProcessGuid: "{a6385ccd-7fc6-6850-1702-000000001700}"
                                ProcessId: "700"
                                RuleName: "-"
                                User: NT AUTHORITY\SYSTEM
                                UtcTime: "2025-06-17 18:05:00.000"
                              System:
                                Channel: Microsoft-Windows-Sysmon/Operational
                                Computer: testhost.domain.com
                                EventID: "18"
                                _event_id: "18"
                          routing:
                            event_type: WEL
                            hostname: testhost
                      # Test 5: Non-WEL event type
                      - - event:
                            PROCESS_ID: 1234
                            FILE_PATH: \Device\NamedPipe\mojo.test
                          routing:
                            event_type: NEW_NAMED_PIPE
                            hostname: testhost
            usr_mtd:
                enabled: true
                expiry: 0
                tags: []
                comment: "Detects the creation of a named pipe with a pattern found in CobaltStrike malleable C2 profiles"
```

---

#### What's Next

* [Detection and Response Examples](/docs/detection-and-response-examples)

Table of contents

+ [{{glossary.D&amp;R}} Rules Unit Tests](#{{glossary-d-amp-r}}-rules-unit-tests)

---

## User Access

# User Access
To control who has access to an Organization, and what they have access to, go to the "Users" section of the web application.

Adding users is done by email address and requires the user to already have a limacharlie.io account.

The first user of an organization is added with Owner permissions at creation time. Owner permissions give full access to everything.

New users added after the creation of an organization are added with Unset privileges, which means the user is only able to get the most basic information on the organization.

Therefore, the first step after adding a new user should always be to change their permissions by clicking the Edit icon beside their name.

Permissions can be controlled individually, or you can apply pre-set permission schemes by selecting it at the top of the dialog box, clicking Apply, and then clicking the Save button at the bottom.

User Permissions

We offer granular user permissions, allowing you to customize what roles and how much access users should have. For a full list of permissions, see [Reference: Permissions](/v2/docs/reference-permissions).

## Access on a per-organization basis

To add a user to an Organization, the new user needs to first create their own LimaCharlie account.

After the new user has created their LimaCharlie account, you can add them by inputting their email account to your Organization.

After adding the user, you have the ability to control what permissions they get in this tenant. To do so, click on their email and adjust their permissions in the modal that opens. (See information about user permissions above).

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/NewSS_1.png)

## Access via Organization Groups

Groups allow you to grant permissions to a set of users on a group of organizations. To get started, navigate to the upper right section of the web app and select groups.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/NewSS_2.png)

From there, create a new group or click to edit an existing one.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/NewSS_3.png)

The user who creates a group becomes a group owner. Group owners manage the group but do not have permissions themselves.

You can add multiple group owners.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/NewSS4.png)

In the **Users** section (left panel), you can add all existing users who should receive access to the organizations included in this group. Note that if you are a Group Owner and you want the permissions of this group to apply to yourself, you will need to add your email here as well.

Adding Accounts

Note that all accounts will need to be *existing* LimaCharlie users.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/NewSS_5.png)

Group owners are allowed to manage the group, but are not affected by the permissions. Members are affected by the permissions but cannot modify the group.

Under **Organizations** (left panel), select a list of organizations you have access to. Note that in order to add an organization to the group, you need to have the user.ctrl permission enabled for that organization.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/NewSS_6.png)

Last, select the permissions you want members of the group to have in the organizations included in this group.

Permissions granted through the group are applied on top of permissions granted at the organization level. The permissions are additive, and a group cannot be used to subtract permissions granted at the organization level.

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/NewSS_7.png)

To finish, click `Update Permissions` at the top right corner.

To review activity that has occurred in this group, click on **Activity Logs** (left panel).

![](https://cdn.document360.io/84ec2311-0e05-4c58-90b9-baa9c041d22b/Images/Documentation/image(343).png)

In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.

---

### Related articles

* [Access and Permissions](/docs/access-and-permissions)
* [Single Sign-On](/docs/single-sign-on)
* [Reference: Permissions](/docs/reference-permissions)
* [API Keys](/docs/api-keys)

---

#### What's Next

* [Single Sign-On](/docs/single-sign-on)

Table of contents

+ [Access on a per-organization basis](#access-on-a-per-organization-basis)
+ [Access via Organization Groups](#access-via-organization-groups)

Tags

* [platform](/docs/en/tags/platform)

---

## Using Custom Billing Plans

# Using Custom Billing Plans
* 1 Minute to read

## What's Next

* [Billing Options](/docs/billing-options)

---

## VDI & Virtual Machine Templates

# VDI & Virtual Machine Templates
The LimaCharlie Endpoint Agent can be installed in template-based environments whether they're VMs or VDIs.

The methodology is the same as described above, but you need to be careful to stage the Endpoint Agent install properly in your templates.

The most common mistake is to install the Sensor directly in the template, and then instantiate the rest of the infrastructure from this template. This will result in "cloned sensors", sensors running using the same Sensor ID on different hosts/VMs/Containers.

If these occur, a [sensor\_clone](/v2/docs/reference-platform-events#sensorclone) event will be generated as well as an error in your dashboard. If this happens you have two choices:

1. Fix the installation process and re-deploy.
2. Run a de-duplication process with a Detection & Response rule [like this](/v2/docs/detection-and-response-examples#deduplicate-cloned-sensors).

Preparing sensors to run properly from templates can be done by creating a special `hcp_vdi` (macOS and Linux) or `hcp_vdi.dat` (Windows) file in the relevant configuration directory:

* Windows: `%SYSTEMROOT%\system32\`
* macOS: `/usr/local/`
* Linux: usually `/etc/` but fundamentally the current working directory of the sensor execution.

The contents of the `hcp_vdi` file should be a string representation of the second-based epoch timestamp when you want the sensors to begin enrolling. For example if the current time is `1696876542`, setting a value of `1696882542` will mean the sensor will only attempt to enroll in 10 minutes in the future. This allows you to install the sensor without risking it enrolling right away before the base image is created.

A shortcut for creating this file is to invoke the LimaCharlie EDR binary (like `lc_sensor.exe`) with the `-t` option, which will create a `hcp_vdi.dat` file with a value +1 day. This is usually plenty of time to finish the creation of the base image, submit it to a VDI platform (which often boots up the image) etc. The next day, any machine generated from this base image will start enrolling.

Example `hcp_vdi.dat` file content:

```
1696882542
```

Note that if a sensor is already enrolled, the presence of the `hcp_vdi` file will be completely ignored.

Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.

Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.

In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.

Endpoint Detection & Response

---

## Related articles

* [Endpoint Agent Installation](/docs/endpoint-agent-installation)
* [Windows Agent Installation](/docs/windows-agent-installation)
* [Building a custom MSI installer for Windows](/docs/building-a-custom-msi-installer-for-windows)

---

### What's Next

* [Windows Agent Installation](/docs/windows-agent-installation)

Tags

* [endpoint agent](/docs/en/tags/endpoint%20agent)
* [sensors](/docs/en/tags/sensors)
* [windows](/docs/en/tags/windows)

---

## WEL Monitoring

# WEL Monitoring
* 1 Minute to read

## What's Next

* [SOAR / Automation](/docs/soar-automation)

Tags

* [use case](/docs/en/tags/use%20case)
* [WEL](/docs/en/tags/WEL)

---

