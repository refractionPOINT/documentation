---
name: output-configurator
description: Use this skill when users need help configuring outputs to route telemetry to SIEMs, data lakes, or other destinations.
---

# LimaCharlie Output Configurator

## Overview

This skill helps users configure LimaCharlie Outputs to route telemetry, detections, audit events, and other data to external systems like SIEMs, data lakes, notification platforms, and more.

Outputs enable organizations to:
- Forward security events to existing SIEM platforms (Splunk, Elastic, etc.)
- Archive data to cloud storage (S3, GCS, Azure Blob)
- Send alerts to collaboration tools (Slack, webhooks)
- Stream data to analytics platforms (BigQuery, data lakes)
- Integrate with orchestration tools (Tines, webhooks)

## When to Use This Skill

Activate this skill when users ask about:
- Configuring outputs to send data to external systems
- Setting up SIEM integrations (Splunk, Elastic, etc.)
- Routing data to cloud storage (S3, GCS, Azure)
- Forwarding detections to webhooks or Slack
- Filtering which events get sent to outputs
- Troubleshooting output configurations
- Understanding output billing and costs
- Managing output authentication and credentials
- Creating tailored output streams

## Quick Start: Most Common Setup

For users who want to get started quickly, the most common configuration is sending detections to Splunk:

```yaml
# Output Configuration
name: splunk-detections
stream: detection
destination: webhook

# Webhook Settings
dest_host: https://splunk.corp.com:8088/services/collector/raw
auth_header_name: Authorization
auth_header_value: Splunk <YOUR_HEC_TOKEN>
secret_key: my-hmac-secret
```

**Testing tip**: Start with the "audit" stream to verify configuration, then switch to your desired stream.

## Understanding Output Streams

LimaCharlie provides several data streams that can be routed to external destinations:

1. **Event Stream** - Real-time telemetry from sensors (EDR events, process creation, network connections, file operations, etc.)
2. **Detection Stream** - Alerts generated by Detection & Response (D&R) rules
3. **Audit Stream** - Platform management events (configuration changes, user actions, API calls)
4. **Deployment Stream** - Sensor lifecycle events (online/offline status, quota events, connection issues)
5. **Artifact Stream** - Files and artifacts collected from sensors
6. **Tailored Stream** - Custom-filtered events routed via D&R rule `output` actions

### Stream Selection Strategy

Choose the appropriate stream based on your use case:

- **Event Stream** - For comprehensive EDR telemetry; best for data lakes and long-term storage
- **Detection Stream** - For security alerts; ideal for SIEM integration and SOC workflows
- **Audit Stream** - For compliance and platform monitoring; useful for administrative oversight
- **Deployment Stream** - For sensor health monitoring; helps track deployment issues
- **Artifact Stream** - For collected files and memory dumps; useful for forensics storage
- **Tailored Stream** - For highly specific event types; best for custom workflows requiring precise filtering

## Common Output Destinations

### Splunk (Most Popular)

Send detections and events to Splunk via HTTP Event Collector (HEC).

**Configuration**:
```yaml
dest_host: https://splunk-host.com:8088/services/collector/raw
auth_header_name: Authorization
auth_header_value: Splunk <HEC_TOKEN>
```

**Setup Notes**:
- Configure HEC in Splunk with source type `_json`
- Use `/services/collector/raw` endpoint for raw JSON
- For Splunk Cloud: `https://<host>.splunkcloud.com:8088/services/collector/raw`

### Amazon S3

Archive events for long-term storage and compliance.

**Configuration**:
```yaml
bucket: my-security-bucket
key_id: AKIAIOSFODNN7EXAMPLE
secret_key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
region_name: us-east-1
is_compression: "true"
is_indexing: "true"
sec_per_file: 300
```

**IAM Requirements**:
- Create IAM user with S3 PutObject permission
- Create S3 bucket in desired region
- Apply bucket policy allowing the IAM user to write

**Cost Tip**: Enable compression (`is_compression: "true"`) to reduce costs by ~70%

### Elastic

Index events and detections in Elasticsearch.

**Configuration**:
```yaml
addresses: elastic-host-1.com,elastic-host-2.com
index: limacharlie
username: elastic_user
password: elastic_password
```

**Authentication Options**:
- Username/password authentication
- API key authentication (use `api_key` field instead of username/password)
- Cloud ID for Elastic Cloud deployments

### Slack

Send detections and audit events to Slack channels.

**Configuration**:
```yaml
slack_api_token: xoxb-your-bot-token
slack_channel: #security-alerts
```

**Setup Steps**:
1. Create Slack App at https://api.slack.com/apps
2. Add `chat:write` OAuth scope
3. Install app to workspace
4. Copy Bot User OAuth Token
5. Invite bot to target channel: `/invite @bot-name`

**Supported Streams**: Detection and Audit only

### Generic Webhook

Send events to any HTTP endpoint.

**Configuration**:
```yaml
dest_host: https://webhooks.corp.com/limacharlie
secret_key: shared-secret-for-hmac
auth_header_name: X-API-Key
auth_header_value: your-api-key
```

**Security**: HMAC signature included in `lc-signature` header for verification

**Bulk Option**: Use "Webhook Bulk" destination type for batched events (more efficient for high volume)

## Configuring Outputs: Step-by-Step

### 1. Access Outputs Configuration

Guide users to:
1. Log in to LimaCharlie web console (https://app.limacharlie.io)
2. Select their organization
3. Navigate to "Outputs" section in left sidebar
4. Click "Add Output" button

### 2. Select Stream Type

Help users choose the appropriate stream:
- **Events** - Full EDR telemetry (high volume)
- **Detections** - Security alerts only (low to medium volume)
- **Audit** - Platform changes (low volume)
- **Deployment** - Sensor status (low volume)
- **Artifact** - Collected files (low volume)

**For initial testing**, recommend using **Audit** stream to verify configuration.

### 3. Select Destination Type

Based on user requirements, recommend the appropriate destination type from the supported list. See REFERENCE.md for all 18+ destination types.

### 4. Configure Destination Parameters

Provide destination-specific guidance:

**For Cloud Storage (S3, GCS, Azure)**:
- Verify IAM/service account permissions
- Enable compression to reduce costs
- Set appropriate `sec_per_file` (300-600 seconds typical)
- Consider enabling indexing for searchability

**For SIEM Platforms (Splunk, Elastic)**:
- Verify authentication credentials
- Test network connectivity from LimaCharlie
- Configure appropriate index/destination
- Consider using bulk webhook for high volume

**For Webhooks**:
- Always set `secret_key` for HMAC verification
- Use HTTPS endpoints
- Implement exponential backoff on receiver
- Consider bulk webhooks for high volume

### 5. Configure Advanced Settings

**Filter by Tag**:
```yaml
tag: production
```
Only sends events from sensors with the specified tag.

**Filter by Event Type (Allow List)**:
```yaml
detection_categories:
  - NEW_PROCESS
  - NETWORK_CONNECTIONS
```

**Filter by Event Type (Deny List)**:
```yaml
disallowed_detection_categories:
  - DNS_REQUEST
  - FILE_GET_REP
```

**Exclude Routing Metadata** (reduces data volume):
```yaml
is_no_routing: true
```

**Flatten JSON** (for relational databases):
```yaml
flatten: true
```

### 6. Save and Test

After configuration:
1. Click "Save Output"
2. For testing, temporarily switch to "Audit" stream
3. Make a configuration change in LimaCharlie (edit the output or any setting)
4. Verify the audit event arrives at destination
5. Switch back to desired stream once confirmed working

## Testing Outputs

### Recommended Testing Strategy

1. **Start with Audit Stream**
   - Set new output to use "Audit" stream
   - Audit events are low-volume and easy to verify
   - Make any platform change to trigger audit event
   - Confirm event arrives at destination

2. **Check Platform Logs**
   - Navigate to "Platform Logs" > "Errors"
   - Look for entries with key `outputs/OUTPUT_NAME`
   - Review any error messages

3. **Verify Destination**
   - Check destination system for received data
   - Verify data format is correct
   - Confirm authentication is working

4. **Switch to Production Stream**
   - Once confirmed working, change to desired stream
   - Monitor for a few minutes to ensure continued operation

## Advanced Filtering with Tailored Streams

For highly specific filtering, use Detection & Response rules with the `output` action:

```yaml
detect:
  event: NEW_PROCESS
  op: contains
  path: event/FILE_PATH
  value: "/suspicious/"

respond:
  - action: output
    name: suspicious-processes-output
```

This forwards only matching events to an output named "suspicious-processes-output" via the "tailored" stream.

**Benefits**:
- Precise control over what gets sent
- Can apply complex detection logic
- Reduces output volume and costs
- Enables different destinations for different event types

## Cost Management

### Output Billing Model

LimaCharlie aims to bill outputs at cost according to published pricing (https://limacharlie.io/pricing).

**Exception - Free GCP Outputs**:
When using GCP-based outputs (GCS, Pub/Sub, BigQuery) with destinations in the same region as the LimaCharlie datacenter, outputs are NOT billed.

LimaCharlie datacenter regions:
- **USA**: `us-central1`
- **Canada**: `northamerica-northeast1`
- **Europe**: `europe-west4`
- **UK**: `europe-west2`
- **India**: `asia-south1`
- **Australia**: `australia-southeast1`

### Cost Optimization Strategies

1. **Use GCP Outputs When Possible**
   - Configure GCS, BigQuery, or Pub/Sub in matching region
   - Zero output costs for same-region transfers

2. **Filter Events Strategically**
   - Use event type filters to reduce volume
   - Apply tag filters to limit to relevant sensors
   - Use tailored streams with D&R rules for precision

3. **Enable Compression**
   - Set `is_compression: "true"` for S3/GCS outputs
   - Reduces data transfer and storage costs significantly

4. **Exclude Routing Metadata**
   - Set `is_no_routing: true` if metadata not needed
   - Routing labels can add significant overhead

5. **Batch When Possible**
   - Use bulk webhooks instead of individual webhooks
   - Set appropriate `sec_per_file` intervals
   - Reduces per-request overhead

6. **Right-size Streams**
   - Don't send full event stream if only detections needed
   - Consider multiple outputs for different purposes
   - Archive full events to cheap storage, send detections to SIEM

### Volume Estimation

Help users estimate output volume:

- **Event Stream**: 5-50 MB per endpoint per day (varies by activity)
- **Detection Stream**: 1-100 KB per endpoint per day (depends on detection rules)
- **Audit Stream**: 1-10 KB per organization per day
- **Deployment Stream**: 1-5 KB per endpoint per day

Factors affecting volume:
- Endpoint activity level
- Number of detection rules
- Event type filters applied
- Compression enabled/disabled

## Security Best Practices

1. **Use Secret Keys**: Always set `secret_key` for webhooks to enable HMAC verification
2. **Minimal Permissions**: Grant service accounts/IAM users only necessary permissions
3. **HTTPS Everywhere**: Use TLS/HTTPS endpoints whenever possible
4. **Rotate Credentials**: Regularly rotate API keys and service account keys
5. **Monitor Platform Logs**: Regularly check for output failures and errors

## Navigation & Additional Resources

- **REFERENCE.md** - Complete configuration syntax for all 18+ output destinations
- **EXAMPLES.md** - 5 complete configuration examples (Splunk, S3, BigQuery, Slack, Tailored)
- **TROUBLESHOOTING.md** - Detailed troubleshooting by issue type

### Documentation References

- Output Destinations: `/home/maxime/goProject/github.com/refractionPOINT/documentation/limacharlie/doc/Outputs/Output_Destinations/`
- Testing Outputs: `/home/maxime/goProject/github.com/refractionPOINT/documentation/limacharlie/doc/Outputs/testing-outputs.md`
- Output Billing: `/home/maxime/goProject/github.com/refractionPOINT/documentation/limacharlie/doc/Outputs/output-billing.md`
- Output Allowlisting: `/home/maxime/goProject/github.com/refractionPOINT/documentation/limacharlie/doc/Outputs/output-allowlisting.md`
- Response Actions (for tailored streams): `/home/maxime/goProject/github.com/refractionPOINT/documentation/limacharlie/doc/Detection_and_Response/Reference/response-actions.md`

### LimaCharlie Resources

- Web Console: https://app.limacharlie.io
- API Documentation: https://api.limacharlie.io
- Pricing: https://limacharlie.io/pricing
- Support: support@limacharlie.io
- Community Slack: https://slack.limacharlie.io

## Quick Reference: Common Parameters

### Filtering Options
- `tag: <tag-name>` - Filter by sensor tag
- `sensor: <sensor-id>` - Filter by specific sensor
- `detection_categories: [LIST]` - Allow specific event types
- `disallowed_detection_categories: [LIST]` - Deny specific event types

### Data Manipulation
- `flatten: true` - Convert nested JSON to flat structure
- `wrap_with_event_type: true` - Add event type prefix
- `is_no_routing: true` - Remove routing metadata
- `custom_transform: <template>` - Custom Go template transformation

### Storage Options
- `is_compression: "true"` - Enable compression (S3, GCS)
- `is_indexing: "true"` - Create manifest files (S3, GCS)
- `sec_per_file: 300` - Seconds per batch/file
- `dir: <path>` - Directory prefix for files

### Security Options
- `secret_key: <value>` - Shared secret for HMAC
- `auth_header_name: <name>` - Custom auth header name
- `auth_header_value: <value>` - Custom auth header value
- `is_tls: "true"` - Enable TLS
- `is_strict_tls: "true"` - Enforce certificate validation

### Management Options
- `delete_on_failure: true` - Auto-delete if output fails
- `is_no_header: true` - Omit syslog header (TCP mode)

## User Interaction Guidelines

When helping users configure outputs:

1. **Understand Requirements First**:
   - What system are they integrating with?
   - What data do they need (events, detections, both)?
   - What is their volume expectation?
   - Are there cost constraints?

2. **Recommend Appropriate Solution**:
   - Match destination type to their system
   - Suggest appropriate stream based on use case
   - Recommend cost optimizations when relevant
   - Warn about high-volume scenarios

3. **Guide Through Configuration**:
   - Provide step-by-step instructions
   - Include credential setup for destination system
   - Explain each configuration parameter
   - Recommend starting with audit stream for testing

4. **Help with Testing**:
   - Guide through testing process
   - Help interpret errors from Platform Logs
   - Suggest verification steps at destination
   - Assist with troubleshooting if issues arise (see TROUBLESHOOTING.md)

5. **Optimize and Refine**:
   - Suggest filters to reduce unnecessary data
   - Recommend compression and batching settings
   - Point out cost optimization opportunities
   - Help configure multiple outputs if needed

## Conclusion

This skill provides comprehensive guidance for configuring LimaCharlie outputs to integrate with external systems. Always prioritize understanding user requirements, recommend appropriate solutions, guide through configuration with security and cost optimization in mind, and provide thorough testing and troubleshooting support.

Remember: Start simple (test with audit stream), verify functionality, then scale to production streams with appropriate filtering and optimization.
