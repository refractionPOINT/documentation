{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"LimaCharlie Documentation","text":"<p>Welcome to the official documentation for LimaCharlie - the SecOps Cloud Platform.</p>"},{"location":"#what-is-limacharlie","title":"What is LimaCharlie?","text":"<p>LimaCharlie is the SecOps Cloud Platform delivering security operations for the modern era. The platform provides comprehensive enterprise protection that brings together critical cybersecurity capabilities and eliminates integration challenges and security gaps for more effective protection against today's threats.</p>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"<ul> <li> <p> Getting Started</p> <p>New to LimaCharlie? Start here to learn the basics and get up and running quickly.</p> <p> Quickstart Guide</p> </li> <li> <p> Detection &amp; Response</p> <p>Build custom detection logic with automated response actions to protect your infrastructure.</p> <p> Detection Rules</p> </li> <li> <p> Sensors &amp; Deployment</p> <p>Deploy sensors across Windows, Linux, macOS, Chrome, and configure log adapters.</p> <p> Sensor Documentation</p> </li> <li> <p> Data &amp; Queries</p> <p>Query your security data with LCQL, explore events, and investigate incidents.</p> <p> Query Console</p> </li> <li> <p> Integrations</p> <p>Connect outputs to SIEMs, enable extensions, and integrate with third-party tools.</p> <p> Browse Integrations</p> </li> <li> <p> Developer Guide</p> <p>Programmatic access via Go and Python SDKs for complete platform automation.</p> <p> SDKs &amp; APIs</p> </li> <li> <p> Administration</p> <p>Manage organizations, users, access control, and billing.</p> <p> Admin Guide</p> </li> <li> <p> Reference</p> <p>Technical reference for operators, commands, event schemas, and FAQ.</p> <p> Reference Docs</p> </li> </ul>"},{"location":"#platform-capabilities","title":"Platform Capabilities","text":"<ul> <li>Endpoint Detection &amp; Response (EDR): Deploy sensors across multiple platforms</li> <li>Detection &amp; Response Rules: Build custom detection logic with automated responses</li> <li>Real-time Telemetry: Centralized event streaming and data collection</li> <li>API Integrations: Connect with threat intelligence, SIEM, and security tools</li> <li>Extensions &amp; Add-ons: Expand capabilities with purpose-built integrations</li> <li>Cloud-native Architecture: Scalable, API-first platform for modern security operations</li> </ul>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li> Join our Community</li> <li> GitHub Repository</li> <li> LimaCharlie Platform</li> <li> Web Console</li> <li> Support</li> </ul>"},{"location":"1-getting-started/","title":"Getting Started","text":"<p>Get started with LimaCharlie.</p>"},{"location":"1-getting-started/#documentation","title":"Documentation","text":"<ul> <li>What is LimaCharlie? - Platform overview</li> <li>Quickstart - Get up and running quickly</li> <li>Core Concepts - Fundamental platform concepts</li> </ul>"},{"location":"1-getting-started/core-concepts/","title":"LimaCharlie Core Concepts","text":""},{"location":"1-getting-started/core-concepts/#sensors","title":"Sensors","text":""},{"location":"1-getting-started/core-concepts/#endpoint-agents","title":"Endpoint Agents","text":"<p>The LimaCharlie endpoint agent is a cross platform endpoint Sensor. It is a low-level, light-weight sensor which executes detection and response functionality in real-time.</p> <p>The sensor provides a wide range of advanced capability.</p> <ul> <li>Flight Data Recorder (FDR) type functionality like Processes, Network Connections, Domain Name requests etc.</li> <li>Host isolation, automated response rules, intelligent local caching of events for in-depth Incident Response (IR) as well as some forensic features like dumping memory.</li> </ul> <p>Sensors are designed to limit the potential for abuse resulting from unauthorized access to the LimaCharlie platform. This is achieved by limiting open-ended commands which might enable an attacker to covertly upload malicious software to your hosts. This means the LimaCharlie sensor is extremely powerful but also keeps its \"read-only\" qualities on your infrastructure. Of course, all access and interactions with the hosts are also logged for audit both within the cloud and tamper-proof forwarding to your own infrastructure.</p> <p>Full commands list is in the Endpoint Agent Commands section.</p>"},{"location":"1-getting-started/core-concepts/#adapters","title":"Adapters","text":"<p>The LimaCharlie Adapter allows for real-time ingestion of any structured data, such as logs or telemetry, into the LimaCharlie platform, treating it as a first-class data source. This enables users to apply detection and response rules or send data to other outputs. Adapters support formats like JSON, Syslog, and CEFL, and can be deployed on-premise or cloud-to-cloud, either with or without the EDR sensor. For known sources like cloud platforms or Windows Event Logs, built-in mappings simplify data ingestion. Text-based Adapters allow for custom mapping and automation of any structured text. Additionally, pre-defined Adapters offer guided setups for common data sources like AWS CloudTrail and GuardDuty, while specialized connectors like Office 365 and Slack are supported with detailed configuration guidance. Some cloud-to-cloud Adapters, such as AWS S3, delete data after ingestion, so dedicated buckets with proper permissions are recommended.</p>"},{"location":"1-getting-started/core-concepts/#installation-keys","title":"Installation Keys","text":"<p>Installation Keys are used to install a sensor. By specifying a key during installation the sensor can cryptographically be tied to your account.</p> <p>Get more details in the Installation Keys section.</p>"},{"location":"1-getting-started/core-concepts/#tags","title":"Tags","text":"<p>Sensors can have Tags associated with them. Tags are added during creation or dynamically through the UI, API or Detection &amp; Response Rules.</p> <p>Get more information in the Sensor tags section.</p>"},{"location":"1-getting-started/core-concepts/#detection-response-rules","title":"Detection &amp; Response Rules","text":"<p>The Detection &amp; Response Rules act as an automation engine. The Detection component is a rule that either matches an event or not. If the Detection component matches, the Response component of the rule is actioned. This can be used to automatically investigate, mitigate or apply Tags.</p> <p>Detailed explanation in the Detection &amp; Response section.</p>"},{"location":"1-getting-started/core-concepts/#insight","title":"Insight","text":"<p>Insight is our built-in data retention and search feature. It is included within our 2 sensor free tier as well.</p> <p>When you enable Insight, we configure everything for you so that you get access to one year of your data for visualization and searching.</p> <p>You don't have to use the built-in data retention; you can forward data directly to your infrastructure if preferred. However, it is generally much simpler and a better experience to use Insight. If you prefer not to use Insight, go through the next section (Outputs).</p>"},{"location":"1-getting-started/core-concepts/#outputs","title":"Outputs","text":"<p>If you are using Insight (data retention) this section is optional.</p> <p>LimaCharlie can relay the data somewhere for longer term storage and analysis. Where that data is sent depends on which Outputs are activated. You can have as many Output modules active as you want, so you can send it to multiple syslog destinations using the Syslog Output module and then send it to some cold storage over an Scp Output module.</p> <p>Output is also split between four categories:</p> <ul> <li>event</li> <li>detect</li> <li>audit</li> <li>deployment</li> </ul> <p>Selecting a Stream when creating an Output will select the relevant type of data to flow through it.</p> <p>More details and exact configuration possibilities in the Outputs section.</p>"},{"location":"1-getting-started/core-concepts/#limacharlie-data-structures","title":"LimaCharlie Data Structures","text":"<p>Understanding the core data structures in LimaCharlie is essential for working with Detection &amp; Response rules, LCQL queries, and outputs. All data in LimaCharlie flows through one of four primary structures.</p>"},{"location":"1-getting-started/core-concepts/#the-four-core-structures","title":"The Four Core Structures","text":""},{"location":"1-getting-started/core-concepts/#1-events-event-stream","title":"1. Events (<code>event</code> stream)","text":"<p>What: Real-time telemetry from sensors and adapters Structure: Two top-level objects - <code>routing</code> (metadata) and <code>event</code> (event-specific data) Examples: Process execution (NEW_PROCESS), DNS queries (DNS_REQUEST), network connections (NETWORK_CONNECTIONS), Windows Event Logs (WEL)</p> <p>Events are the foundation of LimaCharlie. They capture what's happening on your endpoints and in your infrastructure. Every event includes: - <code>routing</code> object: Consistent metadata like sensor ID, timestamp, hostname, platform - <code>event</code> object: Event-type-specific data like file paths, command lines, network addresses</p> <p>See complete Event Structure Reference</p>"},{"location":"1-getting-started/core-concepts/#2-detections-detect-stream","title":"2. Detections (<code>detect</code> stream)","text":"<p>What: Alerts generated when D&amp;R rules match events Structure: Includes original event's <code>routing</code>, the triggering <code>detect</code> (event data), plus detection metadata Key Fields: <code>cat</code> (detection name), <code>source</code>, <code>detect_id</code>, <code>priority</code>, <code>detect_mtd</code> (metadata), <code>detect_data</code> (extracted IOCs)</p> <p>When a D&amp;R rule matches an event, LimaCharlie creates a Detection. Detections inherit the event's routing information and add: - Detection metadata: rule name, author, priority, tags - Extracted data: Structured IOCs pulled from the event - Links: References to documentation or playbooks</p> <p>See complete Detection Structure Reference</p>"},{"location":"1-getting-started/core-concepts/#3-audit-audit-stream","title":"3. Audit (<code>audit</code> stream)","text":"<p>What: Platform management and operational events Structure: Flat object with <code>oid</code>, <code>ts</code> (timestamp), and audit-specific fields Examples: Configuration changes, user actions, API calls, sensor deployments</p> <p>Audit logs track what happens in your LimaCharlie organization: - Who performed actions (<code>ident</code> - identity) - What was affected (<code>entity</code> - object) - Action characteristics (<code>mtd</code> - metadata) - Error messages (<code>component</code>, <code>error</code>)</p>"},{"location":"1-getting-started/core-concepts/#4-deployment-events-deployment-stream","title":"4. Deployment Events (<code>deployment</code> stream)","text":"<p>What: Sensor deployment and lifecycle events Structure: Similar to events - <code>routing</code> and <code>event</code> objects Examples: Sensor installations, uninstallations, version updates</p>"},{"location":"1-getting-started/core-concepts/#why-these-structures-matter","title":"Why These Structures Matter","text":""},{"location":"1-getting-started/core-concepts/#for-dr-rules","title":"For D&amp;R Rules","text":"<p>D&amp;R rules operate on Events and produce Detections. Understanding the Event structure helps you: - Access the right fields with <code>event/</code> and <code>routing/</code> paths - Filter by event type, platform, or sensor - Correlate related events using <code>routing/this</code> and <code>routing/parent</code></p>"},{"location":"1-getting-started/core-concepts/#for-lcql-queries","title":"For LCQL Queries","text":"<p>LCQL can query all three primary streams (event, detect, audit). Knowing the structure helps you: - Select the right fields for investigation - Join data across streams - Filter efficiently using the correct field paths</p>"},{"location":"1-getting-started/core-concepts/#for-outputs","title":"For Outputs","text":"<p>Each output stream type has a different structure. Understanding this helps you: - Configure the right stream for your destination - Build parsers for external systems - Filter data before sending it</p>"},{"location":"1-getting-started/core-concepts/#data-flow-event-detection","title":"Data Flow: Event \u2192 Detection","text":"<p>This is the most common data transformation in LimaCharlie:</p> <pre><code>1. Sensor generates Event\n   {routing: {...}, event: {FILE_PATH: \"evil.exe\", ...}}\n\n2. D&amp;R rule matches Event\n   detect: {event: NEW_PROCESS, op: contains, path: event/FILE_PATH, value: \"evil\"}\n\n3. LimaCharlie creates Detection\n   {routing: {...},          # Inherited from Event\n    detect: {...},           # Copy of the Event data\n    cat: \"Suspicious File\",  # Detection metadata\n    detect_id: \"uuid...\",\n    priority: 5,\n    detect_data: {malicious_file: \"evil.exe\"}}\n</code></pre>"},{"location":"1-getting-started/core-concepts/#field-path-patterns","title":"Field Path Patterns","text":"<p>All LimaCharlie structures use consistent path patterns:</p> <ul> <li>Events: <code>event/FIELD_NAME</code> or <code>routing/FIELD_NAME</code></li> <li>Detections: <code>detect/FIELD_NAME</code> (for event data), <code>routing/FIELD_NAME</code>, or top-level like <code>cat</code>, <code>priority</code></li> <li>Audit: Direct field access like <code>ident</code>, <code>entity/type</code>, <code>mtd/action</code></li> </ul>"},{"location":"1-getting-started/core-concepts/#next-steps","title":"Next Steps","text":"<ul> <li>Writing D&amp;R Rules: Detection &amp; Response Documentation</li> <li>Querying Data: LCQL Examples</li> <li>Configuring Outputs: Output Stream Structures</li> <li>Event Schema Details: Event Schemas</li> </ul>"},{"location":"1-getting-started/core-concepts/#api-keys","title":"API Keys","text":"<p>The API keys are represented as UUIDs. They are linked to your specific organization and enable you to programmatically acquire authorization tokens that can be used on our REST API. See the API key section for more details.</p>"},{"location":"1-getting-started/core-concepts/#see-also","title":"See Also","text":"<ul> <li>Quickstart Guide</li> <li>Sensor Deployment</li> <li>Detection &amp; Response</li> <li>LCQL Queries</li> </ul>"},{"location":"1-getting-started/quickstart/","title":"Quickstart","text":"<p>LimaCharlie is infrastructure to connect sources of security data, automate activity based on what's being observed, and forward data to where you need it. There's no correct way to use it - every environment is different.</p> <p>That said, the majority of LimaCharlie users require basic endpoint detection and response (EDR) capabilities. This guide will cover:</p> <ol> <li>Creating a new Organization</li> <li>Deploying a Sensor to the Organization</li> <li>Adding Sigma rules to detect suspicious activity</li> <li>Forwarding detections to an external destination as an Output</li> </ol> <p>All of this can be done within our free tier, which offers full platform functionality for up to two (2) sensors. If you haven't already signed up for a free account, please do so at app.limacharlie.io.</p> <p>Let's get started!</p>"},{"location":"1-getting-started/quickstart/#creating-an-organization","title":"Creating an Organization","text":"<p>LimaCharlie organizations are isolated tenants in the cloud, conceptually equivalent to \"projects\". They can be configured to suit the needs of each deployment.</p> <p>After accepting the initial Terms of Service, you'll be offered a prompt to create an organization in a selected <code>Region</code> with a globally unique <code>Name</code>.</p> <p>Region Selection</p> <p>The region that you select for an organization is permanent. Please also consider regulatory requirements for you and/or your customers' data.</p> <p>Once the organization is created, you'll be forwarded to our initial dashboard and Sensor list, which will be empty and ready for the next step.</p>"},{"location":"1-getting-started/quickstart/#deploying-a-sensor","title":"Deploying a Sensor","text":"<p>From the Sensors page in your new organization, click <code>Add Sensor</code> to open the setup flow for new sensors. Generally speaking, Sensors are executables that install on hosts and connect them to the LimaCharlie cloud to send telemetry, receive commands, and other capabilities.</p> <p>Sensors Overview</p> <p>For a full overview of types of sensors and their capabilities, check out Sensors.</p> <p>The setup flow should make this process straightforward. For example's sake, let's say we're installing a sensor on a Windows 10 (64 bit) machine we have in front of us.</p> <ul> <li>Choose the Windows sensor type</li> <li>Create an Installation Key - this registers the executable to communicate securely with your organization</li> <li>Choose the <code>64 bit (.exe)</code> installer</li> <li>Follow the on-screen instructions to execute the installer properly</li> <li>See immediate feedback when the sensor registers successfully with the cloud</li> </ul> <p>Potential Issues</p> <p>Since sensors are executables that talk to the cloud, antivirus software and networking layers may interfere with installation. If you run into an issue, take a look at troubleshooting.</p> <p>With a Windows sensor connected to the cloud, you should gain a lot of visibility into the endpoint. If we view the new sensor inside the web application, we'll have access to views such as:</p> <ul> <li><code>Timeline</code>: the viewer for telemetry events being collected from the endpoint</li> <li><code>Processes</code>: the list of processes running on the endpoint, their level of network activity, and commands to manipulate processes (i.e. kill / pause / resume process, or view modules)</li> <li><code>File System</code>: an explorer for the endpoint's file system, right in the browser</li> <li><code>Console</code>: a safe shell-like environment for issuing commands</li> <li><code>Live Feed</code>: a running view of the live output of all the sensor's events</li> </ul> <p>With telemetry coming in from the cloud, let's add rules to detect potentially malicious activity.</p>"},{"location":"1-getting-started/quickstart/#adding-sigma-rules","title":"Adding Sigma Rules","text":"<p>Writing security rules and automations from scratch is a huge effort. To set an open, baseline standard of coverage, LimaCharlie maintains a <code>sigma</code> add-on which can be enabled for free, and is kept up to date with the openly maintained threat signatures.</p> <p>Enabling the Sigma add-on will automatically apply rules to your organization to match these threat signatures so we can begin to see Detections on incoming endpoint telemetry.</p> <p>Writing Detection and Response rules</p> <p>Writing your own rules is outside the scope of this guide, but we do encourage checking out Detection &amp; Response when you're finished.</p>"},{"location":"1-getting-started/quickstart/#output","title":"Output","text":"<p>Security data generated from sensors is yours to do with as you wish. For example's sake, let's say we want to forward detections to an Amazon S3 bucket for longer-lived storage of detections.</p> <p>From the Outputs page in your organization, click <code>Add Output</code> to open the setup flow for new outputs. Again, the setup flow should make this process straightforward.</p> <ul> <li>Choose the Detections stream</li> <li>Choose the Amazon S3 destination</li> <li>Configure the Output and ensure it connects securely to the correct bucket:</li> <li>Output Name</li> <li>Bucket Name</li> <li>Key ID</li> <li>Secret Key</li> <li>Region</li> <li>Optionally, you can view samples of the detection stream's data (assuming recent detections have occurred)</li> </ul> <p>With this output in place you can extend the life of your detections beyond the 1 year LimaCharlie retains them, and stage them for any tool that can pull from S3.</p>"},{"location":"1-getting-started/quickstart/#see-also","title":"See Also","text":"<ul> <li>Core Concepts</li> <li>Installation Keys</li> <li>Your First Detection Rule</li> </ul>"},{"location":"1-getting-started/what-is-limacharlie/","title":"What is LimaCharlie?","text":"<p>LimaCharlie is the SecOps Cloud Platform - delivering security operations for the modern era.</p> <p>LimaCharlie's SecOps Cloud Platform provides you with comprehensive enterprise protection that brings together critical cybersecurity capabilities and eliminates integration challenges and security gaps for more effective protection against today's threats.</p> <p>The SecOps Cloud Platform offers a unified platform where you can build customized solutions effortlessly. With open APIs, centralized telemetry, and automated detection and response mechanisms, it's time cybersecurity moves into the modern era.</p> <p>Simplifying procurement, deployment and integration of best-of-breed cybersecurity solutions, the SecOps Cloud Platform delivers complete protection tailored to each organization's specific needs, much in the same way IT Clouds have supported enterprises for years.</p> <p>Our documentation can walk you through setting up your own Organization, deploying Sensors, writing detection and response rules, or outputting your data to any destination of your choosing. To dive in immediately, see our Quickstart guide.</p> <p>Dig in, and build the security program you need and have always wanted.</p>"},{"location":"1-getting-started/what-is-limacharlie/#see-also","title":"See Also","text":"<ul> <li>Quickstart Guide</li> <li>Core Concepts</li> <li>Use Cases</li> </ul>"},{"location":"1-getting-started/tutorials/","title":"Tutorials","text":"<p>Step-by-step guides for LimaCharlie.</p> <p>Refer to the specific documentation sections for tutorials related to:</p> <ul> <li>Detection and Response</li> <li>Sensors</li> <li>Add-Ons</li> <li>Getting Started</li> </ul>"},{"location":"1-getting-started/use-cases/adversary-techniques/","title":"Uncovering Adversary Techniques","text":"<p>LimaCharlie's SecOps Cloud Platform provides a comprehensive approach to combating ransomware, focusing on early detection during the reconnaissance stage and rapid response in the event of a detonation. By gathering telemetry from a wide range of sources, enabling widespread deployment, and leveraging real-time response capabilities, LimaCharlie empowers organizations to effectively detect, stop, and mitigate ransomware attacks, minimizing damage and ensuring business continuity.</p>"},{"location":"1-getting-started/use-cases/adversary-techniques/#problems-with-uncovering-adversary-techniques","title":"Problems with uncovering adversary techniques","text":"<p>Ransomware attacks have become increasingly sophisticated and targeted, posing a significant threat to organizations of all sizes. The challenges in effectively combating ransomware include:</p> <ul> <li>Extended dwell time: Ransomware attacks often involve weeks or months of reconnaissance, during which malicious actors seek to identify optimal detonation points. Detecting and stopping the attack during this stage is crucial but challenging.</li> <li>Difficulty in correlating data: Malicious actors often move around and attempt to hide their presence, making it difficult to identify and correlate their activities across various systems and data sources.</li> <li>Rapid spread and damage: In the event of a successful ransomware detonation, the malware can spread rapidly, encrypting files and causing significant damage before security teams can respond.</li> </ul>"},{"location":"1-getting-started/use-cases/adversary-techniques/#limacharlies-solution","title":"LimaCharlie's solution","text":"<p>LimaCharlie's SecOps Cloud Platform offers a comprehensive approach to combating ransomware, focusing on early detection during the reconnaissance stage and rapid response in the event of a detonation:</p> <ul> <li>Comprehensive telemetry gathering: LimaCharlie gathers telemetry and external artifacts from a wide range of sources, including endpoints, networks, and cloud environments. By normalizing all data to JSON and processing it through the SecOps Cloud Platform's detection, automation, and response engine, LimaCharlie gains a global view of the organization's security posture, enabling it to identify suspicious activities and correlations that may indicate a ransomware attack in progress.</li> <li>Early detection through widespread deployment: LimaCharlie's ability to deploy everywhere allows it to detect intruders faster than the competition, often before malicious actors can lay an effective trap. By monitoring everything from one place and leveraging advanced detection logic, LimaCharlie can identify and stop ransomware attacks during the crucial reconnaissance stage.</li> <li>Real-time response with semi-persistent TLS connection: In the event of a ransomware detonation, LimaCharlie's real-time, semi-persistent TLS connection with endpoints enables an unparalleled response capability. If detection logic is in place to catch a ransomware event, response actions can be taken across the entire fleet in real-time. This allows security teams to instantly isolate affected machines from the network while maintaining command and control through LimaCharlie, minimizing further damage and data exfiltration.</li> <li>Advanced threat hunting and remediation: With LimaCharlie, analysts responding to a ransomware event have access to all affected machines and a full year's history of telemetry. This enables them to run remediation scripts on the endpoints, kill process trees, and hunt for any malicious presence. By leveraging advanced indicators, such as FILE_TYPE_ACCESSED events, security teams can detect ransomware detonation events before the malware proliferates, significantly reducing the impact of the attack.</li> </ul>"},{"location":"1-getting-started/use-cases/adversary-techniques/#whats-next","title":"What's Next","text":"<ul> <li>WEL Monitoring</li> </ul>"},{"location":"1-getting-started/use-cases/building-products/","title":"Building Products","text":"<p>The LimaCharlie SecOps Cloud Platform (SCP) is a unified platform for modern cybersecurity operations.</p> <p>The SCP delivers core cybersecurity capabilities and infrastructure via a public cloud model: on-demand, pay-per-use, and API-first. For the cybersecurity industry, this is a paradigm shift comparable to how the IT public cloud revolutionized IT.</p> <p>For cybersecurity startups and builders, the SecOps Cloud Platform offers a robust foundation to create valuable products and services. The SCP helps innovators get to market faster, build genuinely independent businesses, increase their probability of success, and scale successful offerings with ease.</p>"},{"location":"1-getting-started/use-cases/building-products/#3-ways-to-go-to-market-more-effectively","title":"3 ways to go to market more effectively","text":"<p>The SecOps Cloud Platform provides the tools and infrastructure needed to secure any given organization\u2014and is designed to be flexible and highly customizable. Because of this, the SCP enables many different types of solutions. Individual builders' use cases can vary significantly. Nevertheless, all startups and product developers using the platform will benefit from the following three recommendations:</p> <ul> <li>Focus on Your Core Value</li> <li>Reduce Up-front Costs</li> <li>Build to Scale</li> </ul>"},{"location":"1-getting-started/use-cases/building-products/#focus-on-your-core-value","title":"Focus on Your Core Value","text":"<p>The SecOps Cloud Platform delivers foundational, well-understood security technologies as capabilities: as open, cloud-native primitives instead of black-box tools. Here's how builders can use this fact to create better products and service offerings:</p> <p>Clarify your differentiators. In a crowded marketplace where buyers are already wary of tool sprawl, it's difficult to stand out\u2014and challenging to convince buyers to take on another vendor. To succeed, startups must demonstrate clear value and differentiate themselves. Determine what sets you apart, and where you can deliver the greatest value to customers. This is where your internal engineering resources should be focused.</p> <p>Offload infrastructure work. The SecOps Cloud Platform offers the kinds of mature cybersecurity capabilities that teams used to have to develop themselves or purchase as part of a product. This includes things like: Deploying endpoint capabilities via a multiplatform agent, alerting and correlating logs from any source, automating real-time analysis and response regardless of the environment, routing telemetry data to any destination, performing historical threat hunts, isolating endpoints from a network remotely, and many more.</p> <p>In short, cybersecurity builders no longer need to \"reinvent the wheel\" in order to get to market. Here again, the clear analogy is to the IT public cloud. Most software developers today wouldn't invest in physical servers or develop complex, in-house solutions to handle application deployment and scaling. They would simply leverage cloud-based services like AWS Lambda or Azure Functions and run their applications without ever worrying about the underlying infrastructure.</p> <p>Similarly, by using the infrastructure capabilities of the SCP, cybersecurity builders can spend their time and resources on their core value proposition\u2014thereby reducing maintenance and integration challenges, eliminating external dependencies, and avoiding the risk that comes from building on someone else's product.</p> <p>Work with SCP engineers to develop custom integrations. The SecOps Cloud Platform is a vendor-neutral provider of tooling and infrastructure for the cybersecurity industry. It is not a potential competitor.</p> <p>As you develop on the SCP, reach out to LimaCharlie engineers for support in creating customized integrations, advice on best practices for a configurations or deployments, or feature requests that you'd like to see in the development roadmap. The SCP's public cloud business model means that the platform succeeds when its users succeed, so someone will always be on hand to help.</p> <p>By building on a public cloud for cybersecurity, startups can focus on what they do best without having to develop and maintain DIY solutions\u2014and without putting their business in the hands of a traditional vendor.</p>"},{"location":"1-getting-started/use-cases/building-products/#reduce-up-front-costs","title":"Reduce up-front costs","text":"<p>The SecOps Cloud Platform has a transparent, pay-per-use pricing model and delivers all capabilities on demand. In addition, the platform offers a number of valuable free resources. This helps builders to cut costs and reduce initial investment in several ways:</p> <p>Conduct research and develop a prototype for free. The SCP gives all users access to a fully featured free tier that includes two sensors. There is thus zero up-front cost to begin researching the platform, testing your idea, or even developing a prototype. Start by seeing if the SCP is the right choice for your project. Then, save money on early-stage development work once you begin.</p> <p>Build without lock-in. The SCP's pricing model means you only pay for what you need, for as long as you use it. You don't have to deal with mandatory minimums, long-term contracts, complex licensing, or termination fees. This enables you to create on the platform secure in the knowledge that you are not committed to a given level of spending before your growth justifies it\u2014and that you aren't locked into your infrastructure provider.</p> <p>Use available SCP resources to save money. Building on the SCP also offers several direct and indirect ways to lower costs during development.</p> <p>The SecOps Cloud Platform is designed to be as user-friendly and easy to master as possible. In addition, the SCP is supported by extensive documentation, an active community forum of users, and a learning library full of tutorials and walkthroughs. This means developers will spend less time learning a new technology\u2014and more time building.</p> <p>In addition, you can make use of more direct forms of assistance. Users can reach out to SCP engineers at any time for help. Qualified builders can also apply for a $1000 platform credit through the platform's Cybersecurity Infrastructure Grant Program. Leverage these resources to reduce your development costs and ensure that your engineers are spending their time on tasks that add the most value.</p> <p>Meet compliance needs with free storage. All telemetry data brought into the SCP is stored for the cost of ingestion for one full year. If your project has data retention or compliance needs, leverage the SCP's default storage capability to help keep your data storage costs down.</p> <p>Take advantage of discounted pricing. If you've decided to build with the SCP for the foreseeable future\u2014or if your product or service has started to see significant uptake\u2014use discounted pricing options to save money as you grow. The SecOps Cloud Platform provides volume-based discounts to help you improve your savings as usage increases, as well as annual or multi-year discounts for those ready to commit to longer-term platform usage.</p> <p>The SCP gives cybersecurity builders many of the competitive advantages the IT public cloud offers to startups in other verticals\u2014and a high degree of direct assistance and support as well.</p>"},{"location":"1-getting-started/use-cases/building-products/#build-to-scale","title":"Build to scale","text":"<p>The SecOps Cloud Platform enables scalable cybersecurity operations. Here's how developers can benefit from building on such a platform:</p> <p>Future-proof your infrastructure. Cybersecurity startups often turn to open-source or custom-built infrastructure to save money and stay independent. But while this approach may work early on, its limitations become apparent over time. It's possible to build performant and successful cybersecurity projects on open-source or DIY technologies.</p> <p>However, many businesses that take this route experience difficulties when they grow. The complexity, integration challenges, and troubleshooting work that are manageable with a small user base can quickly become untenable at scale. Before basing a part of your project on a custom or open-source solution, consider the challenges you will encounter later on if you are successful. You may be better served by using the SCP for that aspect of your offering.</p> <p>Build on a scalable platform. The SecOps Cloud Platform is designed to help organizations scale their security operations. Basic assumptions of the platform include things like multitenancy, flexibility, open APIs, and rich automation capabilities. Builders should plan to scale from the outset\u2014leveraging the SCP's engineering-centric approach to support future growth by developing architectures, integrations, and workflows that will enable scaling without limits.</p> <p>Any successful cybersecurity business will encounter challenges as it attempts to increase its customer support or its development work. However, building on an engineering-centric platform enables startups to plan for the future from day one\u2014and makes growth easier and more trouble-free.</p> <p>Scale with your revenue. A major problem for early-stage cybersecurity startups is that they must spend money on fixed infrastructure costs without having enough users for that to be profitable. If funding runs out before a product\u2013market fit is found, the business fails.</p> <p>The SecOps Cloud Platform offers an alternative route. Leverage the SCP's pay-per-use pricing to scale your infrastructure spending with your revenue. Even if you start off with a small customer base, you won't be losing money on infrastructure costs. Conserve your resources and allocate your spending to development, marketing, and sales efforts instead.</p> <p>The SCP offers builders a firm foundation for success. It provides a platform that is built to scale\u2014and its pay-as-you-go pricing helps startups extend their runway and grow gradually and safely.</p>"},{"location":"1-getting-started/use-cases/chromeos-support/","title":"ChromeOS Support","text":"<p>Gain visibility in your Chrome fleet and enhance ChromeOS security to unify endpoint protection across your organization with LimaCharlie's comprehensive, centralized, and adaptable platform.</p>"},{"location":"1-getting-started/use-cases/chromeos-support/#chromeos-support-problems","title":"ChromeOS support problems","text":"<ul> <li>Growing in popularity: Chrome books are the fastest growing segment of personal computers and are being adopted by organizations and schools en masse. Despite this, there is very little security coverage (other than that which is conferred by the platform) and without LimaCharlie, visibility requires an SSL proxy.</li> <li>Visibility gap: Managing and monitoring ChromeOS devices within traditional security infrastructures is challenging due to compatibility limitations and lack of centralized visibility, especially in enterprise environments.</li> <li>Chromebook threats rising: ChromeOS vulnerabilities and zero-day exploits are victim to targeted attacks, demanding a robust and adaptable security solution.</li> </ul>"},{"location":"1-getting-started/use-cases/chromeos-support/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>Comprehensive endpoint protection: LimaCharlie's Chrome Sensor delivers endpoint detection and response (EDR) capabilities directly on Chromebooks and for ChromeOS, providing deep visibility into network activity, installed packages, and downloaded files.</li> <li>Centralized management and insights: Integrate ChromeOS devices seamlessly into your existing security ecosystem, gain centralized telemetry and threat detection across all endpoints, and simplify management through policies and rules.</li> <li>Advanced detection and threat hunting: Utilize LimaCharlie's advanced analytics and threat intelligence to proactively identify suspicious activities, hunt for hidden threats, and respond effectively to evolving cyber threats.</li> </ul> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p>"},{"location":"1-getting-started/use-cases/cloud-security/","title":"Cloud Security","text":"<p>The SecOps Cloud Platform simplifies the difficult task of securing cloud resources and managing complex cloud-based or hybrid infrastructure. LimaCharlie brings better visibility, robust interoperability, and better options for storing data to cloud and hybrid environments.</p>"},{"location":"1-getting-started/use-cases/cloud-security/#cloud-security-problems","title":"Cloud security problems","text":"<p>Organizations are increasingly embracing the benefits of cloud services and solutions. As your business infrastructure integrates with cloud resources securing your environment becomes more complex, leading to:</p> <ul> <li>Visibility challenges: Cloud environments suffer from a lack of visibility that makes it difficult to secure their complex infrastructure.</li> <li>Data volume challenges: Cloud environments can generate a high volume of logs forcing security teams to make trade-offs when it comes to data ingest cost and visibility.</li> <li>Multi-cloud challenges: Many organizations use multiple cloud platforms causing visibility challenges across platforms.</li> </ul>"},{"location":"1-getting-started/use-cases/cloud-security/#limacharlies-solution","title":"LimaCharlie's solution","text":"<p>LimaCharlie simplifies management of cloud and multi-cloud environments by unifying them on a single platform. In addition to making integrations easier and bringing scalability to security operations, the SecOps Cloud Platform offers:</p> <ul> <li>Centralized monitoring: The LimaCharlie SecOps Cloud Platform offers a unified view across cloud environments that gives users granular visibility into their operation and current state.</li> <li>Highly efficient storage: LimaCharlie's proprietary high performance storage reduces the complexity and cost associated with long term data retention. All data ingested and alerts generated include a full year of searchable data retention to meet regulatory compliance and security requirements.</li> <li>Platform-independence: LimaCharlie is platform-independent and can ingest log data from any cloud platform or SaaS application with log retention often cheaper than the cloud vendors themselves.</li> </ul>"},{"location":"1-getting-started/use-cases/cost-effective-siem/","title":"Cost Effective SIEM Alternative","text":"<p>LimaCharlie's SecOps Cloud Platform provides a cost-effective and flexible alternative or supplement to traditional Security Information and Event Management (SIEM) offering essential capabilities while addressing the challenges of high costs, vendor lock-in, and complexity. By leveraging LimaCharlie's interoperability, automation, and detection and response () capabilities, security teams can optimize their operations and maintain a robust posture without the high costs and limitations of legacy SIEM solutions.</p>"},{"location":"1-getting-started/use-cases/cost-effective-siem/#siem-problems","title":"SIEM problems","text":"<p>The capabilities of SIEM solutions are essential for managing logs, correlating events, monitoring and alerting, and storing telemetry data. However, traditional SIEMs often present several challenges for organizations:</p> <ul> <li>High costs: SIEMs are typically very expensive to implement and maintain, with costs escalating as data volumes grow and additional features are required.</li> <li>Vendor lock-in: Many SIEMs are proprietary, closed systems that make it difficult for organizations to switch providers or integrate with other security tools.</li> <li>Complexity: SIEMs can be complex to set up and manage, requiring specialized skills and resources that may strain already overburdened security teams.</li> </ul>"},{"location":"1-getting-started/use-cases/cost-effective-siem/#limacharlies-solution","title":"LimaCharlie's solution","text":"<p>LimaCharlie's SecOps Cloud Platform offers a cost-effective alternative to traditional SIEMs, providing essential capabilities while addressing the challenges of high costs, vendor lock-in, and complexity:</p> <ul> <li>Cost savings through flexible data management: LimaCharlie provides one year of free telemetry storage in a fully searchable format, reducing the need to store all data in expensive SIEMs. The platform's ability to classify, filter, and route telemetry data intelligently allows organizations to send only critical data to their SIEM, further reducing costs.</li> <li>Interoperability and customization: Built with interoperability in mind, LimaCharlie seamlessly integrates with a wide range of security tools and platforms, enabling organizations to create custom workflows and avoid vendor lock-in. The platform's open architecture and extensive API support make it easy to integrate with existing security infrastructure.</li> <li>Automation and ease of use: LimaCharlie's Detection, Automation, and Response Engine enables security teams to create sophisticated detection rulesets and automate response actions, reducing alert fatigue and simplifying security operations. The SecOps Cloud Platform's powerful query language (LCQL) makes it easy for security professionals to access and analyze telemetry data without the complexity of traditional SIEMs.</li> <li>Advanced capabilities: LimaCharlie offers advanced threat hunting and integration with third-party threat intelligence platforms, providing security teams with the context and insights they need to identify and respond to threats effectively.</li> </ul>"},{"location":"1-getting-started/use-cases/cti-capabilities/","title":"Build CTI Capabilities","text":"<p>Ready to ditch the data silos and blind spots? LimaCharlie empowers you with a centralized intelligence hub, seamless integrations, BinLib, your own private VirusTotal-like solution, and the unparalleled precision of YARA scanning. Gain a comprehensive understanding of the threat landscape, proactively hunt for hidden attackers, and build a resilient security posture that leaves no stone unturned in the fight against malware**.**</p>"},{"location":"1-getting-started/use-cases/cti-capabilities/#cyber-threat-intelligence-cti-gathering-problems","title":"Cyber threat intelligence (CTI) gathering problems","text":"<ul> <li>Fragmented and siloed data: Security teams often struggle to gain a holistic understanding of threats due to siloed data from disparate security tools and sensors. This fragmented intelligence hinders effective threat detection, investigation, and response.</li> <li>Manual correlation: Manually correlating data points from diverse sources is time-consuming and error-prone, making it difficult to identify emerging threats and uncover hidden connections.</li> <li>Visibility gaps: Unknown malware and suspicious binaries often fly under the radar of traditional antivirus solutions, leaving organizations vulnerable to zero-day attacks and advanced threats.</li> </ul>"},{"location":"1-getting-started/use-cases/cti-capabilities/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>Data consolidation: Aggregate telemetry from all your security tools, endpoints, and network sources into a single platform. LimaCharlie's comprehensive data ingestion capabilities break down data silos and unify your threat intelligence landscape.</li> <li>Seamless integrations: Leverage LimaCharlie's robust API integrations to seamlessly connect with external threat feeds, threat intelligence platforms, and security tools. Enrich your internal data with external insights for a broader view of the threat landscape.</li> <li>Private binary library: Analyze unknown binaries and suspicious files with LimaCharlie's built-in Binary Library. This private VirusTotal-like environment leverages community and internal threat intelligence to rapidly identify malware, even zero-day variants, and assess associated risks.</li> <li>Utilize YARA rules: Conduct enterprise-wide malware scanning with LimaCharlie's integrated YARA engine. Utilize your own or community-developed YARA rules to detect specific malware families, variants, and even customized threats tailored to your environment, leaving no malicious code undetected.</li> </ul>"},{"location":"1-getting-started/use-cases/devops-security/","title":"Security Monitoring for DevOps","text":"<p>Ditch the data silos and sluggish response \u2013 LimaCharlie illuminates your DevOps pipeline, automates threat detection and response, and fosters real-time collaboration, empowering you to build secure and resilient software at record speed.</p>"},{"location":"1-getting-started/use-cases/devops-security/#problems-monitoring-devops-security","title":"Problems monitoring DevOps security","text":"<ul> <li>Blind Spots in the Pipeline: Siloed DevOps data from code repositories, third-party tools, and SaaS platforms leaves security teams in the dark, unable to detect threats hidden within routine operations.</li> <li>Reactive Response, Slowed Agility: Manual security checks and sluggish incident response hinder DevOps agility, creating vulnerable gaps between development and deployment.</li> <li>DevSecOps Disconnect: Disparate tools and fragmented communication between security and operations teams lead to inefficient incident response and missed opportunities for proactive mitigation.</li> </ul>"},{"location":"1-getting-started/use-cases/devops-security/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>Unified Visibility Across the Flow: LimaCharlie's architecture effortlessly ingests telemetry from all your DevOps data sources, providing a unified view of your entire pipeline from code commits to production deployments.</li> <li>Automated Threat Detection and Response: Leverage LimaCharlie's pre-built and custom detection rules to automatically identify suspicious activities within your DevOps data. Trigger instant alerts and pre-defined response actions, including stopping deployments, rolling back changes, or notifying teams.</li> <li>Centralized Collaboration for Faster Response: Break down silos with LimaCharlie's collaborative platform. Security and operations teams can visualize incidents across the pipeline, analyze threats jointly, and orchestrate coordinated responses in real-time.</li> </ul>"},{"location":"1-getting-started/use-cases/devops-security/#whats-next","title":"What's Next","text":"<ul> <li>Table Top Exercises</li> </ul>"},{"location":"1-getting-started/use-cases/edr/","title":"Endpoint Detection and Response (EDR)","text":"<p>The SecOps Cloud Platform, revolutionizes endpoint security by providing true real-time visibility, versatile detection capabilities, integration with open-source and managed rulesets, and vendor-agnostic telemetry ingestion. By leveraging LimaCharlie's API-first approach, flexible billing model, and seamless integration with your existing security stack, security teams can effectively detect, investigate, and respond to threats while avoiding the limitations of traditional EDR solutions.</p>"},{"location":"1-getting-started/use-cases/edr/#edr-problems","title":"EDR problems","text":"<p>Endpoint Detection and Response (EDR) solutions are crucial for organizations to detect, investigate, and respond to threats on endpoints. However, traditional EDR solutions often present several challenges:</p> <ul> <li>Lack of real-time visibility: Many EDR solutions rely on periodic scans or delayed data collection, making it difficult to detect and respond to threats in real-time.</li> <li>Limited customization and flexibility: Traditional EDRs often use proprietary detection languages or rulesets, limiting the ability of security teams to create custom detections tailored to their unique environments.</li> <li>Vendor lock-in and high costs: Legacy EDR solutions often require long-term contracts, have high minimum commitments, and can be expensive to scale, leading to vendor lock-in and budget constraints.</li> </ul>"},{"location":"1-getting-started/use-cases/edr/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>True real-time EDR: LimaCharlie provides true real-time visibility by streaming verbose telemetry from the endpoint sensor to the cloud over a semi-persistent TLS connection. This enables response actions to be taken on the endpoint within 100ms of the triggering action or behavior, drastically reducing the time to detect and respond to threats.</li> <li>Versatile detection syntax: LimaCharlie uses a YAML-based detection syntax that allows security teams to create highly sophisticated detections, including the ability to track state and build multi-step detection logic. This versatile syntax empowers security teams to create custom detections tailored to their specific needs and environment.</li> <li>Integration with open-source and managed rulesets: Leverage detections created by best-in-class security professionals using managed and open-source rulesets. With one-click access to sources like SOC Prime, Soteria, Sigma, and YARA, teams can gain unparalleled cost efficiencies and stay ahead of emerging threats.</li> <li>Reduced mean time to respond (MTTR): LimaCharlie allows security teams to execute a full suite of remediation responses, such as triggering memory dumps or killing process trees. By simplifying the process of activating rulesets and building custom rules, LimaCharlie significantly reduces MTTR.</li> <li>Vendor-agnostic telemetry ingestion: Ingest data from any source, including existing EDR solutions, in real-time. This allows security teams to avoid vendor lock-in and leverage the SCP's powerful Detection, Automation, and Response Engine on all of their telemetry, regardless of the source.</li> </ul>"},{"location":"1-getting-started/use-cases/enterprises/","title":"Enterprise SOC","text":"<p>The LimaCharlie SecOps Cloud Platform (SCP) is a unified platform for modern cybersecurity operations.</p> <p>The SCP delivers core cybersecurity capabilities and infrastructure via a public cloud model: on-demand, pay-per-use, and API-first. For the cybersecurity industry, this is a paradigm shift comparable to how the IT public cloud revolutionized IT.</p> <p>For enterprises and other large organizations, the SecOps Cloud Platform is a powerful way to take control of security posture and scale operations. The SCP can help teams gain visibility into their environments, eliminate coverage gaps, solve integration challenges, reduce spending on high-cost tools, free themselves from vendor lock-in, and build custom security solutions to meet their organization's unique needs.</p>"},{"location":"1-getting-started/use-cases/enterprises/#3-implementation-plans-for-immediate-value","title":"3 implementation plans for immediate value","text":"<p>The SecOps Cloud Platform is a comprehensive platform for cybersecurity operations\u2014but it doesn't have to be implemented all at once. The SCP's public cloud-like delivery model eliminates adoption hurdles for enterprises. Easily scaled and API-first, the SCP enables teams to integrate the platform into their security operations gradually, leveraging its capabilities progressively as they go. Here are three recommended first steps to help enterprises realize value from the SCP quickly.</p>"},{"location":"1-getting-started/use-cases/enterprises/#1-centralize-telemetry-data-to-improve-visibility-and-streamline-operations","title":"1. Centralize telemetry data to improve visibility and streamline operations","text":"<p>The SecOps Cloud Platform allows enterprises to bring all of their telemetry data into one place\u2014improving visibility, eliminating coverage gaps, and enabling streamlined SecOps workflows. Here is a general outline of what that looks like:</p> <p>Bring your telemetry data into the SCP. The SecOps Cloud Platform allows enterprise teams to ingest data from any source. The platform's endpoint detection and response (EDR)-type sensors can be deployed directly on Windows, Mac, and Linux endpoints with full feature parity across these OSes. These sensors allow security teams to capture system events and other telemetry data in real time\u2014or import event data from third-party EDR tools such as VMWare Carbon Black, CrowdStrike, SentinelOne, or Microsoft Defender. There are also browser-based EDR sensors to support Chrome and Edge deployments.</p> <p>Log-type data can also be brought into the SCP using a system of adapters or via webhook. Supported log data sources include O365, 1Password, AWS CloudTrail, Google Cloud Platform (GCP), Slack Audit logs, and many more. For a comprehensive list, refer to the SCP documentation.</p> <p>Visualize and manage your telemetry data under a single plane. Telemetry data brought into the SCP is normalized to a common JSON format and explorable through a single interface. The immediate advantage for security teams is improved visibility\u2014and an end to coverage gaps that can jeopardize organizational security and compliance. In addition, the ability to manipulate data through a single UI helps teams eliminate integration challenges caused by other solutions and streamline their internal workflows.</p> <p>Go beyond observability. The SecOps Cloud Platform's data-routing capabilities mean that it can be used as a simple observability point solution if you choose. But the SCP is capable of far more than this. All telemetry data brought into the platform can be run through an advanced detection and response engine, and wire-speed response actions can be taken on endpoints via the multiplatform SCP agent. From day one, security teams using the SCP for centralization and observability can also apply their own custom detection and response (D&amp;R) logic to all telemetry data brought into the platform, leverage curated rulesets like Sigma, Soteria, or SOC Prime rules for the same purpose, or run historical threat hunts against data stored in the SCP.</p> <p>The SecOps Cloud Platform helps enterprises improve visibility, eliminate coverage gaps, solve integration challenges, and make their workflows more efficient\u2014and this is just the first step in what teams can achieve with the platform.</p>"},{"location":"1-getting-started/use-cases/enterprises/#2-reduce-spending-on-siems-and-other-high-cost-solutions","title":"2. Reduce spending on SIEMs and other high-cost solutions","text":"<p>Because the SCP lets security teams bring in data from any source and export it to any destination, the platform can also be used as a pass-through to observe, transform, enrich, and anonymize data in-flight and route it to different destinations in a fine-grained way. This strategy can significantly reduce the costs of security information and event management (SIEM) tools and other expensive third-party solutions.</p> <p>Identify inefficiencies in your current data flow. Many organizations simply send 100% of their telemetry data to their SIEM. They only use a fraction of that data, but they pay for all of it. Conduct a thorough review of how you are currently routing your telemetry data. Determine what data truly needs to be sent to your highest-cost tools\u2014and what can be retained in lower-cost storage.</p> <p>Use the SCP's output controls to optimize your data routing. Your options here are highly flexible and customizable:</p> <p>Telemetry data can be sent to Splunk, Humio, Elastic, Amazon S3 buckets, Azure Event Hubs, Google Cloud Storage, and many other destinations.</p> <p>Data can also be streamed to your destination(s) of choice with different degrees of granularity. On the more verbose end of the spectrum, it is possible to send all data events from a sensor to a given destination. But you can also create a tailored stream that sends only specific events to your output destination.</p> <p>Enterprise teams can thus route their data for optimal cost savings. For example, a team might send only high-priority detections and failed 1Password login attempts to Splunk, a secondary tranche of log data and events to an Amazon S3 bucket, and retain everything else in low-cost cold storage.</p> <p>Use free storage and transparent pricing for compliance and additional savings. The SCP offers one year of free storage of all telemetry data for the cost of ingestion. Pricing is transparent and easy to calculate, making it simple to determine the most cost-effective data flow and storage sites for your telemetry. All telemetry data is retained for one year by default in a fully searchable and explorable format, so you don't have to worry about losing data that you may need later on. Because the total cost of storage in the SCP cloud is often far more affordable than traditional data lakes, many organizations will be able to use the platform's built-in storage to address compliance requirements and reduce costs.</p> <p>The SCP's data routing capabilities put enterprise teams in full control of their telemetry data, allowing them to cut spending on high-cost solutions while ensuring access to critical data in order to meet compliance and operational needs.</p>"},{"location":"1-getting-started/use-cases/enterprises/#3-simplify-tooling-and-control-your-infrastructure","title":"3. Simplify tooling and control your infrastructure","text":"<p>The SecOps Cloud Platform delivers the core components required to secure and monitor any organization. Over time, enterprises can leverage the SCP's numerous capabilities to develop a custom security infrastructure that they control completely. And while that is clearly a long-term project, enterprises that adopt the SCP can begin using the platform to simplify their stack right away:</p> <p>Replace one-off solutions. The increasing specialization of cybersecurity products means most enterprise teams rely on a patchwork of solutions\u2014and are sometimes forced to buy a tool to satisfy one, extremely narrow use case. Teams should begin by identifying their one-off tools and vendors and determining how they can be replaced with an SCP solution. The SecOps Cloud Platform offers a rich ecosystem of 100+ cybersecurity capabilities and integrations and a marketplace of add-ons to extend the platform. In many cases, teams will find that it is possible to replace single-use vendors with an SCP solution that offers equal or better performance, reducing tool sprawl and improving security operations at the same time.</p> <p>Upgrade existing tools or features. The fragmentation of the current cybersecurity vendor space means that many enterprise teams end up using tools that excel in one arena but fall short in others. Instead of simply accepting the unsatisfactory parts of their stack, teams can use the SCP to augment or replace underperforming tools and features with best-in-breed alternatives.</p> <p>Begin your transition to infrastructure independence. After teams shed one-off and redundant tools, they should begin to think strategically about how to leverage the SCP to free themselves from vendor lock-in once and for all. Look for vendor contracts due to expire or products nearing end-of-life and work with LimaCharlie engineers to develop, validate, and deploy a custom replacement ahead of time.</p> <p>In the near term, the SecOps Cloud Platform lets enterprises simplify their deployments significantly. In the long term, it allows organizations to take full control of their tooling, infrastructure, and security posture.</p>"},{"location":"1-getting-started/use-cases/fim/","title":"File and Registry Integrity Monitoring (FIM) Deployments","text":"<p>Use the SecOps Cloud Platform to gain comprehensive visibility, control, and proactive protection for sensitive files and registry keys with LimaCharlie's robust FIM capabilities.</p>"},{"location":"1-getting-started/use-cases/fim/#fim-deployment-problems","title":"FIM deployment problems","text":"<ul> <li>Undetected unauthorized changes: Malicious actors often target sensitive files and registry keys to install malware, exfiltrate data, or disrupt operations, often evading traditional security measures.</li> <li>Challenges of manual monitoring: Manually tracking changes to critical files and registry entries across large environments is time-consuming, error-prone, and often reactive rather than proactive.</li> <li>Limited visibility into past events: Traditional FIM tools might lack comprehensive historical data storage, hindering investigations and threat hunting efforts.</li> <li>Fragmented solutions: File and registry integrity monitoring can be siloed in separate platforms or integrated with data loss prevention (DLP) tools, lacking the comprehensive visibility and detection capabilities of a unified security platform.</li> </ul>"},{"location":"1-getting-started/use-cases/fim/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>Unified Visibility and Response: Consolidate FIM with other endpoint detection and response (EDR) capabilities within LimaCharlie, eliminating the need for separate platforms and streamlining security operations.</li> <li>Continuous Monitoring and Alerting: LimaCharlie's FIM capability continuously monitors designated files and registry keys for any modifications, generating real-time alerts to security teams for immediate action.</li> <li>Granular Configuration and Rules: Define specific files, directories, and registry paths to monitor based on your unique security needs, ensuring focused protection for critical assets.</li> <li>Historical Data Storage and Analysis: LimaCharlie stores one year of historical FIM data, enabling in-depth investigations, threat hunting, and identification of potential attack patterns that might have been missed initially.</li> </ul>"},{"location":"1-getting-started/use-cases/incident-response/","title":"Incident Response","text":"<p>LimaCharlie provides incident response teams with a powerful, centralized solution that unifies threat visibility across diverse data sources, streamlines detection capabilities, enhances threat hunting and analysis, and enables instant deployment. IR teams can respond to incidents with unparalleled speed, accuracy, and effectiveness.</p>"},{"location":"1-getting-started/use-cases/incident-response/#incident-response-problems","title":"Incident response problems","text":"<ul> <li>Limited visibility and data correlation: Incident response teams often face incomplete or fragmented data from clients, hindering their ability to grasp the full extent of an incident and make informed analysis.</li> <li>Time-consuming manual analysis: Manually sifting through large volumes of logs, alerts, and endpoint data can be time-consuming and prone to human error, delaying incident response and remediation.</li> <li>Lack of centralized threat hunting capabilities: Traditional IR toolkits often lack advanced analytics and threat hunting features, making it challenging to proactively uncover hidden threats or investigate complex attack patterns.</li> <li>Slow infrastructure deployment: Setting up traditional incident response infrastructure can take hours or even days, leaving critical time gaps where attackers have the upper hand.</li> </ul>"},{"location":"1-getting-started/use-cases/incident-response/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>Unified Threat Visibility: LimaCharlie aggregates data from diverse sources (endpoints, networks, cloud environments, security tools), providing incident response teams with centralized visibility and context for swift analysis.</li> <li>Streamlined Detection Capabilities: The platform's powerful detection and response capabilities allow IR teams to quickly pinpoint relevant data, identify patterns, and correlate events across multiple impacted systems.</li> <li>Enhanced Threat Hunting and Analysis: LimaCharlie's advanced analytics and threat intelligence feeds enable IR teams to proactively hunt for hidden threats, investigate attack chains, and attribute attacks with greater confidence.</li> <li>Instant Deployment: Launch LimaCharlie in seconds, not hours, gaining immediate visibility and control over the compromised environment to outpace attacker timelines and minimize damage.</li> </ul>"},{"location":"1-getting-started/use-cases/incident-response/#related-resources","title":"Related Resources","text":"<ul> <li>Investigation Guide - Best practices for documenting investigations with MITRE ATT&amp;CK mapping and standardized tagging</li> </ul>"},{"location":"1-getting-started/use-cases/investigation-guide/","title":"Investigation Guide","text":"<p>This guide provides opinionated best practices for SOC analysts using LimaCharlie Investigations to document and encode security investigations. By following these conventions, you enable attack chain visualization, cross-investigation analysis, and consistent reporting.</p>"},{"location":"1-getting-started/use-cases/investigation-guide/#tag-format-specification","title":"Tag Format Specification","text":"<p>Use colon-separated tags to categorize events, detections, and entities within your timeline. This section defines the format patterns - actual values are either format-based (you define them) or fetched dynamically from authoritative sources.</p>"},{"location":"1-getting-started/use-cases/investigation-guide/#mitre-attck-tags-dynamic","title":"MITRE ATT&amp;CK Tags (Dynamic)","text":"<p>MITRE ATT&amp;CK tags should be validated against the authoritative MITRE STIX data rather than hardcoded lists.</p> <p>Authoritative Source: https://github.com/mitre-attack/attack-stix-data</p> <p>Tag Formats:</p> Format Description Example <code>phase:{tactic-name}</code> Attack phase aligned with MITRE tactic <code>phase:initial-access</code> <code>mitre:{technique-id}</code> Specific MITRE ATT&amp;CK technique <code>mitre:T1566</code> <p>Fetching Valid Values at Runtime:</p> <pre><code>URL: https://raw.githubusercontent.com/mitre-attack/attack-stix-data/master/enterprise-attack/enterprise-attack.json\n\nParsing:\n1. Tactics: Filter objects where type=\"x-mitre-tactic\"\n   - Use x_mitre_shortname for phase tag values\n\n2. Techniques: Filter objects where type=\"attack-pattern\"\n   - Extract external_references[] where source_name=\"mitre-attack\"\n   - Use external_id for mitre: tag values (e.g., T1566)\n</code></pre>"},{"location":"1-getting-started/use-cases/investigation-guide/#operational-tags-format-based","title":"Operational Tags (Format-Based)","text":"<p>These tags follow a consistent format pattern. You define the values based on your investigation context.</p> Category Format Description Examples Timing <code>timing:{marker}</code> Investigation timing markers <code>timing:first-observed</code>, <code>timing:pivot-point</code>, <code>timing:detection-trigger</code> Confidence <code>confidence:{level}</code> Analyst confidence in findings <code>confidence:high</code>, <code>confidence:medium</code>, <code>confidence:low</code> Actor <code>actor:{identifier}</code> Threat actor attribution <code>actor:apt-29</code>, <code>actor:ransomware-lockbit</code>, <code>actor:nation-state</code> Tool <code>tool:{name}</code> Identified attack tools <code>tool:cobalt-strike</code>, <code>tool:mimikatz</code>, <code>tool:psexec</code> Impact <code>impact:{type}</code> Observed or potential impact <code>impact:data-exfiltration</code>, <code>impact:ransomware</code>, <code>impact:credential-compromise</code> Scope <code>scope:{extent}</code> Attack scope <code>scope:single-host</code>, <code>scope:subnet</code>, <code>scope:domain-wide</code> Root Cause <code>root-cause:{cause}</code> Initial access method <code>root-cause:phishing</code>, <code>root-cause:vuln-exploit</code>, <code>root-cause:credential-reuse</code> Defense Gap <code>gap:{deficiency}</code> Security control failures <code>gap:no-mfa</code>, <code>gap:missing-detection</code>, <code>gap:no-segmentation</code> Asset <code>asset:{classification}</code> Business asset classification <code>asset:crown-jewels</code>, <code>asset:pci-scope</code>, <code>asset:external-facing</code> Customer <code>customer:{name}</code> MSSP customer identifier <code>customer:acme-corp</code>"},{"location":"1-getting-started/use-cases/investigation-guide/#attack-chain-visualization","title":"Attack Chain Visualization","text":"<p>Use <code>phase:</code> tags chronologically to visualize attack progression through MITRE ATT&amp;CK tactics:</p> <pre><code>[phase:initial-access] \u2192 [phase:execution] \u2192 [phase:persistence] \u2192 [phase:credential-access] \u2192 [phase:lateral-movement] \u2192 [phase:exfiltration]\n</code></pre>"},{"location":"1-getting-started/use-cases/investigation-guide/#timing-markers","title":"Timing Markers","text":"<p>Apply timing tags to key events:</p> Tag When to Apply <code>timing:first-observed</code> Earliest confirmed malicious activity <code>timing:pivot-point</code> Critical decision points in the attack chain <code>timing:detection-trigger</code> Event/detection that initiated the investigation"},{"location":"1-getting-started/use-cases/investigation-guide/#example-attack-chain-tags","title":"Example: Attack Chain Tags","text":"<pre><code>{\n  \"events\": [\n    {\n      \"atom\": \"evt-001\",\n      \"tags\": [\"phase:initial-access\", \"mitre:T1566\", \"timing:first-observed\"],\n      \"relevance\": \"User opened phishing attachment\"\n    },\n    {\n      \"atom\": \"evt-002\",\n      \"tags\": [\"phase:execution\", \"mitre:T1059\", \"timing:pivot-point\"],\n      \"relevance\": \"Encoded PowerShell executed from macro\"\n    },\n    {\n      \"atom\": \"evt-003\",\n      \"tags\": [\"phase:credential-access\", \"mitre:T1003\", \"tool:mimikatz\"],\n      \"relevance\": \"LSASS memory access detected\"\n    }\n  ]\n}\n</code></pre>"},{"location":"1-getting-started/use-cases/investigation-guide/#entity-enrichment-best-practices","title":"Entity Enrichment Best Practices","text":""},{"location":"1-getting-started/use-cases/investigation-guide/#ioc-provenance","title":"IOC Provenance","text":"<p>Document how entities were discovered and validated in the <code>context</code> field:</p> <p>Pattern: <code>Provenance: [how discovered]. Validation: [how confirmed]. Attribution: [threat intel correlation].</code></p> <p>Example: <pre><code>{\n  \"type\": \"ip\",\n  \"value\": \"203.0.113.50\",\n  \"context\": \"Provenance: Extracted from C2 beacon traffic. Validation: Cross-referenced with TI feed (58/72 VirusTotal). Attribution: Matches APT29 infrastructure per CISA AA24-001.\",\n  \"verdict\": \"malicious\"\n}\n</code></pre></p>"},{"location":"1-getting-started/use-cases/investigation-guide/#verdict-assignment","title":"Verdict Assignment","text":"Verdict Criteria <code>malicious</code> Confirmed IOC match, known-bad behavior, validated threat <code>suspicious</code> Anomalous but not definitively malicious, requires review <code>benign</code> Cleared by investigation, legitimate activity <code>unknown</code> Insufficient context, further analysis needed"},{"location":"1-getting-started/use-cases/investigation-guide/#entity-context-templates","title":"Entity Context Templates","text":"<p>For IPs: <pre><code>Provenance: [discovered in which event type]. Geo: [country/ASN]. TI: [threat intel match]. Historical: [seen before in org?].\n</code></pre></p> <p>For Hashes: <pre><code>Provenance: [file name and path]. AV: [detection ratio]. Sandbox: [behavior summary]. First seen: [date].\n</code></pre></p> <p>For Domains: <pre><code>Provenance: [DNS query or URL]. Registration: [age, registrar]. TI: [threat intel match]. Resolution: [IP addresses].\n</code></pre></p>"},{"location":"1-getting-started/use-cases/investigation-guide/#note-taking-templates","title":"Note-Taking Templates","text":"<p>Use structured note types for consistent documentation:</p>"},{"location":"1-getting-started/use-cases/investigation-guide/#observation-notes","title":"Observation Notes","text":"<p>Record raw facts without interpretation: <pre><code>[TIMESTAMP] [HOST] [EVENT_TYPE]\nObserved: [description of what was seen]\nKey data: [relevant field values]\nRelated atoms: [list of event atoms]\n</code></pre></p>"},{"location":"1-getting-started/use-cases/investigation-guide/#hypothesis-notes","title":"Hypothesis Notes","text":"<p>Document working theories: <pre><code>HYPOTHESIS: [statement]\n\nSupporting evidence:\n- [evidence 1]\n- [evidence 2]\n\nTests to validate:\n1. [query or action to confirm/refute]\n2. [additional validation step]\n\nAlternative explanations:\n- [alternative 1]\n</code></pre></p>"},{"location":"1-getting-started/use-cases/investigation-guide/#finding-notes","title":"Finding Notes","text":"<p>Document confirmed discoveries: <pre><code>FINDING: [definitive statement]\n\nEvidence:\n- [primary evidence]\n- [corroborating evidence]\n\nImpact:\n- Affected systems: [list]\n- Data at risk: [description]\n\nConfidence: [high/medium/low]\n</code></pre></p>"},{"location":"1-getting-started/use-cases/investigation-guide/#attack-chain-summary-note","title":"Attack Chain Summary Note","text":"<p>Document the full attack narrative: <pre><code>ATTACK CHAIN:\n[Phase 1] \u2192 [Phase 2] \u2192 [Phase 3] \u2192 ...\n\nTechniques: [T1566] \u2192 [T1059] \u2192 [T1003] \u2192 ...\nDwell time: [hours/days from first access to detection]\n\nRoot cause: [initial access method]\nDefense gaps: [what failed]\n</code></pre></p>"},{"location":"1-getting-started/use-cases/investigation-guide/#investigation-workflow","title":"Investigation Workflow","text":""},{"location":"1-getting-started/use-cases/investigation-guide/#status-transitions","title":"Status Transitions","text":"Status When to Use <code>new</code> Timeline just created, investigation not started <code>in_progress</code> Active investigation underway <code>pending_review</code> Analyst completed, awaiting peer review <code>escalated</code> Requires senior analyst or management attention <code>closed_false_positive</code> Confirmed benign, documented rationale <code>closed_true_positive</code> Confirmed incident, remediation complete"},{"location":"1-getting-started/use-cases/investigation-guide/#closure-criteria","title":"Closure Criteria","text":"<p>For <code>closed_false_positive</code>: - [ ] Benign explanation documented in conclusion - [ ] Finding note with FP rationale - [ ] Consider FP rule if pattern is common</p> <p>For <code>closed_true_positive</code>: - [ ] All action item notes resolved - [ ] Containment/eradication verified - [ ] Root cause identified - [ ] Summary field completed - [ ] Conclusion field completed - [ ] All entities have verdicts assigned</p>"},{"location":"1-getting-started/use-cases/investigation-guide/#summary-and-conclusion-fields","title":"Summary and Conclusion Fields","text":""},{"location":"1-getting-started/use-cases/investigation-guide/#summary-field-executive-audience","title":"Summary Field (Executive Audience)","text":"<p>Write for non-technical stakeholders: <pre><code>On [date], [attack type] was detected on [target]. The attacker [brief action summary].\nImpact: [what was affected]. Status: [current state]. Attribution: [if known].\n</code></pre></p> <p>Example: <pre><code>On November 15, 2024, a targeted spearphishing attack compromised a Finance department workstation.\nThe attacker harvested credentials and moved laterally to 15 servers, exfiltrating approximately 50GB\nof financial data over 72 hours. Containment was achieved by isolating affected systems.\nAttribution: Financially-motivated actor (medium confidence).\n</code></pre></p>"},{"location":"1-getting-started/use-cases/investigation-guide/#conclusion-field-technical-closure","title":"Conclusion Field (Technical Closure)","text":"<p>Document technical determination: <pre><code>CLASSIFICATION: [true positive/false positive] - [incident type]\nROOT CAUSE: [initial access method]\nATTRIBUTION: [threat actor/campaign] ([confidence level])\nIMPACT: [data affected], [systems affected]\nDWELL TIME: [duration from first access to detection]\nCONTAINMENT: [status and date]\n</code></pre></p>"},{"location":"1-getting-started/use-cases/investigation-guide/#example-complete-tagged-timeline","title":"Example: Complete Tagged Timeline","text":"<p>Note: MITRE technique IDs shown are illustrative. Validate against the authoritative STIX source.</p> <pre><code>{\n  \"name\": \"APT-Investigation-2024-001\",\n  \"description\": \"Investigation of targeted attack against Finance department\",\n  \"status\": \"closed_true_positive\",\n  \"priority\": \"critical\",\n  \"events\": [\n    {\n      \"atom\": \"evt-001\",\n      \"sid\": \"sensor-001\",\n      \"tags\": [\"phase:initial-access\", \"mitre:T1566\", \"timing:first-observed\", \"root-cause:phishing\"],\n      \"relevance\": \"User opened phishing attachment with malicious macro\",\n      \"verdict\": \"malicious\"\n    },\n    {\n      \"atom\": \"evt-002\",\n      \"sid\": \"sensor-001\",\n      \"tags\": [\"phase:execution\", \"mitre:T1059\", \"timing:pivot-point\"],\n      \"relevance\": \"Encoded PowerShell executed by Word macro\",\n      \"verdict\": \"malicious\"\n    },\n    {\n      \"atom\": \"evt-003\",\n      \"sid\": \"sensor-001\",\n      \"tags\": [\"phase:credential-access\", \"mitre:T1003\", \"tool:mimikatz\"],\n      \"relevance\": \"LSASS memory access - credential harvesting\",\n      \"verdict\": \"malicious\"\n    },\n    {\n      \"atom\": \"evt-004\",\n      \"sid\": \"sensor-002\",\n      \"tags\": [\"phase:lateral-movement\", \"mitre:T1021\", \"scope:domain-wide\"],\n      \"relevance\": \"RDP to domain controller with stolen credentials\",\n      \"verdict\": \"malicious\"\n    },\n    {\n      \"atom\": \"evt-005\",\n      \"sid\": \"sensor-003\",\n      \"tags\": [\"phase:exfiltration\", \"mitre:T1041\", \"impact:data-exfiltration\", \"timing:detection-trigger\"],\n      \"relevance\": \"Large HTTPS upload to external IP\",\n      \"verdict\": \"malicious\"\n    }\n  ],\n  \"entities\": [\n    {\n      \"type\": \"ip\",\n      \"value\": \"203.0.113.50\",\n      \"name\": \"C2 Server\",\n      \"context\": \"Provenance: Network connection from compromised host. TI: Matches APT29 infrastructure per CISA AA24-001.\",\n      \"verdict\": \"malicious\",\n      \"related_events\": [\"evt-005\"]\n    },\n    {\n      \"type\": \"hash\",\n      \"value\": \"d41d8cd98f00b204e9800998ecf8427e\",\n      \"context\": \"Provenance: Dropped by macro execution. AV: 52/72 detections. Sandbox: Downloads secondary payload.\",\n      \"verdict\": \"malicious\",\n      \"related_events\": [\"evt-002\"]\n    }\n  ],\n  \"notes\": [\n    {\n      \"type\": \"finding\",\n      \"content\": \"ATTACK CHAIN:\\nInitial Access (T1566) \u2192 Execution (T1059) \u2192 Credential Access (T1003) \u2192 Lateral Movement (T1021) \u2192 Exfiltration (T1041)\\n\\nDwell time: 48 hours from first access to detection.\"\n    },\n    {\n      \"type\": \"finding\",\n      \"content\": \"DEFENSE GAPS IDENTIFIED:\\n- gap:no-mfa on domain admin accounts\\n- gap:missing-detection for PowerShell script block logging\\n- gap:no-segmentation between workstations and servers\"\n    },\n    {\n      \"type\": \"action_item\",\n      \"content\": \"Rotate all domain admin credentials\",\n      \"resolved\": true\n    }\n  ],\n  \"summary\": \"Targeted spearphishing attack compromised Finance workstation. Attacker harvested domain admin credentials within 4 hours, moved laterally to file server, exfiltrated 50GB over 48 hours. Attributed to financially-motivated actor (medium confidence).\",\n  \"conclusion\": \"CLASSIFICATION: True positive - data breach\\nROOT CAUSE: Spearphishing with compromised vendor sender\\nATTRIBUTION: Financially-motivated (medium confidence)\\nIMPACT: 50GB data exfiltrated, 15 servers accessed\\nDWELL TIME: 48 hours\\nCONTAINMENT: Complete as of 2024-11-18\"\n}\n</code></pre>"},{"location":"1-getting-started/use-cases/investigation-guide/#cross-timeline-analysis","title":"Cross-Timeline Analysis","text":"<p>Consistent tagging enables searching across multiple investigations:</p> Search Goal Tag Pattern to Query All ransomware incidents <code>impact:ransomware</code> APT activity <code>actor:apt-*</code> Critical asset compromises <code>asset:crown-jewels</code> Open investigations <code>status:in_progress</code> Phishing-originated attacks <code>root-cause:phishing</code> MFA gaps <code>gap:no-mfa</code> Specific customer (MSSP) <code>customer:acme-corp</code>"},{"location":"1-getting-started/use-cases/investigation-guide/#related-documentation","title":"Related Documentation","text":"<ul> <li>Config Hive: Investigation - Investigation schema reference</li> </ul>"},{"location":"1-getting-started/use-cases/ma-due-diligence/","title":"M&amp;A Cyber Due Diligence","text":"<p>LimaCharlie makes merger and acquisition (M&amp;A) cyber due diligence cost-effective and easy to deploy, allowing you to only pay for the resources you need. However, our extensible platform allows you to add as many tools as needed, all within a single agent, streamlining the assessment process.</p>"},{"location":"1-getting-started/use-cases/ma-due-diligence/#ma-problems","title":"M&amp;A problems","text":"<ul> <li>Inefficiencies in evaluating risks and vulnerabilities: During the M&amp;A process, it's crucial to identify and assess the cybersecurity risks associated with the target company's digital assets, including intellectual property, customer data, and financial information.</li> <li>Complex infrastructures: Merging two organizations' IT infrastructures can be a complex and time-consuming process which requires a smooth and secure integration of the acquired company's network into the parent company's infrastructure.</li> <li>Limited visibility and control: After the M&amp;A process is complete, it's essential to continuously monitor and manage the merged organization's cybersecurity posture.</li> </ul>"},{"location":"1-getting-started/use-cases/ma-due-diligence/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>Cost-effective and scalable: LimaCharlie allows you to be a cost-effective, scalable solution to perform a compromise assessment on to-be-acquired networks, and evaluate pre-existing threats.</li> <li>Continuous visibility and control: Automated, detection-as-code integration with powerful rulesets like Sigma and YARA rules provide continuous visibility into the merged organization's infrastructure, enabling you to detect and respond to potential threats in real-time.</li> <li>Integrate with any tool: Our extensible platform allows you to customize your additional tools, all through a single agent, achieving maximum performance with minimal footprint.</li> <li>Centralized telemetry: LimaCharlie's centralized platform provides a single pane of glass for monitoring and managing the merged infrastructure, simplifying the integration process and reducing the risk of security gaps.</li> </ul>"},{"location":"1-getting-started/use-cases/mssp-msp-mdr/","title":"Security Service Providers (MSSP, MSP, MDR)","text":"<p>The LimaCharlie SecOps Cloud Platform (SCP) is a unified platform for modern cybersecurity operations.</p> <p>The SCP delivers core cybersecurity capabilities and infrastructure via a public cloud model: on-demand, pay-per-use, and API-first. For the cybersecurity industry, this is a paradigm shift comparable to how the IT public cloud revolutionized IT.</p> <p>For managed security services providers (MSSPs), managed detection and response (MDR) firms, and all those involved in digital forensics and incident response (DFIR), the SecOps Cloud Platform is a powerful way to improve security operations and compete more effectively. With the SCP, service providers can deliver security services at scale, control costs, consolidate and customize security tooling, take on new businesses with confidence, and much more.</p> <p>The platform's public cloud-like delivery model also helps service providers integrate the SCP into their operations gradually and safely. Flexible pay-as-you-go pricing means you only pay for the capabilities you need, and only for as long as you use them\u2014without long-term contracts, complex licensing, capacity planning, price modeling, or termination fees.</p>"},{"location":"1-getting-started/use-cases/mssp-msp-mdr/#implementation-strategies-for-quick-wins","title":"Implementation strategies for quick wins","text":"<p>The SecOps Cloud Platform contains numerous capabilities and is designed to be highly flexible and customizable. Nevertheless, there are some common implementation strategies that MSSP users have found to be good starting points with the platform. Here are three easy ways that the SCP can help service providers improve security operations and expand their businesses immediately:</p>"},{"location":"1-getting-started/use-cases/mssp-msp-mdr/#gain-greater-visibility-into-client-environments","title":"Gain greater visibility into client environments","text":"<p>The SCP can help service providers gain greater visibility into client environments\u2014and bring telemetry data under a single plane for a more unified view. This is one of the first realizations of value for service providers using the SCP platform. Here's an outline of what this looks like:</p> <p>Decide what telemetry data you need to support security operations. Your options here are extensive. In the SCP, there are two main sources of telemetry:</p> <p>First, there are the platform's endpoint detection and response (EDR)-type sensors, which can be deployed directly on Windows, Mac, and Linux endpoints with full feature parity across these OSes to capture system events and other telemetry data. There are also browser-based sensors for Chrome and Edge. Sensors stream telemetry data and artifacts into the SCP in real time (and can also be used to take response actions on endpoints). Importing event data from third-party EDR tools such as VMWare Carbon Black, CrowdStrike, and Microsoft Defender is also possible.</p> <p>The second source of telemetry data can be classed as log-type data. This data can be brought into the SCP using a system of adapters or via webhook. The options are too numerous to list here in full, but supported log data sources include O365, 1Password, AWS CloudTrail, Google Cloud Platform (GCP), Slack Audit logs, and more. For a more comprehensive list, refer to the SCP documentation.</p> <p>Configure client organizations to provide the required visibility. The SCP web interface makes this as simple as making a few clicks to set up the required installation keys. More advanced configuration management options using a REST API or a command-line interface (CLI) are also available. After setup, your client organizations' configurations\u2014including what telemetry you want to bring into the SecOps Cloud Platform\u2014will be stored as simple YAML files. Note here that it's possible to use the SCP's multitenancy and organization management features to make configuration changes to multiple organizations at the same time. For a more detailed example of what this might look like, see this demo MSSP setup.</p> <p>Bring your data under a single plane. All telemetry data brought into the SCP is normalized to a common JSON format and explorable through a single interface. In itself, this represents a huge step forward for many service providers because they will no longer have to deal with a fragmented jumble of UIs or competing data formats in order to view and act on their telemetry data.</p> <p>Operationalize your telemetry data. Seeing into your clients' environments is an essential first step\u2014but this is only the beginning of what is possible with the SecOps Cloud Platform. The SCP's advanced detection and response engine can act on every piece of telemetry brought into the platform, making it possible to apply sophisticated detection and response () logic to telemetry data. Applying D&amp;R logic can be as tailored or as simple as you choose, from using custom detections that you write yourself to leveraging curated rulesets like Sigma, Soteria, or SOC Prime rules\u2014or a combination of both approaches.</p> <p>It's impossible to protect what you can't see. The SCP makes it possible to gain full visibility into a client environment, visualize that telemetry in a single interface and data format, and take action on telemetry data via a powerful detection, automation, and response engine.</p>"},{"location":"1-getting-started/use-cases/mssp-msp-mdr/#implement-scalable-secops-and-simplified-client-management","title":"Implement scalable SecOps and simplified client management","text":"<p>The SecOps Cloud Platform is multitenant by design, offers fine-grained role-based access control (RBAC), and supports an Infrastructure-as-Code (IaC) approach to configuration management. These core aspects of the SCP enable service providers to practice modern cybersecurity operations at scale.</p> <p>Separate client environments intelligently. The multitenancy of the SCP allows service providers to create a logical boundary between their client organizations' data while still being able to view and manage everything from a single platform. Multitenancy makes it easier to avoid commingling client data\u2014and comply with regional regulatory requirements such as data residency rules.</p> <p>Manage access and permissions more effectively. RBAC allows you to grant users the access to organizations and the permissions that they need. You can give individual users permissions on a per-organization basis if you choose. But for more efficient access management, you can use Organization Groups, which are groupings of client organizations, permissions, and users.</p> <p>Organization Groups give the same permissions and organizational access to any user added to the group. Typically, Organization Groups are set up by job function. For example, you might create an Organization Group for security engineers that allows members to edit telemetry ingestion configurations for all of your client organizations, and a separate Organization Group for non-technical roles that provides read-only access or the ability to view general organizational information.</p> <p>Build SecOps workflows that scale. The SecOps Cloud Platform enables service providers to take an infrastructure-as-code approach to security operations. All of your client organizations' security configurations\u2014from D&amp;R rules to data forwarding and output settings\u2014can be stored and managed as simple YAML files.</p> <p>Create new organizations quickly by cloning an existing organization's configurations or using a configuration template. Maintain a global set of configuration settings for all client organizations and then add per-client config files as needed. If you need to make changes to multiple client organizations, this is as simple as editing a global configuration file via CLI or web UI and pushing out the change to all of your organizations at scale.</p> <p>The SecOps Cloud Platform helps service providers adopt a truly modern and scalable approach to cybersecurity operations. For a more detailed look at how these SCP concepts work in practice, watch  Setting Up an MSSP with LimaCharlie.</p>"},{"location":"1-getting-started/use-cases/mssp-msp-mdr/#improve-incident-response-times-and-offer-unbeatable-service-level-agreements","title":"Improve incident response times and offer unbeatable service-level agreements","text":"<p>The SecOps Cloud Platform can be tremendously valuable for service providers doing incident response (IR) work. Here are some of the most significant capabilities for IR teams:</p> <p>Begin IR engagements without delay. The on-demand nature of the SecOps Cloud Platform means you will never need to talk to a vendor sales representative or renegotiate a contract before starting an IR engagement. With the SCP, you log into your account, use a credit card or increase your existing sensor quota, and begin.</p> <p>In addition, it's possible to preconfigure tenants ahead of an IR engagement. Set up your desired SCP IR configuration using custom D&amp;R rulesets, curated rulesets, memory dump capabilities, YARA scanning, and more. Then, export the configuration files for your IR tenant and reuse them whenever you have a new IR engagement to hit the ground running.</p> <p>Take the fight to the adversary. During IR engagements with an active attacker in the environment, the SecOps Cloud Platform gives you a robust response capability on your client's endpoints.</p> <p>Mass-deploy SCP sensors using an enterprise deployment tool. Then, use those sensors to gather real-time event data, run shell commands and executables on endpoints, deploy security tools and remediation packages at scale, or isolate compromised machines from the network\u2014all with minimal impact on the client's operations and mission-critical IT infrastructure.</p> <p>Use security intelligence as soon as you have it. The SCP's IaC approach means you don't have to rely on a vendor to update a tool or publish an indicator of compromise (IoC) in an emergency. For example, imagine a scenario in which you're dealing with a 0-day compromise. If you have early access to an IoC via an information-sharing network or a colleague, you can literally copy-paste the relevant IoC data from a Slack message into a new SCP D&amp;R rule, update the relevant config file, and push out the change to your client's environment\u2014while the all of the vendor-dependent service providers are still waiting on someone else to act.</p> <p>Build a true rapid-response capability. LimaCharlie sensors can be pre-deployed to client environments in \"sleeper\" mode: i.e., with the telemetry collection settings tuned down to a bare minimum to keep costs to just pennies per month. If an incident occurs, the sensors are already there, ready and waiting on the endpoints, and can turned on for an immediate response. This use case has allowed SCP service provider partners to offer service-level agreements of as little as 20 minutes\u2014a considerable advantage when it comes to pitching (and closing) new MDR or MSSP clients.</p> <p>IR work is high-stakes and high-pressure\u2014and, unfortunately, is far too often complicated by the cumbersome sales processes and technical limitations of legacy cybersecurity vendors. The SCP allows incident responders to take action quickly and independently during an incident. It also lets cybersecurity service providers improve their overall response capabilities, enabling attractive service-level agreements that can help win over prospective clients.</p>"},{"location":"1-getting-started/use-cases/network-monitoring/","title":"Network Monitoring","text":"<p>LimaCharlie's SecOps Cloud Platform, through its integration with Zeek, revolutionizes network security monitoring by providing scalable semantic analysis, seamless artifact ingestion, and powerful detection and response capabilities. By automating threat detection and enabling efficient incident investigation and response, LimaCharlie helps organizations stay ahead of evolving network threats and maintain a robust security posture.</p>"},{"location":"1-getting-started/use-cases/network-monitoring/#network-monitoring-problems","title":"Network monitoring problems","text":"<ul> <li>Scalability issues: Traditional monitoring tools struggle to keep up with the increased volume and variety of network traffic, leading to performance bottlenecks and reduced visibility.</li> <li>Lack of semantic analysis: Many network monitoring solutions focus primarily on capturing and storing network traffic data without providing deep, semantic analysis of the content, making it difficult to identify and understand sophisticated threats.</li> <li>Limited automation and response capabilities: Monitoring tools often lack advanced detection, automation, and response features, requiring manual intervention and slowing down incident response times.</li> </ul>"},{"location":"1-getting-started/use-cases/network-monitoring/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>Scalable semantic security monitoring: By leveraging Zeek's robust platform, LimaCharlie enables organizations to perform semantic security monitoring at scale. The Zeek service automatically analyzes ingested PCAP files, extracting rich, structured data that provides deep insights into network activity and potential security threats.</li> <li>Seamless integration with Artifact Ingestion: LimaCharlie's Zeek extension seamlessly integrates with the platform's Artifact Ingestion system. As PCAP files are ingested, the Zeek service automatically processes them, generating detailed log files that are then re-ingested into the Artifact Ingestion system for further analysis and action.</li> <li>Customizable Detection &amp; Response (D&amp;R) rules: With the Zeek log files available as artifacts within LimaCharlie, security teams can create sophisticated D&amp;R rules to automate threat detection and response. These rules can be customized to match an organization's specific security requirements, enabling rapid identification and mitigation of potential threats.</li> <li>Efficient incident investigation and response: LimaCharlie's integration with Zeek empowers security teams to perform efficient incident investigations by providing rich, contextual data about network activity. The platform's powerful search capabilities allow security teams to quickly identify relevant artifacts and take appropriate actions to contain and remediate threats.</li> </ul>"},{"location":"1-getting-started/use-cases/observability-pipeline/","title":"Observability Pipeline","text":"<p>The SecOps Cloud Platform (SCP) creates a scalable, versatile, and actionable observability pipeline by collecting and standardizing telemetry from the full security stack. Stream data from any input, route it to any output. The SCP provides visibility into telemetry sources and empowers users to create automated responses to actionable events in the pipeline.</p>"},{"location":"1-getting-started/use-cases/observability-pipeline/#observability-pipeline-problems","title":"Observability pipeline problems","text":"<p>Creating an observability pipeline can be a daunting task as users try to integrate a complex and diverse technological environment into a single pipeline solution. When successful, ingesting, managing, and storing data can create significant costs, including:</p> <ul> <li>Data costs: Collecting and storing telemetry can be extremely expensive. As your business grows, so does its data, leading to escalating data storage costs as well.</li> <li>Infrastructure demands: Creating, managing, and monitoring the infrastructure required to operate an observability pipeline requires system engineers. As this infrastructure grows to accommodate your business, so does the headcount needed to maintain operations.</li> <li>Delayed responsiveness: Traditional observability pipelines collect and route data.If something appears in the pipeline that warrants concern, it must be routed to a destination for further analysis before action occurs.</li> <li>High SIEM costs: Data ingestion adds considerable costs to SIEM operations. As an organization expands its digital footprint these costs can increase rapidly.</li> <li>Vendor lock-in constraints: Many organizations find themselves trapped with security vendors who deliberately create dependencies through restrictive contracts, proprietary data formats, and closed ecosystems \u2014 limiting flexibility, driving up costs, and forcing security decisions based on vendor limitations rather than actual security needs.</li> </ul>"},{"location":"1-getting-started/use-cases/observability-pipeline/#limacharlies-solutions","title":"LimaCharlie's solutions","text":"<p>The SecOps Cloud Platform unifies telemetry collection by using an API-first approach for integrating the security stack. It creates a natural observability pipeline that scales without limit, facilitates automated responses, and greatly reduces data costs across the board. With the SCP you get a fully interactive observability pipeline that can facilitate countless other critical security operations as well.</p> <ul> <li>Free data retention: LimaCharlie offers a rolling year of free data storage.</li> <li>Infrastructure-as-a-Service: LimaCharlie provides a scalable, cloud-native infrastructure on an API-first platform. This gives our users maximum flexibility, scalability, and integration capabilities across the full security stack, including the observability pipeline.</li> <li>Instant, bi-directional response: LimaCharlie supports bi-directionality which allows automated responses sent directly to the source of a detection. For example, if the SecOps Cloud Platform receives a suspicious login alert from O365 it can immediately send a response to suspend the account before telemetry is sent for further processing.</li> <li>Reduce SIEM spend: LimaCharlie makes it easy to send only relevant telemetry to your SIEM, while still retaining all of your data in storage. This instantly reduces the costs of operating your SIEM while also accommodating any regulatory compliance requirements involving your data.</li> <li>No vendor lock-in: The API-first nature of LimaCharlie allows you to integrate and use whatever security solutions, services, and resources you prefer. There are no contracts or artificial barriers put in place to restrict your choices.</li> </ul>"},{"location":"1-getting-started/use-cases/purple-teaming/","title":"Purple Teaming","text":"<p>LimaCharlie introduces a dynamic, continuous approach to purple teaming. Experience rapid deployment, centralized visibility, flexible outputs, and automated validation to keep your security posture agile and adaptable in the face of ever-changing threats.</p>"},{"location":"1-getting-started/use-cases/purple-teaming/#purple-teaming-problems","title":"Purple teaming problems","text":"<ul> <li>Slow and cumbersome purple teaming exercises: Traditional purple teaming setups involve deploying complex infrastructure, manually configuring attack simulations, and waiting for results, hindering the frequency and efficiency of security validation.</li> <li>Limited visibility and control: Siloed security tools often lack centralized visibility into both red and blue team activities, making it difficult to measure the effectiveness of implemented controls and identify gaps in defense strategy.</li> <li>Inaccessible validation results: Sharing and analyzing purple teaming outputs across different platforms and teams can be tedious and time-consuming, hampering efficient collaboration and feedback loops.</li> <li>Static security posture: Traditional setups rarely provide continuous validation, leaving organizations vulnerable to evolving threats and undetected weaknesses between infrequent purple teaming exercises.</li> </ul>"},{"location":"1-getting-started/use-cases/purple-teaming/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>Rapid deployment and execution: Leverage LimaCharlie's multi-platform, full-parity Sensors and pre-built Atomic Red Team integrations to launch sophisticated attack simulations instantly across your entire infrastructure. No need for time-consuming manual setups or specialized red team expertise.</li> <li>Unified visibility and control: Gain a single pane of glass view into both red and blue team activities within LimaCharlie. Monitor attack simulations, analyze responses from your security tools, and identify areas for improvement with ease.</li> <li>Flexible output destinations: Seamlessly send purple teaming outputs to any destination you choose \u2013 SIEMs, security dashboards, incident response platforms, or even custom tools. Streamline collaboration, facilitate data analysis, and accelerate the validation process.</li> <li>Continuous feedback loop: Integrate LimaCharlie into your security workflow for ongoing validation. Conduct automated purple teaming exercises at regular intervals, continuously testing your defenses against the latest threats and adapting your security posture based on feedback.</li> </ul>"},{"location":"1-getting-started/use-cases/secops-development/","title":"SecOps Development","text":"<p>The SecOps Cloud Platform accelerates building, customizing, integrating, and scaling security operations. By handling the infrastructure-intensive aspects of security engineering, LimaCharlie takes on the heavy lifting making it easy for developers to focus on their core projects.</p>"},{"location":"1-getting-started/use-cases/secops-development/#secops-development-problems","title":"SecOps development problems","text":"<p>Innovating new security products and modifying existing ones is crucial for protecting organizations from evolving cyberthreats. Unfortunately, the process of building better cybersecurity solutions is often hampered by:</p> <ul> <li>Time consuming infrastructure management: Developers spend too much time building, maintaining, and updating infrastructure instead of working on projects.</li> <li>Integration headaches: Valuable time is lost to solving integration issues between the tools, services, and platforms critical to a project's success.</li> <li>Scalability issues: While your solution works well at a small scale there are serious concerns over whether it can scale effectively as your business grows.</li> <li>Lack of control: Your project relies on third-party or open source tooling that lacks the flexibility you need to succeed.</li> </ul>"},{"location":"1-getting-started/use-cases/secops-development/#limacharlies-solution","title":"LimaCharlie's solution","text":"<p>The SecOps Cloud Platform delivers core security capabilities in the form of \"primitives\" that can be modified to accommodate specific needs. It offers infrastructure-as-code and other resources that can improve a developer's mean-time-to-market, including:</p> <ul> <li>Infrastructure-as-a-service: LimaCharlie delivers security-oriented cloud-primitives that provide scalable infrastructure and critical resources for your project development. Think AWS, but for security.</li> <li>API-first foundation: The SecOps Cloud Platform (SCP) is built upon an API-first foundation. Information normalized and shared via API, freeing you from vendor lock-in and giving you maximum flexibility.</li> <li>Seamless scalability: The SCP is a cloud platform, and scales effortlessly with the growth of your company.</li> <li>Maximum flexibility: The SCP offers full transparency and granular management of the resources you choose to incorporate. Where third-party tools or open source solutions offer roadblocks, the SCP provides the capability to customize, innovate, and create needed capabilities.</li> </ul>"},{"location":"1-getting-started/use-cases/sleeper-mode/","title":"Sleeper Mode","text":"<p>LimaCharlie's sleeper mode is not just about cost-efficiency; it's about transforming your entire network into a dynamic, responsive security infrastructure. By pre-deploying sensors and strategically activating them during incidents, you gain the element of surprise, optimize resource allocation, and ultimately, mitigate the impact of cyberattacks with unmatched agility.</p>"},{"location":"1-getting-started/use-cases/sleeper-mode/#traditional-sensor-deployment-problems","title":"Traditional sensor deployment problems","text":"<p>Traditional IR relies on reactive deployment of sensors, leaving critical blind spots during early stages of an incident. Delays in gaining visibility slow down response times and increase damage potential.</p> <ul> <li>Limited visibility: Lack of visibility during the early stages of an incident due to the absence of pre-deployed sensors.</li> <li>Manual processes: Delayed response times caused by the need to manually deploy sensors after an incident has been detected.</li> <li>Delayed response: Increased potential for damage and lateral movement of threats while waiting for sensor deployment and data collection.</li> </ul>"},{"location":"1-getting-started/use-cases/sleeper-mode/#limacharlies-solution","title":"LimaCharlie's solution","text":"<p>Sleeper mode transforms your entire network into a pre-wired security grid. Sensors sit silently, consuming minimal resources while collecting basic system information and detecting critical events. This provides:</p> <ul> <li>Instant Activation, Rapid Response: Need deep process monitoring or memory forensic capabilities? Instantly activate sleepers within the affected area, gaining full-fledged EDR visibility for targeted investigation and containment. No more waiting for manual installation during critical moments.</li> <li>Surgical Precision: Focus resources where they matter most. Activate sleepers only on specific endpoints or clusters suspected of involvement, reducing unnecessary data collection and analysis overload. This streamlines investigations and saves valuable time.</li> <li>Critical Assets Under Cover: Pre-deploy sensors in sleeper mode on high-value servers, executive machines, or sensitive data repositories. When an incident strikes, instant activation grants immediate visibility and control, safeguarding your most crucial assets.</li> <li>Targeted Threat Hunting: Identify potential targets based on threat intelligence or internal red teaming exercises. Pre-emptively activate sleepers in these areas, creating a proactive surveillance network to catch early signs of malicious activity.</li> <li>Isolate and Contain: Sleeper mode empowers swift containment. Upon detecting suspicious activity, activate neighboring sleepers to cordon off the affected area, preventing lateral movement and limiting damage.</li> <li>Deep Dive Forensics: Need detailed forensic disk or memory analysis? Activate the relevant sleeper for comprehensive forensic investigation, dissecting the incident and identifying root causes for future prevention.</li> </ul>"},{"location":"1-getting-started/use-cases/soar-automation/","title":"SOAR / Automation","text":"<p>The SecOps Cloud Platform makes building, modifying, or streamlining your security orchestration, automation, and response (SOAR) operations simple. Lower your costs and increase your response time by aggregating SOAR tooling, integrating resources, and normalizing telemetry with the SecOps Cloud Platform.</p>"},{"location":"1-getting-started/use-cases/soar-automation/#soarautomation-problems","title":"SOAR/Automation problems","text":"<p>Security orchestration, automation, and response (SOAR) solutions play a key role in detecting and responding to cyber threats. However, adopting a standalone SOAR solution may also create new challenges including:</p> <ul> <li>Alert fatigue: Security analysts receive and evaluate countless alerts before uncovering and responding to legitimate issues.</li> <li>High data costs: Sending telemetry data to a SIEM can be an expensive, resource-intensive process that only increases as businesses grow, resulting in new endpoints and data sources.</li> <li>Unnecessary detection friction: Security tools detect suspicious activity and send events to the SIEM, generating an alert for the analyst to investigate. After investigation, various manual procedures are invoked to remediate the alert.</li> <li>Inefficient manual processes: Critical time is lost as analysts coordinate transferring crucial information into various tools and performing response actions.</li> </ul>"},{"location":"1-getting-started/use-cases/soar-automation/#limacharlies-solutions","title":"LimaCharlie's solutions","text":"<p>The SecOps Cloud Platform consolidates and integrates SOAR tooling in a single place. It offers a more efficient, customizable way to implement SOAR by integrating the security stack, normalizing data, and expanding automation capabilities.</p> <ul> <li>Data normalization, collection, false positive rules, and filtering: The LimaCharlie SecOps Cloud Platform collects and normalizes telemetry making it easy to filter out noise, share information between resources, and detect real problems.</li> <li>Reduced data costs: All events, telemetry, and detections within LimaCharlie are stored online and searchable for one year. This allows users to keep everything instead of aggregating and having to choose which data is important.</li> <li>Bi-directionality: LimaCharlie supports bi-directionality which allows automated responses to be sent directly to the source of a detection. For example, if the SecOps Cloud Platform receives a suspicious login alert from O365 it can send a direct automated response to suspend the account. This eliminates a persistence method for attackers.</li> <li>API-first foundation: LimaCharlie can perform critical response actions for any asset in your security stack via API. Automated responses can trigger remediation actions and send telemetry to security tooling without (comparatively slow) human intervention. Python playbooks allow you to automatically perform standard, repetitive tasks, reducing mean time to resolve, and allowing analysts to focus on higher priority alerts.</li> </ul>"},{"location":"1-getting-started/use-cases/table-top-exercises/","title":"Table Top Exercises","text":"<p>Enhance your security preparedness table-top exercises with LimaCharlie. Conduct realistic multi-platform simulations, optimize incident response procedures, and empower your team to face evolving cyber threats with confidence.</p>"},{"location":"1-getting-started/use-cases/table-top-exercises/#problems-with-table-top-exercises","title":"Problems with table top exercises","text":"<ul> <li>**Costly and time-consuming setup:**Traditional tabletop exercises (TTX) often require dedicated infrastructure, extensive preparation, and significant resource investment, making them infrequent and burdensome.</li> <li>Limited platform capabilities: Many TTX platforms lack cross-platform support, realistic attack simulations, and comprehensive reporting, hindering effective incident response training.</li> <li>Fragmented security awareness: Traditional scenarios might not encompass multi-platform environments and evolving attack vectors, leaving security teams unprepared for real-world threats.</li> </ul>"},{"location":"1-getting-started/use-cases/table-top-exercises/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>Pay-as-you-go platform: Access LimaCharlie's fully featured capabilities with flexible, pay-as-you-go pricing. Conduct exercises as needed without costly upfront investments or long-term contracts.</li> <li>Rapid deployment and customization: Get started with LimaCharlie's quickly and easily. Launch realistic cyber attack simulations within minutes, tailored to your specific environment and security concerns.</li> <li>Comprehensive multi-platform simulations: Test your team's response to complex attack scenarios across Windows, macOS, Linux, and cloud environments, mimicking real-world threats. Leverage LimaCharlie's API to integrate your existing security tools, creating a truly holistic response simulation.</li> <li>Detailed reporting and insights: Gain valuable insights from post-exercise reports that analyze team performance, identify skill gaps, and offer actionable recommendations for improving your incident response procedures.</li> <li>Customizable attack libraries: Utilize pre-built or customize attack scenarios, based on Atomic Red Team, to run your training exercises. Based on your specific industry, threat landscape, and vulnerabilities, ensure you conduct relevant and valuable training exercises.</li> </ul>"},{"location":"1-getting-started/use-cases/threat-hunting/","title":"Threat Hunting","text":"<p>Stop settling for static defenses \u2013 become a threat hunting powerhouse with LimaCharlie! One-year historical data, intuitive exploration, and seamless rule creation empower you to uncover hidden threats, predict future attacks, and continuously optimize your security posture for maximum resilience.</p>"},{"location":"1-getting-started/use-cases/threat-hunting/#threat-hunting-problems","title":"Threat hunting problems","text":"<ul> <li>Limited visibility into past activity: Traditional security solutions focus on real-time threats, leaving hidden attacker footprints and lingering malware remnants undetected in historical data.</li> <li>Cumbersome historical data analysis: Complex log aggregation and analysis tools hinder efficient threat hunting investigations across vast datasets, delaying threat discovery and response.</li> <li>Static detection and response: The disconnect between reactive threat hunts and proactive defense leaves organizations vulnerable to future attacks from similar tactics, techniques, and procedures (TTPs).</li> </ul>"},{"location":"1-getting-started/use-cases/threat-hunting/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>Deep Dive into One Year of Data: Explore past events, analyze suspicious activities, and uncover hidden threats with LimaCharlie's one-year historical data storage. Don't let potential attacker footprints remain invisible.</li> <li>Effortless Exploration with Intuitive Queries: Utilize LimaCharlie's powerful search engine and pre-built queries to navigate historical data with ease. Find connections, identify anomalies, and conduct in-depth investigations without cumbersome tools.</li> <li>From Hunt to Rule\u2014Seamless Transformation: Easily convert your threat hunting discoveries into actionable detection and response rules within LimaCharlie. Automate future defense against similar attacks by leveraging insights from your historical investigations, closing the loop between reactive hunting and proactive prevention.</li> <li>Continuous Optimization\u2014A Cycle of Resilience: Re-run historical threat hunts with evolving queries and filters to adapt your detection and response rules as the threat landscape changes. Continuously refine your defenses based on new insights and stay ahead of adversaries.</li> </ul>"},{"location":"1-getting-started/use-cases/wel-monitoring/","title":"WEL Monitoring","text":"<p>LimaCharlie's SecOps Cloud Platform transforms Windows Event Log monitoring by providing real-time visibility, streamlined infrastructure, and powerful detection and response capabilities. Effectively monitor and protect your Windows environments, ensuring rapid detection and response to potential security incidents.</p>"},{"location":"1-getting-started/use-cases/wel-monitoring/#wel-monitoring-problems","title":"WEL monitoring problems","text":"<ul> <li>Limited real-time visibility: Traditional WEL monitoring solutions often rely on periodic log collection, resulting in delayed visibility into potential security incidents, limiting real-time visibility.</li> <li>Complex and costly infrastructure: Forwarding WEL data to a centralized monitoring system typically requires additional infrastructure, such as log collectors and forwarders, which can be complex to set up and maintain, as well as costly to scale.</li> <li>Difficulty in creating custom detection rules: Writing custom rules to detect malicious behavior in WEL data can be challenging, especially when dealing with large volumes of logs and a lack of standardized formats.</li> </ul>"},{"location":"1-getting-started/use-cases/wel-monitoring/#limacharlies-solution","title":"LimaCharlie's solution","text":"<ul> <li>Real-time WEL ingestion: LimaCharlie's Sensor enables direct, real-time importation of WEL data, eliminating the need for complex forwarding infrastructure and reducing costs and management overhead.</li> <li>Powerful Detection &amp; Response (**) engine**: Ingested WEL data is automatically indexed against common indicators of compromise (IoCs) and processed through LimaCharlie's advanced Detection and Response engine, enabling rapid detection of malicious activity.</li> <li>Flexible and customizable rule creation: With WEL data structured as JSON, security teams can easily create custom D&amp;R rules to detect and respond to specific Windows events as they occur, tailoring the monitoring process to their unique needs and environment.</li> <li>Historical log analysis: Import historical event log data from disk, empowering teams to conduct in-depth investigations and gain valuable context around endpoint activity.</li> </ul> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p>"},{"location":"1-getting-started/use-cases/wel-monitoring/#whats-next","title":"What's Next","text":"<ul> <li>SOAR / Automation</li> </ul>"},{"location":"2-sensors-deployment/","title":"Sensors","text":"<p>Sensor deployment and management.</p>"},{"location":"2-sensors-deployment/#documentation","title":"Documentation","text":"<ul> <li>Installation Keys - Create and manage installation keys</li> <li>Sensor Connectivity - Network requirements and connectivity</li> <li>Sensor Tags - Organize sensors with tags</li> </ul>"},{"location":"2-sensors-deployment/#see-also","title":"See Also","text":"<ul> <li>Installation Keys</li> <li>Endpoint Agents</li> <li>Adapters</li> <li>Sensor Tags</li> </ul>"},{"location":"2-sensors-deployment/connectivity/","title":"Sensor Connectivity","text":"<p>The network connection required by the LimaCharlie Sensor is very simple. It requires a single TCP connection over port 443 to a specific domain, and optionally another destination for the Artifact Collection service.</p> <p>The specific domains are listed in the Sensor Downloads section of your Organization's dashboard. They will vary depending on the datacenter you chose to create your organization in. To find yours, see the screenshots below.</p> <p>Currently, web proxies are not supported, but since LimaCharlie requires a single connection to a single dedicated domain, it makes creating a single exception safe and easy.</p>"},{"location":"2-sensors-deployment/connectivity/#proxy-tunneling","title":"Proxy Tunneling","text":"<p>The LimaCharlie sensor supports unauthenticated proxy tunneling through HTTP CONNECT.</p> <p>This allows the LimaCharlie connection to go through the proxy in an opaque way (since the sensor does not support SSL interception).</p> <p>To activate this feature, set the <code>LC_PROXY</code> environment variable to the DNS or hostname of the proxy to use. For example you could use: <code>LC_PROXY=proxy.corp.com:8080</code>.</p>"},{"location":"2-sensors-deployment/connectivity/#windows","title":"Windows","text":"<p>On Windows, you may use a light auto-detection of a globally-configured, unauthenticated proxy.</p> <p>To enable this, set the same environment variable to the <code>-</code> value, like <code>LC_PROXY=-</code>. This will make the sensor query the registry key <code>HKLM\\Software\\Policies\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\\ProxyServer</code> and use its value as the proxy destination.</p> <p>Also on Windows, in some cases the environment variable changes do not propagate to all processes in the expected way. Usually a reboot of the machine will fix it, but for machines that cannot be rebooted you have the ability to set a special value to the environment variable (deletion is usually problematic but setting a var works) that will disable the proxy specifically: <code>!</code>. So if you set the <code>LC_PROXY</code> variable to <code>!</code> (exclamation mark), the proxy will be disabled.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p>"},{"location":"2-sensors-deployment/installation-keys/","title":"Installation Keys","text":"<p>Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.</p> <p>There are four components of an Installation Key:</p> <ul> <li>Organization ID (**OID)**: The Organization ID that this key should enroll into.</li> <li>Installer ID (IID): Installer ID that is generated and associated with every Installation Key.</li> <li>Tags: A list of Tags automatically applied to sensors enrolling with the key.</li> <li>Description: The description used to help you differentiate uses of various keys.</li> </ul>"},{"location":"2-sensors-deployment/installation-keys/#management","title":"Management","text":"<p>Installation keys can be managed on the Sensors &gt; Installation Keys page in the web app.</p> <p>On this page, under the <code>Connectivity</code> section, you will see the various URLs associated with Sensor and Adapter connectivity.</p>"},{"location":"2-sensors-deployment/installation-keys/#pinned-certificates","title":"Pinned Certificates","text":"<p>Typically, Sensors require access over port 443 and use pinned SSL certificates. This is the default deployment option, and does not support traffic interception.</p> <p>If you need to install sensors without pinned certificates, an installation key must be created with a specific flag. This must be done via the REST API, by setting the <code>use_public_root_ca</code> flag to <code>true</code>.</p> <p>More details can be found here.</p>"},{"location":"2-sensors-deployment/installation-keys/#use-of-tags","title":"Use of Tags","text":"<p>Generally speaking, we use at least one Installation Key per organization. Then we use different keys to help differentiate parts of our infrastructure. For example, you may create a key with Tag \"server\" that you will use to install on your servers, a key with \"vip\" for executives in your organization, or a key with \"sales\" for the sales department, etc. This way you can use the tags on various sensors to figure out different detection and response rules for different types of hosts on your infrastructure.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.</p> <p>In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.</p> <p>In LimaCharlie, an Organization ID (OID) is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p> <p>Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.</p>"},{"location":"2-sensors-deployment/installation-keys/#see-also","title":"See Also","text":"<ul> <li>Sensor Deployment Overview</li> <li>Windows Installation</li> <li>Linux Installation</li> </ul>"},{"location":"2-sensors-deployment/log-collection-guide/","title":"Log Collection Guide","text":"<p>This guide covers how to collect various Linux system logs into LimaCharlie using USP adapters. LimaCharlie provides flexible log collection capabilities through file monitoring and syslog ingestion.</p>"},{"location":"2-sensors-deployment/log-collection-guide/#collection-methods","title":"Collection Methods","text":""},{"location":"2-sensors-deployment/log-collection-guide/#file-adapter-recommended-for-log-files","title":"File Adapter (Recommended for Log Files)","text":"<p>The file adapter monitors log files for changes and streams new entries to LimaCharlie. It supports glob patterns for monitoring multiple files and handles log rotation automatically.</p>"},{"location":"2-sensors-deployment/log-collection-guide/#key-features","title":"Key Features:","text":"<ul> <li>Glob pattern support (/var/log/*.log)</li> <li>Automatic log rotation handling</li> <li>Backfill support for historical data</li> <li>Multi-line JSON parsing</li> <li>Grok pattern parsing for structured log extraction</li> </ul>"},{"location":"2-sensors-deployment/log-collection-guide/#basic-configuration","title":"Basic Configuration:","text":"<pre><code>file:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"text\"  # or \"json\" for structured logs\n    sensor_seed_key: \"linux-logs\"\n  file_path: \"/path/to/logfile\"\n  backfill: false  # Set true to read existing content\n  no_follow: false # Set true to stop after reading existing content\n</code></pre>"},{"location":"2-sensors-deployment/log-collection-guide/#syslog-adapter","title":"Syslog Adapter","text":"<p>runs as a syslog server, accepting logs via TCP or UDP. This is useful for centralizing logs from multiple systems or integrating with existing syslog infrastructure.</p>"},{"location":"2-sensors-deployment/log-collection-guide/#key-features_1","title":"Key Features:","text":"<ul> <li>TCP and UDP support</li> <li>TLS encryption support</li> <li>Mutual TLS authentication</li> <li>RFC 3164/5424 syslog format support</li> </ul>"},{"location":"2-sensors-deployment/log-collection-guide/#basic-configuration_1","title":"Basic Configuration:","text":"<pre><code>syslog:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"text\"\n    sensor_seed_key: \"syslog-server\"\n  port: 514\n  interface: \"0.0.0.0\"\n  is_udp: false  # Use TCP by defaultLog Parsing Options\n</code></pre> <p>LimaCharlie supports two methods for parsing unstructured log data:</p> <ul> <li>parsing_grok: Uses Grok patterns (recommended) - pre-built patterns for common log formats, easier to read and maintain</li> <li>parsing_re: Uses regular expressions - for custom formats or when Grok patterns don't meet specific needs</li> </ul> <p>Grok patterns are built on regular expressions but provide named patterns for common elements like timestamps, IP addresses, and log formats. Use Grok when possible for better maintainability.</p>"},{"location":"2-sensors-deployment/log-collection-guide/#common-log-sources","title":"Common Log Sources","text":""},{"location":"2-sensors-deployment/log-collection-guide/#system-logs-varlogmessages-varlogsyslog","title":"System Logs (/var/log/messages, /var/log/syslog)","text":"<p>Traditional system logs contain kernel messages, service logs, and general system events.</p> <p>File Adapter Approach:</p> <pre><code>file:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"text\"\n    sensor_seed_key: \"system-logs\"\n    mapping:\n      parsing_grok:\n        message: \"%{SYSLOGTIMESTAMP:date} %{HOSTNAME:host} %{DATA:service}(?:\\\\[%{POSINT:pid}\\\\])?: %{GREEDYDATA:message}\"\n      sensor_hostname_path: \"host\"\n      event_type_path: \"service\"\n  file_path: \"/var/log/messages\"  # or /var/log/syslogKernel Logs (/var/log/kern.log)\n</code></pre> <p>Kernel-specific messages including hardware events, driver messages, and security events.</p> <pre><code>file:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"text\"\n    sensor_seed_key: \"kernel-logs\"\n    mapping:\n      parsing_grok:\n        message: \"%{SYSLOGTIMESTAMP:date} %{HOSTNAME:host} kernel: %{GREEDYDATA:message}\"\n      sensor_hostname_path: \"host\"\n      event_type_path: \"kernel\"\n  file_path: \"/var/log/kern.log\"\n</code></pre> <p>Apache Logs (/var/log/httpd/, /var/log/apache2/):</p> <pre><code>file:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"text\"\n    sensor_seed_key: \"apache-logs\"\n    mapping:\n      parsing_grok:\n        message: \"%{COMMONAPACHELOG}\"\n      event_type_path: \"verb\"\n  file_path: \"/var/log/apache2/access.log\"  # or /var/log/httpd/access_log\n</code></pre> <p>Nginx Logs (/var/log/nginx/*):</p> <pre><code>file:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"text\"\n    sensor_seed_key: \"nginx-logs\"\n    mapping:\n      parsing_grok:\n        message: \"%{NGINXACCESS}\"\n      event_type_path: \"verb\"\n  file_path: \"/var/log/nginx/access.log\"\n</code></pre>"},{"location":"2-sensors-deployment/log-collection-guide/#audit-logs-varlogauditauditlog","title":"Audit Logs (/var/log/audit/audit.log)","text":"<p>Linux audit logs are critical for CIS Controls compliance and security monitoring.</p> <pre><code>file:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"text\"\n    sensor_seed_key: \"audit-logs\"\n    mapping:\n      parsing_grok:\n        message: \"type=%{DATA:audit_type} msg=audit\\\\(%{NUMBER:timestamp}:%{NUMBER:serial}\\\\): %{GREEDYDATA:audit_data}\"\n      event_type_path: \"audit_type\"\n      event_time_path: \"timestamp\"\n  file_path: \"/var/log/audit/audit.log\"\n</code></pre>"},{"location":"2-sensors-deployment/log-collection-guide/#journalctl","title":"Journalctl","text":"<p>Modern logging solution that can output in JSON format for structured parsing.</p> <p>Method 1: Pipe to Syslog Adapter</p> <pre><code># Stream journalctl to syslog adapter\njournalctl -f -q --output=json | nc localhost 514\n</code></pre> <p>Method 2: Output to File and Monitor</p> <pre><code># Create a systemd service to write journal to file\nsudo tee /etc/systemd/system/journal-export.service &lt;&lt; EOF\n[Unit]\nDescription=Export systemd journal to file\nAfter=systemd-journald.service\n\n[Service]\nExecStart=/usr/bin/journalctl -f -q --output=json\nStandardOutput=append:/var/log/journal-export.json\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\nsudo systemctl enable journal-export.service\nsudo systemctl start journal-export.service\n</code></pre> <p>Then monitor the file:</p> <pre><code>file:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"json\"  # JSON format for structured data\n    sensor_seed_key: \"journalctl-logs\"\n    mapping:\n      sensor_hostname_path: \"_HOSTNAME\"\n      event_type_path: \"_SYSTEMD_UNIT\"\n      event_time_path: \"__REALTIME_TIMESTAMP\"\n  file_path: \"/var/log/journal-export.json\"\n</code></pre>"},{"location":"2-sensors-deployment/log-collection-guide/#multi-file-collection","title":"Multi-File Collection","text":"<p>For collecting multiple log types simultaneously:</p> <pre><code># /var/log/messages\nfile:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"text\"\n    sensor_seed_key: \"system-logs\"\n  file_path: \"/var/log/messages\"\n\n---\n\n# Kernel logs\nfile:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"text\"\n    sensor_seed_key: \"kernel-logs\"\n  file_path: \"/var/log/kern.log\"\n\n---\n\n# Audit logs\nfile:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"text\"\n    sensor_seed_key: \"audit-logs\"\n  file_path: \"/var/log/audit/audit.log\"\n\n---\n\n# Web server logs (glob pattern for multiple files)\nfile:\n  client_options:\n    identity:\n      oid: \"your-organization-id\"\n      installation_key: \"your-installation-key\"\n    platform: \"text\"\n    sensor_seed_key: \"web-logs\"\n  file_path: \"/var/log/nginx/*.log\"\n</code></pre>"},{"location":"2-sensors-deployment/log-collection-guide/#best-practices","title":"Best Practices","text":"<ul> <li>Use JSON format when possible - Modern logs often support JSON output, which provides better structure and parsing.</li> <li>Configure appropriate Grok patterns - Grok provides pre-built patterns for common log formats and is easier to maintain than regex. Use <code>parsing_grok</code> over <code>parsing_re</code> when possible.</li> <li>Set sensor_seed_key appropriately - Use descriptive names that identify the log source for easier management.</li> <li>Monitor file permissions - Ensure the adapter has read access to log files.</li> <li>Use backfill carefully - Only enable for initial historical data collection to avoid duplicates.</li> <li>Implement proper field mapping - Extract hostname, timestamps, and event types for better searchability.</li> <li>Pattern testing - Test Grok patterns against sample log lines before deployment. Common patterns include %{COMMONAPACHELOG}, %{SYSLOGTIMESTAMP}, and %{NGINXACCESS}.</li> </ul>"},{"location":"2-sensors-deployment/log-collection-guide/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues:</p> <ul> <li>File permission errors: Check that the adapter process has read access to log files</li> <li>Parse failures: Validate Grok patterns against actual log formats</li> <li>Missing logs: Verify file paths and glob patterns</li> <li>Connection issues: Check network connectivity and authentication credentials</li> </ul> <p>Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.</p>"},{"location":"2-sensors-deployment/sensor-tags/","title":"Sensor Tags","text":"<p>Tags in LimaCharlie are simple strings that can be associated with any number of sensors. A Sensor can also have an arbitrary number of tags associated with it.</p> <p>Tags appear in every event coming from a sensor under the <code>routing</code> component of the event. This greatly simplifies the writing of detection and response rules based on the presence of specific tags, at the cost of including more non-unique data per event. Tags can be used for a variety of purposes, including:</p> <ul> <li>to classify endpoints</li> <li>automate detection and response</li> <li>create powerful workflows</li> <li>trigger automations</li> </ul>"},{"location":"2-sensors-deployment/sensor-tags/#use-cases-for-sensor-tags","title":"Use Cases for Sensor Tags","text":""},{"location":"2-sensors-deployment/sensor-tags/#classification","title":"Classification","text":"<p>You can use tags to classify an endpoint in a number of different ways based on what is important to you.  Some examples of classifications are shown below for inspiration.</p> <p>Departments</p> <p>Create tags to classify endpoints based on what business department they belong to.  e.g. sales, finance, operations, development, support, legal, executives.</p> <p>Usage Type</p> <p>You may wish to tag endpoints based on their type of usage.  e.g. workstation, server, production, staging.</p> <p>By having endpoints tagged in this manner you can easily identify endpoints and decide what actions you may wish to take while considering the tag.  For example, if you see an endpoint is tagged with <code>workstation</code> and <code>executives</code>, and you happen to see suspicious activity on the endpoint, it may be worthwhile for you to prioritize response.</p>"},{"location":"2-sensors-deployment/sensor-tags/#automating-detection-and-response","title":"Automating detection and response","text":"<p>You can use tags to automate detection and response.</p> <p>For example, you can create a detection &amp; response rule so that when a specific user logs in on a device, the box is tagged as <code>VIP-sales</code> and the sensor starts collecting an extended list of events from that box.</p>"},{"location":"2-sensors-deployment/sensor-tags/#creating-workflows","title":"Creating workflows","text":"<p>You can use tags to create workflows and automations. For instance, you can configure an output (forwarder) to send all detections containing <code>VIP-sales</code> tag to Slack so that you can review them asap, while detections tagged as <code>sales</code> can be sent to an email address.</p>"},{"location":"2-sensors-deployment/sensor-tags/#trigger-automations","title":"Trigger Automations","text":"<p>Create a Yara scanning rule so that endpoints tagged as 'sales' are continuously scanned against the specific sets of Yara signatures.</p>"},{"location":"2-sensors-deployment/sensor-tags/#adding-tags","title":"Adding Tags","text":"<p>Tags can be added to a sensor a few different ways:</p> <ol> <li>Enrollment: the installation keys can optionally have a list of Tags that will get applied to sensors that use them.</li> <li>Manually: using the API as described below, either manually by a human or through some other integration.</li> <li>Detection &amp; Response: automated detection and response rules can programatically add a tag (and check for tags).</li> </ol>"},{"location":"2-sensors-deployment/sensor-tags/#manual-api","title":"Manual API","text":"<p>Issue a <code>POST</code> to <code>/{sid}/tags</code> REST endpoint</p>"},{"location":"2-sensors-deployment/sensor-tags/#detection-response","title":"Detection &amp; Response","text":"<p>In detection and response rules. To achieve this, in the response part of the detection &amp; response rule, specify the add tag action. For example, to tag a device as DESKTOP, you would say:</p> <pre><code>- action: add tag\ntag: DESKTOP\n</code></pre>"},{"location":"2-sensors-deployment/sensor-tags/#removing-tags","title":"Removing Tags","text":""},{"location":"2-sensors-deployment/sensor-tags/#manual-api_1","title":"Manual API","text":"<p>Issue a <code>DELETE</code> to <code>/{sid}/tags</code> REST endpoint</p>"},{"location":"2-sensors-deployment/sensor-tags/#detection-response_1","title":"Detection &amp; Response","text":"<p>In detection and response rules</p>"},{"location":"2-sensors-deployment/sensor-tags/#manual-in-the-web-app","title":"Manual in the web app","text":"<p>In the web app, click on the sensor in question to expand it. You will see the list of tags you can add/edit/remove.</p>"},{"location":"2-sensors-deployment/sensor-tags/#checking-tags","title":"Checking Tags","text":""},{"location":"2-sensors-deployment/sensor-tags/#manual-api_2","title":"Manual API","text":"<p>Issue a <code>GET</code> to <code>/{sid}/tags</code> REST endpoint</p>"},{"location":"2-sensors-deployment/sensor-tags/#detection-response_2","title":"Detection &amp; Response","text":"<p>In detection and response rules</p>"},{"location":"2-sensors-deployment/sensor-tags/#system-tags","title":"System Tags","text":"<p>We provide system level functionality with a few system tags.  Those tags are listed below for reference:</p>"},{"location":"2-sensors-deployment/sensor-tags/#lclatest","title":"lc:latest","text":"<p>When you tag a sensor with <code>lc:latest</code>, the sensor version currently assigned to the Organization will be ignored for that specific sensor, and the latest version of the sensor will be used instead. This means you can tag a representative set of computers in the Organization with the <code>lc:latest</code> tag in order to test-deploy the latest version and confirm no negative effects.</p>"},{"location":"2-sensors-deployment/sensor-tags/#lcstable","title":"lc:stable","text":"<p>When you tag a sensor with <code>lc:stable</code>, the sensor version currently assigned to the Organization will be ignored for that specific sensor, and the stable version of the sensor will be used instead. This means you can upgrade an organization as a whole, but leave a few specific sensors behind by assigning the lc:stable tag to them.</p>"},{"location":"2-sensors-deployment/sensor-tags/#lcexperimental","title":"lc:experimental","text":"<p>When you tag a sensor with <code>lc:experimental</code>, the sensor version currently assigned to the Organization will be ignored for that specific sensor. An experimental version of the sensor will be used instead. This tag is typically used when working with the LimaCharlie team to troubleshoot sensor-specific issues.</p>"},{"location":"2-sensors-deployment/sensor-tags/#lcno_kernel","title":"lc:no_kernel","text":"<p>When you tag a sensor with <code>lc:no_kernel</code>, the kernel component will not be loaded on the host.</p>"},{"location":"2-sensors-deployment/sensor-tags/#lcdebug","title":"lc:debug","text":"<p>When you tag a sensor with <code>lc:debug</code>, the debug version of the sensor currently assigned to the Organization will be used.</p>"},{"location":"2-sensors-deployment/sensor-tags/#lclimit-update","title":"lc:limit-update","text":"<p>When you tag a sensor with lc:limit-update, the sensor will not update the version it's running at run-time. The version will only be loaded when the sensor starts from scratch like after a reboot.</p>"},{"location":"2-sensors-deployment/sensor-tags/#lcsleeper","title":"lc:sleeper","text":"<p>When you tag a sensor with lc:sleeper, the sensor will keep its connection to the LimaCharlie Cloud, but will disable all other functionality to avoid any impact on the system.</p>"},{"location":"2-sensors-deployment/sensor-tags/#lcusage","title":"lc:usage","text":"<p>When you tag a sensor with lc:usage, the sensor will work as usual, but its connection will not count against the normal sensor quota. Instead, the time the sensor spends connected will be billed separately per second, and so will events received by the sensor. For more details, see Sleeper Deployments.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p>"},{"location":"2-sensors-deployment/sensor-tags/#see-also","title":"See Also","text":"<ul> <li>D&amp;R Rules with Tags</li> <li>Sensor Selectors</li> </ul>"},{"location":"2-sensors-deployment/telemetry-index/","title":"Telemetry","text":"<p>Telemetry collection and data formats.</p> <p>Refer to the Events section for detailed event schemas and telemetry documentation.</p>"},{"location":"2-sensors-deployment/adapters/","title":"Adapters","text":"<p>Adapters enable log ingestion from external sources into LimaCharlie. They transform various log formats into normalized LimaCharlie events.</p>"},{"location":"2-sensors-deployment/adapters/#deployment-options","title":"Deployment Options","text":"<ul> <li>Deployment Guide - How to deploy adapters</li> <li>Adapters as a Service - Cloud-managed adapter deployment</li> <li>Usage &amp; Configuration - Configuration options and best practices</li> </ul>"},{"location":"2-sensors-deployment/adapters/#adapter-types","title":"Adapter Types","text":""},{"location":"2-sensors-deployment/adapters/#cloud-providers","title":"Cloud Providers","text":"<ul> <li>AWS CloudTrail</li> <li>AWS GuardDuty</li> <li>AWS S3</li> <li>Azure Event Hub</li> <li>GCP Pub/Sub</li> <li>GCP Storage</li> </ul>"},{"location":"2-sensors-deployment/adapters/#identity-access","title":"Identity &amp; Access","text":"<ul> <li>Okta</li> <li>Microsoft Entra ID</li> <li>Duo</li> <li>1Password</li> </ul>"},{"location":"2-sensors-deployment/adapters/#security-tools","title":"Security Tools","text":"<ul> <li>CrowdStrike</li> <li>Microsoft Defender</li> <li>SentinelOne</li> <li>Sophos</li> <li>Carbon Black</li> </ul>"},{"location":"2-sensors-deployment/adapters/#generic-formats","title":"Generic Formats","text":"<ul> <li>Syslog</li> <li>JSON</li> <li>File</li> <li>Windows Event Log</li> <li>EVTX</li> </ul>"},{"location":"2-sensors-deployment/adapters/#tutorials","title":"Tutorials","text":"<ul> <li>Creating a Webhook Adapter</li> <li>Ingesting Google Cloud Logs</li> </ul>"},{"location":"2-sensors-deployment/adapters/#see-also","title":"See Also","text":"<ul> <li>Adapter Deployment</li> <li>Adapters as a Service</li> <li>Outputs</li> </ul>"},{"location":"2-sensors-deployment/adapters/as-a-service/","title":"Adapters as a Service","text":"<p>In some cases, users may need to install the LimaCharlie Adapter with persistence, to ensure that data collection survives a reboot and/or other disruptions.</p> <p>To accommodate this need, the LimaCharlie adapter can be installed as a service.</p>"},{"location":"2-sensors-deployment/adapters/as-a-service/#service-installation","title":"Service Installation","text":""},{"location":"2-sensors-deployment/adapters/as-a-service/#windows","title":"Windows","text":"<p>To install the Windows LimaCharlie adapter as a service, insert the <code>-install:&lt;service_name&gt;</code> flag in the command line, following the adapter executable name.</p> <p>For example:</p> <p><code>./lc_adapter.exe azure_event_hub client_options.identity.installation_key=...</code></p> <p>would be replaced with</p> <p><code>./lc_adapter.exe -install:azure_collection azure_event_hub client_options.identity.installation_key=...</code></p> <p>This would create a service named <code>azure_collection</code> with the adapter config.</p> <p>Remember, adapter configurations can be provided via two methods:</p> <ul> <li>In the command line, as part of a list of flags</li> <li>Via a YAML config file</li> </ul> <p>Note: The service will point to <code>lc_adapter.exe</code> based on its path at the creation of the service. If you wish to move the adapter to a permanent location, please do so before creating the service.</p>"},{"location":"2-sensors-deployment/adapters/as-a-service/#linux-systemd","title":"Linux / systemd","text":"<p>To install a LimaCharlie adapter as a service on a Linux system with systemd, you will need a service file, the adapter binary, and your adapter command.</p>"},{"location":"2-sensors-deployment/adapters/as-a-service/#adapter-binary","title":"Adapter Binary","text":"<p>Download one of the adapter binaries and apply the necessary permissions:</p> <pre><code>wget -O /path/to/adapter-directory/lc-adapter $ADAPTER_BINARY_URL\nchmod +x /path/to/adapter-directory/lc-adapter\n</code></pre>"},{"location":"2-sensors-deployment/adapters/as-a-service/#service-file-etcsystemdsystemlimacharlie-adapter-nameservice","title":"Service File - /etc/systemd/system/limacharlie-adapter-name.service","text":"<p>You will replace <code>$ADAPTER_COMMAND</code> in the service file with your actual adapter command below.</p> <pre><code>[Unit]\nDescription=LC Adapter Name\nAfter=network.target\n\n[Service]\nType=simple\nExecStart=$ADAPTER_COMMAND\nWorkingDirectory=/path/to/adapter-directory\nRestart=always\nRestartSec=10\nStandardOutput=journal\nStandardError=journal\nSyslogIdentifier=lc-adapter-name\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"2-sensors-deployment/adapters/as-a-service/#adapter-command","title":"Adapter Command","text":"<p>Your adapter command may differ depending on your use case--this is an example of a file adapter to ingest logs from a JSON file.</p> <pre><code>/path/to/adapter-directory/lc-adapter file file_path=/path/to/logs.json client_options.identity.installation_key=&lt;INSTALLATION KEY&gt; client_options.identity.oid=&lt;ORG ID&gt; client_options.platform=json client_options.sensor_seed_key=&lt;SENSOR SEED KEY&gt; client_options.mapping.event_type_path=&lt;EVENT TYPE FIELD&gt; client_options.hostname=&lt;HOSTNAME&gt;\n</code></pre>"},{"location":"2-sensors-deployment/adapters/as-a-service/#enable-and-start-the-service","title":"Enable and Start the Service","text":"<pre><code>sudo systemctl enable lc-adapter-name\nsudo systemctl start lc-adapter-name\nsudo systemctl status lc-adapter-name\n</code></pre>"},{"location":"2-sensors-deployment/adapters/as-a-service/#service-uninstallation","title":"Service Uninstallation","text":""},{"location":"2-sensors-deployment/adapters/as-a-service/#windows_1","title":"Windows","text":"<p>To remove a Windows LimaCharlie Adapter service, use the <code>-remove:&lt;service_name&gt;</code> flag.</p>"},{"location":"2-sensors-deployment/adapters/as-a-service/#linux","title":"Linux","text":"<p>If your service is running with a systemd script, you can disable and remove it with the following:</p> <pre><code>sudo systemctl stop lc-adapter-name\nsudo systemctl disable lc-adapter-name\nsudo rm /etc/systemd/system/lc-adapter-name.service\nsudo rm /path/to/adapter-directory/lc-adapter\n</code></pre>"},{"location":"2-sensors-deployment/adapters/deployment/","title":"Adapter Deployment","text":"<p>Adapters can be deployed in one of two ways:</p> <ul> <li>On-prem, Adapters utilize the LC Adapter binary to ingest a data source and forward it to LimaCharlie.</li> <li>Cloud-to-cloud, connects the LimaCharlie cloud directly with your cloud source and automatically ingests data.</li> </ul> <p>Which Adapter Do I Use for Cloud Data?</p> <p>You can use on-prem adapters to forward cloud data, or you could acquire the same data with a cloud-to-cloud connection. So, which one to use?</p> <p>The answer lies in how you want to send your data to LimaCharlie. Are you OK with configuring a connector from our platform, or would you rather use a bastion box in between? Either way works for us!</p> <p>The data ingested from adapters is parsed/mapped into JSON by LimaCharlie, according to the parameters you provided, unless using a pre-defined format.</p>"},{"location":"2-sensors-deployment/adapters/deployment/#adapter-binaries","title":"Adapter Binaries","text":"<p>Software-based, or \"on-prem\" adapters are available in the following formats:</p> <ul> <li> <p>Binaries:</p> </li> <li> <p>*nix</p> <ul> <li>AIX ppc64</li> <li>Linux (Generic) 64-bit</li> <li>Linux (Generic) arm</li> <li>Linux (Generic) arm64</li> <li>FreeBSD 64-bit</li> <li>OpenBSD 64-bit</li> <li>NetBSD 64-bit</li> <li>Solaris 64-bit</li> <li> <p>macOS</p> </li> <li> <p>macOS x64</p> </li> <li>macOS arm64</li> <li> <p>Windows</p> </li> <li> <p>Windows x64</p> </li> <li>Docker:</li> </ul> </li> <li> <p>https://hub.docker.com/r/refractionpoint/lc-adapter</p> </li> </ul> <p>Another platform?</p> <p>If you need support for a specific platform, or require more information about supported platforms, please let us know.</p>"},{"location":"2-sensors-deployment/adapters/deployment/#on-prem-cloud-management","title":"On-Prem + Cloud Management","text":"<p>LimaCharlie Adapters deployed manually (on-prem) also support cloud-based management. This makes the deployment of the adapter extremely easy while also making it easy to update the configs remotely after the fact. This is particularly critical for service providers that may be deploying adapters on customer networks where gaining access to the local adapter may be difficult.</p> <p>To accomplish this, you need the <code>externaladapter.*</code> permissions.</p>"},{"location":"2-sensors-deployment/adapters/deployment/#preparing","title":"Preparing","text":"<p>The first step of deploying this way is to create a new External Adapter record. These are found in the <code>external_adapter</code> Hive or under the Sensors section of the web app.</p> <p>The content of an external adapter is exactly the same as a traditional adapter configuration in YAML. It describes what you want your external adapter to do, like collect from file, operate as a syslog server etc. For example:</p> <pre><code>sensor_type: syslog\nsyslog:\n  client_options:\n    buffer_options: {}\n    hostname: test-syslog\n    identity:\n      installation_key: aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa\n      oid: bbbbbbbb-bbbb-bbbb-bbbb-bbbbbbbbbbbb\n    mapping: {}\n    platform: text\n    sensor_seed_key: test-syslog\n  port: 4242\n</code></pre> <p>Once your external adapter record is created, take note of the <code>GUID</code> (Globally Unique ID) found under the <code>sys_mtd</code> section of the JSON record, or on the right-hand side of the record view in the web app</p> <p>.</p> <p>This <code>GUID</code> is a shared secret value you will use in the deployed adapter to reference it to the record it should update and operate from.</p>"},{"location":"2-sensors-deployment/adapters/deployment/#deploying","title":"Deploying","text":"<p>Now that the configuration of the adapter is ready, you can deploy the adapter on-prem according to the normal process. The only difference is that instead of running it with the full configuration locally, you can run it with the <code>cloud</code> collection method like this:</p> <pre><code>./lc_adapter cloud conf_guid=XXXXXXXXXXXXXXXXXXXXx oid=YYYYYYYYYYYYYYYYYYY\n</code></pre> <p>This will start the adapter telling it to fetch the configuration it requires from the cloud based on the Organization ID (your tenant in LC) and the <code>GUID</code> of the record it should use.</p> <p>From this point on, updating the record in LimaCharlie will automatically reconfigure the adapter on-prem, within about 1 minute of the change.</p> <p>Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.</p>"},{"location":"2-sensors-deployment/adapters/usage/","title":"Adapter Usage","text":"<p>The Adapter can be used to access many different sources and many different event types. The main mechanisms specifying the source and type of events are:</p> <ol> <li>Adapter Type: this indicates the technical source of the events, like <code>syslog</code> or S3 buckets.</li> <li>Platform: the platform indicates the type of events that are acquired from that source, like <code>text</code> or <code>carbon_black</code>.</li> </ol> <p>Depending on the Adapter Type specified, configurations that can be specified will change. Running the adapter with no command line arguments will list all available Adapter Types and their configurations.</p> <p>Configurations can be provided to the adapter in one of three ways:</p> <ol> <li>By specifying a configuration file.</li> <li>By specifying the configurations via the command line in the format <code>config-name=config-value</code>.</li> <li>By specifying the configurations via the environment variables in the format <code>config-name=config-value</code>.</li> </ol> <p>Here's an example config as a config file for an adapter using the <code>file</code> method of collection:</p> <pre><code>file: // The root of the config is the adapter collection method.\n  client_options:\n    identity:\n      installation_key: e9a3bcdf-efa2-47ae-b6df-579a02f3a54d\n      oid: 8cbe27f4-bfa1-4afb-ba19-138cd51389cd\n    platform: json\n    sensor_seed_key: testclient3\n    mapping:\n      event_type_path: syslog-events\n  file_path: /var/log/syslog\n</code></pre>"},{"location":"2-sensors-deployment/adapters/usage/#multi-adapter","title":"Multi-Adapter","text":"<p>It is possible to execute multiple instances of adapters of the same type within the same adapter process, for example to have a single adapter process monitor files in multiple directories with slightly different configurations.</p> <p>This is achieved by using a configuration file (as described above) with multiple YAML \"documents\" within like this:</p> <pre><code>file:\n  client_options:\n    identity:\n      installation_key: e9a3bcdf-efa2-47ae-b6df-579a02f3a54d\n      oid: 8cbe27f4-bfa1-4afb-ba19-138cd51389cd\n    platform: json\n    sensor_seed_key: testclient1\n    mapping:\n      event_type_path: syslog-events\n  file_path: /var/log/dir1/*\n\n---\n\nfile:\n  client_options:\n    identity:\n      installation_key: e9a3bcdf-efa2-47ae-b6df-579a02f3a54d\n      oid: 8cbe27f4-bfa1-4afb-ba19-138cd51389cd\n    platform: json\n    sensor_seed_key: testclient2\n    mapping:\n      event_type_path: syslog-events\n  file_path: /var/log/dir2/*\n\n---\n\nfile:\n  client_options:\n    identity:\n      installation_key: e9a3bcdf-efa2-47ae-b6df-579a02f3a54d\n      oid: 8cbe27f4-bfa1-4afb-ba19-138cd51389cd\n    platform: json\n    sensor_seed_key: testclient3\n    mapping:\n      event_type_path: syslog-events\n  file_path: /var/log/dir3/*\n</code></pre>"},{"location":"2-sensors-deployment/adapters/usage/#runtime-configuration","title":"Runtime Configuration","text":"<p>The Adapter runtime supports some custom behaviors to make it more suitable for specific deployment scenarios:</p> <ul> <li><code>healthcheck</code>: an integer that specifies a port to start an HTTP server on that can be used for healthchecks.</li> </ul>"},{"location":"2-sensors-deployment/adapters/usage/#core-configuration","title":"Core Configuration","text":"<p>All Adapter types support the same <code>client_options</code>, plus type-specific configurations. The following configurations are required for every Adapter:</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> <li><code>client_options.hostname</code>: a hostname for the adapter.</li> </ul>"},{"location":"2-sensors-deployment/adapters/usage/#example","title":"Example","text":"<p>Using inline parameters:</p> <pre><code>./lc-adapter file file_path=/path/to/logs.json \\\n  client_options.identity.installation_key=&lt;INSTALLATION KEY&gt; \\\n  client_options.identity.oid=&lt;ORG ID&gt; \\\n  client_options.platform=json \\\n  client_options.sensor_seed_key=&lt;SENSOR SEED KEY&gt; \\\n  client_options.mapping.event_type_path=&lt;EVENT TYPE FIELD&gt; \\\n  client_options.hostname=&lt;HOSTNAME&gt;\n</code></pre> <p>Using Docker:</p> <pre><code>docker run -d --rm -it -p 4404:4404/udp refractionpoint/lc-adapter syslog \\\n  client_options.identity.installation_key=&lt;INSTALLATION KEY&gt; \\\n  client_options.identity.oid=&lt;ORG ID&gt; \\\n  client_options.platform=cef \\\n  client_options.hostname=&lt;HOSTNAME&gt; \\\n  client_options.sensor_seed_key=&lt;SENSOR SEED KEY&gt; \\\n  port=4404 \\\n  iface=0.0.0.0 \\\n  is_udp=true\n</code></pre> <p>Using a configuration file:</p> <pre><code>./lc-adapter file config_file.yaml\n</code></pre>"},{"location":"2-sensors-deployment/adapters/usage/#parsing-and-mapping","title":"Parsing and Mapping","text":""},{"location":"2-sensors-deployment/adapters/usage/#transformation-order","title":"Transformation Order","text":"<p>Data sent via USP can be formatted in many different ways. Data is processed in a specific order as a pipeline:</p> <ol> <li>Regular Expression with named capture groups parsing a string into a JSON object.</li> <li>Built-in (in the cloud) LimaCharlie parsers that apply to specific <code>platform</code> values (like <code>carbon_black</code>).</li> <li>The various \"extractors\" defined, like <code>EventTypePath</code>, <code>EventTimePath</code>, <code>SensorHostnamePath</code> and <code>SensorKeyPath</code>.</li> <li>Custom <code>Mappings</code> directives provided by the client.</li> </ol>"},{"location":"2-sensors-deployment/adapters/usage/#configurations","title":"Configurations","text":"<p>The following configurations allow you to customize the way data is ingested by the platform, including mapping and redefining fields such as the event type path and time.</p> <ul> <li><code>client_options.mapping.parsing_re</code>: regular expression with named capture groups. The name of each group will be used as the key in the converted JSON parsing.</li> <li><code>client_options.mapping.parsing_grok:</code>  grok pattern parsing for structured data extraction from unstructured log messages. Grok patterns combine regular expressions with predefined patterns to simplify log parsing and field extraction.</li> <li><code>client_options.mapping.sensor_key_path</code>: indicates which component of the events represent unique sensor identifiers.</li> <li><code>client_options.mapping.hostname</code>: indicates which component of the event represents the hostname of the resulting Sensor in LimaCharlie.</li> <li><code>client_options.mapping.event_type_path</code>: indicates which component of the event represents the Event Type of the resulting event in LimaCharlie. It also supports template strings based on each event.</li> <li><code>client_options.mapping.event_time_path</code>: indicates which component of the event represents the Event Time of the resulting event in LimaCharlie.</li> <li><code>client_options.mapping.event_time_timezone</code>: specifies the timezone for parsing timestamps that don't include timezone information. Uses IANA timezone names (e.g., <code>America/New_York</code>, <code>Europe/London</code>, <code>UTC</code>). If not specified, timestamps without timezone info are treated as UTC.</li> <li><code>client_options.mapping.rename_only</code>: deprecated</li> <li><code>client_options.mapping.mappings</code>: deprecated</li> <li><code>client_options.mapping.transform</code>: a Transform to apply to events.</li> <li><code>client_options.mapping.drop_fields</code>: a list of field paths to be dropped from the data before being processed and retained.</li> </ul>"},{"location":"2-sensors-deployment/adapters/usage/#parsing","title":"Parsing","text":""},{"location":"2-sensors-deployment/adapters/usage/#named-group-parsing","title":"Named Group Parsing","text":"<p>If the data ingested in LimaCharlie is text (a syslog line for example), you may automatically parse it into a JSON format. To do this, you need to define one of the following:</p> <ul> <li>a grok pattern, using the <code>client_options.mapping.parsing_grok</code> option</li> <li>a regular expression, using the <code>client_options.mapping.parsing_re</code> option</li> </ul>"},{"location":"2-sensors-deployment/adapters/usage/#grok-patterns","title":"Grok Patterns","text":""},{"location":"2-sensors-deployment/adapters/usage/#basic-syntax","title":"Basic Syntax","text":"<p>Grok patterns use the following syntax:</p> <p>The grok pattern line must start with message: , followed by the patterns, as in the example below</p> <ul> <li><code>%{PATTERN_NAME:field_name}</code> - Extract a pattern into a named field</li> <li><code>%{PATTERN_NAME}</code> - Match a pattern without extraction</li> </ul> <p>Custom patterns can be defined using the pattern name as a key</p> <p>This means that the patterns should not include extracted field names called message as it will conflict with the assumed root of the grok pattern called message.</p>"},{"location":"2-sensors-deployment/adapters/usage/#built-in-patterns","title":"Built-in Patterns","text":"<p>LimaCharlie includes standard Grok patterns for common data types:</p> <ul> <li><code>%{IP:field_name}</code> - IP addresses (IPv4/IPv6)</li> <li><code>%{NUMBER:field_name}</code> - Numeric values</li> <li><code>%{WORD:field_name}</code> - Single words (no whitespace)</li> <li><code>%{DATA:field_name}</code> - Any data up to delimiter</li> <li><code>%{GREEDYDATA:field_name}</code> - All remaining data</li> <li><code>%{TIMESTAMP_ISO8601:field_name}</code> - ISO 8601 timestamps</li> <li><code>%{LOGLEVEL:field_name}</code> - Log levels (DEBUG, INFO, WARN, ERROR)</li> </ul> <p>Example Firewall Log Record:</p> <pre><code>2024-01-01 12:00:00 ACCEPT TCP 192.168.1.100:54321 10.0.0.5:443 packets=1 bytes=78\n</code></pre> <p>LimaCharlie Configuration to Match Firewall Log:</p> <pre><code>client_options:\n  mapping:\n    parsing_grok:\n      message: '%{TIMESTAMP_ISO8601:timestamp} %{WORD:action} %{WORD:protocol} %{IP:src_ip}:%{NUMBER:src_port} %{IP:dst_ip}:%{NUMBER:dst_port} packets=%{NUMBER:packets} bytes=%{NUMBER:bytes}'\n    event_type_path: \"action\"\n    event_time_path: \"timestamp\"\n</code></pre> <p>Fields Extracted by the Above Configuration:</p> <pre><code>{\n  \"timestamp\": \"2024-01-01 12:00:00\",\n  \"action\": \"ACCEPT\",\n  \"protocol\": \"TCP\",\n  \"src_ip\": \"192.168.1.100\",\n  \"src_port\": \"54321\",\n  \"dst_ip\": \"10.0.0.5\",\n  \"dst_port\": \"443\",\n  \"packets\": \"1\",\n  \"bytes\": \"78\"\n}\n</code></pre>"},{"location":"2-sensors-deployment/adapters/usage/#timezone-handling","title":"Timezone Handling","text":"<p>Many log sources emit timestamps without timezone information (e.g., <code>2024-01-01 12:00:00</code> or <code>Jan 15 14:30:22</code>). By default, LimaCharlie interprets these as UTC. If your logs use local time, you can specify the timezone using <code>event_time_timezone</code>:</p> <pre><code>client_options:\n  mapping:\n    parsing_grok:\n      message: '%{SYSLOGTIMESTAMP:timestamp} %{HOSTNAME:host} %{GREEDYDATA:message}'\n    event_time_path: \"timestamp\"\n    event_time_timezone: \"America/New_York\"\n</code></pre> <p>The timezone must be a valid IANA timezone name. Common examples:</p> Timezone Description <code>America/New_York</code> US Eastern Time <code>America/Los_Angeles</code> US Pacific Time <code>Europe/London</code> UK Time <code>Europe/Paris</code> Central European Time <code>Asia/Tokyo</code> Japan Standard Time <code>UTC</code> Coordinated Universal Time <p>Note: Unix epoch timestamps (e.g., <code>1704067200</code>) are timezone-agnostic and are not affected by this setting.</p>"},{"location":"2-sensors-deployment/adapters/usage/#regular-expressions","title":"Regular Expressions","text":"<p>With this log line as an example:</p> <pre><code>Nov 09 10:57:09 penguin PackageKit[21212]: daemon quit\n</code></pre> <p>you could apply the following regular expression as <code>parsing_re</code>:</p> <pre><code>(?P&lt;date&gt;... \\d\\d \\d\\d:\\d\\d:\\d\\d) (?P&lt;host&gt;.+) (?P&lt;exe&gt;.+?)\\[(?P&lt;pid&gt;\\d+)\\]: (?P&lt;msg&gt;.*)\n</code></pre> <p>which would result in the following event in LimaCharlie:</p> <pre><code>{\n  \"date\": \"Nov 09 10:57:09\",\n  \"host\": \"penguin\",\n  \"exe\": \"PackageKit\",\n  \"pid\": \"21212\",\n  \"msg\": \"daemon quit\"\n}\n</code></pre>"},{"location":"2-sensors-deployment/adapters/usage/#keyvalue-parsing","title":"Key/Value Parsing","text":"<p>Alternatively you can specify a regular expression that does NOT contain Named Groups, like this:</p> <pre><code>(?:&lt;\\d+&gt;\\s*)?(\\w+)=(\".*?\"|\\S+)\n</code></pre> <p>When in this mode, LimaCharlie assumes the regular expression will generate a list of matches where each match has 2 submatches, and submatch index 1 is the Key name, and submatch index 2 is the value. This is compatible with logs like CEF for example where the log could look like:</p> <pre><code>&lt;20&gt;hostname=my-host log_name=http_logs timestamp=....\n</code></pre> <p>which would end up generating:</p> <p><pre><code>{\n  \"hostname\" : \"my-host\",\n  \"log_name\": \"http_logs\",\n  \"timestamp\": \"...\"\n}\n```yaml\n\n#### Extraction\n\nLimaCharlie has a few core constructs that all events and sensors have.\nNamely:\n\n* Sensor ID\n* Hostname\n* Event Type\n* Event Time\n\nYou may specify certain fields from the JSON logs to be extracted into these common fields.\n\nThis process is done by specifying the \"path\" to the relevant field in the JSON data. Paths are like a directory path using `/` for each sub directory except that in our case, they describe how to get to the relevant field from the top level of the JSON.\n\nFor example, using this event:\n</code></pre> {   \"a\": \"x\",   \"b\": \"y\",   \"c\": {     \"d\": {       \"e\": \"z\"     }   } } <pre><code>The following paths would yield the following results:\n\n* `a`: `x`\n* `b`: `y`\n* `c/d/e`: `z`\n\nThe following extractors can be specified:\n\n* `client_options.mapping.sensor_key_path`: indicates which component of the events represent unique sensor identifiers.\n* `client_options.mapping.sensor_hostname_path`: indicates which component of the event represents the hostname of the resulting Sensor in LimaCharlie.\n* `client_options.mapping.event_type_path`: indicates which component of the event represents the Event Type of the resulting event in LimaCharlie. It also supports template strings based on each event.\n* `client_options.mapping.event_time_path`: indicates which component of the event represents the Event Time of the resulting event in LimaCharlie.\n\n### Indexing\n\nIndexing occurs in one of 3 ways:\n\n1. By the built-in indexer for specific platforms like Carbon Black.\n2. By a generic indexer applied to all fields if no built-in indexer was available.\n3. Optionally, user-specific indexing guidelines.\n\n#### User Defined Indexing\n\nAn Adapter can be configured to do custom indexing on the data it feeds.\n\nThis is done by setting the `indexing` element in the `client_options`. This field contains a list of index descriptors.\n\nAn index descriptor can have the following fields:\n\n* `events_included`: optionally, a list of event\\_type that this descriptor applies to.\n* `events_excluded`: optionally, a list of event\\_type this descriptor *does not* apply to.\n* `path`: the element path this descriptor targets, like `user/metadata/user_id`.\n* `regexp`: optionally, a regular expression used on the `path` field to extract the item to index, like `email: (.+)`.\n* `index_type`: the category of index the value extracted belongs to, like `user` or `file_hash`.\n\nHere is an example of a simple index descriptor:\n</code></pre> events_included:   - PutObject path: userAgent index_type: user <pre><code>Put together in a client option, you could have:\n</code></pre> {   \"client_options\": {     ...,     \"indexing\": [{       \"events_included\": [\"PutObject\"],       \"path\": \"userAgent\",       \"index_type\": \"user\"     }, {       \"events_included\": [\"DelObject\"],       \"path\": \"original_user/userAgent\",       \"index_type\": \"user\"     }]   } } ```</p>"},{"location":"2-sensors-deployment/adapters/usage/#supported-indexes","title":"Supported Indexes","text":"<p>This is the list of currently supported index types:</p> <ul> <li><code>file_hash</code></li> <li><code>file_path</code></li> <li><code>file_name</code></li> <li><code>domain</code></li> <li><code>ip</code></li> <li><code>user</code></li> <li><code>service_name</code></li> <li><code>package_name</code></li> </ul>"},{"location":"2-sensors-deployment/adapters/usage/#sensor-ids","title":"Sensor IDs","text":"<p>USP Clients generate LimaCharlie Sensors at runtime. The ID of those sensors (SID) is generated based on the Organization ID (OID) and the Sensor Seed Key.</p> <p>This implies that if want to re-key an IID (perhaps it was leaked), you may replace the IID with a new valid one. As long as you use the same OID and Sensor Seed Key, the generated SIDs will be stable despite the IID change.</p>"},{"location":"2-sensors-deployment/adapters/examples/stdin-json/","title":"Stdin JSON","text":"<p>This example is similar to the Stdin example above, except it assumes the data being read is JSON, not just text. If your data source is already JSON, it's much simpler to let LimaCharlie do the JSON parsing directly.</p> <pre><code>./lc_adapter stdin client_options.identity.installation_key=e9a3bcdf-efa2-47ae-b6df-579a02f3a54d \\\n    client_options.identity.oid=8cbe27f4-bfa1-4afb-ba19-138cd51389cd \\\n    client_options.platform=json \\\n    client_options.sensor_seed_key=testclient3 \\\n    client_options.mapping.event_type_path=type \\\n    client_options.hostname=testclient3\n</code></pre> <p>Here's a breakdown of the above example:</p> <ul> <li><code>lc_adapter</code>: simply the CLI Adapter.</li> <li><code>stdin</code>: the method the Adapter should use to collect data locally. The <code>stdin</code> value will simply ingest from the Adapter's STDIN.</li> <li><code>client_options.identity.installation_key=....</code>: the Installation Key value from LimaCharlie.</li> <li><code>client_options.identity.oid=....</code>: the Organization ID from LimaCharlie the installation key above belongs to.</li> <li><code>client_options.platform=json</code>: this indicates that the data read is already JSON, so just parse it as so.</li> <li><code>client_options.sensor_seed_key=....</code>: this is the value that identifies this instance of the Adapter. Record it to re-use the Sensor ID generated for this Adapter later if you have to re-install the Adapter.</li> <li><code>client_options.mapping.event_type_path=....</code>: specifies the field that should be interpreted as the \"event_type\" in LimaCharlie.</li> <li><code>client_options.hostname=....</code>: specifies the sensor hostname for the adapter</li> </ul> <p>Note that we did not need to specify a <code>parsing_re</code> or <code>parsing_grok</code>  because the data ingested is not text, but already JSON, so the Parsing step is already done for us by setting a <code>platform=json</code>.</p> <p>Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.</p> <p>Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p>"},{"location":"2-sensors-deployment/adapters/examples/stdin/","title":"Stdin","text":"<p>This example is similar to the Syslog example above, except it uses the CLI Adapter and receives the data from the CLI's STDIN interface. This method is perfect for ingesting arbitrary logs on disk or from other applications locally.</p> <pre><code>./lc_adapter stdin client_options.identity.installation_key=e9a3bcdf-efa2-47ae-b6df-579a02f3a54d \\\n      client_options.identity.oid=8cbe27f4-bfa1-4afb-ba19-138cd51389cd \\\n      client_options.platform=text \\\n      \"client_options.mapping.parsing_grok.message=%{DATESTAMP:date} %{HOSTNAME:host} %{WORD:exe}\\[%{INT:pid}\\]: %{GREEDYDATA:msg}\" \\\n      client_options.sensor_seed_key=testclient3 \\\n      client_options.mapping.event_type_path=exe\n</code></pre> <p>Here's a breakdown of the above example:</p> <ul> <li><code>lc_adapter</code>: simply the CLI Adapter.</li> <li><code>stdin</code>: the method the Adapter should use to collect data locally. The <code>stdin</code> value will simply ingest from the Adapter's STDIN.</li> <li><code>client_options.identity.installation_key=....</code>: the Installation Key value from LimaCharlie.</li> <li><code>client_options.identity.oid=....</code>: the Organization ID from LimaCharlie the installation key above belongs to.</li> <li><code>client_options.platform=text</code>: this indicates the type of data that will be received from this adapter. In this case it's <code>text</code> lines.</li> <li><code>client_options.mapping.parsing_grok.message=....</code>: this is the grok expression describing how to interpret the text lines and how to convert them to JSON.</li> <li><code>client_options.sensor_seed_key=....</code>: this is the value that identifies this instance of the Adapter. Record it to re-use the Sensor ID generated for this Adapter later if you have to re-install the Adapter.</li> <li><code>client_options.mapping.event_type_path=....</code>: specifies the field that should be interpreted as the \"event_type\" in LimaCharlie.</li> </ul> <p>Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.</p> <p>Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p>"},{"location":"2-sensors-deployment/adapters/examples/windows-event-logs/","title":"Windows Event Logs","text":"<p>This example shows collecting Windows Event Logs (<code>wel</code>) from a Windows box natively (and therefore is only available using the Windows Adapter). This is useful for cases where you'd like to collect WEL without running the LimaCharlie Windows Agent.</p> <pre><code>./lc_adapter wel client_options.identity.installation_key=e9a3bcdf-efa2-47ae-b6df-579a02f3a54d `\n    client_options.identity.oid=8cbe27f4-bfa1-4afb-ba19-138cd51389cd `\n    client_options.sensor_seed_key=domain-controller1 `\n    client_options.platform=wel `\n    evt_sources=security:*,application:*,system:*,Microsoft-Windows-Windows Defender/Operational:*\n</code></pre> <p>Here's a breakdown of the above example:</p> <ul> <li><code>lc_adapter</code>: simply the CLI Adapter.</li> <li><code>wel</code>: the method the Adapter should use to collect data locally. The <code>wel</code> value will use a native local Windows Event Logs subscription.</li> <li><code>client_options.identity.installation_key=....</code>: the Installation Key value from LimaCharlie.</li> <li><code>client_options.identity.oid=....</code>: the Organization ID from LimaCharlie the installation key above belongs to.</li> <li><code>client_options.platform=wel</code>: this indicates the type of data that will be received from this adapter. In this case it's <code>wel</code> events.</li> <li><code>client_options.sensor_seed_key=....</code>: this is the value that identifies this instance of the Adapter. Record it to re-use the Sensor ID generated for this Adapter later if you have to re-install the Adapter.</li> <li><code>evt_sources=....</code>: a comma separated list of event channel to collect along with a XPath filter expression for each. The format is <code>CHANNEL_NAME:FILTER_EXPRESSION</code> where a filter of <code>*</code> means all events. Common channels: <code>security</code>, <code>system</code> and <code>application</code>.</li> </ul> <p>Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.</p> <p>Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p>"},{"location":"2-sensors-deployment/adapters/tutorials/cloud-telemetry/","title":"Tutorial: Ingesting Telemetry from Cloud-Based External Sources","text":"<p>LimaCharlie allows for ingestion of logs or telemetry from any external source in real-time. It includes built-in parsing for popular formats, with the option to define your own for custom sources.</p> <p>There are two ways to ingest logs or telemetry from external sources:</p> <ul> <li>Run the LimaCharlie Adapter on premises or on your cloud</li> <li>Provide credentials for the destination and allow LimaCharlie cloud to connect directly (available for cloud-based Adapters)</li> </ul> <p>To connect with the cloud-based external source, first ensure you have the appropriate <code>cloudsensor.*</code> permissions.</p> <p>After the permissions have been enabled, navigate to the <code>Sensors</code> page of the web app and click <code>Add Sensor</code>.</p> <p>Choose an external source you would like to ingest logs or telemetry from, or filter the list to only include <code>Cloud &amp; External Sources</code> to see available options.</p> <p>If there is an external source you wish to connect that is not listed, you can still ingest via the LimaCharlie Adapter with self-defined parsing. Alternatively, please contact us to discuss adding this source in LimaCharlie.</p> <p>After selecting the Sensor type, choose or create an Installation Key. Then, enter the name for the sensor and provide method-specific credentials for connection.</p> <p>If the sensor you selected is cloud-based, you will see the call to action <code>Complete Cloud Installation</code>.</p> <p>Note: Sensors that support cloud to cloud communication, can also be installed by running an adapter on-prem or on cloud hosted by the customer. While it is a rare scenario, some customers might prefer that option when they do not want to share the sensor's API credentials with LimaCharlie.</p>"},{"location":"2-sensors-deployment/adapters/tutorials/google-cloud-logs/","title":"Tutorial: Ingesting Google Cloud Logs","text":"<p>With LimaCharlie, you can easily ingest Google Cloud logs for further processing and automation. This article covers the following high-level steps of shipping logs from GCP into LimaCharlie:</p> <ol> <li>Create a Log Sink to Pubsub in GCP</li> <li>Create a Subscription for the Topic</li> <li>Create a Service Account with the required permissions.</li> <li>[Optional] Create a GCE instance to run the Adapter.</li> <li>Create an Installation Key in LimaCharlie</li> <li>Run the LC Adapter to ingest the logs.</li> </ol> <p>Note: This tutorial is a synthesized version of this official GCP article.</p>"},{"location":"2-sensors-deployment/adapters/tutorials/google-cloud-logs/#step-1-create-a-log-sink","title":"Step 1: Create a Log Sink","text":"<p>In your GCP Project, or Organization, go to the Logging product and the Logs Router section.</p> <p></p> <p>Click the Create Sink button, give it a Name and Description.</p> <p>In the Sink Destination choose Cloud Pub/Sub Topic as a sink service.</p> <p>Below, select Create a Topic.</p> <p></p> <p>Give the Topic an ID and click Create Topic.</p> <p>The Topic should now be creating, which can take a few seconds.</p> <p>Click Next.</p> <p>Now you need to choose which logs you want included. Be careful selecting exactly what you want as GCP logs can get very verbose.</p> <p></p> <p>Click the Preview Logs button in the top right to be taken to the main logging interface where you can experiment with selecting the right logs.</p> <p>For this example, let's use the following log filter:</p> <pre><code>logName:cloudaudit.googleapis.com\nprotoPayload.serviceName!=\"k8s.io\"\nprotoPayload.serviceName!=\"compute.googleapis.com\"\n</code></pre> <p>This filter will include all cloudaudit logs, except some GKE and GCE logs.</p> <p>Click Next. You can optionally define an exclusion filter. Let's skip this step.</p> <p>Click Create Sink. You should get a confirmation the sink was created.</p> <p></p>"},{"location":"2-sensors-deployment/adapters/tutorials/google-cloud-logs/#step-2-create-a-subscription","title":"Step 2: Create a Subscription","text":"<p>Go to the Pubsub product.</p> <p></p> <p>Click on your new Topic.</p> <p>Click on the Create Subscription button and select Create Subscription.</p> <p></p> <p>Give this Subscription a name, you will need this name later when configuring the Adapter.</p> <p>You can leave all other options to their default. Click Create.</p>"},{"location":"2-sensors-deployment/adapters/tutorials/google-cloud-logs/#step-3-create-a-service-account","title":"Step 3: Create a Service Account","text":"<p>Head over to the IAM &amp; Admin product. Then the Service Accounts section.</p> <p></p> <p>Click Create Service Account.</p> <p>Give the new Service Account a Name and Description. Click Create and Continue.</p> <p>Select a Role. You want to select Pub/Sub Subscriber.</p> <p></p> <p>Click Continue. And finally click Done.</p> <p>This new Service Account has access to the Topic created.</p>"},{"location":"2-sensors-deployment/adapters/tutorials/google-cloud-logs/#optional-step-4-create-a-gce-instance","title":"[OPTIONAL] Step 4: Create a GCE Instance","text":"<p>This step is optional. You may already have a machine you want to run the collector from, in which case you can skip this step.</p> <p>Head over to the Compute Engine product.</p> <p></p> <p>Click the Create Instance button.</p> <p>There is a lot you can customize here, but we'll skip over the more complex aspects you don't need to worry about here.</p> <ul> <li>Give the instance a name.</li> <li>Select a zone nearby the LimaCharlie datacenter you're using.</li> <li>As a Machine Type, select e2-micro (the smallest and cheapest machine type).</li> <li>In the Identity and API access section, select the Service Account you created earlier. This will set this service account as the default identity of the machine, which in turn means you won't have to specify your credentials to the LimaCharlie Adapter we're about to run.</li> </ul> <p>Click Create. This may take a minute.</p> <p>Once created, click the SSH button to log on the machine.</p> <p></p> <p>This will bring you to a console on the machine, ready to install the Adapter.</p>"},{"location":"2-sensors-deployment/adapters/tutorials/google-cloud-logs/#step-5-create-an-installation-key-in-limacharlie","title":"Step 5: Create an Installation Key in LimaCharlie","text":"<p>In your Org in LimaCharlie, go to the Sensors &gt; Installation Keys section.</p> <p>Click the Create Installation Key button. Enter a name for the key. This name will not impact the name given to the source of the logs.</p> <p>Click on the copy-to-clipboard button next to the Adapter Key column. The value should be a UUID, keep note of it, you'll need it in the next step.</p> <p></p>"},{"location":"2-sensors-deployment/adapters/tutorials/google-cloud-logs/#step-6-run-the-adapter","title":"Step 6: Run the Adapter","text":"<p>First let's download the latest adapter for Linux.</p> <pre><code>curl -L https://downloads.limacharlie.io/adapter/linux/64 -o lc_adapter\nchmod +x lc_adapter\n</code></pre> <p>We can confirm the adapter is running as expected:</p> <pre><code>./lc_adapter\n</code></pre> <p>You should see all the options available to all the collection methods being printed to the console.</p> <p>Now let's run the adapter with all the relevant configurations, replacing the various values necessary.</p> <pre><code>./lc_adapter pubsub \\\nclient_options.identity.installation_key=YOUR_INSTALLATION_KEY \\\nclient_options.identity.oid=YOUR_LC_OID \\\nclient_options.platform=gcp \\\nsub_name=YOUR_SUBSCRIPTION_NAME \\\nproject_name=YOUR_GCP_PROJECT_NAME \\\nclient_options.sensor_seed_key=SOME_ARBITRARY_ADAPTER_NAME\n</code></pre> <p>You should see some text letting you know the adapter is connecting to LimaCharlie, and if any errors occur fetching data from pubsub.</p> <p>Within a few seconds you should see the new Sensor in your Sensor List in LimaCharlie.</p> <p>Within a minute or two you should see the events flowing in the Timeline section of this new sensor.</p> <p>That's it, you're good to go!</p> <p>The next step towards production would be to run the Adapter as a service, or within tmux/screen on the Linux host. Alternatively you could also replicate the above setup using the Docker container and a serverless platform like Cloud Run.</p> <p>For more documentation on configuring Adapters, see here.</p>"},{"location":"2-sensors-deployment/adapters/tutorials/webhook-adapter/","title":"Tutorial: Creating a Webhook Adapter","text":"<p>LimaCharlie supports webhooks as a telemetry ingestion method. Webhooks are technically cloud Adapters, as they cannot be deployed on-prem or through the downloadable Adapter binary.</p> <p>Webhook adapters are created by enabling a webhook through the <code>cloud_sensor</code> Hive feature. Webhook creation will enable a specific URL that can receive webhooks from any platform. Received data will be ingested in LimaCharlie as a Sensor, similar to an Office365 or Syslog Adapter.</p>"},{"location":"2-sensors-deployment/adapters/tutorials/webhook-adapter/#creating-a-webhook-adapter","title":"Creating a Webhook Adapter","text":"<p>Webhook adapters can be created either through the webapp, API, or CLI. Before creation, let's look at the basic webhook configuration and values necessary to build the adapter.</p> <pre><code>{\n    \"sensor_type\": \"webhook\",\n    \"webhook\": {\n        // This secret value will be part of the URL to accept your webhooks.\n        // It enables you to prevent or revoke unauthorized access to a hook.\n        \"secret\": \"some-secret-value-hard-to-predict\",\n\n        // Placeholder for generic webhook signature validation.\n        // If you require a specific format, please get in touch with us.\n        \"signature_secret\": \"\",\n        \"signature_header\": \"\",\n        \"signature_scheme\": \"\",\n\n        // Format with which the data is ingested in LC.\n        \"client_options\": {\n            // Provide your own name for the webhook adapter\n            \"hostname\": \"&lt;any_name&gt;\",\n            \"identity\": {\n                // Provide the OID of the organization you wish to send to\n                \"oid\": \"&lt;oid&gt;\",\n                // Provide the installation key to be used for the adapter\n                \"installation_key\": \"&lt;installation_key&gt;\"\n            },\n            \"platform\": \"json\",\n            \"sensor_seed_key\": \"&lt;any-super-secret-seed-key&gt;\"\n        }\n    }\n}\n</code></pre> <p>When the above configuration is provided to LimaCharlie, a webhook adapter will appear and be available for webhook event ingestion. Here's an example of creating the above record through the LimaCharlie CLI:</p> <pre><code>echo '{\"sensor_type\": \"webhook\", \"webhook\": {\"secret\": \"some-secret-value-hard-to-predict\", \"signature_secret\": \"\", \"signature_header\": \"\", \"signature_scheme\": \"\", \"client_options\": {\"hostname\": \"&lt;any_name&gt;\", \"identity\": {\"oid\": \"&lt;oid&gt;\", \"installation_key\": \"&lt;installation_key&gt;\"}, \"platform\": \"json\", \"sensor_seed_key\": \"test-webhook\"}}}' | limacharlie hive set cloud_sensor --key my-webhook --data -\n</code></pre> <p>After creating the webhook, you will be provided with a geo-dependent URL, respective to your LimaCharlie Organization location. You can also retrieve your webhook URLs with either of the following commands:</p> <ul> <li>REST API: getOrgURLs</li> <li>Python SDK:</li> </ul> <pre><code>python3 -c \"import limacharlie; print(limacharlie.Manager().getOrgURLs()['hooks'])\"\n</code></pre>"},{"location":"2-sensors-deployment/adapters/tutorials/webhook-adapter/#using-the-webhook-adapter","title":"Using the webhook adapter","text":"<p>After capturing the webhook URL in the previous step, only a few more pieces of data are necessary to construct the webhook ingestion.</p> <p>Let's assume the returned domain looks like <code>9157798c50af372c.hook.limacharlie.io</code>, the format of the URL would be:</p> <p><code>https://9157798c50af372c.hook.limacharlie.io/OID/HOOKNAME/SECRET</code>, where:</p> <ul> <li>OID is the Organization OID provided in the configuration above.</li> <li>HOOKNAME is the name of the hook provided in the configuration above.</li> <li>SECRET is the secret value provided in the configuration. You can provide the secret value in the URL or as an HTTP header named <code>lc-secret</code>.</li> </ul>"},{"location":"2-sensors-deployment/adapters/tutorials/webhook-adapter/#supported-webhook-format","title":"Supported Webhook Format","text":"<p>When sending data via POST requests to the URL, the body of your request is expected to be one or many JSON events. Supported formats include:</p> <ul> <li> <p>Simple JSON object:</p> </li> <li> <p><code>{\"some\":\"data\"}</code></p> </li> <li> <p>List of JSON objects:</p> </li> <li> <p><code>[{\"some\":\"data\"},{\"some\":\"data\"}]</code></p> </li> <li>Newline separated JSON objects like:</li> </ul> <pre><code>{\"some\":\"data\"}\n{\"some\":\"data\"}\n{\"some\":\"data\"}\n</code></pre> <p>Or, one of the above, but compressed using gzip.</p> <p>With the completed webhook URL, you can begin sending events and will see them in the Timeline for your webhook Adapater.</p>"},{"location":"2-sensors-deployment/adapters/types/1password/","title":"1Password","text":"<p>1Password provides an events API to fetch audit logs. Events can be ingested directly via a cloud-to-cloud or CLI Adapter.</p> <p>See 1Password's official API documentation here.</p> <p>1Password telemetry can be addressed via the <code>1password</code> platform.</p>"},{"location":"2-sensors-deployment/adapters/types/1password/#adapter-deployment","title":"Adapter Deployment","text":"<p>1Password events can be collected directly from the 1Password API, via a cloud-to-cloud Adapter, or via the CLI Adapter. 1Password adapters require the following options:</p> <ul> <li><code>token</code>: the API token provisioned through 1password.</li> <li><code>endpoint</code>: the API endpoint to use, depending on your 1password plan, see their documentation below.</li> </ul> <p>You can generate an access token from 1Password at this link.</p>"},{"location":"2-sensors-deployment/adapters/types/1password/#cloud-to-cloud-adapter","title":"Cloud-to-Cloud Adapter","text":"<p>LimaCharlie offers a 1Password guided configuration in the web UI. From your 1Password instance, you will need:</p> <ul> <li>1Password API Access Token</li> <li> <p>Endpoint; one of the following:</p> </li> <li> <p>1Password.com (Business)</p> </li> <li>1Password.com (Enterprise)</li> <li>1Password.ca</li> <li>1Password.eu</li> </ul> <p>After providing an Installation Key, provide the required values and LimaCharlie will establish a Cloud Adapter for 1Password events</p>"},{"location":"2-sensors-deployment/adapters/types/1password/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<p>LimaCharlie IaC Adapter can also be used to ingest 1Password events.</p> <pre><code># 1Password Specific Docs: https://docs.limacharlie.io/docs/adapter-types-1password\n\nsensor_type: \"1password\"\n  1password:\n    token: \"hive://secret/your-1password-api-token-secret\"\n    endpoint: \"business\"  # or \"enterprise\", \"ca\", \"eu\"\n    client_options:\n      identity:\n        oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n        installation_key: \"YOUR_LC_INSTALLATION_KEY_1PASSWORD\"\n      hostname: \"1password-audit-adapter\"\n      platform: \"json\"\n      sensor_seed_key: \"1password-sensor-unique-name\"\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/atlassian/","title":"Atlassian","text":"<p>Atlassian makes a suite of products that help foster enterprise work management, IT service management, and Agile development. Atlassian's products include:</p> <ul> <li>Bitbucket</li> <li>Confluence</li> <li>Jira Work Management (this includes a suite of products, include Jira Software, Service Management, and Product Discovery)</li> <li>Opsgenie</li> <li>Trello</li> </ul> <p>Atlassian has extensive documentation for both their Cloud and Data Center/Server editions.</p> <p>Currently, LimaCharlie supports ingestion of Jira events. Jira events can be ingested in LimaCharlie via a <code>json</code> webhook Adapter.</p>"},{"location":"2-sensors-deployment/adapters/types/atlassian/#adapter-deployment","title":"Adapter Deployment","text":"<p>Jira events are ingested via a cloud-to-cloud webhook Adapter, configured to receive JSON events. In the creation of the Adapter, we map fields directly to the expected Atlassian events. The steps of creating this Adapter and enabling the input include:</p> <ol> <li>Creating the webhook Adapter via the LimaCharlie CLI.</li> <li>Discovering the URL created for the webhook Adapter.</li> <li>Providing the completed URL to Jira for webhook events.</li> </ol>"},{"location":"2-sensors-deployment/adapters/types/atlassian/#1-creating-the-limacharlie-webhook-adapter","title":"1. Creating the LimaCharlie Webhook Adapter","text":"<p>The following steps are modified from the generic webhook adapter creation documentation, found here.</p> <p>Creating a Webhook Adapter requires a set of parameters, including organization ID, Installation Key, platform, and mapping details. The following configuration has been provided to configure a webhook Adapter for ingesting Jira events:</p> <pre><code>{\n    \"sensor_type\": \"webhook\",\n    \"webhook\": {\n       \"secret\": \"atlassian-jira-secret\",\n        \"client_options\": {\n            \"hostname\": \"atlassian-jira\",\n            \"identity\": {\n                \"oid\": \"&lt;your_oid&gt;\",\n                \"installation_key\": \"&lt;your_installation_key&gt;\"\n            },\n            \"platform\": \"json\",\n            \"sensor_seed_key\": \"atlassian-jira-super-secret-key\",\n            \"mapping\" : {\n                \"event_type_path\" : \"webhookEvent\",\n                \"event_time_path\" : \"timestamp\"\n            }\n        }\n    }\n}\n</code></pre> <p>The mapping above is based on the expected webhook event from Jira. Note that in the mapping above, we make the following change:</p> <ul> <li><code>event_type_path</code> is mapped to the <code>webhookEvent</code> field</li> <li><code>event_time_path</code> is mapped to the <code>timestamp</code> field</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/atlassian/#2-building-the-webhook-url","title":"2. Building the Webhook URL","text":"<p>After creating the webhook, you'll need to retrieve the webhook URL from the Get Org URLs API call. You'll need the following information to complete the Webhook URL:</p> <ul> <li>Organization ID</li> <li>Webhook name (from the config)</li> <li>Secret (from the config)</li> </ul> <p>Let's assume the returned domain looks like <code>9157798c50af372c.hook.limacharlie.io</code>, the format of the URL would be:</p> <p><code>https://9157798c50af372c.hook.limacharlie.io/OID/HOOKNAME/SECRET</code></p> <p>Note that the <code>secret</code> value can be provided in the webhook URL or as an HTTP header named <code>lc-secret</code>.</p>"},{"location":"2-sensors-deployment/adapters/types/atlassian/#3-providing-the-url-to-jira-for-webhook-events","title":"3. Providing the URL to Jira for Webhook Events","text":"<p>Within the Atlassian Admin window, navigate to Jira Administration &gt; Jira settings &gt; Advanced &gt; WebHooks. Select + Create a WebHook.</p> <p></p> <ul> <li>Choose an appropriate name to differentiate that this is a LimaCharlie webhook</li> <li>Provide the webhook URL (see step 2 above)</li> <li>(optional) Provide a description</li> <li>(optional) Provide a JQL query to select certain issues that will trigger Webhooks. The default selection is All issues.</li> </ul> <p>Within the WebHook creation dialog, you can also select the granularity of events to send via the WebHook. High-level event categories include:</p> <ul> <li>Issues</li> <li>Issue events</li> <li>Worklog</li> <li>Comment(s)</li> <li>Entity Properties</li> <li>Attachment</li> <li>Issue Link</li> <li>Filter</li> <li>User-related</li> <li>Jira configuration</li> <li>Project-related</li> <li>Jira Software-related</li> </ul> <p>By default, issues will be sent as JSON, which is natively accepted by LimaCharlie. Save your WebHook configuration, and perform an action that you know will trigger the event.</p> <p>If configured properly, you should see your Jira events in LimaCharlie. Here's an example event:</p> <pre><code>{\n  \"event\": {\n    \"issue\": {\n      \"fields\": {\n        \"aggregateprogress\": {\n          \"progress\": 0,\n          \"total\": 0\n        },\n        \"aggregatetimeestimate\": null,\n        \"aggregatetimeoriginalestimate\": null,\n        \"aggregatetimespent\": null,\n        \"assignee\": null,\n        \"attachment\": [],\n        \"comment\": {\n          \"comments\": [],\n          \"maxResults\": 0,\n          \"self\": \"https://###.atlassian.net...\",\n          \"startAt\": 0,\n          \"total\": 0\n        },\n        \"components\": [],\n        \"created\": \"2023-12-02T11:16:02.927-0600\",\n        \"creator\": {\n          \"accountId\": \"...\",\n          \"accountType\": \"atlassian\",\n          \"active\": true,\n          \"avatarUrls\": {\n            \"16x16\": \"...\",\n            \"24x24\": \"...\",\n            \"32x32\": \"...\",\n            \"48x48\": \"...\"\n          },\n          \"displayName\": \"Matt Bromiley\",\n          \"self\": \"https://###.atlassian.net...\",\n          \"timeZone\": \"America/Chicago\"\n        },\n        \"customfield_10001\": null,\n        \"customfield_10002\": null,\n        \"customfield_10003\": null,\n        \"customfield_10004\": null,\n        \"customfield_10005\": null,\n        \"customfield_10006\": null,\n        \"customfield_10007\": null,\n        \"customfield_10008\": null,\n        \"customfield_10009\": null,\n        \"customfield_10010\": null,\n        \"customfield_10014\": null,\n        \"customfield_10015\": null,\n        \"customfield_10016\": null,\n        \"customfield_10017\": null,\n        \"customfield_10018\": {\n          \"hasEpicLinkFieldDependency\": false,\n          \"nonEditableReason\": {\n            \"message\": \"The Parent Link is only available to Jira Premium users.\",\n            \"reason\": \"PLUGIN_LICENSE_ERROR\"\n          },\n          \"showField\": false\n        },\n        \"customfield_10019\": \"0|hzzzzz:\",\n        \"customfield_10020\": null,\n        \"customfield_10021\": null,\n        \"customfield_10022\": null,\n        \"customfield_10023\": null,\n        \"customfield_10024\": null,\n        \"customfield_10025\": null,\n        \"customfield_10026\": null,\n        \"customfield_10027\": null,\n        \"customfield_10028\": null,\n        \"customfield_10029\": null,\n        \"customfield_10030\": null,\n        \"description\": null,\n        \"duedate\": null,\n        \"environment\": null,\n        \"fixVersions\": [],\n        \"issuelinks\": [],\n        \"issuerestriction\": {\n          \"issuerestrictions\": {},\n          \"shouldDisplay\": true\n        },\n        \"issuetype\": {\n          \"avatarId\": 10318,\n          \"description\": \"Tasks track small, distinct pieces of work.\",\n          \"entityId\": \"e44d856a-3c4b-4a5e-bc67-c3c93227fe18\",\n          \"hierarchyLevel\": 0,\n          \"iconUrl\": \"https://###.atlassian.net/rest/api/...\",\n          \"id\": \"10001\",\n          \"name\": \"Task\",\n          \"self\": \"https://###.atlassian.net/rest/api/...\",\n          \"subtask\": false\n        },\n        \"labels\": [],\n        \"lastViewed\": \"2023-12-02T17:18:42.192-0600\",\n        \"priority\": {\n          \"iconUrl\": \"https://###.atlassian.net/rest/api/...\",\n          \"id\": \"3\",\n          \"name\": \"Medium\",\n          \"self\": \"https://###.atlassian.net/rest/api/...\"\n        },\n        \"progress\": {\n          \"progress\": 0,\n          \"total\": 0\n        },\n        \"project\": {\n          \"avatarUrls\": {\n            \"16x16\": \"...\",\n            \"24x24\": \"...\",\n            \"32x32\": \"...\",\n            \"48x48\": \"...\"\n          },\n          \"id\": \"10000\",\n          \"key\": \"KAN\",\n          \"name\": \"My Kanban Project\",\n          \"projectTypeKey\": \"software\",\n          \"self\": \"https://###.atlassian.net/rest/api/...\",\n          \"simplified\": true\n        },\n        \"reporter\": {\n          \"accountId\": \"...\",\n          \"accountType\": \"atlassian\",\n          \"active\": true,\n          \"avatarUrls\": {\n            \"16x16\": \"...\",\n            \"24x24\": \"...\",\n            \"32x32\": \"...\",\n            \"48x48\": \"...\"\n          },\n          \"displayName\": \"Matt Bromiley\",\n          \"self\": \"...\",\n          \"timeZone\": \"America/Chicago\"\n        },\n        \"resolution\": null,\n        \"resolutiondate\": null,\n        \"security\": null,\n        \"status\": {\n          \"description\": \"\",\n          \"iconUrl\": \"https://###.atlassian.net/\",\n          \"id\": \"10000\",\n          \"name\": \"To Do\",\n          \"self\": \"https://###.atlassian.net/rest/api/...\",\n          \"statusCategory\": {\n            \"colorName\": \"blue-gray\",\n            \"id\": 2,\n            \"key\": \"new\",\n            \"name\": \"To Do\",\n            \"self\": \"https://###.atlassian.net/rest/api/...\"\n          }\n        },\n        \"statuscategorychangedate\": \"2023-12-02T11:16:03.211-0600\",\n        \"subtasks\": [],\n        \"summary\": \"sample issue\",\n        \"timeestimate\": null,\n        \"timeoriginalestimate\": null,\n        \"timespent\": null,\n        \"timetracking\": {},\n        \"updated\": \"2023-12-02T11:16:03.129-0600\",\n        \"versions\": [],\n        \"votes\": {\n          \"hasVoted\": false,\n          \"self\": \"https://###.atlassian.net/rest/api/...\",\n          \"votes\": 0\n        },\n        \"watches\": {\n          \"isWatching\": true,\n          \"self\": \"https://###.atlassian.net/rest/api/...\",\n          \"watchCount\": 1\n        },\n        \"worklog\": {\n          \"maxResults\": 20,\n          \"startAt\": 0,\n          \"total\": 0,\n          \"worklogs\": []\n        },\n        \"workratio\": -1\n      },\n      \"id\": \"10012\",\n      \"key\": \"KAN-13\",\n      \"self\": \"https://###.atlassian.net/rest/api/...\"\n    },\n    \"timestamp\": 1701559124723,\n    \"user\": {\n      \"accountId\": \"...\",\n      \"accountType\": \"atlassian\",\n      \"active\": true,\n      \"avatarUrls\": {\n        \"16x16\": \"...\",\n        \"24x24\": \"...\",\n        \"32x32\": \"...\",\n        \"48x48\": \"...\"\n      },\n      \"displayName\": \"Matt Bromiley\",\n      \"self\": \"...\",\n      \"timeZone\": \"America/Chicago\"\n    },\n    \"webhookEvent\": \"jira:issue_deleted\"\n  },\n  \"routing\": {...},\n  \"ts\": \"2023-12-02 23:18:44\"\n}\n</code></pre> <p>Note that the Jira \"webhookEvent\" becomes the event type, also represented in the LimaCharlie Adapter timeline.</p>"},{"location":"2-sensors-deployment/adapters/types/aws-cloudtrail/","title":"AWS CloudTrail","text":"<p>AWS CloudTrail logs allow you to monitor AWS deployments. CloudTrail logs can provide granular visibility into AWS instances and can be used within D&amp;R rules to identify AWS abuse.</p> <p>This Adapter allows you to ingest AWS CloudTrail events via either an S3 bucket or SQS message queue.</p> <p>CloudTrail events can be addressed in LimaCharlie as the <code>aws</code> platform.</p>"},{"location":"2-sensors-deployment/adapters/types/aws-cloudtrail/#adapter-deployment","title":"Adapter Deployment","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/aws-cloudtrail/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>CloudTrail logs can be collected via a cloud-to-cloud Adapter, or via the CLI Adapter. Furthermore, within each option, there is a choice of collecting logs from an S3 bucket or an SQS message queue.</p>"},{"location":"2-sensors-deployment/adapters/types/aws-cloudtrail/#cloud-to-cloud-adapter","title":"Cloud-to-Cloud Adapter","text":"<p>Within the LimaCharlie web application, you can create an AWS CloudTrail Cloud Connector using the <code>+ Add Sensor</code> option.</p> <p></p> <p>After providing an Installation Key, you will be guided through connecting either an S3 bucket or SQS queue to ingest AWS CloudTrail events.</p>"},{"location":"2-sensors-deployment/adapters/types/aws-cloudtrail/#collecting-aws-cloudtrail-logs-via-an-s3-bucket","title":"Collecting AWS CloudTrail Logs via an S3 Bucket","text":"<p>If collecting CloudTrail logs via an S3 bucket, you will need the following parameters:</p> <ul> <li><code>bucket_name</code> - The name of the S3 bucket holding the data)</li> <li><code>secret_key</code> - The API key for AWS that has access to the respective bucket.</li> <li><code>access_key</code> - The AWS access key for the API key</li> </ul> <p>The following sample configuration can be used to create an S3 CLI Adapter for AWS CloudTrail events:</p> <pre><code>s3:\n  client_options:\n    hostname: aws-cloudtrail-logs\n    identity:\n      installation_key: &lt;INSTALLATION_KEY&gt;\n      oid: &lt;OID&gt;\n    platform: aws\n    sensor_seed_key: super-special-seed-key\n  bucket_name: &lt;S3_BUCKET_NAME&gt;\n  secret_key: &lt;S3_SECRET_KEY&gt;\n  access_key: &lt;S3_ACCESS_KEY&gt;\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/aws-cloudtrail/#collecting-aws-cloudtrail-logs-via-an-sqs-queue","title":"Collecting AWS CloudTrail Logs via an SQS Queue","text":"<p>If collecting CloudTrail logs via an SQS queue, you will need the following parameters:</p> <ul> <li><code>secret_key</code> - The API key for AWS that has access to the respective bucket.</li> <li><code>access_key</code> - The AWS access key for the API key</li> <li><code>region</code> - The AWS region where the SQS instance lives</li> <li><code>queue_url</code> - The URL to the SQS instance</li> </ul> <p>The following sample configuration can be used to create an SQS CLI Adapter for AWS CloudTrail events:</p> <pre><code>sqs:\n  client_options:\n    hostname: aws-cloudtrail-logs\n    identity:\n      installation_key: &lt;INSTALLATION_KEY&gt;\n      oid: &lt;OID&gt;\n    platform: aws\n    sensor_seed_key: super-special-seed-key\n  region: &lt;SQS_REGION&gt;\n  secret_key: &lt;SQS_SECRET_KEY&gt;\n  access_key: &lt;SQS_ACCESS_KEY&gt;\n  queue_url: &lt;SQS_QUEUE_URL&gt;\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/aws-guardduty/","title":"AWS GuardDuty","text":""},{"location":"2-sensors-deployment/adapters/types/aws-guardduty/#overview","title":"Overview","text":"<p>This Adapter allows you to ingest AWS GuardDuty events via either an S3 bucket or SQS message queue.</p> <p>AWS GuardDuty helps you protect your AWS accounts with intelligent threat detection.</p> <p>Telemetry Platform: <code>guard_duty</code></p>"},{"location":"2-sensors-deployment/adapters/types/aws-guardduty/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/aws-guardduty/#adapter-specific-options","title":"Adapter-specific Options","text":""},{"location":"2-sensors-deployment/adapters/types/aws-guardduty/#collecting-aws-guardduty-logs-via-an-s3-bucket","title":"Collecting AWS GuardDuty Logs via an S3 Bucket","text":"<p>If collecting GuardDuty logs via an S3 bucket, you will need the following parameters:</p> <ul> <li><code>bucket_name</code> - The name of the S3 bucket holding the data)</li> <li><code>secret_key</code> - The API key for AWS that has access to the respective bucket.</li> <li><code>access_key</code> - The AWS access key for the API key</li> </ul> <p>The following command will create an Adapter using the (1) Adapter binary and (2) logs stored in an S3 bucket:</p> <pre><code>./lc_adapter s3 client_options.identity.installation_key=&lt;INSTALLATION_KEY&gt; \\\nclient_options.identity.oid=&lt;OID&gt; \\\nclient_options.platform=guard_duty \\\nbucket_name=lc-ct-test \\\naccess_key=YYYYYYYYYY \\\nsecret_key=XXXXXXXX \\\nclient_options.hostname=guardduty-logs\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/aws-guardduty/#collecting-aws-guardduty-logs-via-an-sqs-queue","title":"Collecting AWS GuardDuty Logs via an SQS Queue","text":"<p>If collecting GuardDuty logs via an SQS queue, you will need the following parameters:</p> <ul> <li><code>secret_key</code> - The API key for AWS that has access to the respective bucket.</li> <li><code>access_key</code> - The AWS access key for the API key</li> <li><code>region</code> - The AWS region where the SQS instance lives</li> <li><code>queue_url</code> - The URL to the SQS instance</li> </ul> <p>The following command will create an Adapter using the (1) Adapter binary and (2) logs stored in an SQS queue:</p> <pre><code>./lc_adapter sqs client_options.identity.installation_key=&lt;INSTALLATION_KEY&gt; \\\nclient_options.identity.oid=&lt;OID&gt; \\\nclient_options.platform=guard_duty \\\nclient_options.sensor_seed_key=&lt;SENSOR_SEED_KEY&gt; \\\nclient_options.hostname=guardduty-logs \\\naccess_key=YYYYYYYYYY \\\nsecret_key=XXXXXXXX \\\nqueue_url=&lt;QUEUE_URL&gt; \\\nregion=&lt;AWS-REGION&gt;\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/aws-guardduty/#guided-deployment","title":"Guided Deployment","text":"<p>Within the LimaCharlie web application, you can create an AWS GuardDuty Cloud Connector using the <code>+ Add Sensor</code> option.</p> <p></p>"},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/","title":"Azure Event Hub","text":""},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to an Azure Event Hub to fetch structured data stored there.</p> <p>Azure Event Hubs are fully managed, real-time data ingestion services that allow for event streaming from various Microsoft Azure services. LimaCharlie can ingest either structured known data (such as JSON or XML) or known Microsoft data types, including:</p> <ul> <li>Azure Monitor (Platform: <code>azure_monitor</code>)</li> <li>Entra ID [formerly Azure AD] (Platform: <code>azure_ad</code>)</li> <li>Microsoft Defender (Platform: <code>msdefender</code>)</li> </ul> <p>Documentation for creating an event hub can be found here here.</p>"},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/#configuring-data-streams","title":"Configuring Data Streams","text":"<p>When using Azure Event Hub, you must configure the source service to stream data to your Event Hub. The data you receive depends entirely on what you configure in Azure.</p>"},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/#for-entra-id-azure_ad","title":"For Entra ID (<code>azure_ad</code>)","text":"<p>Configure Azure AD Diagnostic Settings to stream to your Event Hub:</p> <ol> <li>In Azure Portal, go to Entra ID &gt; Diagnostic settings</li> <li>Add a diagnostic setting and select your Event Hub</li> <li>Choose which logs to stream (SignInLogs, AuditLogs, etc.)</li> </ol> <p>See: Stream Entra ID logs to Event Hub</p>"},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/#for-microsoft-defender-msdefender","title":"For Microsoft Defender (<code>msdefender</code>)","text":"<p>Configure Defender Streaming API to export raw telemetry:</p> <ol> <li>In Microsoft Defender portal, go to Settings &gt; Streaming API</li> <li>Add your Event Hub connection</li> <li>Select which event types to stream (DeviceProcessEvents, DeviceNetworkEvents, etc.)</li> </ol> <p>See: Defender XDR streaming event types</p>"},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/#for-azure-monitor-azure_monitor","title":"For Azure Monitor (<code>azure_monitor</code>)","text":"<p>Configure Diagnostic Settings on individual Azure resources:</p> <ol> <li>Navigate to the Azure resource you want to monitor</li> <li>Go to Diagnostic settings and add a setting</li> <li>Select your Event Hub and choose logs/metrics to stream</li> </ol> <p>See: Stream Azure platform logs to Event Hub</p>"},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/#adapter-specific-options","title":"Adapter-specific Options","text":"<ul> <li>If using a binary Adapter, <code>azure_event_hub</code> will be the ingestion type.</li> <li><code>connection_string</code> - The connection string provided in Azure for connecting to the Azure Event Hub, including the <code>EntityPath=...</code> at the end which identifies the Hub Name (this component is sometimes now shown in the connection string provided by Azure).</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/#guided-deployment","title":"Guided Deployment","text":"<p>Azure Event Hub data can be pulled via either a cloud or binary Adapter.</p>"},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/#cloud-to-cloud","title":"Cloud-to-Cloud","text":"<p>LimaCharlie offers several helpers within the webapp that allow you to ingest Microsoft data, such as Entra ID or Microsoft Defender, from Azure Event Hubs.</p>"},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/#cli-deployment","title":"CLI Deployment","text":"<p>The following example configures a binary Adapter to collect Microsoft Defender data from an Azure Event Hub:</p> <pre><code>./lc_adapter azure_event_hub client_options.identity.installation_key=&lt;INSTALLATION_KEY&gt; \\\nclient_options.identity.oid=&lt;OID&gt; \\\nclient_options.platform=msdefender \\\nclient_options.sensor_seed_key=&lt;SENSOR_SEED_KEY&gt; \\\nclient_options.hostname=&lt;HOSTNAME&gt; \\\n\"connection_string=Endpoint=sb://mynamespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=fnaaaaaaaaaaaaaaak0g54alYbbbbbbbbbbbbbbbALQ=;EntityPath=lc-stream\"\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/azure-event-hub/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Azure Event Hub Specific Docs: https://docs.limacharlie.io/docs/adapter-types-azure-event-hub\n\nsensor_type: \"azure_event_hub\"\n  azure_event_hub:\n    connection_string: \"Endpoint=sb://your-eventhub-namespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=YOUR_EVENT_HUB_SHARED_ACCESS_K\n  EY_HERE;EntityPath=your-actual-event-hub-name\"\n    client_options:\n      identity:\n        oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n        installation_key: \"YOUR_LC_INSTALLATION_KEY_FOR_AZURE\"\n      hostname: \"azure-eventhub-adapter\"\n      platform: \"json\"\n      sensor_seed_key: \"azure-eventhub-prod-sensor\"\n      indexing: []\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/canarytokens/","title":"Canarytokens","text":"<p>Canarytokens are a free, quick, painless way to help defenders discover they've been breached (by having attackers announce themselves). Canarytokens are digital traps, or tripwires, that can be placed in an organization's network as a \"lure\" for adversaries. When actioned against, canaries will fire an alert, that can be forwarded to LimaCharlie.</p> <p>Canarytokens can be ingested in LimaCharlie via a Webhook Adapter, and are recognized as the <code>canary_token</code> platform.</p>"},{"location":"2-sensors-deployment/adapters/types/canarytokens/#a-little-more","title":"A Little More","text":"<p>LimaCharlie published a blog post in April 2023 to discuss the Canarytoken integration. You can read more about that here.</p>"},{"location":"2-sensors-deployment/adapters/types/canarytokens/#adapter-deployment","title":"Adapter Deployment","text":"<p>Canarytoken alerts are ingested via a cloud-to-cloud webhook Adapter configured to receive JSON events. The LimaCharlie platform has pre-built mapping for Canarytoken alerts. A Canarytokens Adapter can be initially deployed in two ways:</p> <ul> <li>Via the LimaCharlie web UI</li> <li>Via the LimaCharlie CLI</li> </ul> <p>Regardless of which method utilized, Steps 2 and 3 will still be the same.</p>"},{"location":"2-sensors-deployment/adapters/types/canarytokens/#1a-initial-deployment-via-the-limacharlie-web-ui","title":"1a. Initial deployment via the LimaCharlie web UI","text":"<p>Within the LimaCharlie UI, navigate to Sensors &gt; Sensors List &gt; + Add Sensor. Select the Canary Token option.</p> <p>After selecting or creating an Installation Key, the web UI will ask you to name the Adapter and select a Secret value.</p> <p>Click Complete Cloud Installation to create the cloud-to-cloud Adapter. Proceed to step 2 to continue.</p>"},{"location":"2-sensors-deployment/adapters/types/canarytokens/#1b-initial-deployment-via-the-limacharlie-cli","title":"1b. Initial deployment via the LimaCharlie CLI","text":"<p>A Canarytokens Adapter can be deployed via the LimaCharlie CLI. The following step is modified from the generic Webhook Adapter created documentation, found here.</p> <p>The following configuration can be modified to easily configure a Webhook Adapter for receiving Canarytokens events.</p> <pre><code>{\n    \"sensor_type\": \"webhook\",\n    \"webhook\": {\n       \"secret\": \"canarytoken-secret\",\n        \"client_options\": {\n            \"hostname\": \"canarytokens\",\n            \"identity\": {\n                \"oid\": \"&lt;your_oid&gt;\",\n                \"installation_key\": \"&lt;your_installation_key&gt;\"\n            },\n            \"platform\": \"canary_token\",\n            \"sensor_seed_key\": \"canary-super-secret-key\",\n            \"mapping\" : {\n                \"event_type_path\" : {{ 'Canarytoken Hit' }}\n            }\n        }\n    }\n}\n</code></pre> <p>Note that in the mapping above, the <code>event_type_path</code> field is set to a static string of <code>Canarytoken Hit</code>. You can change this to any desired value.</p> <p>To create this webhook adapter, run the following command, replacing <code>&lt;json_config_file&gt;</code> with the name of the config file from above:</p> <p><code>limacharlie hive set cloud_sensor --key canarytoken --data &lt;json_config_file&gt;</code></p>"},{"location":"2-sensors-deployment/adapters/types/canarytokens/#2-building-the-webhook-url","title":"2. Building the Webhook URL","text":"<p>After creating the webhook, you'll need to retrieve the webhook URL from the Get Org URLs API call. You'll need the following information to complete the Webhook URL:</p> <ul> <li>Organization ID</li> <li>Webhook name (from the config)</li> <li>Secret (from the config)</li> </ul> <p>Let's assume the returned domain looks like <code>9157798c50af372c.hook.limacharlie.io</code>, the format of the URL would be:</p> <p><code>https://9157798c50af372c.hook.limacharlie.io/OID/HOOKNAME/SECRET</code></p> <p>Note that the <code>secret</code> value can be provided in the webhook URL or as an HTTP header named <code>lc-secret</code>.</p>"},{"location":"2-sensors-deployment/adapters/types/canarytokens/#3-configuring-the-canaryalert-webhook-output","title":"3. Configuring the Canaryalert Webhook Output","text":"<p>Navigate to the Canarytokens generate page to create your token of choice.</p> <p></p> <p>Utilize the URL from Step 2 as the webhook URL. Provide a reminder note, which will also appear in the Canarytoken alert when tripped. Click Create my Canarytoken, which will provide you the content related to the selected token. When the Canarytoken is tripped, a webhook alert will be forwarded to the LimaCharlie Adapter.</p>"},{"location":"2-sensors-deployment/adapters/types/carbon-black/","title":"VMWare Carbon Black","text":""},{"location":"2-sensors-deployment/adapters/types/carbon-black/#overview","title":"Overview","text":"<p>LimaCharlie can ingest Carbon Black events from a number of storage locations. Typically, an organization would export Carbon Black data via the API to a storage mechanism, such as an S3 bucket, which would then be ingested by LimaCharlie.</p> <p>Carbon Black events are observable in Detection &amp; Response rules via the <code>carbon_black</code> platform.</p>"},{"location":"2-sensors-deployment/adapters/types/carbon-black/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/carbon-black/#config-file","title":"Config File","text":"<p>VMWare Carbon Black data can be exported via the API to an S3 bucket, and then ingested with LimaCharlie. The following command utilizes a CLI Adapter to ingest these events</p> <pre><code>./lc_adapter s3 client_options.identity.installation_key=&lt;INSTALLATION_KEY&gt; \\\nclient_options.identity.oid=&lt;OID&gt; \\\nclient_options.platform=carbon_black \\\nclient_options.sensor_seed_key=tests3 \\\nbucket_name=lc-cb-test \\\naccess_key=YYYYYYYYYY \\\nsecret_key=XXXXXXXX  \\\n\"prefix=events/org_key=NKZAAAEM/\"\n</code></pre> <p>Here's a breakdown of the above example:</p> <ul> <li><code>lc_adapter</code>: simply the CLI Adapter.</li> <li><code>s3</code>: the data will be collected from an AWS S3 bucket.</li> <li><code>client_options.identity.installation_key=....</code>: the Installation Key value from LimaCharlie.</li> <li><code>client_options.identity.oid=....</code>: the Organization ID from LimaCharlie the installation key above belongs to.</li> <li><code>client_options.platform=carbon_black</code>: this indicates the data received will be Carbon Black events from their API.</li> <li><code>client_options.sensor_seed_key=....</code>: this is the value that identifies this instance of the Adapter. Record it to re-use the Sensor IDs generated for the Carbon Black sensors from this Adapter later if you have to re-install the Adapter.</li> <li><code>bucket_name:....</code>: the name of the S3 bucket holding the data.</li> <li><code>access_key:....</code>: the AWS Access Key for the API key below.</li> <li><code>secret_key:....</code>: the API key for AWS that has access to this bucket.</li> <li><code>prefix=....</code>: the file/directory name prefix that holds the Carbon Black data within the bucket.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/cato/","title":"Cato","text":""},{"location":"2-sensors-deployment/adapters/types/cato/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to the Cato API to fetch logs from the events feed.</p>"},{"location":"2-sensors-deployment/adapters/types/cato/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/cato/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>Adapter Type: <code>cato</code></p> <ul> <li><code>apikey</code>: your CATO API key/token</li> <li><code>accountid</code>: your CATO account ID</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/cato/#manual-deployment","title":"Manual Deployment","text":"<p>Adapter downloads can be found here.</p> <pre><code>chmod +x /path/to/lc_adapter\n\n/path/to/lc_adapter cato client_options.identity.installation_key=$INSTALLATION_KEY \\\nclient_options.identity.oid=$OID \\\nclient_options.platform=json \\\nclient_options.sensor_seed_key=$SENSOR_NAME \\\nclient_options.hostname=$SENSOR_NAME \\\napikey=$API_KEY \\\naccountid=$ACCOUNT_ID\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/cato/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/crowdstrike/","title":"CrowdStrike Falcon Cloud","text":""},{"location":"2-sensors-deployment/adapters/types/crowdstrike/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to CrowdStrike Falcon Cloud to stream events as they happen in the CrowdStrike Falcon Console.</p>"},{"location":"2-sensors-deployment/adapters/types/crowdstrike/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/crowdstrike/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>Adapter Type: <code>falconcloud</code></p> <ul> <li><code>client_id</code>: your CrowdStrike Falcon Cloud client ID</li> <li><code>client_secret</code>: your CrowdStrike Falcon Cloud client secret</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/crowdstrike/#manual-deployment","title":"Manual Deployment","text":"<p>Adapter downloads can be found here.</p> <pre><code>chmod +x /path/to/lc_adapter\n\n/path/to/lc_adapter falconcloud client_options.identity.installation_key=$INSTALLATION_KEY \\\nclient_options.identity.oid=$OID \\\nclient_options.platform=json \\\nclient_options.sensor_seed_key=$SENSOR_NAME \\\nclient_options.hostname=$SENSOR_NAME \\\nclient_options.mappings.event_type_path=metadata/eventType \\\nclient_id=$CLIENT_ID \\\nclient_secret=$CLIENT_SECRET\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/crowdstrike/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># CrowdStrike Falcon (\"falconcloud\") Specific Docs: https://docs.limacharlie.io/docs/adapter-types-crowdstrike\n\nsensor_type: \"falconcloud\"\n  falconcloud:\n    client_id: \"YOUR_CROWDSTRIKE_FALCON_API_CLIENT_ID\"\n    client_secret: \"YOUR_CROWDSTRIKE_FALCON_API_CLIENT_SECRET\"\n    client_options:\n      identity:\n        oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n        installation_key: \"YOUR_LC_INSTALLATION_KEY_FALCONCLOUD\"\n      hostname: \"crowdstrike-falcon-adapter\"\n      platform: \"falconcloud\"\n      sensor_seed_key: \"falcon-cloud-sensor\"\n      indexing: []\n    # Optional configuration\n    write_timeout_sec: 600  # Default: 10 minutes\n    is_using_offset: false  # Default: false (recommended)\n    offset: 0               # Only used if is_using_offset is true\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/crowdstrike/#api-doc","title":"API Doc","text":"<p>See the official documentation and additional docs on the library used to access the Falcon APIs.</p>"},{"location":"2-sensors-deployment/adapters/types/duo/","title":"Duo","text":""},{"location":"2-sensors-deployment/adapters/types/duo/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to the Duo Admin API and fetch logs from it.</p>"},{"location":"2-sensors-deployment/adapters/types/duo/#configurations","title":"Configurations","text":"<p>Adapter Type: <code>duo</code></p> <ul> <li><code>client_options</code>: common configuration for adapter as defined here.</li> <li><code>integration_key</code>: an integration key created from within Duo that associated with your \"app\".</li> <li><code>secret_key</code>: the secret key for your \"app\".</li> <li><code>api_hostname</code>: the DNS for your \"app\", a value given to you by Duo.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/duo/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Duo Security Specific Docs: https://docs.limacharlie.io/docs/adapter-types-duo\n\n# For cloud sensor deployment, store credentials as hive secrets:\n#   integration_key: \"hive://secret/duo-integration-key\"\n#   secret_key: \"hive://secret/duo-secret-key\"\n\nsensor_type: \"duo\"\n  duo:\n    integration_key: \"YOUR_DUO_INTEGRATION_KEY_DIXXXXXXXXXXXXXXXXXX\"\n    secret_key: \"YOUR_DUO_SECRET_KEY_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n    api_hostname: \"api-xxxxxxxx.duosecurity.com\"\n    client_options:\n      identity:\n        oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n        installation_key: \"YOUR_LC_INSTALLATION_KEY_DUO\"\n      hostname: \"duo-security-adapter\"\n      platform: \"duo\"\n      sensor_seed_key: \"duo-sensor-prod\"\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/duo/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/evtx/","title":"EVTX","text":""},{"location":"2-sensors-deployment/adapters/types/evtx/#overview","title":"Overview","text":"<p>This Adapter allows you to ingest and convert a <code>.evtx</code> file into LimaCharlie. The <code>.evtx</code> files are the binary format used by Microsoft for Windows Event Logs. This is useful to ingest historical Windows Event Logs, for example during an Incident Response (IR) engagement.</p> <p>For real-time collection of Windows Event Logs, see the Windows Event Logs documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/evtx/#configurations","title":"Configurations","text":"<p>Adapter Type: <code>evtx</code></p> <ul> <li><code>client_options</code>: common configuration for adapter as defined here.</li> <li><code>file_path</code>: path to the <code>.evtx</code> file to ingest.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/evtx/#api-doc","title":"API Doc","text":"<p>See the unofficial documentation on EVTX.</p>"},{"location":"2-sensors-deployment/adapters/types/file/","title":"File","text":""},{"location":"2-sensors-deployment/adapters/types/file/#overview","title":"Overview","text":"<p>This Adapter allows you to ingest logs from a file, either as a one time operation or by following its output (like <code>tail -f</code>). A more detailed guide to file collection can be found in the Log Collection Guide.</p>"},{"location":"2-sensors-deployment/adapters/types/file/#configuration","title":"Configuration","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul> <p>Adapter type <code>file</code>:</p> <ul> <li><code>file_path</code>: simple file pattern like <code>./files_*.txt</code></li> <li><code>no_follow</code>: if <code>true</code>, the file content will be sent, but additions to the file will not be reported</li> <li><code>inactivity_threshold</code>: the number of seconds after which an unmodified file becomes ignored</li> <li><code>backfill</code>: if <code>true</code>, a single pass at all the matching files will be made to ingest them, useful for historical ingestion</li> <li><code>serialize_files</code>: if <code>true</code>, files will be ingested one at a time, useful for very large number of files that could blow up memory</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/file/#cli-deployment","title":"CLI Deployment","text":"<p>Adapter downloads can be found here.</p> <pre><code>chmod +x /path/to/lc_adapter\n\n/path/to/lc_adapter file client_options.identity.installation_key=$INSTALLATION_KEY \\\nclient_options.identity.oid=$OID \\\nclient_options.platform=text \\\nclient_options.sensor_seed_key=$SENSOR_NAME \\\nclient_options.hostname=$SENSOR_NAME \\\nfile_path=/path/to/file\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/google-cloud-pubsub/","title":"Google Cloud Pubsub","text":""},{"location":"2-sensors-deployment/adapters/types/google-cloud-pubsub/#overview","title":"Overview","text":"<p>This Adapter allows you to ingest events from a Google Cloud Pubsub subscription.</p>"},{"location":"2-sensors-deployment/adapters/types/google-cloud-pubsub/#configurations","title":"Configurations","text":"<p>Adapter Type: <code>pubsub</code></p> <ul> <li><code>client_options</code>: common configuration for adapter as defined here.</li> <li><code>sub_name</code>: the name of the subscription to subscribe to.</li> <li><code>service_account_creds</code>: the string version of the JSON credentials for a (Google) Service Account to use accessing the subscription.</li> <li><code>project_name</code>: project name where the <code>sub_name</code> exists.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/google-cloud-pubsub/#cli-deployment","title":"CLI Deployment","text":"<p>This example assumes that the Adapter is running from a host that has default credentials (via the <code>GOOGLE_APPLICATION_CREDENTIALS</code> environment variable) setup. If it's not the case you will need to use <code>service_account_creds</code> to provide the contents of the JSON credentials of the GCP Service Account to use.</p> <pre><code>./lc_adapter pubsub client_options.identity.installation_key=f5eaaaad-575a-498e-bfc2-5f83e249a646 \\\n    client_options.identity.oid=8cbe27f4-bfa1-4afb-ba19-138cd51389cd \\\n    client_options.platform=gcp \\\n    sub_name=usp \\\n    project_name=monitored-proj \\\n    client_options.sensor_seed_key=gcplogs\n</code></pre> <p>Here's the breakdown of the above example:</p> <ul> <li><code>lc_adapter</code>: simply the CLI Adapter.</li> <li><code>pubsub</code>: the method the Adapter should use to collect data locally.</li> <li><code>client_options.identity.installation_key=....</code>: the Installation Key value from LimaCharlie.</li> <li><code>client_options.identity.oid=....</code>: the Organization ID from LimaCharlie the installation key above belongs to.</li> <li><code>client_options.platform=gcp</code>: this indicates that the data read is logs from Google Cloud Platform.</li> <li><code>client_options.sensor_seed_key=....</code>: this is the value that identifies this instance of the Adapter. Record it to re-use the Sensor ID generated for this Adapter later if you have to re-install the Adapter.</li> <li><code>sub_name=usp</code>: the Subscription name to consume the logs from.</li> <li><code>project_name=monitored-proj</code>: the GCP Project name this Subscription belongs to.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/google-cloud-pubsub/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Google Cloud Pub/Sub Specific Docs: https://docs.limacharlie.io/docs/adapter-types-google-cloud-pubsub\n\nsensor_type: \"pubsub\"\npubsub:\n  sub_name: \"your-pubsub-subscription-name\"\n  project_name: \"your-gcp-project-id\"\n  service_account_creds: \"hive://secret/gcp-pubsub-service-account\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_PUBSUB\"\n    platform: \"json\"\n    sensor_seed_key: \"gcp-pubsub-sensor\"\n    mapping:\n      # Map Pub/Sub message to sensor fields\n      sensor_hostname_path: \"attributes.hostname\"\n      event_type_path: \"attributes.eventType\"\n      event_time_path: \"publishTime\"\n    indexing: []\n  # Optional configuration\n  max_ps_buffer: 1048576  # 1MB buffer (optional)\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/google-cloud-pubsub/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/google-cloud-storage/","title":"Google Cloud Storage","text":""},{"location":"2-sensors-deployment/adapters/types/google-cloud-storage/#overview","title":"Overview","text":"<p>This Adapter allows you to ingest files/blobs stored in Google Cloud Storage (GCS).</p> <p>Note that this adapter operates as a sink by default, meaning it will \"consume\" files from the GCS bucket by deleting them once ingested.</p>"},{"location":"2-sensors-deployment/adapters/types/google-cloud-storage/#configurations","title":"Configurations","text":"<p>Adapter Type: <code>gcs</code></p> <ul> <li><code>client_options</code>: common configuration for adapter as defined here.</li> <li><code>bucket_name</code>: the name of the bucket to ingest from.</li> <li><code>service_account_creds</code>: the string version of the JSON credentials for a (Google) Service Account to use accessing the bucket.</li> <li><code>prefix</code>: only ingest files with a given path prefix.</li> <li><code>single_load</code>: if <code>true</code>, the adapter will not operate as a sink, it will ingest all files in the bucket once and will then exit.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/google-cloud-storage/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Google Cloud Storage (GCS) Specific Docs: https://docs.limacharlie.io/docs/adapter-types-gcs\n\nsensor_type: \"gcs\"\ngcs:\n  bucket_name: \"your-gcs-bucket-for-limacharlie-logs\"\n  service_account_creds: \"hive://secret/gcs-service-account\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_GCS\"\n    platform: \"json\"\n    sensor_seed_key: \"gcs-log-processor\"\n    mapping:\n      sensor_hostname_path: \"resource.labels.instance_id\"\n      event_type_path: \"logName\"\n      event_time_path: \"timestamp\"\n    indexing: []\n  # Optional configuration\n  prefix: \"security_logs/firewall/\"  # Filter by path prefix\n  parallel_fetch: 5                  # Parallel downloads\n  single_load: false                 # Continuous processing\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/google-cloud-storage/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/google-workspace/","title":"Google Workspace","text":"<p>Google Workspace provides various communication, collaboration, and productivity applications for businesses of all sizes. Google Workspace audit logs provide data to help track \"Who did what, where, an when?\".</p> <p>Google Workspace Audit logs can be ingested via a Google Cloud Platform, deploye as a cloud-to-cloud LimaCharlie Adapter. Events will be ingested and observed via the <code>gcp</code> platform.</p>"},{"location":"2-sensors-deployment/adapters/types/google-workspace/#adapter-deployment","title":"Adapter Deployment","text":"<p>Prior to ingesting Google Workspace Audit logs in LimaCharlie, you must first configure logs to be written to GCP. Afterwards, a cloud-to-cloud GCP Adapter can be deployed to ingest these events into LimaCharlie.</p> <p>The following steps help prepare this:</p> <p>Step 1: Enable Platform Sharing in Google Workspace</p> <p>In the Google Workspace admin console navigate to Account -&gt; Account Settings -&gt; Legal and Compliance</p> <p>Verify that under \"Sharing options\", <code>Google Cloud Platform Sharing Options</code> is set to Enabled.</p> <p>For further details, refer to Google's documentation on Audit logs for Google Workspace</p> <p>Step 2: Verify logs appear in Google Cloud Platform</p> <p>In the GCP Console go to the Logs Explorer.  Ensure you're at the organization level (and not in a particular folder).</p> <p>From the Resources drop-down, choose <code>Audited Resource</code>, then press Apply.</p> <p>You should see logging details related to Google Workspace, under the following log name(s):</p> <p><code>logName:admin.googleapis.com</code></p> <p>Step 3: Create a cloud-to-cloud GCP Adapter</p> <p>Once Google Workspace Audit logs are pushed to GCP, events can be ingested via either Google Cloud Storage or Google Cloud Pubsub. Utilize the appropriate documentation to set up the desired Adapter.</p>"},{"location":"2-sensors-deployment/adapters/types/hubspot/","title":"HubSpot","text":""},{"location":"2-sensors-deployment/adapters/types/hubspot/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to HubSpot to fetch account activity logs.</p>"},{"location":"2-sensors-deployment/adapters/types/hubspot/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/hubspot/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>Adapter Type: <code>hubspot</code></p> <ul> <li><code>access_token</code>: your HubSpot access token</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/hubspot/#manual-deployment","title":"Manual Deployment","text":"<p>Adapter downloads can be found here.</p> <pre><code>chmod +x /path/to/lc_adapter\n\n/path/to/lc_adapter hubspot client_options.identity.installation_key=$INSTALLATION_KEY \\\nclient_options.identity.oid=$OID \\\nclient_options.platform=json \\\nclient_options.sensor_seed_key=$SENSOR_NAME \\\nclient_options.hostname=$SENSOR_NAME \\\nclient_options.mappings.event_type_path=category \\\naccess_token=$ACCESS_TOKEN\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/hubspot/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code>sensor_type: hubspot\n  hubspot:\n    access_token: \"YOUR_HUBSPOT_PRIVATE_APP_ACCESS_TOKEN\"\n    client_options:\n      identity:\n        oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n        installation_key: \"YOUR_LC_INSTALLATION_KEY_HUBSPOT\"\n      destination:\n        hostname: \"input.limacharlie.io\"\n        port: 443\n        is_tls: true\n      net:\n        identity_timeout: 30\n        request_timeout: 30\n        heartbeat_timeout: 120\n      indexing: []\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/hubspot/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/iis/","title":"IIS Logs","text":"<p>Microsoft's Internet Information Services (IIS) web server is a web server commonly found on Microsoft Windows servers. This Adapter assists with sending IIS web logs to LimaCharlie via the Adapter binary.</p> <p>Telemetry Platform (if applicable): <code>iis</code></p>"},{"location":"2-sensors-deployment/adapters/types/iis/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/iis/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>IIS web logs often have a standardized schema, unless manually changed by administrators. The <code>iis</code> platform in LimaCharlie expects the following structure:</p> <p><code>#Fields: date time s-ip cs-method cs-uri-stem cs-uri-query s-port cs-username c-ip cs(User-Agent) cs(Referer) sc-status sc-substatus sc-win32-status time-taken</code></p> <p>Log Structure</p> <p>If your IIS logs are a different structure from above, please let us know and we can assist in customizing the parser!</p> <p>The structure of these fields is as follows:</p> Field Name Explanation date Date of log entry time Time of log entry s-ip The IP address of the web server cs-method The method of request from the client cs-uri-stem The URI requested by the client cs-uri-query The query added to the URI in the client request s-port The server port) cs-username The client username (if provided) c-ip The IP address of the client cs-user-agent The user-agent of the client cs-referer The referer that directed the client to the site sc-status The service status code sc-substatus The service substatus code (if applicable) sc-win32-status The Windows status code time-taken The time taken to render the request resource(s)"},{"location":"2-sensors-deployment/adapters/types/iis/#configuration-file","title":"Configuration File","text":"<p>IIS logs are typically stored \"on disk\" of the web server, in files that roll daily. Thus, collecting IIS web logs would be done with a binary Adapter that can monitor specific IIS log folder(s) for new files. The Adapter type would be <code>file</code>, while the platform is <code>iis</code>.</p> <p>The following configuration file can be used as a starter to monitor IIS web log directories. Replace any values with <code>&lt; &gt;</code> characters with values unique to your Organization and/or deployment. Do not include the <code>&lt;</code> or <code>&gt;</code> characters in your config file!</p> <p>Please customize according to your environment/LimaCharlie organization</p> <pre><code>file:\n  client_options:\n    identity:\n      installation_key: &lt;installation key&gt;\n      oid: &lt;organization id&gt;\n    platform: iis\n    sensor_seed_key: &lt;sensor_seed_key&gt;\n    // The following will map the timestamp of the event to the timestamp in the web log. Remove if you'd prefer to keep the event time as the time of ingestion.\n    mapping:\n      event_time_path: ts\n  file_path: &lt;C:\\path\\to\\web\\logs\\u*.log&gt;\n  no_follow: false\n</code></pre> <p>A few notes about the IIS platform parser:</p> <ul> <li>The server IP address (identified in the logs as <code>s-ip</code> will be used as the hostname within LimaCharlie.</li> <li>The <code>date</code> and <code>time</code> fields are combined to a single field represented as <code>ts</code>. The above configuration uses this field as the event time, unless removed.</li> <li>The <code>sensor_seed_key</code> can be any value of your choosing, please make sure it's unique per web server.</li> <li>You can specify multiple configurations in one file if you wish to collect logs from multiple folders.</li> <li>The <code>no_follow: false</code> specification ensures that the Adapter monitors for new files and/or writes to existing files. You can exclude this option if you are going to ingest \"dead\" log files.</li> <li>All IIS events will be represented as <code>IIS_WEBLOG</code> in the Adapter telemetry.</li> </ul> <p>If you have any questions about collecting IIS web logs, please reach out to the LimaCharlie team.</p> <p>Once the config file is set, you can run the Adapter on Windows with the following command (assuming the file is named <code>config.yaml</code>):</p> <p><code>&lt;adapter_name&gt;.exe file config.yaml</code></p>"},{"location":"2-sensors-deployment/adapters/types/iis/#example-event","title":"Example Event","text":"<pre><code>{\n    \"c-ip\": \"192.168.1.11\",\n    \"cs-method\": \"GET\",\n    \"cs-referer)\": \"-\",\n    \"cs-uri-query\": \"-\",\n    \"cs-uri-stem\": \"/path/to/my/web/page\",\n    \"cs-user-agent\": \"Mozilla/5.0+(Windows+NT+10.0;+Win64;+x64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/128.0.0.0+Safari/537.36\",\n    \"cs-username\": \"-\",\n    \"s-ip\": \"192.168.1.10\",\n    \"s-port\": \"99\",\n    \"sc-status\": \"401\",\n    \"sc-substatus\": \"2\",\n    \"sc-win32-status\": \"5\",\n    \"time-taken\": \"143\",\n    \"ts\": \"2024-09-05 12:36:14\"\n}\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/imap/","title":"IMAP","text":""},{"location":"2-sensors-deployment/adapters/types/imap/#overview","title":"Overview","text":"<p>This Adapter allows you to ingest emails as events from an IMAP server.</p>"},{"location":"2-sensors-deployment/adapters/types/imap/#configurations","title":"Configurations","text":"<p>Adapter Type: <code>imap</code></p> <ul> <li><code>client_options</code>: common configuration for adapter as defined here.</li> <li><code>server</code>: the domain and port of the IMAP server, like <code>imap.gmail.com:993</code>.</li> <li><code>username</code>: the user name to log in to IMAP as.</li> <li><code>password</code>: the password for the above user name.</li> <li><code>inbox_name</code>: the name of the inbox to monitor.</li> <li><code>is_insecure</code>: do NOT connect using SSL.</li> <li><code>from_zero</code>: collect all existing emails in the inbox.</li> <li><code>include_attachments</code>: send attachment data to LimaCharlie, used to generate attachent hashes in the cloud.</li> <li><code>max_body_size</code>: only send attachments below this many bytes to LimaCharlie.</li> <li><code>attachment_ingest_key</code>: if specified, an Ingestion Key used to ingest attachment as Artifacts into LimaCharlie.</li> <li><code>attachment_retention_days</code>: the number of days to retain Artifact attachment for.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/imap/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># IMAP Specific Docs: https://docs.limacharlie.io/docs/adapter-types-imap\n\nsensor_type: \"imap\"\nimap:\n  server: \"imap.yourmailserver.com:993\"\n  username: \"hive://secret/imap-username\"\n  password: \"hive://secret/imap-password\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_IMAP\"\n    hostname: \"imap-email-collector\"\n    platform: \"json\"\n    sensor_seed_key: \"imap-sensor-001\"\n    mapping:\n      sensor_hostname_path: \"headers.X-Originating-IP\"\n      event_type_path: \"headers.Subject\"\n      event_time_path: \"headers.Date\"\n    indexing: []\n  # Optional IMAP-specific configuration\n  inbox_name: \"INBOX\"                    # Default: \"INBOX\"\n  is_insecure: false                     # Default: false (use SSL/TLS)\n  from_zero: false                       # Default: false (only new emails)\n  include_attachments: true              # Default: false\n  max_body_size: 102400                  # Default: 0 (no limit)\n  attachment_ingest_key: \"attachments_data\"      # Default: empty\n  attachment_retention_days: 30          # Default: 0 (no retention)\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/imap/#use-cases","title":"Use Cases","text":"<p>Although this Adapter can be used on any IMAP server for any inbox, it is often used to perform enterprise wide analysis and alerting using Email Journaling.</p> <p>Email Journaling is supported by all major email platforms to perform analysis at scale. It generally involves enabling a data flow of all emails on the platform towards a specific email account where all emails accumulate.</p> <p>Documentation for common platforms:</p> <ul> <li>Exchange Online</li> <li>Google Workspace</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/imap/#example-format","title":"Example Format","text":"<p>Emails ingested through the IMAP Adapter are in raw format so that detailed header information can be included and analyzed. Below is an example of an email received into LimaCharlie from a Google Workspace mailbox:</p> <pre><code>{\n    \"event\": {\n        \"headers\": {\n            \"arc-authentication-results\": [\n                \"i=1; mx.google.com; dkim=pass header.i=@evil.com header.s=google header.b=LdyiNwmQ; spf=pass (google.com: domain of badguy@evil.com designates 209.85.220.41 as permitted sender) smtp.mailfrom=badguy@evil.com; dmarc=pass (p=NONE sp=NONE dis=NONE) header.from=evil.com; dara=pass header.i=@gmail.com\"\n            ],\n            \"arc-message-signature\": [\n                \"i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816; h=to:subject:message-id:date:from:mime-version:dkim-signature; bh=NWZDzWD3fcPGImfiLFJgiOAWQBc6o9f064zRNQOEAZA=; fh=LdhDNbjh6ex3RxMo3wPAKsbuLWT+x/GDPYiwjW9lr10=; b=Y4WpYrqSVH+EuabO9I4v/LUf9MpLBNxghhA3btw3i31h3YHwssUKcYmfGu/LN5+2qc O4h7QYPT8oq5Sbk5T9NYYXb/u2XEyFmcHq78X9r1VBGgRXVzDVoAVE6uYdE+bMSsnBCx grJrZV+HEejJh91iNRlJ8+RDlESBAWastC6YpDHmZkAveUjMUzFBYzTiqCmGBjNYjfoF FOZSrlXMPj4fitoFunI57miFMXjXxiselSo9UEMuyeEcHAuiGZUyNHhLDTri+Nmf/5w1 QvaKCTx7iL4HpeS7budFLf4CuPbqNVIKmvsGq5vn68WFSO8i8AOW08IsKVlw/13KWQlu 6pTg==; dara=google.com\"\n            ],\n            \"arc-seal\": [\n                \"i=1; a=rsa-sha256; t=1725302104; cv=none; d=google.com; s=arc-20160816; b=VPXTfX1HVTFWRixWBstbi2VEAFi6Tt7tfZPEn+4DBZ84n6Jn0MxTWRLP/2Y2GZkDC4 /ugCK/hRaxSqb9UzO9H/AGyrc2qX+rrX1OwLyQqSX5mA6ovrtNOuuHdS5BIBZjNQJS9X +aZICM/ZlkBvcPTKk8xLv/7yLD08xfaIZLdDWmbasg+pxKE5l+nLaxg7mXNC++8PaJRV ziaF9M7xd+Cx1kzDaSMBjTaubqtv3k7rQCqCN7WSLtxn0l2oz/Mdzvntdfcc7/qLrwNi yfmoG/lB4SrikCJJ7DsnGBvn7uCQZjsVbVTi4wLzIUCjqk5XNjIbTVZ1zVQ/HNwvg43g 6MiQ==\"\n            ],\n            \"authentication-results\": [\n                \"mx.google.com; dkim=pass header.i=@evil.com header.s=google header.b=LdyiNwmQ; spf=pass (google.com: domain of badguy@evil.com designates 209.85.220.41 as permitted sender) smtp.mailfrom=badguy@evil.com; dmarc=pass (p=NONE sp=NONE dis=NONE) header.from=evil.com; dara=pass header.i=@gmail.com\"\n            ],\n            \"content-type\": [\n                \"multipart/alternative; boundary=\\\"00000000000006151206212733f4\\\"\"\n            ],\n            \"date\": [\n                \"Mon, 2 Sep 2024 11:34:26 -0700\"\n            ],\n            \"delivered-to\": [\n                \"acme@gmail.com\"\n            ],\n            \"dkim-signature\": [\n                \"v=1; a=rsa-sha256; c=relaxed/relaxed; d=evil.com; s=google; t=1725302104; x=1725906904; dara=google.com; h=to:subject:message-id:date:from:mime-version:from:to:cc:subject :date:message-id:reply-to; bh=NWZDzWD3fcPGImfiLFJgiOAWQBc6o9f064zRNQOEAZA=; b=LdyiNwmQU+l8TQfVFgJYRNMvGqiplaqTOqlGWpSMUGm8891aHvKrxkqpjnHULKaY5l PzU3i0TK4Xl5Mdhjde5ewyD1o5BWTx8qEOFMuiZBOwOQys6nzcwBzQxKEuc8d6+GN8Z1 2H4uBqSxYfOaHAVU5qVx5/7IJF4TMDY/LK8A4=\"\n            ],\n\"from\": [\n                \"Bad Guy &lt;badguy@evil.io&gt;\"\n            ],\n            \"message-id\": [\n                \"&lt;CAD-4=gGtg=3dbuOO8M6pLairyXpnTD6Oh3P1OXauW5-SOXV0yw@mail.gmail.com&gt;\"\n            ],\n            \"mime-version\": [\n                \"1.0\"\n            ],\n            \"received\": [\n                \"by 2002:a05:7010:161f:b0:3f2:d648:d2e9 with SMTP id l31csp230833mdi; Mon, 2 Sep 2024 11:35:05 -0700 (PDT)\",\n                \"from mail-sor-f41.google.com (mail-sor-f41.google.com. [209.85.220.41]) by mx.google.com with SMTPS id d2e1a72fcca58-715e5749b07sor4893537b3a.11.2024.09.02.11.35.04 for &lt;acme@gmail.com&gt; (Google Transport Security); Mon, 02 Sep 2024 11:35:04 -0700 (PDT)\"\n            ],\n            \"received-spf\": [\n                \"pass (google.com: domain of badguy@evil.com designates 209.85.220.41 as permitted sender) client-ip=209.85.220.41;\"\n            ],\n            \"return-path\": [\n                \"&lt;badguy@evil.com&gt;\"\n            ],\n            \"subject\": [\n                \"more testing\"\n            ],\n            \"to\": [\n                \"acme@gmail.com\"\n            ],\n            \"x-gm-message-state\": [\n                \"AOJu0YzthcsAvu7FAaCG7tVsbF4IP4NAAP2ICmXBCZM3q/X+EjpqD6L+ HBDMSMll8JxmIsLL9Hq4U6l/4iwLiRBys3iUsJ3A03Tr5TQVO+PUZyvd5CBxtrsj0Hy675LgaQ7 0oJ2lN6XxBJuSm+/UvFWcTafXVHpnHqvcnYE6cByvJzwFOaEV06U=\"\n            ],\n\"x-google-dkim-signature\": [\n                \"v=1; a=rsa-sha256; c=relaxed/relaxed; d=1e100.net; s=20230601; t=1725302104; x=1725906904; h=to:subject:message-id:date:from:mime-version:x-gm-message-state :from:to:cc:subject:date:message-id:reply-to; bh=NWZDzWD3fcPGImfiLFJgiOAWQBc6o9f064zRNQOEAZA=; b=VNAyNje9Qf3Xz7pGtX6FCaK67/ICW8aVWws/VdEDA/Ay1XO91LBQdEv7cKjZ+mcm1K uS5gPPVBMXVf+68KmiWyoiartMf/X4VsuTWzJRHyrtL9O8fX26xcgElzkAmm9N6/hKYg qsZujh4fpii2jk8VIz3jGNWB41qUbJklu9BNSRLiwzQnew9Av/J48+JaxfZA38qD08x4 o7UPxTick1figeCmYpAR0x16ETNg6lLC8GdJEnnWlIUZJN+K2z3A7xwD6SdAjsy6HFur 6oonKeJjVIzirWToF2mspK5MHbGI8aXmFzpu51gvQsC9caRDNaod9C9GlwSM/2oLhQWN kozw==\"\n            ],\n            \"x-google-smtp-source\": [\n                \"AGHT+IF4ypTOZTFYRo4zx1pdxWk8sJAzLq+8GoGM8toOjlzCT7o9u5Tw0AWDAwK+2MjV6eBL1v0fhHbYcjfipAgz4Y4=\"\n            ],\n\"x-received\": [\n                \"by 2002:a05:6a00:9451:b0:714:3153:ab4 with SMTP id d2e1a72fcca58-717458aeedemr5351482b3a.27.1725302104964; Mon, 02 Sep 2024 11:35:04 -0700 (PDT)\",\n                \"by 2002:a05:6a20:c68e:b0:1ce:d412:f407 with SMTP id adf61e73a8af0-1ced412f48bmr6010277637.18.1725302103735; Mon, 02 Sep 2024 11:35:03 -0700 (PDT)\"\n            ]\n        },\n        \"parts\": [\n            {\n                \"body_text\": \"One more test email.\\r\\n\",\n                \"hashes\": {\n                    \"md5\": \"cbe37e2ee4cf3c35d67a7c4a8e6a9e35\",\n                    \"sha1\": \"c2f203f43304ab0a4c3154a84d0c876fa9c23204\",\n                    \"sha256\": \"95dbb63f3fd41f7852395d84ef9570ef4db567c43d20e3f1e27c72c903b94686\"\n                },\n                \"headers\": {\n                    \"content-type\": [\n                        \"text/plain; charset=\\\"UTF-8\\\"\"\n                    ]\n                }\n            },\n            {\n                \"body_text\": \"&lt;div dir=\\\"ltr\\\"&gt;One more test email.&lt;/div&gt;\\r\\n\",\n                \"hashes\": {\n                    \"md5\": \"a2fcd5c1aa40abe526bbbbd58251a90f\",\n                    \"sha1\": \"5748cc5fc2cd318a5584651731887ac9d9df4df2\",\n                    \"sha256\": \"1f3877f593c1af2ad3e482aee2f4181a34e0f502799908f4ca330f3327d6c175\"\n                },\n                \"headers\": {\n                    \"content-type\": [\n                        \"text/html; charset=\\\"UTF-8\\\"\"\n                    ]\n                }\n            }\n        ]\n    },\n    \"routing\": {\n        \"arch\": 9,\n        \"did\": \"\",\n        \"event_id\": \"fb9554d8-522e-4977-a378-df7f3fcc186a\",\n        \"event_time\": 1725302106808,\n        \"event_type\": \"email\",\n        \"ext_ip\": \"internal\",\n        \"hostname\": \"testimap\",\n        \"iid\": \"XXXXXXX\",\n        \"int_ip\": \"\",\n        \"moduleid\": 6,\n        \"oid\": \"YYYYYY\",\n        \"plat\": 436207616,\n        \"sid\": \"ZZZZZZZZ\",\n        \"tags\": [\n            \"cloud2\"\n        ],\n        \"this\": \"f4925ea82ef44d18b349695466d6055a\"\n    }\n}\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/it-glue/","title":"IT Glue","text":""},{"location":"2-sensors-deployment/adapters/types/it-glue/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to IT Glue to fetch activity logs.</p>"},{"location":"2-sensors-deployment/adapters/types/it-glue/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/it-glue/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>Adapter Type: <code>itglue</code></p> <ul> <li><code>token</code>: your API key/token for IT Glue</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/it-glue/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Adapter Documentation: https://docs.limacharlie.io/docs/adapter-types\n# For Cloud Sensor configurations, use:\n#        token: \"hive://secret/itglue-api-token\"\n\nsensor_type: \"itglue\"\nitglue:\n  token: \"hive://secret/itglue-api-token\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_ITGLUE\"\n    hostname: \"itglue-adapter\"\n    platform: \"json\"\n    sensor_seed_key: \"itglue-audit-sensor\"\n    mapping:\n      sensor_hostname_path: \"attributes.resource_name\"\n      event_type_path: \"attributes.action\"\n      event_time_path: \"attributes.created_at\"\n    indexing: []\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/it-glue/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/json/","title":"JSON","text":""},{"location":"2-sensors-deployment/adapters/types/json/#overview","title":"Overview","text":"<p>This Adapter allows you to ingest logs from a file as JSON.</p> <p>Adapter type: <code>file</code></p>"},{"location":"2-sensors-deployment/adapters/types/json/#configuration","title":"Configuration","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/json/#deployment","title":"Deployment","text":"<p>Adapter downloads can be found here.</p> <pre><code>chmod +x /path/to/lc_adapter\n\n/path/to/lc_adapter file client_options.identity.installation_key=$INSTALLATION_KEY \\\nclient_options.identity.oid=$OID \\\nclient_options.platform=json \\\nclient_options.sensor_seed_key=$SENSOR_NAME \\\nclient_options.hostname=$SENSOR_NAME \\\nfile_path=/path/to/file\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/kubernetes-pods/","title":"Kubernetes Pods Logs","text":""},{"location":"2-sensors-deployment/adapters/types/kubernetes-pods/#overview","title":"Overview","text":"<p>This Adapter allows you to ingest the logs from the pods running in a Kubernetes cluster.</p> <p>The adapter relies on local filesystem access to the standard Kubernetes pod logging structure. This means the adapter is best run as a Daemon Set in Kubernetes with the pod logs location mounted (usually <code>/var/log/pods</code>).</p> <p>A public Docker container is available here as <code>refractionpoint/lc-adapter-k8s-pods</code>.</p>"},{"location":"2-sensors-deployment/adapters/types/kubernetes-pods/#configurations","title":"Configurations","text":"<p>Adapter Type: <code>k8s_pods</code></p> <p>The following fields are required for configuration:</p> <ul> <li><code>client_options</code>: common configuration for adapter as defined here.</li> <li><code>root</code>: The root of the Kubernetes directory storing logs, usually <code>/var/log/pods</code>.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/kubernetes-pods/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Kubernetes Pods Specific Docs: https://docs.limacharlie.io/docs/adapter-types-k8s-pods\n\nsensor_type: \"k8_pods\"\nk8s_pods:\n    client_options:\n      identity:\n        oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n        installation_key: \"YOUR_LC_INSTALLATION_KEY_K8SPODS\"\n      hostname: \"k8s-worker-node\"\n      platform: \"k8s_pods\"\n      sensor_seed_key: \"k8s-pods-sensor\"\n    root: \"/var/log/pods\"                              # Required: Pod logs directory\n    write_timeout_sec: 600                             # Optional: defaults to 600\n    include_pods_re: \"^production_.*\"                  # Optional: include filter\n    exclude_pods_re: \"^kube-system_kube-proxy-.*$\"    # Optional: exclude filter\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/kubernetes-pods/#sample-kubernetes-configuration","title":"Sample Kubernetes Configuration","text":"<p>An example Daemon Set configuration for Kubernetes:</p> <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: lc-adapter-k8s-pods\n  namespace: default\nspec:\n  minReadySeconds: 30\n  selector:\n    matchLabels:\n      name: lc-adapter-k8s-pods\n  template:\n    metadata:\n      labels:\n        name: lc-adapter-k8s-pods\n    spec:\n      containers:\n      - image: refractionpoint/lc-adapter-k8s-pods\n        name: lc-adapter-k8s-pods\n        volumeMounts:\n        - mountPath: /k8s-pod-logs\n          name: pod-logs\n        env:\n        - name: K8S_POD_LOGS\n          value: /k8s-pod-logs\n        - name: OID\n          value: aaaaaaaa-bfa1-bbbb-cccc-138cd51389cd\n        - name: IKEY\n          value: aaaaaaaa-9ae6-bbbb-cccc-5e42b854adf5\n        - name: NAME\n          value: k8s-pods\n      volumes:\n      - hostPath:\n          path: /var/log/pods\n        name: pod-logs\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 1\n    type: RollingUpdate\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/mac-unified-logging/","title":"Mac Unified Logging","text":""},{"location":"2-sensors-deployment/adapters/types/mac-unified-logging/#overview","title":"Overview","text":"<p>This Adapter allows you to collect events from MacOS Unified Logging.</p>"},{"location":"2-sensors-deployment/adapters/types/mac-unified-logging/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul> <p>Optional Arguments:</p> <ul> <li><code>predicate</code>: example, <code>predicate='subsystem==\"com.apple.TimeMachine\"'</code></li> </ul>"},{"location":"2-sensors-deployment/adapters/types/mac-unified-logging/#cli-deployment","title":"CLI Deployment","text":"<p>Adapter downloads can be found here.</p> <pre><code>chmod +x /path/to/lc_adapter\n\n/path/to/lc_adapter mac_unified_logging client_options.identity.installation_key=$INSTALLATION_KEY \\\nclient_options.identity.oid=$OID \\\nclient_options.platform=json \\\nclient_options.sensor_seed_key=$SENSOR_NAME \\\nclient_options.hostname=$SENSOR_NAME\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/mac-unified-logging/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># macOS Unified Logging Specific Docs: https://docs.limacharlie.io/docs/adapter-types-macos-unified-logging\n\nsensor_type: \"mac_unified_logging\"\n  mac_unified_logging:\n    client_options:\n      identity:\n        oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n        installation_key: \"YOUR_LC_INSTALLATION_KEY_MACOSUL\"\n      hostname: \"user-macbook-pro\"\n      platform: \"mac_unified_logging\"\n      sensor_seed_key: \"macos-unified-logging-sensor\"\n    # Optional configuration\n    write_timeout_sec: 600                           # Default: 600 seconds\n    predicate: 'processImagePath endswith \"/usr/sbin/sshd\" OR subsystem == \"com.apple.security\"'\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/mac-unified-logging/#service-creation","title":"Service Creation","text":"<p>If you want this adapter to run as a service, you can run the following script to add a plist file to the endpoint with your variables replaced. Please note that this example also has an example predicate, so if you do not wish to use a predicate, remove that line.</p> <pre><code>sudo -i\n\ncurl https://downloads.limacharlie.io/adapter/mac/64 -o /usr/local/bin/lc_adapter\nchmod +x /usr/local/bin/lc_adapter\n\ntee -a /Library/LaunchDaemons/io.limacharlie.adapter.macunifiedlogging.plist &lt;&lt;EOF\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"&gt;\n&lt;plist version=\"1.0\"&gt;\n  &lt;dict&gt;\n    &lt;key&gt;Label&lt;/key&gt;\n    &lt;string&gt;io.limacharlie.adapter.macunifiedlogging&lt;/string&gt;\n    &lt;key&gt;UserName&lt;/key&gt;\n    &lt;string&gt;root&lt;/string&gt;\n    &lt;key&gt;RunAtLoad&lt;/key&gt;\n    &lt;true/&gt;\n    &lt;key&gt;WorkingDirectory&lt;/key&gt;\n    &lt;string&gt;/usr/local/bin&lt;/string&gt;\n    &lt;key&gt;KeepAlive&lt;/key&gt;\n    &lt;true/&gt;\n    &lt;key&gt;EnvironmentVariables&lt;/key&gt;\n    &lt;dict&gt;\n      &lt;key&gt;PATH&lt;/key&gt;\n      &lt;string&gt;/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&lt;/string&gt;\n    &lt;/dict&gt;\n    &lt;key&gt;Program&lt;/key&gt;\n    &lt;string&gt;/usr/local/bin/lc_adapter&lt;/string&gt;\n    &lt;key&gt;ProgramArguments&lt;/key&gt;\n    &lt;array&gt;\n        &lt;string&gt;/usr/local/bin/lc_adapter&lt;/string&gt;\n        &lt;string&gt;mac_unified_logging&lt;/string&gt;\n        &lt;string&gt;client_options.identity.installation_key=$INSTALLATION_KEY&lt;/string&gt;\n        &lt;string&gt;client_options.identity.oid=$OID&lt;/string&gt;\n        &lt;string&gt;client_options.hostname=$SENSOR_NAME&lt;/string&gt;\n        &lt;string&gt;client_options.platform=json&lt;/string&gt;\n        &lt;string&gt;client_options.sensor_seed_key=$SENSOR_NAME&lt;/string&gt;\n        &lt;string&gt;predicate=eventMessage CONTAINS[c] \"corp.sap.privileges\"&lt;/string&gt;\n    &lt;/array&gt;\n  &lt;/dict&gt;\n&lt;/plist&gt;\nEOF\n\nlaunchctl load -w /Library/LaunchDaemons/io.limacharlie.adapter.macunifiedlogging.plist\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/microsoft-365/","title":"Microsoft 365","text":"<p>Microsoft 365, formerly Office 365, is a product family of productivity software, collaboration and cloud-based services owned by Microsoft. This Adapter allows you to ingest audit events from the Office 365 Management Activity API.</p> <p>Microsoft 365 events can be ingested in LimaCharlie and observed as the <code>office365</code> platform.</p> <p>Note on naming: The platform identifier <code>office365</code> reflects the legacy product name. Microsoft renamed Office 365 to Microsoft 365 in 2020.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-365/#adapter-deployment","title":"Adapter Deployment","text":"<p>Microsoft 365 events are ingested via a cloud-to-cloud Adapter configured specifically to review M365 events. When creating an Adapter, the following data points are required:</p> <ul> <li><code>domain</code>: Office 365 domain</li> <li><code>tenant_id</code>: Office 365 tenant ID</li> <li><code>publisher_id</code>: Office 365 publisher ID (for single-tenant Apps, the PublisherID is the same as the Tenant ID)</li> <li><code>client_id</code>: Office 365 client ID</li> <li><code>client_secret</code>: Office 365 client secret</li> <li><code>endpoint</code>: Office 365 API endpoint</li> <li> <p><code>content_types</code>: content types of events to ingest.</p> </li> <li> <p>Options include:</p> Content Type Description <code>Audit.AzureActiveDirectory</code> User and admin activities in Azure AD: sign-ins, password changes, group/user management, app consent, directory role changes <code>Audit.Exchange</code> Mailbox activities: message access, send/receive, folder operations, delegate permissions, mailbox audit events <code>Audit.SharePoint</code> SharePoint and OneDrive activities: file access, downloads, sharing, site administration, permissions changes <code>Audit.General</code> Activities from other workloads: Microsoft Teams, Power BI, Dynamics 365, Yammer, Stream, and other M365 services <code>DLP.All</code> Data Loss Prevention events: policy matches, alerts when sensitive data is detected in documents or emails </li> <li> <p>Default is all of the above</p> </li> </ul> <p>For the complete list of audit activities by workload, see Microsoft's audit log activities documentation.</p> <p>If creating a Microsoft 365 Adapter via the Web UI, the helper form will navigate you through providing these values.</p> <p>Establishing a cloud-to-cloud connector between LimaCharlie and Office 365 requires a few steps to provide the correct permissions for the Office 365 Management Activity API.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-365/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Office 365 Management Activity API Specific Docs: https://docs.limacharlie.io/docs/adapter-types-office-365-management-activity-api\n# For cloud sensor deployment, store credentials as hive secrets:\n\n#   tenant_id: \"hive://secret/o365-tenant-id\"\n#   client_id: \"hive://secret/o365-client-id\"\n#   client_secret: \"hive://secret/o365-client-secret\"\n\nsensor_type: \"office365\"\noffice365:\n  tenant_id: \"hive://secret/azure-o365-tenant-id\"\n  client_id: \"hive://secret/azure-o365-client-id\"\n  client_secret: \"hive://secret/azure-o365-client-secret\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_O365\"\n    hostname: \"ms-o365-adapter\"\n    platform: \"json\"\n    sensor_seed_key: \"office365-audit-sensor\"\n    mapping:\n      sensor_hostname_path: \"ClientIP\"\n      event_type_path: \"Operation\"\n      event_time_path: \"CreationTime\"\n    indexing: []\n  # Office 365 specific configuration\n  content_types:\n    - \"Audit.AzureActiveDirectory\"\n    - \"Audit.Exchange\"\n    - \"Audit.SharePoint\"\n    - \"Audit.General\"\n    - \"DLP.All\"\n  # Optional configuration\n  endpoint: \"enterprise\"                           # Default: \"enterprise\"\n  start_time: \"2024-01-01T00:00:00Z\"              # Optional: historical start time\n  domain: \"yourcompany.onmicrosoft.com\"           # Optional: for GCC environments\n  publisher_id: \"hive://secret/o365-publisher-id\" # Optional: usually same as tenant_id\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/microsoft-365/#configuring-a-microsoft-365-adapter-in-the-web-ui","title":"Configuring a Microsoft 365 Adapter in the Web UI","text":""},{"location":"2-sensors-deployment/adapters/types/microsoft-365/#preparing-office-365-details","title":"Preparing Office 365 details","text":"<p>To establish an Office 365 adapter, we will need to complete a few steps within the Azure portal. Ensure that you have the correct permissions to set up a new App registration.</p> <ul> <li>Within the Microsoft Azure portal, create a new App registration. You can follow Microsoft's Quickstart guide here.</li> <li>The LimaCharlie connector requires a secret for Office 365 data. You can create one under <code>Certificates &amp; secrets</code>. Be sure to copy this value and save it somewhere - you can only view it once.</li> </ul> <p></p> <ul> <li> <p>Additionally, you'll need to ensure that the app has the correct permissions to view Office 365 data via the Management API. Within <code>API Permissions</code>, configure the following permissions:</p> </li> <li> <p><code>ActivityFeed.Read</code> (Delegated &amp; Application)</p> </li> <li><code>ActivityFeed.ReadDlp</code> (Delegated &amp; Application) [if you want DLP permissions]</li> </ul> <p></p> <p>Additionally, you may need to grant admin consent to the above permissions.</p> <p>At this point, you should have all the details you need to configure the Adapter.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-365/#setting-up-the-adapter","title":"Setting Up the Adapter","text":"<p>Within the LimaCharlie web application, select <code>+ Add</code> Sensor, and then select <code>Office 365</code>:</p> <p>You can select a pre-existing Installation Key or create a new one, unique for this adapter. Once an Installation Key is selected, you will be prompted with a form to finish setting up the adapter. Choose your desired adapter name, and provide the following values:</p> Item Azure Portal Location Domain Home Tenant ID App Registration Overview Publisher ID App Registration Overview Client ID App Registration Overview Client Secret Created during creation in Certificates &amp; secrets API Endpoint <code>enterprise</code>, <code>gcc-gov</code>, <code>gcc-high-gov</code>, or <code>dod-gov</code> <p>Finally, you will also need to select a \"Content Type\" to import. This is the type of events you want to bring in to LimaCharlie. The options are as follows:</p> <ul> <li><code>Audit.AzureActiveDirectory</code></li> <li><code>Audit.Exchange</code></li> <li><code>Audit.SharePoint</code></li> <li><code>Audit.General</code></li> <li><code>DLP.All</code></li> </ul> <p>Without a value, the default is all of the above.</p> <p>Click <code>Complete Cloud Installation</code>, and LimaCharlie will attempt to connect to the Microsoft Office 365 Management API and pull events.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-365/#sample-rule","title":"Sample Rule","text":"<p>When ingested into LimaCharlie, Office 365 data can be referenced directly in your D&amp;R rules. You could do this via a platform operator:</p> <pre><code>op: is platform\nname: office365\n</code></pre> <p>We can also reference Office 365 events directly. The following sample rule looks at <code>FileAccessed</code> events from anonymous user names, and reports accordingly.</p> <pre><code># Detection\nevent: FileAccessed\npath: event/UserId\nop: contains\nvalue: anon\n\n# Response\n- action: report\n  name: OneDrive File Accessed by Anonymous User\n</code></pre> <p>Note that in the detection above, we pivot on the <code>FileAccessed</code> event, which is associated with SharePoint activity. Available event types will depend on source activity and events ingested. More information on audit log activities can be found here.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/","title":"Microsoft Defender","text":""},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/#overview","title":"Overview","text":"<p>LimaCharlie can ingest Microsoft 365 Defender logs via three methods Azure Event Hub Adapter, the Microsoft Defender API, or a Custom Webhook</p> <p>Documentation for creating an event hub can be found here here.</p> <p>Telemetry Platform: <code>msdefender</code></p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/#data-collected","title":"Data Collected","text":""},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/#api-vs-event-hub-comparison","title":"API vs Event Hub Comparison","text":"Method Data Source What You Get Use Case Defender API Microsoft Graph API Security Alerts only Alert-focused monitoring Azure Event Hub Defender Streaming API Raw telemetry events Full visibility into endpoint activity"},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/#microsoft-defender-api","title":"Microsoft Defender API","text":"<p>The API adapter polls Microsoft Graph's <code>/security/alerts_v2</code> endpoint every 30 seconds. This provides security alerts from Microsoft Defender products including:</p> <ul> <li>Defender for Endpoint</li> <li>Defender for Office 365</li> <li>Defender for Identity</li> <li>Defender for Cloud Apps</li> </ul> <p>These are curated, high-fidelity alerts that Microsoft has already correlated and enriched.</p> <p>For alert schema details, see Microsoft's alerts_v2 API documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/#azure-event-hub-streaming-api","title":"Azure Event Hub (Streaming API)","text":"<p>When using Event Hub with Defender, you receive raw telemetry via the Defender Streaming API. This includes detailed event tables such as:</p> <ul> <li>DeviceProcessEvents - Process creation and execution</li> <li>DeviceNetworkEvents - Network connections</li> <li>DeviceFileEvents - File operations</li> <li>DeviceLogonEvents - Authentication events</li> <li>DeviceRegistryEvents - Registry modifications</li> <li>DeviceEvents - Miscellaneous security events</li> </ul> <p>This provides full endpoint telemetry for custom detection rules and threat hunting.</p> <p>For the complete list of supported streaming event types, see Microsoft's Defender XDR streaming event types documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/#defender-api-configuration","title":"Defender API Configuration","text":"<p>To collect data via the Microsoft Defender API, configure an App Registration in Azure with the following permission:</p> <ul> <li><code>SecurityAlert.Read.All</code></li> </ul> <p>Then create a Defender adapter in LimaCharlie with:</p> <ul> <li>Tenant ID</li> <li>Client ID</li> <li>Client Secret</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/#adapter-specific-options","title":"Adapter-specific Options","text":"<ul> <li><code>connection_string</code> - The connection string provided in Azure for connecting to the Azure Event Hub, including the <code>EntityPath=...</code> at the end which identifies the Hub Name (this component is sometimes now shown in the connection string provided by Azure).</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/#guided-deployment","title":"Guided Deployment","text":"<p>In the LimaCharlie web app, you can find a Microsoft Defender helper for connecting to an existing Azure Event Hub and ingesting Microsoft Defender logs.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/#cli-deployment","title":"CLI Deployment","text":"<p>The following example configuration ingests Microsoft Defender logs from an Azure Event Hub to LimaCharlie.</p> <pre><code>./lc_adapter azure_event_hub client_options.identity.installation_key=&lt;INSTALLATION_KEY&gt; \\\nclient_options.identity.oid=&lt;OID&gt; \\\nclient_options.platform=msdefender \\\nclient_options.sensor_seed_key=&lt;SENSOR_SEED_KEY&gt; \\\nclient_options.hostname=msdefender \\\n\"connection_string=Endpoint=sb://mynamespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=fnaaaaaaaaaaaaaaak0g54alYbbbbbbbbbbbbbbbALQ=;EntityPath=lc-stream\"\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/microsoft-defender/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Adapter Documentation: https://docs.limacharlie.io/docs/adapter-types\n# For cloud sensor deployment, store credentials as hive secrets:\n\n#   tenant_id: \"hive://secret/azure-tenant-id\"\n#   client_id: \"hive://secret/defender-client-id\"\n#   client_secret: \"hive://secret/defender-client-secret\"\n\nsensor_type: \"defender\"\ndefender:\n  tenant_id: \"hive://secret/azure-tenant-id\"\n  client_id: \"hive://secret/azure-defender-client-id\"\n  client_secret: \"hive://secret/azure-defender-client-secret\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_DEFENDER\"\n    hostname: \"ms-defender-adapter\"\n    platform: \"json\"\n    sensor_seed_key: \"defender-sensor\"\n    mapping:\n      sensor_hostname_path: \"machineDnsName\"\n      event_type_path: \"alertType\"\n      event_time_path: \"lastUpdateTime\"\n    indexing: []\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/microsoft-entra-id/","title":"Microsoft Entra ID","text":"<p>Microsoft Entra ID, formerly Azure Active Directory, is an identity and access management solution from Microsoft that helps organizations secure and manage identities for hybrid and multicloud environments.</p> <p>The Entra ID API Adapter currently receives risk detection alerts, as generated by Entra ID's Identity Protection feature. You can learn more about these detections here: https://learn.microsoft.com/en-us/entra/id-protection/concept-identity-protection-risks. Data received via an Azure Event Hub or Webhook will be unique to your custom output parameters.</p> <p>Entra ID events are recognized as the <code>azure_ad</code> platform.</p> <p>Note on naming: The platform identifier <code>azure_ad</code> reflects the legacy product name (Azure Active Directory). Microsoft renamed this product to Microsoft Entra ID in 2023.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-entra-id/#data-collected","title":"Data Collected","text":""},{"location":"2-sensors-deployment/adapters/types/microsoft-entra-id/#api-vs-event-hub-vs-webhook-comparison","title":"API vs Event Hub vs Webhook Comparison","text":"Method Data Source What You Get Entra ID API Microsoft Graph API Identity Protection Risk Detections only Azure Event Hub Azure Diagnostic Settings Whatever logs you configure (sign-in, audit, etc.) Webhook Your configuration Whatever you send to the webhook URL"},{"location":"2-sensors-deployment/adapters/types/microsoft-entra-id/#entra-id-api","title":"Entra ID API","text":"<p>The API adapter polls Microsoft Graph's <code>/identityProtection/riskDetections</code> endpoint every 30 seconds. This provides Identity Protection risk detection alerts including:</p> <ul> <li>Risky sign-ins (unfamiliar location, impossible travel, etc.)</li> <li>Compromised credentials</li> <li>Leaked credentials</li> <li>Anonymous IP usage</li> <li>Malware-linked IP addresses</li> </ul> <p>For the full list of risk detection types, see Microsoft's documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-entra-id/#azure-event-hub","title":"Azure Event Hub","text":"<p>When using Event Hub, you receive whatever data you configure Azure to stream. You must configure Azure Diagnostic Settings in Entra ID to send logs to your Event Hub. Common log types include:</p> <ul> <li>Sign-in logs - Interactive and non-interactive authentication events</li> <li>Audit logs - Directory changes (user/group management, app registrations)</li> <li>Provisioning logs - User provisioning to SaaS apps</li> <li>Risky users/sign-ins - Identity Protection detections (alternative to API)</li> </ul> <p>See Microsoft's documentation on streaming Entra ID logs.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-entra-id/#adapter-deployment","title":"Adapter Deployment","text":"<p>Microsoft Entra ID logs are ingested into LimaCharlie via:</p> <ol> <li>Azure Event Hub</li> <li>Entra ID API</li> <li>Webhooks</li> </ol>"},{"location":"2-sensors-deployment/adapters/types/microsoft-entra-id/#azure-event-hub_1","title":"Azure Event Hub","text":"<p>Within the LimaCharlie web app, there is a helper that can be used to easily configure receiving Entra ID events via an Azure Event Hub.</p> <p>If utilizing the helper, only two fields are required:</p> <ul> <li>Name for the adapter</li> <li>Connection string to the Azure Event Hub</li> </ul> <p>You can find more information about Azure Event Hub Adapters here.</p> <p>Documentation for creating an event hub can be found here here.</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-entra-id/#entra-id-api_1","title":"Entra ID API","text":"<p>To collect data via the Entra ID API, you'll need to configure an App Registration in Azure and ensure it has the correct permissions.</p> <ol> <li>In Azure, navigate to the Entra ID Overview page. Select App Registrations and click <code>+ New Registration</code>.</li> <li>Name the application, and select the Supported account types.</li> <li>After registering an App, you'll be provided metadata for that application. Take note of the <code>Application (client) ID</code> and <code>Directory (tenant) ID</code> fields, as you will need them for configuration.</li> <li>Select Add a certificate or secret, and create a new client secret. Provide a description and select an applicable Expiration time. Note: You will need to refresh the Secret in LimaCharlie once it expires!</li> <li>After creating the secret, copy the <code>Secret Value</code>. You will need this to configure the LimaCharlie Adapter.</li> <li> <p>Navigate to the Manage &gt; API permissions menu for your newly-created application. Ensure that the following permissions have been enabled:</p> </li> <li> <p>IdentityRiskEvent.Read.All</p> </li> <li>IdentityRiskEvent.ReadWrite.All</li> <li>IdentityRiskyServicePrincipal.Read</li> <li>IdentityRiskyServicePrincipal.ReadWrite.All</li> <li>IdentityRiskyUser.Read.All</li> <li>IdentityRiskyUser.Read.Write.All</li> <li>User.Read (default)</li> </ol> <p>Create a new Adapter within LimaCharlie, and select Microsoft Entra ID. Select <code>Microsoft Entra ID API</code> as the ingestion method.</p> <ol> <li> <p>Name the Adapter and provide the following details:</p> </li> <li> <p>Tenant ID</p> </li> <li>Client ID</li> <li>Client Secret</li> <li>Note: You can use the Secrets Manager for these values if you wish!</li> </ol> <p>Click Complete Cloud Installation, and the Adapter should be created successfully. Monitor the Platform Logs for any errors.</p> <p>Note: As previously mentioned, the API Adapter receives events from the Risk Detections API. You will only receive events when these events are sent by the platform. Thus, if you're not receiving any events immediately after Adapter creation, this may be due to no risky events occurring!</p>"},{"location":"2-sensors-deployment/adapters/types/microsoft-entra-id/#webhooks","title":"Webhooks","text":"<p>Within the LimaCharlie web app, there is a helper that can be used to easily configure receiving Entra ID events.</p> <p>If utilizing the helper, only two fields are required:</p> <ul> <li>Name for the adapter</li> <li>Secret component of the URL for the webhook</li> </ul> <p>More information about creating a webhook and obtaining the completed URL, utilizing the secret component, can be found here.</p>"},{"location":"2-sensors-deployment/adapters/types/mimecast/","title":"Mimecast","text":""},{"location":"2-sensors-deployment/adapters/types/mimecast/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to the Mimecast API to stream audit events as they happen.</p>"},{"location":"2-sensors-deployment/adapters/types/mimecast/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/mimecast/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>Adapter Type: <code>mimecast</code></p> <ul> <li><code>client_id</code>: your Mimecast client ID</li> <li><code>client_secret</code>: your Mimecast client secret</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/mimecast/#cli-deployment","title":"CLI Deployment","text":"<p>Adapter downloads can be found here.</p> <pre><code>chmod +x /path/to/lc_adapter\n\n/path/to/lc_adapter mimecast client_options.identity.installation_key=$INSTALLATION_KEY \\\nclient_options.identity.oid=$OID \\\nclient_options.platform=json \\\nclient_options.sensor_seed_key=$SENSOR_NAME \\\nclient_options.hostname=$SENSOR_NAME \\\nclient_options.mappings.event_type_path=category \\\nclient_id=$CLIENT_ID client_secret=$CLIENT_SECRET\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/mimecast/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Mimecast Specific Docs: https://docs.limacharlie.io/docs/adapter-types-mimecast\n# For cloud sensor deployment, store credentials as hive secrets:\n\n#   client_id: \"hive://secret/mimecast-client-id\"\n#   client_secret: \"hive://secret/mimecast-client-secret\"\n\nsensor_type: \"mimecast\"\nmimecast:\n  client_id: \"hive://secret/mimecast-client-id\"\n  client_secret: \"hive://secret/mimecast-client-secret\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_MIMECAST\"\n    hostname: \"mimecast-logs-adapter\"\n    platform: \"json\"\n    sensor_seed_key: \"mimecast-audit-sensor\"\n    mapping:\n      sensor_hostname_path: \"sender\"\n      event_type_path: \"eventType\"\n      event_time_path: \"eventTime\"\n    indexing: []\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/mimecast/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/okta/","title":"Okta","text":""},{"location":"2-sensors-deployment/adapters/types/okta/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to Okta to fetch system logs.</p>"},{"location":"2-sensors-deployment/adapters/types/okta/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/okta/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>Adapter Type: <code>okta</code></p> <ul> <li><code>apikey</code>: your Okta API key/token</li> <li><code>url</code>: your Okta URL (ex: <code>https://dev-003462479.okta.com</code>)</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/okta/#cli-deployment","title":"CLI Deployment","text":"<p>Adapter downloads can be found here.</p> <pre><code>chmod +x /path/to/lc_adapter\n\n/path/to/lc_adapter okta client_options.identity.installation_key=$INSTALLATION_KEY \\\nclient_options.identity.oid=$OID \\\nclient_options.platform=json \\\nclient_options.sensor_seed_key=$SENSOR_NAME \\\nclient_options.hostname=$SENSOR_NAME \\\napikey=$API_KEY url=$URL\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/okta/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Okta Specific Docs: https://docs.limacharlie.io/docs/adapter-types-okta\n# For cloud sensor deployment, store credentials as hive secrets:\n\n#   apikey: \"hive://secret/okta-api-token\"\n\nsensor_type: \"okta\"\nokta:\n  apikey: \"hive://secret/okta-api-key\"\n  url: \"https://your-company.okta.com\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_OKTA\"\n    hostname: \"okta-systemlog-adapter\"\n    platform: \"json\"\n    sensor_seed_key: \"okta-system-logs-sensor\"\n    mapping:\n      sensor_hostname_path: \"client.device\"\n      event_type_path: \"eventType\"\n      event_time_path: \"published\"\n    indexing: []\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/okta/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/pandadoc/","title":"PandaDoc","text":""},{"location":"2-sensors-deployment/adapters/types/pandadoc/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to PandaDoc to fetch API logs.</p>"},{"location":"2-sensors-deployment/adapters/types/pandadoc/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/pandadoc/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>Adapter Type: <code>pandadoc</code></p> <ul> <li><code>api_key</code>: your PandaDoc API key</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/pandadoc/#cli-deployment","title":"CLI Deployment","text":"<p>Adapter downloads can be found here.</p> <pre><code>chmod +x /path/to/lc_adapter\n\n/path/to/lc_adapter pandadoc client_options.identity.installation_key=$INSTALLATION_KEY \\\nclient_options.identity.oid=$OID \\\nclient_options.platform=json \\\nclient_options.sensor_seed_key=$SENSOR_NAME \\\nclient_options.hostname=$SENSOR_NAME \\\nclient_options.mappings.event_type_path=method \\\napi_key=$API_KEY\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/pandadoc/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># PandaDoc Specific Docs: https://docs.limacharlie.io/docs/adapter-types-pandadoc\n# For cloud sensor deployment, store credentials as hive secrets:\n\n#   api_key: \"hive://secret/pandadoc-api-key\"\n\nsensor_type: \"pandadoc\"\npandadoc:\n  api_key: \"hive://secret/pandadoc-api-key\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_PANDADOC\"\n    hostname: \"pandadoc-events-adapter\"\n    platform: \"json\"\n    sensor_seed_key: \"pandadoc-logs-sensor\"\n    mapping:\n      sensor_hostname_path: \"ip\"\n      event_type_path: \"method\"\n      event_time_path: \"request_time\"\n    indexing: []\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/pandadoc/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/s3/","title":"S3","text":""},{"location":"2-sensors-deployment/adapters/types/s3/#overview","title":"Overview","text":"<p>This Adapter allows you to ingest files/blobs stored in AWS S3.</p> <p>Note that this adapter operates as a sink by default, meaning it will \"consume\" files from the S3 bucket by deleting them once ingested.</p>"},{"location":"2-sensors-deployment/adapters/types/s3/#aws-s3-requirements","title":"AWS S3 Requirements","text":"<p>Required IAM Permissions:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n      {\n        \"Effect\": \"Allow\",\n        \"Action\": [\n          \"s3:ListBucket\",\n          \"s3:GetObject\",\n          \"s3:DeleteObject\"\n        ],\n        \"Resource\": [\n          \"arn:aws:s3:::your-bucket-name\",\n          \"arn:aws:s3:::your-bucket-name/*\"\n        ]\n      }\n    ]\n  }\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/s3/#configurations","title":"Configurations","text":"<p>Adapter Type: <code>s3</code></p> <ul> <li><code>client_options</code>: common configuration for adapter as defined here.</li> <li><code>bucket_name</code>: the name of the bucket to ingest from.</li> <li><code>access_key</code>: an Access Key from S3 used to access the bucket.</li> <li><code>secret_key</code>: the secret key associated with the <code>access_key</code> used to access the bucket.</li> <li><code>prefix</code>: only ingest files with a given path prefix. Do not include a leading <code>/</code> in the prefix.</li> <li><code>single_load</code>: if <code>true</code>, the adapter will not operate as a sink, it will ingest all files in the bucket once and will then exit.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/s3/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># AWS S3 Specific Docs: https://docs.limacharlie.io/docs/adapter-types-s3\n# For cloud sensor deployment, store credentials as hive secrets:\n\n#   access_key: \"hive://secret/aws-access-key\"\n#   secret_key: \"hive://secret/aws-secret-key\"\n\nsensor_type: \"s3\"\ns3:\n  bucket_name: \"your-s3-bucket-name-for-logs\"\n  access_key: \"hive://secret/aws-s3-access-key\"\n  secret_key: \"hive://secret/aws-s3-secret-key\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_S3\"\n    hostname: \"aws-s3-adapter\"\n    platform: \"json\"\n    sensor_seed_key: \"s3-log-processor\"\n    mapping:\n      sensor_hostname_path: \"source_host\"\n      event_type_path: \"event_category\"\n      event_time_path: \"timestamp\"\n    indexing: []\n  # Optional S3-specific configuration\n  prefix: \"logs/application_xyz/\"              # Filter by object prefix\n  parallel_fetch: 5                           # Parallel downloads\n  single_load: false                          # Continuous processing\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/s3/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/sentinelone/","title":"SentinelOne","text":"<p>This Adapter allows you to stream SentinelOne activities, threats, and alerts to LimaCharlie via SentinelOne API.</p>"},{"location":"2-sensors-deployment/adapters/types/sentinelone/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/sentinelone/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>Adapter Type: <code>sentinel_one</code></p> <ul> <li><code>domain</code> - your SentinelOne MGMT endpoint, <code>https://&lt;your-instance&gt;.sentinelone.net</code></li> <li><code>api_key</code> - SentinelOne API token</li> <li><code>start_time</code> - optional start time to fetch past events.</li> <li><code>urls</code> - Advanced, CLI only: a comma-separated list of REST API paths to scrub. If omitted, by default the adapter brings activities, alerts, and threats:</li> </ul> <pre><code>/web/api/v2.1/activities,\n/web/api/v2.1/cloud-detection/alerts,\n/web/api/v2.1/threats\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/sentinelone/#deployment-examples","title":"Deployment Examples","text":""},{"location":"2-sensors-deployment/adapters/types/sentinelone/#web-app","title":"Web App","text":"<p>On the Sensors page, Add Sensor, and choose SentinelOne sensor type. Fill out the parameters, and complete the cloud installation.</p> <p></p>"},{"location":"2-sensors-deployment/adapters/types/sentinelone/#on-prem-deployment","title":"On-prem deployment","text":"<p>Follow docs Adapter Deployment, download the binaries for your platform, and run the adapter:</p> <pre><code>./lc_adapter sentinel_one client_options.identity.installation_key=714e1fa5-aaaa-aaaa-aaaa-aaaaaaaaaaaa client_options.identity.oid=aaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa client_options.platform=sentinel_one client_options.hostname=s1 client_options.sensor_seed_key=s1 'domain=https://datacenter.sentinelone.net' \"api_key=$S1_API_KEY\"\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/slack-audit-logs/","title":"Slack Audit Logs","text":"<p>Slack audit logs allow for ingestion of audit events in a Slack Enterprise Grid organization. Events can be ingested directly from the Slack API via a cloud-to-cloud or CLI Adapter.</p> <p>Slack telemetry can be addressed via the <code>slack</code> platform.</p> <p>Note: Audit Logs via API are only available to Slack workspaces on the Enterprise Grid plan.</p>"},{"location":"2-sensors-deployment/adapters/types/slack-audit-logs/#adapter-deployment","title":"Adapter Deployment","text":"<p>Slack Audit Logs can be collected directly from the Slack API, via a cloud-to-cloud Adapter, or via the CLI Adapter. You will need a Slack App OAuth token prior to deploying this Adapter. More information on generating Slack OAuth tokens can be found at this link.</p>"},{"location":"2-sensors-deployment/adapters/types/slack-audit-logs/#cloud-to-cloud-adapter","title":"Cloud-to-Cloud Adapter","text":"<p>Slack API telemetry can be configured directly from the LimaCharlie web application. Under <code>Sensors List</code>, select <code>+ Add Sensor &gt; Slack Audit Logs</code>. After providing an Installation Key will be prompted to provide an Adapter Name and a Slack App OAuth Token.</p>"},{"location":"2-sensors-deployment/adapters/types/slack-audit-logs/#deploying-via-the-cli-adapter","title":"Deploying via the CLI Adapter","text":"<p>The LimaCharlie CLI Adapter can also be used to ingest Slack events, if you do not wish to create a cloud-to-cloud connector. The following sample configuration can be used to create a Slack CLI Adapter:</p> <pre><code>slack:\n  client_options:\n    hostname: slack-audit\n    identity:\n      installation_key: &lt;INSTALLATION_KEY&gt;\n      oid: &lt;OID&gt;\n    platform: slack\n    sensor_seed_key: super-special-seed-key\n  token: &lt;SLACK OAUTH TOKEN&gt;\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/sophos/","title":"Sophos","text":""},{"location":"2-sensors-deployment/adapters/types/sophos/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to Sophos Central to fetch event logs.</p>"},{"location":"2-sensors-deployment/adapters/types/sophos/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/sophos/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>Adapter Type: <code>sophos</code></p> <ul> <li><code>tenantid</code>: your Sophos Central tenant ID</li> <li><code>clientid</code>: your Sophos Central client ID</li> <li><code>clientsecret</code>: your Sophos Central client secret</li> <li><code>url</code>: your Sophos Central URL (ex: <code>https://api-us01.central.sophos.com</code>)</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/sophos/#creating-your-credentials-and-getting-your-tenant-id","title":"Creating Your Credentials and Getting Your Tenant ID","text":"<p>Sophos documentation - https://developer.sophos.com/getting-started-tenant</p> <ol> <li>Add a new credential here</li> <li>Get your client ID and client secret from the credentials you just created</li> <li>Get your JWT -- be sure to replace the values with the client ID and secret from the last step</li> </ol> <pre><code>curl -XPOST -H \"Content-Type:application/x-www-form-urlencoded\" -d \"grant_type=client_credentials&amp;client_id=YOUR_CLIENT_ID&amp;client_secret=YOUR_CLIENT_SECRET&amp;scope=token\" https://id.sophos.com/api/v2/oauth2/token\n</code></pre> <p>Response content -- grab the <code>access_token</code> from the output:</p> <p><pre><code>{\n   \"access_token\": \"SAVE_THIS_VALUE\",\n   \"errorCode\": \"success\",\n   \"expires_in\": 3600,\n   \"message\": \"OK\",\n   \"refresh_token\": \"&lt;token&gt;\",\n   \"token_type\": \"bearer\",\n   \"trackingId\": \"&lt;uuid&gt;\"\n}\n</code></pre> 4. Get your tenant ID -- you will need the <code>access_token</code> (JWT) from the last step.</p> <pre><code>curl -XGET -H \"Authorization: Bearer YOUR_JWT_HERE\" https://api.central.sophos.com/whoami/v1\n</code></pre> <p>Response content -- grab the <code>id</code> (<code>tenant_id</code>) and <code>dataRegion</code> (<code>url</code>) from the output. You will need these for your LimaCharlie Sophos adapter configuration.</p> <p><pre><code>{\n    \"id\": \"57ca9a6b-885f-4e36-95ec-290548c26059\",\n    \"idType\": \"tenant\",\n    \"apiHosts\": {\n        \"global\": \"https://api.central.sophos.com\",\n        \"dataRegion\": \"https://api-us03.central.sophos.com\"\n    }\n}\n</code></pre> 5. Now you have all the pieces for your adapter:</p> <ol> <li><code>client_id</code></li> <li><code>client_secret</code></li> <li><code>tenant_id</code></li> <li><code>url</code></li> </ol>"},{"location":"2-sensors-deployment/adapters/types/sophos/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Sophos Central Specific Docs: https://docs.limacharlie.io/docs/adapter-types-sophos-central\n# For cloud sensor deployment, store credentials as hive secrets:\n\n#   clientid: \"hive://secret/sophos-client-id\"\n#   clientsecret: \"hive://secret/sophos-client-secret\"\n#   tenantid: \"hive://secret/sophos-tenant-id\"\n\nsensor_type: \"sophos\"\nsophos:\n  clientid: \"hive://secret/sophos-client-id\"\n  clientsecret: \"hive://secret/sophos-client-secret\"\n  tenantid: \"hive://secret/sophos-tenant-id\"\n  url: \"https://api-us01.central.sophos.com\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_SOPHOS\"\n    hostname: \"sophos-central-adapter\"\n    platform: \"json\"\n    sensor_seed_key: \"sophos-siem-sensor\"\n    mapping:\n      sensor_hostname_path: \"endpoint.hostname\"\n      event_type_path: \"type\"\n      event_time_path: \"raisedAt\"\n    indexing: []\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/sophos/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/sqs/","title":"SQS","text":""},{"location":"2-sensors-deployment/adapters/types/sqs/#overview","title":"Overview","text":"<p>This Adapter allows you to ingest events received from an AWS SQS instance.</p>"},{"location":"2-sensors-deployment/adapters/types/sqs/#configurations","title":"Configurations","text":"<p>Adapter Type: <code>sqs</code></p> <ul> <li><code>client_options</code>: common configuration for adapter as defined here.</li> <li><code>access_key</code>: an Access Key from AWS used to access the queue.</li> <li><code>secret_key</code>: the secret key associated with the <code>access_key</code> used to access the queue.</li> <li><code>queue_url</code>: the queue URL for the SQS instance.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/sqs/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># AWS SQS Specific Docs: https://docs.limacharlie.io/docs/adapter-types-sqs\n\nsensor_type: \"sqs\"\nsqs:\n  queue_url: \"https://sqs.us-east-1.amazonaws.com/123456789012/your-security-logs-queue\"\n  aws_access_key_id: \"hive://secret/aws-access-key-id\"\n  aws_secret_access_key: \"hive://secret/aws-secret-access-key\"\n  aws_region: \"us-east-1\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_SQS\"\n    platform: \"json\"\n    sensor_seed_key: \"aws-sqs-sensor\"\n    mapping:\n      sensor_hostname_path: \"source.instance_id\"\n      event_type_path: \"detail.eventName\"\n      event_time_path: \"time\"\n    indexing: []\n  # Optional SQS-specific configuration\n  max_messages: 10                       # Default: 10 (max messages per poll)\n  wait_time_seconds: 20                  # Default: 20 (long polling)\n  visibility_timeout: 300                # Default: 300 seconds\n  delete_after_processing: true          # Default: true\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/sqs/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/stdin/","title":"Stdin","text":""},{"location":"2-sensors-deployment/adapters/types/stdin/#overview","title":"Overview","text":"<p>This Adapter allows you to ingest logs from the adapter stdin.</p>"},{"location":"2-sensors-deployment/adapters/types/stdin/#configurations","title":"Configurations","text":"<p>Adapter Type: <code>stdin</code></p> <ul> <li><code>client_options</code>: common configuration for adapter as defined here.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/stdin/#api-doc","title":"API Doc","text":"<p>None</p>"},{"location":"2-sensors-deployment/adapters/types/sublime-security/","title":"Sublime Security","text":"<p>Sublime Security is a comprehensive email security platform that allows users to create custom detections, gain visibility and control, and focus on prevention of malicious emails.</p>"},{"location":"2-sensors-deployment/adapters/types/sublime-security/#ingesting-audit-logs","title":"Ingesting Audit Logs","text":"<p>Audit logs from Sublime can be ingested cloud-to-cloud via the API.</p>"},{"location":"2-sensors-deployment/adapters/types/sublime-security/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>Adapter Type: <code>sublime</code></p> <ul> <li><code>api_key</code>: your Okta API key/token</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/sublime-security/#cli-deployment","title":"CLI Deployment","text":"<p>Adapter downloads can be found here.</p> <pre><code>chmod +x /path/to/lc_adapter\n\n/path/to/lc_adapter sublime client_options.identity.installation_key=$INSTALLATION_KEY \\\nclient_options.identity.oid=$OID \\\nclient_options.platform=sublime \\\nclient_options.sensor_seed_key=$SENSOR_NAME \\\nclient_options.hostname=$SENSOR_NAME \\\napi_key=$API_KEY\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/sublime-security/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Sublime Security Specific Docs: https://docs.limacharlie.io/docs/adapter-types-sublime-security\n# For cloud sensor deployment, store credentials as hive secrets:\n\n#   api_key: \"hive://secret/sublime-api-key\"\n\nsensor_type: \"sublime\"\nsublime:\n  api_key: \"hive://secret/sublime-api-key\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_SUBLIME\"\n    hostname: \"sublime-security-adapter\"\n    platform: \"json\"\n    sensor_seed_key: \"sublime-audit-sensor\"\n    mapping:\n      sensor_hostname_path: \"user.email\"\n      event_type_path: \"type\"\n      event_time_path: \"created_at\"\n    indexing: []\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/sublime-security/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/sublime-security/#ingesting-alerts","title":"Ingesting Alerts","text":"<p>Sublime events can be ingested in LimaCharlie via a <code>json</code> Webhook Adapter configuration.</p>"},{"location":"2-sensors-deployment/adapters/types/sublime-security/#adapter-deployment","title":"Adapter Deployment","text":"<p>Sublime Security logs are ingested via a cloud-to-cloud webhook Adapter configured to receive JSON events. The steps of creating this Adapter and enabling the input include:</p> <ol> <li>Creating the Webhook Adapter via the LimaCharlie CLI</li> <li>Discovering the URL created for the Webhook Adapter.</li> <li>Providing the completed URL to Sublime Security for webhook events.</li> </ol>"},{"location":"2-sensors-deployment/adapters/types/sublime-security/#1-creating-the-limacharlie-webhook-adapter","title":"1. Creating the LimaCharlie Webhook Adapter","text":"<p>The following steps are modified from the generic Webhook Adapter creation documentation, found here.</p> <p>Creating a Webhook Adapter requires a set of parameters, including organization ID, Installation Key, platform, and mapping details, among other parameters. The following configuration can be modified to easily configure a Webhook Adapter for ingesting Sublime Security events:</p> <pre><code>{\n    \"sensor_type\": \"webhook\",\n    \"webhook\": {\n       \"secret\": \"sublime-security\",\n        \"client_options\": {\n            \"hostname\": \"sublime-security\",\n            \"identity\": {\n                \"oid\": \"&lt;your_oid&gt;\",\n                \"installation_key\": \"&lt;your_installation_key&gt;\"\n            },\n            \"platform\": \"json\",\n            \"sensor_seed_key\": \"sublime-super-secret-key\",\n            \"mapping\" : {\n                \"event_type_path\" : \"data/flagged_rules/name\",\n                \"event_time_path\" : \"created_at\"\n            }\n        }\n    }\n}\n</code></pre> <p>Note that in the mapping above, we make the following changes:</p> <ul> <li><code>event_type_path</code> is mapped to the rule name from the Sublime alert</li> <li><code>event_time_path</code> is mapped to the <code>created_at</code> field from the Sublime alert</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/sublime-security/#2-building-the-adapter-url","title":"2. Building the Adapter URL","text":"<p>After creating the webhook, you'll need to retrieve the webhook URL from the Get Org URLs API call. You'll need the following information to complete the Webhook URL:</p> <ul> <li>Organization ID</li> <li>Webhook name (from the config)</li> <li>Secret (from the config)</li> </ul> <p>Let's assume the returned domain looks like <code>9157798c50af372c.hook.limacharlie.io</code>, the format of the URL would be:</p> <p><code>https://9157798c50af372c.hook.limacharlie.io/OID/HOOKNAME/SECRET</code></p> <p>Note that the <code>secret</code> value can be provided in the webhook URL or as an HTTP header named <code>lc-secret</code>.</p>"},{"location":"2-sensors-deployment/adapters/types/sublime-security/#3-configuring-the-sublime-webhook-action","title":"3. Configuring the Sublime webhook Action","text":"<p>Within the Sublime Security console, navigate to Manage &gt; Actions. From here, you can select New Action &gt; Webhook.</p> <p></p> <p>Within the Configure webhook menu, provide a name and the Adapter URL constructed in Step 2 above.</p> <p></p> <p>As mentioned in Step 2, you can configure the HTTP header <code>lc-secret</code>, if so desired.</p> <p>Upon configuration of the webhook within Sublime Security, alerts can be configured to be sent to the LimaCharlie platform. To test the Webhook, select Trigger Custom Action from any Flagged message, and send to the LimaCharlie webhook.</p>"},{"location":"2-sensors-deployment/adapters/types/syslog/","title":"Syslog","text":"<p>Syslog is both a protocol and common logging format that consolidate events to a central location for storage. On *nix systems, Syslog often outputs to predefined locations, such as <code>/var/log</code>. The LimaCharlie Adapter can be configured as a Syslog endpoint to collect events either via TCP or UDP.</p> <p>Syslog data can also be ingested via other data platforms, such as an S3 bucket.</p> <p>Syslog events are observed in LimaCharlie as the <code>text</code> platform.</p> <p>A more detailed guide to syslog collection can be found in the Log Collection Guide.</p>"},{"location":"2-sensors-deployment/adapters/types/syslog/#adapter-deployment","title":"Adapter Deployment","text":"<p>Given its ubiquity, Syslog can be ingested via a myriad of methods in both text/log and streaming formats. For non-streaming methods, please refer to the corresponding Adapter type (such as S3, GCP, etc.)</p>"},{"location":"2-sensors-deployment/adapters/types/syslog/#syslog-specific-configurations","title":"Syslog-specific Configurations","text":"<p>All Adapters have the same common client configuration options, found here. A syslog Adapter has a few unique configuration options not found with other Adapter types. These include:</p> <ul> <li><code>port</code>: port to listen for syslog from.</li> <li><code>iface</code>: the interface name to listen for new connections/packets from, defaults to all.</li> <li><code>is_udp</code>: if <code>true</code>, listen over UDP instead of TCP.</li> <li><code>ssl_cert</code>: path to a file with the SSL cert to use to receive logs over TCP.</li> <li><code>ssl_key</code>: path to a file with the SSL key to use to receive logs over TCP.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/syslog/#collecting-syslog-via-docker","title":"Collecting Syslog via Docker","text":"<p>The following example walks through configuring a Docker container as a syslog Adapter.</p> <pre><code>docker run --rm -it -p 1514:1514 refractionpoint/lc-adapter:latest syslog port=1514 \\\n  client_options.identity.installation_key=e9a3bcdf-efa2-47ae-b6df-579a02f3a54d \\\n  client_options.identity.oid=8cbe27f4-bfa1-4afb-ba19-138cd51389cd \\\n  client_options.platform=text \"client_options.mapping.parsing_grok=%{DATESTAMP:date} %{HOSTNAME:host} %{WORD:exe}\\[%{INT:pid}\\]: %{GREEDYDATA:msg}\" \\\n  client_options.sensor_seed_key=testclient1 \\\n  client_options.mapping.rename_only=true \\\n  \"client_options.mapping.mapping[0].src_field=host\" \\\n  \"client_options.mapping.mapping[0].dst_field=syslog_hostname\"\n</code></pre> <p>Here's a breakdown of the above example:</p> <ul> <li><code>docker run --rm</code>: run a container and don't keep the contents around when it's stopped.</li> <li><code>-it</code>: make the container interactive so you can ctrl-c to stop it.</li> <li><code>-p 1514:1514</code>: allow the container to listen on port <code>1514</code> on the local host and use the same port within the container.</li> <li><code>refractionpoint/lc-adapter:latest</code>: this is the name of the public container provided by LimaCharlie.</li> <li><code>syslog</code>: the method the Adapter should use to collect data locally. The <code>syslog</code> value will operate as a syslog endpoint on the TCP port specified.</li> <li><code>port=1514</code>: the TCP port the Adapter should listen on. By default this is a normal TCP connection (not SSL), although SSL options exist.</li> <li><code>client_options.identity.installation_key=....</code>: the Installation Key from LimaCharlie.</li> <li><code>client_options.identity.</code>OID<code>=....</code>: the Organization ID from LimaCharlie the installation key above belongs to.</li> <li><code>client_options.platform=text</code>: this indicates the type of data that will be received from this adapter. In this case it's syslog, so <code>text</code> lines.</li> <li><code>client_options.mapping.parsing_grok=....</code>: this is the grok expression describing how to interpret the text lines and how to convert them to JSON.</li> <li><code>client_options.sensor_seed_key=....</code>: this is the value that identifies this instance of the Adapter. Record it to re-use the Sensor generated for this Adapter later if you have to re-install the Adapter.</li> <li><code>client_options.mapping.rename_only=true</code>: only rename the field in mapping below, so keep the other original fields.</li> <li><code>client_options.mapping.mapping[0].src_field=....</code>: the source field of the first mapping record.</li> <li><code>client_options.mapping.mapping[0].dst_field=....</code>: the destination field of the first mapping record.</li> </ul> <p>To test it, assuming we're on the same Debian box as the container, pipe the syslog to the container:</p> <pre><code>journalctl -f -q | netcat 127.0.0.1 1514\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/syslog/#collecting-syslog-via-binary-adapter","title":"Collecting Syslog via Binary Adapter","text":"<p>The LimaCharlie binary Adapter can be deployed as a syslog listener. This option allows you to configure multiple syslog outputs to a single listener, and ingest multiple types of events with a single Adapter.</p>"},{"location":"2-sensors-deployment/adapters/types/syslog/#step-1-create-an-installation-key","title":"Step 1: Create an installation key","text":"<p>We recommend utilizing a unique installation key for this deployment, specifically with a <code>syslog</code> Tag. This allows for a level of delineation within  rules and outputs via Tags.</p>"},{"location":"2-sensors-deployment/adapters/types/syslog/#step-2-create-an-adapter-config-file","title":"Step 2: Create an Adapter config file","text":"<p>Syslog events are typically ingested as <code>text</code>, however often have specific structures to them. Utilizing a config file allows for easy management of a regex string to extract relevant fields from syslog output.</p> <p>The following example config file can be a starting point. However, you might need to modify the regex to match your specific message.</p> <pre><code># Syslog Specific Docs: https://docs.limacharlie.io/docs/adapter-types-syslog\n\nsensor_type: \"syslog\"\n  syslog:\n    port: 1514\n    iface: \"0.0.0.0\"\n    client_options:\n      identity:\n        oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n        installation_key: \"YOUR_LC_INSTALLATION_KEY_SYSLOG\"\n      hostname: \"syslog-adapter\"\n      platform: \"linux\"\n      sensor_seed_key: \"syslog-collector\"\n      mapping:\n        parsing_grok:\n          message: \"^&lt;%{INT:pri}&gt;%{SYSLOGTIMESTAMP:timestamp}\\\\s+%{HOSTNAME:hostname}\\\\s+%{WORD:tag}(?:\\\\[%{INT:pid}\\\\])?:\\\\s+%{GREEDYDATA:message}\"\n        sensor_hostname_path: \"hostname\"\n        event_type_path: \"tag\"\n        event_time_path: \"timestamp\"\n        event_time_timezone: \"America/New_York\"  # Required if logs use local time (SYSLOGTIMESTAMP has no timezone)\n    # Optional syslog-specific configuration\n    is_udp: false                               # TCP (default) vs UDP\n    write_timeout_sec: 30                       # Write timeout\n    ssl_cert: \"/certs/syslog_server.pem\"       # Optional SSL cert\n    ssl_key: \"/certs/syslog_server.key\"        # Optional SSL key\n    mutual_tls_cert: \"/certs/client_ca.pem\"    # Optional mTLS\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/syslog/#step-3-configure-syslog-output-to-send-messages-to-a-local-listener","title":"Step 3: Configure syslog output to send messages to a local listener","text":"<p>This step will depend on the type of syslog daemon you are using (syslog, rsyslog, syslog-ng, etc.) Within the daemon configuration file, configure the desired facility(-ies) to direct to the local listener. In the following example, we configured <code>auth</code> and <code>authpriv</code> events to write to both <code>/var/log/audit.log</code> and <code>127.0.0.1:1514</code>.</p> <pre><code>auth,authpriv.*         /var/log/auth.log\nauth,authpriv.*         @@127.0.0.1:1514\n</code></pre> <p>After applying the appropriate configuration, restart the syslog daemon.</p>"},{"location":"2-sensors-deployment/adapters/types/syslog/#step-4-confirm-that-syslog-messages-are-sent-to-the-correct-location","title":"Step 4: Confirm that syslog messages are sent to the correct location","text":"<p>Utilizing a tool like <code>netcat</code>, you can listen on the appropriate port to confirm that messages are being sent. The following command will spawn a <code>netcat</code> listener on port 1514:</p> <pre><code>nc -l -p 1514\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/syslog/#step-5-run-the-limacharlie-adapter","title":"Step 5: Run the LimaCharlie Adapter","text":"<p>Execute the binary Adapter with the syslog configuration file in order to start the LimaCharlie listener. If started correctly, you should see the following messages in <code>stdout</code>:</p> <pre><code>DBG &lt;date&gt;: usp-client connecting\nDBG &lt;date&gt;: usp-client connected\nDBG &lt;date&gt;: listening for connections on :1514\n</code></pre> <p>Double-check the LimaCharlie Sensors list, and you should see the text adapter with the respective hostname sending <code>Syslog</code> events.</p>"},{"location":"2-sensors-deployment/adapters/types/tailscale/","title":"Tailscale","text":"<p>Tailscale is a VPN service that makes devices and applications accessible anywhere in the world. Relying on the open source WireGuard protocol, Tailscale enables encrypted point-to-point connections.</p> <p>Tailscale events can be ingested in LimaCharlie via a <code>json</code> Webhook Adapter.</p>"},{"location":"2-sensors-deployment/adapters/types/tailscale/#adapter-deployment","title":"Adapter Deployment","text":"<p>Tailscale events are ingested via a cloud-to-cloud webhook Adapter configured to receive JSON events. In the creation of the Adapter, we map fields directly to the expected Tailscale webhook events. The steps of creating this Adapter and enabling the input include:</p> <ol> <li>Creating the Webhook Adapter via the LimaCharlie CLI.</li> <li>Discovering the URL created for the Webhook Adapter.</li> <li>Providing the completed URL to Tailscale for Webhook events.</li> </ol>"},{"location":"2-sensors-deployment/adapters/types/tailscale/#1-creating-the-limacharlie-webhook-adapter","title":"1. Creating the LimaCharlie Webhook Adapter","text":"<p>The following steps are modified from the generic Webhook Adapter creation doc, found here.</p> <p>Creating a Webhook Adapter requires a set of parameters, including organization ID, Installation Key, platform, and mapping details. The following configuration has been provided to configure a Webhook Adapter for ingesting Tailscale events:</p> <pre><code>{\n    \"sensor_type\": \"webhook\",\n    \"webhook\": {\n       \"secret\": \"tailscale-secret\",\n        \"client_options\": {\n            \"hostname\": \"tailscale\",\n            \"identity\": {\n                \"oid\": \"&lt;your_oid&gt;\",\n                \"installation_key\": \"&lt;your_installation_key&gt;\"\n            },\n            \"platform\": \"json\",\n            \"sensor_seed_key\": \"tailscale-super-secret-key\",\n            \"mapping\" : {\n                \"event_type_path\" : \"message\"\n            }\n        }\n    }\n}\n</code></pre> <p>The mapping above is based on the expected Webhook event from Tailscale (example provided here). Note that in the mapping above, we make the following change:</p> <ul> <li><code>event_type_path</code> is mapped to the <code>message</code> field</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/tailscale/#2-building-the-webhook-url","title":"2. Building the Webhook URL","text":"<p>After creating the webhook, you'll need to retrieve the webhook URL from the Get Org URLs API call. You'll need the following information to complete the Webhook URL:</p> <ul> <li>Organization ID</li> <li>Webhook name (from the config)</li> <li>Secret (from the config)</li> </ul> <p>Let's assume the returned domain looks like <code>9157798c50af372c.hook.limacharlie.io</code>, the format of the URL would be:</p> <p><code>https://9157798c50af372c.hook.limacharlie.io/OID/HOOKNAME/SECRET</code></p> <p>Note that the <code>secret</code> value can be provided in the webhook URL or as an HTTP header named <code>lc-secret</code>.</p>"},{"location":"2-sensors-deployment/adapters/types/tailscale/#3-providing-the-url-to-tailscale-for-webhook-events","title":"3. Providing the URL to Tailscale for Webhook Events","text":"<p>Within the Tailscale Admin Console, navigate to Settings &gt; Webhooks. Select Add endpoint...</p> <p></p> <p>Provide the completed Webhook URL from Step 2, above. You can also select the various events you want sent via Webhook. Options include:</p> <p></p> <p>Select Add endpoint. Tailscale will provide you a webhook secret unique to this endpoint. You may want to keep this value, however it is not required within LimaCharlie.</p>"},{"location":"2-sensors-deployment/adapters/types/tailscale/#4-test-webhook-output","title":"4. Test Webhook Output","text":"<p>Within the Tailscale Admin Console, you can test the webhook out and ensure that LimaCharlie is receiving events. Within the Webhook Endpoint options, select Test endpoint....</p> <p>You should see the webhook event populate within the LimaCharlie Adapter a moment later. Note that the <code>event_type</code> will match the <code>message</code> field from the Tailscale webhook event.</p>"},{"location":"2-sensors-deployment/adapters/types/windows-event-log/","title":"Windows Event Log","text":""},{"location":"2-sensors-deployment/adapters/types/windows-event-log/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to the local Windows Event Logs API on Windows. This means this Adapter is only available from Windows builds and only works locally (will not connect to remote Windows instances).</p>"},{"location":"2-sensors-deployment/adapters/types/windows-event-log/#configurations","title":"Configurations","text":"<p>Adapter Type: <code>wel</code></p> <ul> <li><code>client_options</code>: common configuration for adapter as defined here.</li> <li><code>evt_sources</code>: a comma separated list of elements in the format <code>SOURCE:FILTER</code>, where <code>SOURCE</code> is an Event Source name like <code>Application</code>, <code>System</code> or <code>Security</code> and <code>FILTER</code> is an <code>XPath</code> filter value as described in the documentation linked below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/windows-event-log/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Windows Event Log (WEL) Specific Docs: https://docs.limacharlie.io/docs/adapter-types-windows-event-log\n\n# Basic Event Sources:\n# evt_sources: \"Security,System,Application\"\n\n# With XPath Filters:\n# evt_sources: \"Security:'*[System[(Level=1 or Level=2 or Level=3)]]',System:'*[System[Provider[@Name=\\\"Microsoft-Windows-Kernel-General\\\"]]]'\"\n\n# File-Based Sources:\n# evt_sources: \"C:\\\\Windows\\\\System32\\\\winevt\\\\Logs\\\\Security.evtx:'*[System[(EventID=4624)]]'\"\n\n  wel:\n    evt_sources: \"Security:'*[System[(Level=1 or Level=2 or Level=3)]]',System,Application\"\n    client_options:\n      identity:\n        oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n        installation_key: \"YOUR_LC_INSTALLATION_KEY_WEL\"\n      hostname: \"prod-dc01.example.local\"\n      platform: \"windows\"\n      sensor_seed_key: \"wel-collector\"\n    write_timeout_sec: 30\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/windows-event-log/#xpath-filter-examples","title":"XPath Filter Examples","text":"<p>Security Events (High Priority):</p> <pre><code>  Security:'*[System[(Level=1 or Level=2 or Level=3)]]'\n</code></pre> <p>Logon Events Only:</p> <pre><code>  Security:'*[System[(EventID=4624 or EventID=4625 or EventID=4634)]]'\n</code></pre> <p>System Errors:</p> <pre><code>  System:'*[System[(Level=1 or Level=2)]]'\n</code></pre> <p>Specific Provider:</p> <pre><code>  Application:'*[System[Provider[@Name=\"Microsoft-Windows-ApplicationError\"]]]'\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/windows-event-log/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/zendesk/","title":"Zendesk","text":""},{"location":"2-sensors-deployment/adapters/types/zendesk/#overview","title":"Overview","text":"<p>This Adapter allows you to connect to Zendesk to fetch account activity logs.</p>"},{"location":"2-sensors-deployment/adapters/types/zendesk/#deployment-configurations","title":"Deployment Configurations","text":"<p>All adapters support the same <code>client_options</code>, which you should always specify if using the binary adapter or creating a webhook adapter. If you use any of the Adapter helpers in the web app, you will not need to specify these values.</p> <ul> <li><code>client_options.identity.oid</code>: the LimaCharlie Organization ID (OID) this adapter is used with.</li> <li><code>client_options.identity.installation_key</code>: the LimaCharlie Installation Key this adapter should use to identify with LimaCharlie.</li> <li><code>client_options.platform</code>: the type of data ingested through this adapter, like <code>text</code>, <code>json</code>, <code>gcp</code>, <code>carbon_black</code>, etc.</li> <li><code>client_options.sensor_seed_key</code>: an arbitrary name for this adapter which Sensor IDs (SID) are generated from, see below.</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/zendesk/#adapter-specific-options","title":"Adapter-specific Options","text":"<p>Adapter Type: <code>zendesk</code></p> <ul> <li><code>api_token</code>: your Zendesk API token</li> <li><code>zendesk_domain</code>: your Zendesk domain, like <code>initech.zendesk.com</code></li> <li><code>zendesk_email</code>: your Zendesk email address that created the API token</li> </ul>"},{"location":"2-sensors-deployment/adapters/types/zendesk/#cli-deployment","title":"CLI Deployment","text":"<p>Adapter downloads can be found here.</p> <pre><code>chmod +x /path/to/lc_adapter\n\n/path/to/lc_adapter zendesk client_options.identity.installation_key=$INSTALLATION_KEY \\\nclient_options.identity.oid=$OID \\\nclient_options.platform=json \\\nclient_options.sensor_seed_key=$SENSOR_NAME \\\nclient_options.hostname=$SENSOR_NAME \\\nclient_options.mappings.event_type_path=action \\\napi_token=$API_TOKEN \\\nzendesk_domain='$YOUR_COMPANY.zendesk.com' \\\nzendesk_email=you@yourcompany.com\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/zendesk/#infrastructure-as-code-deployment","title":"Infrastructure as Code Deployment","text":"<pre><code># Zendesk Specific Docs: https://docs.limacharlie.io/docs/adapter-types-zendesk\n# For cloud sensor deployment, store credentials as hive secrets:\n#   api_token: \"hive://secret/zendesk-api-token\"\n#   zendesk_email: \"hive://secret/zendesk-email\"\n\nsensor_type: \"zendesk\"\nzendesk:\n  api_token: \"hive://secret/zendesk-api-token\"\n  zendesk_domain: \"yourcompany.zendesk.com\"\n  zendesk_email: \"hive://secret/zendesk-api-email\"\n  client_options:\n    identity:\n      oid: \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n      installation_key: \"YOUR_LC_INSTALLATION_KEY_ZENDESK\"\n    hostname: \"zendesk-support-adapter\"\n    platform: \"json\"\n    sensor_seed_key: \"zendesk-audit-sensor\"\n    mapping:\n      sensor_hostname_path: \"actor_name\"\n      event_type_path: \"action\"\n      event_time_path: \"created_at\"\n    indexing: []\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/zendesk/#api-doc","title":"API Doc","text":"<p>See the official documentation.</p>"},{"location":"2-sensors-deployment/adapters/types/azure/key-vault/","title":"Azure Key Vault","text":"<p>Azure Key Vault is a product that helps safeguard cryptographic keys and other secrets used by cloud apps and services. LimaCharlie can ingest and natively parse Key Vault logs.</p>"},{"location":"2-sensors-deployment/adapters/types/azure/key-vault/#log-ingestion","title":"Log Ingestion","text":"<p>Azure Key Vault logs can be ingested via:</p> <ul> <li>Azure Event Hub</li> <li>LimaCharlie Webhooks</li> </ul> <p>Upon ingestion, the log <code>category</code> field is used to define the Event Type.</p>"},{"location":"2-sensors-deployment/adapters/types/azure/key-vault/#sample-event","title":"Sample Event","text":"<p>The following sample event is taken from Microsoft Azure documentation:</p> <pre><code>{\n        \"records\":\n        [\n            {\n                \"time\": \"2016-01-05T01:32:01.2691226Z\",\n                \"resourceId\": \"/SUBSCRIPTIONS/361DA5D4-A47A-4C79-AFDD-XXXXXXXXXXXX/RESOURCEGROUPS/CONTOSOGROUP/PROVIDERS/MICROSOFT.KEYVAULT/VAULTS/CONTOSOKEYVAULT\",\n                \"operationName\": \"VaultGet\",\n                \"operationVersion\": \"2015-06-01\",\n                \"category\": \"AuditEvent\",\n                \"resultType\": \"Success\",\n                \"resultSignature\": \"OK\",\n                \"resultDescription\": \"\",\n                \"durationMs\": \"78\",\n                \"callerIpAddress\": \"104.40.82.76\",\n                \"correlationId\": \"\",\n                \"identity\": {\"claim\":{\"http://schemas.microsoft.com/identity/claims/objectidentifier\":\"d9da5048-2737-4770-bd64-XXXXXXXXXXXX\",\"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/upn\":\"live.com#username@outlook.com\",\"appid\":\"1950a258-227b-4e31-a9cf-XXXXXXXXXXXX\"}},\n                \"properties\": {\"clientInfo\":\"azure-resource-manager/2.0\",\"requestUri\":\"https://control-prod-wus.vaultcore.azure.net/subscriptions/361da5d4-a47a-4c79-afdd-XXXXXXXXXXXX/resourcegroups/contosoresourcegroup/providers/Microsoft.KeyVault/vaults/contosokeyvault?api-version=2015-06-01\",\"id\":\"https://contosokeyvault.vault.azure.net/\",\"httpStatusCode\":200}\n            }\n        ]\n    }\n</code></pre>"},{"location":"2-sensors-deployment/adapters/types/azure/kubernetes-service/","title":"Azure Kubernetes Service (AKS)","text":"<p>Azure Kubernetes Service (AKS) is a quick way to start developing and deploying cloud-native apps in Azure. LimaCharlie can ingest Azure Kubernetes Service logs.</p> <p>More information about Azure Kubernetes logs and metrics can be found here.</p>"},{"location":"2-sensors-deployment/adapters/types/azure/kubernetes-service/#log-ingestion","title":"Log Ingestion","text":"<p>AKS logs can be ingested via:</p> <ul> <li>Azure Event Hub</li> <li>LimaCharlie Webhooks</li> </ul> <p>Upon ingestion, the log <code>category</code> field is used to define the Event Type.</p>"},{"location":"2-sensors-deployment/adapters/types/azure/monitor/","title":"Azure Monitor","text":"<p>Azure Monitor Logs are a feature of Azure Monitor that collect and organize log and performance data from monitored resources. More information on Azure Monitor Logs can be found here.</p> <p>LimaCharlie can ingest and natively parse Azure Monitor Logs.</p>"},{"location":"2-sensors-deployment/adapters/types/azure/monitor/#log-ingestion","title":"Log Ingestion","text":"<p>Azure Monitor logs can be ingested via:</p> <ul> <li>Azure Event Hub</li> <li>LimaCharlie Webhooks</li> </ul> <p>Upon ingestion, the log <code>category</code> field is used to define the Event Type.</p>"},{"location":"2-sensors-deployment/adapters/types/azure/network-security-group/","title":"Azure Network Security Group","text":"<p>Azure Network security groups help filter network traffic between Azure resources in an Azure virtual network. More information on Azure network security groups can be found here.</p> <p>LimaCharlie can ingest and natively parse Azure Network Security Group logs.</p>"},{"location":"2-sensors-deployment/adapters/types/azure/network-security-group/#log-ingestion","title":"Log Ingestion","text":"<p>Azure Network Security Group logs can be ingested via:</p> <ul> <li>Azure Event Hub</li> <li>LimaCharlie Webhooks</li> </ul> <p>Upon ingestion, the log <code>category</code> field is used to define the Event Type.</p>"},{"location":"2-sensors-deployment/adapters/types/azure/sql-audit-logs/","title":"Azure SQL Audit Logs","text":"<p>Microsoft Azure SQL is a scalable, cloud-hosted database that integrates with the Azure ecosystem. More information on Azure SQL can be found here.</p> <p>LimaCharlie can ingest and natively parse Azure SQL Server audit logs.</p>"},{"location":"2-sensors-deployment/adapters/types/azure/sql-audit-logs/#log-ingestion","title":"Log Ingestion","text":"<p>Azure SQL Server audit logs can be ingested via:</p> <ul> <li>Azure Event Hub</li> <li>LimaCharlie Webhooks</li> </ul> <p>Upon ingestion, the log <code>category</code> field is used to define the Event Type.</p>"},{"location":"2-sensors-deployment/endpoint-agent/hostname-resolution/","title":"Hostname Resolution","text":"<p>The Endpoint Agent reports its hostname to the LimaCharlie cloud where it shows up as the <code>hostname</code> field for the Sensor.</p> <p>The resolution of that hostname is done in a few different ways:</p> <ol> <li>The main local interface is detected by looking for the route to <code>8.8.8.8</code>.</li> <li>A <code>getnameinfo()</code> with <code>NI_NAMEREQD</code> is performed to resolve the FQDN of the box.</li> <li>If the above hostname resolved is valid (no failure, and it is not equal to the static hostname of a few VPN and virtualization providers), this is the hostname we use.</li> <li>If the FQDN could not be resolved, the local hostname of the box is used.</li> </ol> <p>This method allows the endpoint agent to better resolve its hostname in large environments where different regions re-use the same hostname.</p>"},{"location":"2-sensors-deployment/endpoint-agent/payloads/","title":"Payloads","text":""},{"location":"2-sensors-deployment/endpoint-agent/payloads/#overview","title":"Overview","text":"<p>Payloads are executables or scripts that can be delivered and executed through LimaCharlie's Endpoint Agent.</p> <p>Those payloads can be any executable or script natively understood by the endpoint. The main use case is to run something with specific functionality not available in the main LimaCharlie functionality. For example: custom executables provided by another vendor to cleanup a machine, forensic utilities or firmware-related utilities.</p> <p>We encourage you to look at LimaCharlie native functionality first as it has several advantages:</p> <ul> <li>Usually has better performance.</li> <li>Data returned is always well structured JSON.</li> <li>Can be tasked automatically and Detection &amp; Response Rules can be created from their data.</li> <li>Data returned is indexed and searchable.</li> </ul> <p>It is possible to set the Payload's file extension on the endpoint by making the Payload name end with that extension. For example, naming a Payload <code>extract_everything.bat</code>, the Payload will be sent as a batch file (<code>.bat</code>) and executed as such.  This is also true for PowerShell files (<code>.ps1</code>).</p>"},{"location":"2-sensors-deployment/endpoint-agent/payloads/#lifecycle","title":"Lifecycle","text":"<p>Payloads are uploaded to the LimaCharlie platform and given a name. The task <code>run</code> can then be used with the <code>--payload-name MY-PAYLOAD --arguments \"-v EulaAccepted\"</code> can be used to run the payload with optional arguments.</p> <p>The STDOUT and STDERR data will be returned in a related <code>RECEIPT</code> event, up to ~10 MB. If your payload generates more data, we recommend to pipe the data to a file on disk and use the <code>log_get</code> command to retrieve it.</p> <p>The payload is retrieved by the endpoint agent over HTTPS to the Ingestion API DNS endpoint. This DNS entry is available from the Sensor Download section of the web app if you need to allow it.</p>"},{"location":"2-sensors-deployment/endpoint-agent/payloads/#upload-download-via-rest","title":"Upload / Download via REST","text":"<p>Creating and getting Payloads is done asynchronously. The relevant REST APIs will return specific signed URLs instead of the actual Payload. In the case of a retrieving an existing payload, simply doing an HTTP GET using the returned URL will download the payload content. When creating a Payload the returned URL should be used in an HTTP PUT using the URL like:</p> <pre><code>curl -X PUT \"THE-SIGNED-URL-HERE\" -H \"Content-Type: application/octet-stream\" --upload-file your-file.exe\n</code></pre> <p>Note that the signed URLs are only valid for a few minutes.</p>"},{"location":"2-sensors-deployment/endpoint-agent/payloads/#permissions","title":"Permissions","text":"<p>Payloads are managed with two permissions:</p> <ul> <li><code>payload.ctrl</code> allows you to create and delete payloads.</li> <li><code>payload.use</code> allows you to run a given payload.</li> </ul>"},{"location":"2-sensors-deployment/endpoint-agent/sleeper/","title":"Sleeper Deployment","text":"<p>LimaCharlie's usage-based billing enables incident responders to offer pre-deployments to their customers at almost zero cost. That is, they can deploy across an Organization's entire fleet and lay dormant in 'sleeper mode' at a cost of just $0.10 per 30 days. With agents deployed ahead of an incident, responders can offer competitive SLAs.</p> <p>Have more questions?</p> <p>For more details on sleeper mode deployments, feel free to contact us at answers@limacharlie.io or book a quick call with the engineering team to discuss your use case.</p> <p>Sleeper and Usage billing use the following metrics:</p> Connected Time Events Processed Events Retained $0.10 per 30 days $0.67 per 100,000 events $0.17 per 100,000 events <p>Using sleeper and usage deployments is done via Sensor tagging. Applying the <code>lc:sleeper</code> Tag to a Sensor will stop LimaCharlie telemetry collection activity on the host. Within 10 minutes of the tag being applied, the sensor will enter sleeper mode and will be billed only for its \"Connected Time\" as outlined above. If the tag is removed, normal operations resume within 10 minutes.</p> <p>Applying the <code>lc:usage</code> tag will make the sensor operate normally as usual, but its connection will not count against the normal Sensor Quota. Instead it will be billed per time spend connected and number of events process/retained as outlined above.</p> <p>Using the \"usage\" and \"sleeper\" mode requires the organization in question to have billing enabled (a quota of at least 3 to be outside of the free tier).</p> <p>This means a sample scenario around pre-deploying in an enterprise could look something like this:</p> <ol> <li>Create a new Organization in LimaCharlie.</li> <li>Set the Quota to 3 to enable billing.</li> <li>Create a new Installation Key, and set the <code>lc:sleeper</code> tag on the key.</li> <li>Enroll any number of EDR sensors. Charges will apply as specified above. For example, if you deploy 100 Sensors in sleeper mode, total monthly costs will be $10.</li> <li> <p>Whenever you need to \"wake up\" and use some of the EDRs, you have 2 options:</p> </li> <li> <p>Set the <code>lc:usage</code> tag on the Sensor(s) you need. Within 10 minutes, telemetry collection will resume and billed on direct usage.</p> </li> <li>Set the quota to the number of Sensor(s) you need, remove the <code>lc:sleeper</code> tag from the specific Sensors, and within 10 minutes they will be online, billed according to the quota.</li> <li>When you're done, just re-add the <code>lc:sleeper</code> tag.</li> </ol> <p>Switching to sleeper mode does not change the binary on disk, however, the code running in memory does change. Whether putting an org into sleeper mode or changing versions, the binary on disk remains as-is.</p> <p>The changes to sleeper mode go into effect without the need for a reboot. In sleeper mode, activities such as read other process' memory (e.g. YARA) will stop.</p>"},{"location":"2-sensors-deployment/endpoint-agent/uninstallation/","title":"Endpoint Agent Uninstallation","text":"<p>There are multiple options available to uninstall the LimaCharlie Sensor, depending on the operating system and/or method of installation. macOS and Windows systems allow for easy uninstallation via sensor commands or  rules. Linux systems may require additional steps, as detailed below.</p>"},{"location":"2-sensors-deployment/endpoint-agent/uninstallation/#manually-uninstalling-the-endpoint-agent","title":"Manually Uninstalling the Endpoint Agent","text":"<p>When uninstalling macOS and Windows Sensors, please attempt to utilize a method similar to sensor deployment. For example, if sensors were deployed via a package manager, then the same package manager may have uninstall options as well. This will help keep software inventories up to date.</p> <p>Details on manual uninstallation is found at the bottom of each respective OS' installation procedures.</p>"},{"location":"2-sensors-deployment/endpoint-agent/uninstallation/#uninstalling-endpoint-agents-from-the-platform","title":"Uninstalling Endpoint Agents from the Platform","text":""},{"location":"2-sensors-deployment/endpoint-agent/uninstallation/#sensor-commands","title":"Sensor Commands","text":"<p>For macOS and Windows operating systems, you can uninstall a sensor with the <code>uninstall</code> command. More information on that can be found here.</p> <p>On Windows, the command defaults to uninstalling the sensor as if installed from the direct installer exe. If an MSI was used for installation, you can add a <code>--msi</code> flag to the <code>uninstall</code> command to trigger an uninstallation that is compatible with MSI.</p>"},{"location":"2-sensors-deployment/endpoint-agent/uninstallation/#sdk","title":"SDK","text":"<p>To run the uninstall command against all Sensors, a simple loop with the SDK in Python would work:</p> <pre><code>import limacharlie\nlc = limacharlie.Manager()\nfor sensor in lc.sensors():\n  sensor.task( 'uninstall' )\n</code></pre>"},{"location":"2-sensors-deployment/endpoint-agent/uninstallation/#using-a-dr-rule","title":"Using a D&amp;R Rule","text":"<p>As an alternative approach, you can also use a Detection &amp; Response (D&amp;R) rule to automatically trigger an uninstall of the LimaCharlie sensor when a sensor connects to the LimaCharlie cloud.  Below is an example of the rule you can use for this purpose. This example is specific to Windows-based endpoints, but can be modified based on your needs:</p> <pre><code># Detect\nevent: SYNC\nop: is windows\n\n# Respond\n- action: task\n  command: uninstall --is-confirmed\n- action: add tag\n  tag: uninstalled\n</code></pre>"},{"location":"2-sensors-deployment/endpoint-agent/uninstallation/#package-management-tools","title":"Package Management Tools","text":"<p>For Package Management tools, and other enterprise application-management tools, we recommend utilizing the integrated program removal options, rather than installing from LimaCharlie. This will help keep software inventories up to date.</p>"},{"location":"2-sensors-deployment/endpoint-agent/versioning-upgrades/","title":"Endpoint Agent Versioning and Upgrades","text":"<p>LimaCharlie frequently releases new versions of the endpoint agent (typically every few weeks), giving you full control over which version runs in your Organization. Sensors are not updated by default, allowing you to manage versioning and deployment as needed.</p>"},{"location":"2-sensors-deployment/endpoint-agent/versioning-upgrades/#endpoint-agent-components","title":"Endpoint Agent Components","text":"<p>The LimaCharlie endpoint agent consists of two main components, each versioned independently:</p> <ol> <li>On-disk agent: Implements core identity, cryptography, and transport mechanisms. This component rarely requires updates and typically remains static.</li> <li>Over-the-air core: The main component that receives frequent updates and delivers advanced functionality. It can be easily updated via the LimaCharlie cloud.</li> </ol> <p>When updates occur, they impact the over-the-air component, as it's the easiest to modify, with the update size generally being around 3-5 MB.</p>"},{"location":"2-sensors-deployment/endpoint-agent/versioning-upgrades/#version-labels","title":"Version Labels","text":"<p>LimaCharlie provides three version labels to simplify version management:</p> <ol> <li>Latest: The most recent release with new fixes and features.</li> <li>Stable: A less frequently updated version, ideal for maintaining slower update cadences.</li> <li>Experimental: The beta version of the next \"Latest\" release.</li> </ol> <p>You can upgrade to any of these version labels for your organization by using the LimaCharlie web interface or the API.</p>"},{"location":"2-sensors-deployment/endpoint-agent/versioning-upgrades/#upgrading-to-specific-versions","title":"Upgrading to Specific Versions","text":"<p>In addition to using version labels, you can upgrade your organization to a specific sensor version using semantic version strings (e.g., <code>4.33.20</code>). This is useful when:</p> <ul> <li>You need to pin your organization to a specific tested version</li> <li>You want to maintain version consistency across multiple organizations</li> <li>You need to rollback to a previous version for compatibility reasons</li> <li>You're testing a specific version before broader deployment</li> </ul> <p>To upgrade or manage sensors using the API:</p> <pre><code># Upgrade to a specific version\ncurl -X POST \"https://api.limacharlie.io/v1/modules/{oid}?specific_version=4.33.20\" \\\n  -H \"Authorization: Bearer {api_key}\" \\\n  -H \"Content-Type: application/json\"\n\n# Upgrade to latest version label\ncurl -X POST \"https://api.limacharlie.io/v1/modules/{oid}?specific_version=latest\" \\\n  -H \"Authorization: Bearer {api_key}\" \\\n  -H \"Content-Type: application/json\"\n\n# Downgrade to previous version (rollback)\ncurl -X POST \"https://api.limacharlie.io/v1/modules/{oid}?is_fallback=true\" \\\n  -H \"Authorization: Bearer {api_key}\" \\\n  -H \"Content-Type: application/json\"\n\n# Move sensors to dormant mode\ncurl -X POST \"https://api.limacharlie.io/v1/modules/{oid}?is_sleep=true\" \\\n  -H \"Authorization: Bearer {api_key}\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Note: Specific version strings follow semantic versioning format (MAJOR.MINOR.PATCH) and must correspond to an available LimaCharlie sensor release. If you specify an invalid or unavailable version, the API will return an error.</p>"},{"location":"2-sensors-deployment/endpoint-agent/versioning-upgrades/#managing-versioning-for-sensors","title":"Managing Versioning for Sensors","text":"<p>To manage the versioning of sensors, you can leverage LimaCharlie's System Tags:</p> <ul> <li> <p><code>lc:latest</code>: Tags the Sensor to receive the most recent version.</p> </li> <li> <p>This tag is primarily intended for testing <code>latest</code> sensor version against a small set of representative sensors before org-wide upgrades to <code>latest</code>.</p> </li> <li><code>lc:stable</code>: Tags the sensor to receive a stable version.</li> <li><code>lc:experimental</code>: Tags the sensor to receive the experimental version.</li> </ul> <p>These tags can be applied to individual sensors to alter version behavior, and updates take effect within 10 minutes. This method also enables staging deployments to test updates on a small group of sensors before organization-wide rollouts.</p>"},{"location":"2-sensors-deployment/endpoint-agent/versioning-upgrades/#updating-endpoint-agents","title":"Updating Endpoint Agents","text":""},{"location":"2-sensors-deployment/endpoint-agent/versioning-upgrades/#best-practices","title":"Best Practices","text":"<p>When deploying new sensor versions, follow a controlled testing approach by first applying the <code>lc:latest</code> tag to a small subset of representative systems across different operating systems and workloads. Monitor these test systems for a period of time, evaluating stability, performance, and telemetry quality. If testing is successful, update the organization-level sensor version and remove the <code>lc:latest</code> tag from test systems, while maintaining a rollback plan and monitoring system health during the deployment. Note that the <code>lc:latest</code> sensor tag should primarily be used for upgrade testing purposes, as it automatically updates sensors to new versions as they are released.</p>"},{"location":"2-sensors-deployment/endpoint-agent/versioning-upgrades/#manual-update","title":"Manual Update","text":"<p>You can manually trigger an update for all endpoint agents in your organization by simply clicking a button in the web interface. This action updates the over-the-air component of the sensors within 20 minutes, with no need to re-download installers, as the installer remains unchanged.</p>"},{"location":"2-sensors-deployment/endpoint-agent/versioning-upgrades/#auto-update","title":"Auto-Update","text":"<p>To automate updates, apply the <code>lc:stable</code> tag to your sensors. This will ensure that sensors automatically update to the latest stable version upon release.</p>"},{"location":"2-sensors-deployment/endpoint-agent/versioning-upgrades/#staged-deployment","title":"Staged Deployment","text":"<p>For testing new versions, tag specific sensors with <code>lc:latest</code> to run the latest version without affecting the rest of your organization. This allows you to test new releases on selected hosts before proceeding with a full rollout.</p>"},{"location":"2-sensors-deployment/endpoint-agent/chrome/installation/","title":"Chrome Agent Installation","text":"<p>LimaCharlie's Chrome Sensor is built as a browser extension and provides visibility for activity performed within the browser. This sensor is particularly useful for gaining affordable network visibility in organizations that make heavy use of ChromeOS.</p> <p>It is delivered as the LimaCharlie Sensor extension available in the Chrome Web Store.</p>"},{"location":"2-sensors-deployment/endpoint-agent/chrome/installation/#installation-instructions","title":"Installation Instructions","text":"<p>The Chrome sensor is available in the Chrome Web Store.</p> <ol> <li>In the LimaCharlie web app (app.limacharlie.io), go to the \"Installation Keys\" section, select your Installation Key and click the \"Chrome Key\" copy icon to copy the key to your clipboard.</li> <li>Install the sensor from: https://downloads.limacharlie.io/sensor/chrome</li> <li> <p>A new tab will open where you can add your installation key from before. If you close it by mistake, you can re-open it by:</p> </li> <li> <p>From the Extensions page at chrome://extensions/ click on the \"Details\" button of the LimaCharlie Sensor extension.</p> </li> <li>Go to the \"Extension options\" section, and enter your installation key from the previous step. Click save.</li> </ol> <p>The installation key can also be pre-configured through the Managed Storage feature (key named <code>installation_key</code>) if you are using a managed Chrome deployment.</p>"},{"location":"2-sensors-deployment/endpoint-agent/chrome/installation/#troubleshooting-the-chrome-sensor","title":"Troubleshooting the Chrome Sensor","text":"<p>If the Chrome extension is giving connectivity issues, the following may help.</p> <p>First, try uninstalling/re-installing the extension.</p> <p>If the extension continues to fail to connect, please provide the LimaCharlie support team with the following details:</p> <ol> <li>Open a new browser tab</li> <li>Go to <code>chrome://extensions/</code></li> <li>Ensure \"Developer Mode\" is enabled (see toggle in the top right)</li> </ol> <p></p> <ol> <li>Click the <code>background.html</code> link in the LimaCharlie Sensor entry.</li> </ol> <p></p> <ol> <li>In the window that opens, click Console and provide us with a screenshot of what appears for analysis.</li> </ol> <p>Please also include your Organization ID, which can be found within the LimaCharlie web interface in the REST API section under <code>OID</code>.</p>"},{"location":"2-sensors-deployment/endpoint-agent/containers/clusters/","title":"Container Clusters","text":"<p>You can also run LimaCharlie at the host level in a container cluster system like Kubernetes in order to monitor all running containers on the host with a single Sensor. In fact, this is the preferred method as it reduces the overhead of running LC within every single container.</p> <p>This is accomplished by a combination of a few techniques:</p> <ol> <li>A privileged container running LC.</li> <li>LC runs with <code>HOST_FS</code> environment variable pointing to the host's root filesystem mounted within the container.</li> <li>LC runs with the <code>NET_NS</code> environment variable pointing to the host's directory listing network namespaces.</li> <li>Running the container with the required flags to make sure it can have proper access.</li> </ol> <p>The first step is straight forward. For example, set the environment like <code>ENV HOST_FS=/rootfs</code> and <code>ENV NET_NS=/netns</code> as part of your <code>Dockerfile</code>. This will let the LC sensor know where it can expect host-level information.</p> <p>The second step is to run the container like: <code>docker run --privileged --net=host -v /:/rootfs:ro --env HOST_FS=/rootfs -v /var/run/docker/netns:/netns:ro --env NET_NS=/netns --env LC_INSTALLATION_KEY=your_key your-lc-container-name</code>.</p> <p>Remember to pick the appropriate LC sensor architecture installer for the container that will be running LC (not the host). So if your privileged container runs Alpine Linux, use the <code>alpine64</code> version of LC.</p> <p>A public version of the container described below is available from dockerhub as: <code>refractionpoint/limacharlie_sensor:latest</code>.</p>"},{"location":"2-sensors-deployment/endpoint-agent/containers/clusters/#sample-configurations","title":"Sample Configurations","text":"<p>This is a sample <code>Dockerfile</code> you may use to run LC within a privileged container as described above:</p> <pre><code># Requires an LC_INSTALLATION_KEY environment variable\n# specifying the installation key value.\n# Requires a HOST_FS environment variable that specifies where\n# the host's root filesystem is mounted within the container\n# like \"/rootfs\".\n# Requires a NET_NS environment variable that specific where\n# the host's namespaces directory is mounted within the container\n# like \"/netns\".\n# Example:\n# export ENV HOST_FS=/rootfs\n# docker run --privileged --net=host -v /:/rootfs:ro -v /var/run/docker/netns:/netns:ro --env HOST_FS=/rootfs --env NET_NS=/netns --env LC_INSTALLATION_KEY=your_key refractionpoint/limacharlie_sensor\n\nFROM alpine\n\nRUN mkdir lc\nWORKDIR /lc\n\nRUN wget https://downloads.limacharlie.io/sensor/linux/alpine64 -O lc_sensor\nRUN chmod 500 ./lc_sensor\n\nCMD ./lc_sensor -d -\n</code></pre> <p>And this is a sample Kubernetes <code>deployment</code> on</p> <p>a cluster supporting eBPF (kernel &gt; 5.7):</p> <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: lc-sensor\n  namespace: lc-monitoring\n  labels:\n    app: lc-monitoring\nspec:\n  minReadySeconds: 30\n  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n  selector:\n    matchLabels:\n      app: lc-monitoring\n  template:\n    metadata:\n      namespace: lc-monitoring\n      labels:\n        app: lc-monitoring\n    spec:\n      hostNetwork: true\n      hostPID: true\n      containers:\n        - name: lc-sensor\n          image: refractionpoint/limacharlie_sensor:latest\n          imagePullPolicy: IfNotPresent\n          securityContext:\n            allowPrivilegeEscalation: true\n            privileged: true\n            capabilities:\n              add: ['CAP_SYS_ADMIN']\n          resources:\n            requests:\n              memory: 128M\n              cpu: 0.01\n            limits:\n              memory: 256M\n              cpu: 0.9\n          volumeMounts:\n            - mountPath: /rootfs\n              name: all-host\n            - mountPath: /netns\n              name: all-host-ns\n            - mountPath: /sys/kernel/debug\n              name: all-host-krnl\n            - mountPath: /sys/kernel/btf\n              name: btf\n            - mountPath: /lib/modules\n              name: libmodules\n          env:\n            - name: HOST_FS\n              value: /rootfs\n            - name: NET_NS\n              value: /netns\n            - name: LC_INSTALLATION_KEY\n              value: &lt;&lt;&lt;&lt; YOUR INSTALLATION KEY GOES HERE &gt;&gt;&gt;&gt;\n      volumes:\n        - name: all-host\n          hostPath:\n            path: /\n        - name: all-host-ns\n          hostPath:\n            path: /var/run/docker/netns\n        - name: all-host-krnl\n          hostPath:\n            path: /sys/kernel/debug\n        - name: btf\n          hostPath:\n            path: /sys/kernel/btf\n        - name: libmodules\n          hostPath:\n            path: /lib/modules\n</code></pre> <p>a cluster not supporting eBPF (kernel &lt; 5.7):</p> <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: lc-sensor\n  namespace: lc-monitoring\n  labels:\n    app: lc-monitoring\nspec:\n  minReadySeconds: 30\n  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n  selector:\n    matchLabels:\n      app: lc-monitoring\n  template:\n    metadata:\n      namespace: lc-monitoring\n      labels:\n        app: lc-monitoring\n    spec:\n      containers:\n        - name: lc-sensor\n          image: refractionpoint/limacharlie_sensor:latest\n          imagePullPolicy: IfNotPresent\n          securityContext:\n            allowPrivilegeEscalation: true\n            privileged: true\n          resources:\n            requests:\n              memory: 128M\n              cpu: 0.01\n            limits:\n              memory: 256M\n              cpu: 0.9\n          volumeMounts:\n            - mountPath: /rootfs\n              name: all-host-fs\n            - mountPath: /netns\n              name: all-host-ns\n          env:\n            - name: HOST_FS\n              value: /rootfs\n            - name: NET_NS\n              value: /netns\n            - name: LC_INSTALLATION_KEY\n              value: &lt;&lt;&lt;&lt; YOUR INSTALLATION KEY GOES HERE &gt;&gt;&gt;&gt;\n      volumes:\n        - name: all-host-fs\n          hostPath:\n            path: /\n        - name: all-host-ns\n          hostPath:\n            path: /var/run/docker/netns\n      hostNetwork: true\n</code></pre>"},{"location":"2-sensors-deployment/endpoint-agent/containers/clusters/#selinux","title":"SELinux","text":"<p>On some hardened versions of Linux, certain file paths are prevented from loading <code>.so</code> (Shared Object) files. LimaCharlie requires a location where it can write <code>.so</code> files and load them. To enable this on hardened versions of Linux, you can specify a <code>LC_MOD_LOAD_LOC</code> environment variable containing a path to a valid directory for loading, like <code>/lc</code> for example. This environment variable needs to be set for the sensor executable (<code>rphcp</code>) at runtime.</p>"},{"location":"2-sensors-deployment/endpoint-agent/docker/installation/","title":"Docker Agent Installation","text":""},{"location":"2-sensors-deployment/endpoint-agent/docker/installation/#docker","title":"Docker","text":"<p>The LimaCharlie agent is designed to run within a Docker container, providing seamless integration with containerized environments. Running the agent in a container allows for efficient deployment and management while ensuring security monitoring and telemetry collection.</p> <p>Additionally, the agent can also be deployed on various container cluster technologies, such as Kubernetes. For Kubernetes deployment details, refer to Container Clusters.</p>"},{"location":"2-sensors-deployment/endpoint-agent/docker/installation/#host-visibility-requirements","title":"Host Visibility Requirements","text":"<p>For the LimaCharlie agent to have full visibility into activities on the host system, the following configurations are required:</p> <ul> <li>The container must run in privileged mode to access host-level resources.</li> <li>The container must use host networking to observe network activity.</li> <li>The container must use host PID mode to track running processes.</li> <li> <p>Various host-level directories must be mounted into the container, including:</p> </li> <li> <p>The root filesystem (<code>rootfs</code>)</p> </li> <li>Docker network namespaces (<code>netns</code>)</li> <li>The directory containing kernel modules and debug symbols</li> </ul> <p>Additionally, on newer Linux kernel versions (5.7+), the agent leverages eBPF for enhanced visibility and telemetry collection.</p>"},{"location":"2-sensors-deployment/endpoint-agent/docker/installation/#agent-docker-image","title":"Agent Docker Image","text":"<p>A publicly available Docker image for the LimaCharlie agent is hosted on Docker Hub:</p> <pre><code>docker pull refractionpoint/limacharlie_sensor:latest\n</code></pre>"},{"location":"2-sensors-deployment/endpoint-agent/docker/installation/#image-flavors","title":"Image Flavors","text":"<p>Docker image is available in different flavors based on specific distributions:</p> <ul> <li><code>latest</code> - Default version based on CentOS Linux.</li> <li><code>alpine</code> - Based on Alpine Linux (smaller image size).</li> <li><code>centos</code> - Based on CentOS Linux.</li> </ul>"},{"location":"2-sensors-deployment/endpoint-agent/docker/installation/#available-environment-variables","title":"Available Environment Variables","text":"<p>The agent supports several environment variables to control its behavior:</p> <ul> <li><code>LC_INSTALLATION_KEY</code> - Specifies the installation key required to authenticate the agent.</li> <li><code>HOST_FS</code> - Defines the path where the host's root filesystem is mounted within the container. Example: <code>/rootfs</code>.</li> <li><code>NET_NS</code> - Specifies the path to the host's network namespace directory. Example: <code>/netns</code>.</li> </ul> <p>These variables must be configured appropriately to ensure the agent functions as expected.</p>"},{"location":"2-sensors-deployment/endpoint-agent/docker/installation/#running-the-agent-using-docker-cli","title":"Running the Agent Using Docker CLI","text":"<p>To run the LimaCharlie agent in a Docker container, use the following command:</p> <pre><code>docker run --privileged --net=host \\\n  -v /:/rootfs:ro \\\n  -v /var/run/docker/netns:/netns:ro \\\n  -v /sys/kernel/debug:/sys/kernel/debug:ro \\\n  -v /sys/kernel/btf:/sys/kernel/btf:ro \\\n  -v /lib/modules:/lib/modules:ro \\\n  --env LC_INSTALLATION_KEY=&lt;your_key&gt; \\\n  --env HOST_FS=/rootfs \\\n  --env NET_NS=/netns \\\n  refractionpoint/limacharlie_sensor:latest\n</code></pre> <p>Ensure that you replace <code>&lt;your_key&gt;</code> with your actual LimaCharlie installation key.</p>"},{"location":"2-sensors-deployment/endpoint-agent/docker/installation/#running-the-agent-using-docker-compose","title":"Running the Agent Using Docker Compose","text":"<p>You can also manage the LimaCharlie agent using Docker Compose. Below is a sample <code>docker-compose.yml</code> file:</p> <pre><code>services:\n  lc-sensor:\n    image: refractionpoint/limacharlie_sensor:latest\n    restart: unless-stopped\n    network_mode: \"host\"\n    pid: \"host\"\n    privileged: true\n    environment:\n      - HOST_FS=/rootfs\n      - NET_NS=/netns\n      - LC_INSTALLATION_KEY=&lt;your key&gt;\n    deploy:\n      resources:\n        limits:\n          cpus: \"0.9\"\n          memory: \"256M\"\n        reservations:\n          cpus: \"0.01\"\n          memory: \"128M\"\n    cap_add:\n      - SYS_ADMIN\n    volumes:\n      - /:/rootfs\n      - /var/run/docker/netns:/netns\n      - /sys/kernel/debug:/sys/kernel/debug\n      - /sys/kernel/btf:/sys/kernel/btf\n      - /lib/modules:/lib/modules\n</code></pre> <p>To start the container, run:</p> <pre><code>docker-compose up -d\n</code></pre> <p>This setup ensures the agent runs as a privileged container, enabling full visibility into the host system while being managed through Docker Compose.</p>"},{"location":"2-sensors-deployment/endpoint-agent/docker/installation/#building-a-custom-docker-image","title":"Building a Custom Docker Image","text":"<p>If you need to create a custom Docker image incorporating the LimaCharlie agent, you can use the following Dockerfile as a base:</p> <pre><code>FROM alpine\n\nRUN mkdir /lc\nWORKDIR /lc\n\nRUN wget https://downloads.limacharlie.io/sensor/linux/alpine64 -O lc_sensor\nRUN chmod 500 ./lc_sensor\n\nCMD [\"./lc_sensor\", \"-d\", \"-\"]\n</code></pre> <p>Build the image using:</p> <pre><code>docker build -t my-lc-agent .\n</code></pre>"},{"location":"2-sensors-deployment/endpoint-agent/edge/installation/","title":"Edge Agent Installation","text":"<p>LimaCharlie's Edge Sensor is delivered as the LimaCharlie Sensor extension, available as an Edge Add-on.</p>"},{"location":"2-sensors-deployment/endpoint-agent/edge/installation/#edge-installation-instructions","title":"Edge Installation Instructions","text":"<p>The Edge sensor is available in the Edge Add-ons section.</p> <ol> <li>In the LimaCharlie web app (app.limacharlie.io), go to the \"Installation Keys\" section, select your Installation Key and click the \"Chrome Key\" copy icon to copy the key to your clipboard.</li> <li>Install the sensor from: https://microsoftedge.microsoft.com/addons/detail/limacharlie-sensor/nomgmkpkkncolnpbkbamfnjhbhmnjehp</li> <li>A new tab will open where you can add your installation key from before.</li> </ol>"},{"location":"2-sensors-deployment/endpoint-agent/linux/installation/","title":"Linux Agent Installation","text":"<p>The LimaCharlie Linux Sensor interfaces with the kernel to acquire deep visibility into the host's activity while taking measures to preserve the host's performance. We make full use of eBPF, which requires Linux 4.4 or above.</p> <p>The Sensor current supports all Linux distributions (including ARM and MIPS).</p> <p>Linux Distribution Support</p> <p>Our Linux Sensor fully utilizes eBPF, which requires at least Linux 4.4 or above. Use the command <code>uname -r</code> to check your kernel version to determine support.</p>"},{"location":"2-sensors-deployment/endpoint-agent/linux/installation/#installation-instructions","title":"Installation Instructions","text":""},{"location":"2-sensors-deployment/endpoint-agent/linux/installation/#system-requirements","title":"System Requirements","text":"<p>All versions of Debian and CentOS starting around Debian 5 should be supported. Due to the high diversity of the ecosystem it's also likely to be working on other distributions. If you need a specific platform, contact us.</p>"},{"location":"2-sensors-deployment/endpoint-agent/linux/installation/#deb-package","title":"Deb Package","text":"<p>If you are deploying on a Debian Linux system, we recommend using the <code>.deb</code> package. You can find a link to the Debian package for various architectures at Downloading the Agent.</p> <p>The deb package will install the LimaCharlie sensor using a <code>systemd</code> service, or if unavailable a <code>system V</code> service.</p> <p>The Installation Key is required by the installer via the <code>debconf</code> configuration mechanism. By default, installing the package interactively will request the installation key via a local command/GUI interface. To perform large scale installations, we recommend setting the installation key programmatically.</p> <p>Installing interactively:</p> <pre><code>sudo dpkg -i limacharlie.deb\n</code></pre> <p>or</p> <pre><code>sudo apt install ./limacharlie.deb\n</code></pre> <p>Uninstalling interactively:</p> <pre><code>sudo dpkg -r limacharlie\n</code></pre> <p>or</p> <pre><code>sudo apt remove limacharlie\n</code></pre> <p>Installing and setting the installation key programmatically with dpkg:</p> <pre><code>echo \"limacharlie limacharlie/installation_key string INSTALLATION_KEY_HERE\" | sudo debconf-set-selections &amp;&amp; sudo dpkg -i limacharlie.deb\n</code></pre> <p>Installing and setting the installation key programmatically with apt:</p> <pre><code>echo \"limacharlie limacharlie/installation_key string INSTALLATION_KEY_HERE\" | sudo debconf-set-selections &amp;&amp; sudo apt install ./limacharlie.deb -y\n</code></pre> <p>Debian packages are offered for the various architectures the Linux sensor supports, like:</p> <ul> <li>x64: https://downloads.limacharlie.io/sensor/linux/deb64</li> <li>arm64: https://downloads.limacharlie.io/sensor/linux/debarm64</li> </ul>"},{"location":"2-sensors-deployment/endpoint-agent/linux/installation/#custom-installation","title":"Custom Installation","text":"<p>For non-Debian systems, download the installer using the following command:</p> <pre><code>wget https://downloads.limacharlie.io/sensor/linux/64 -O /tmp/lc_sensor\n</code></pre> <p>Other Linux Versions</p> <p>If installing on an ARM64 or Alpine64 system, replace the URL in the command above with the respective URL from the installation wizard within LimaCharlie</p> <p>Executing the installer via the command line, pass the <code>-d INSTALLATION_KEY</code> argument where <code>INSTALLATION_KEY</code> is the key mentioned above.</p> <p>Because Linux supports a plethora of service management frameworks, by default the LC sensor does not install itself onto the system. Rather it assumes the \"current working directory\" is the installation directory and immediately begins enrollment from there.</p> <p>This means you can wrap the executable using the specific service management technology used within your Organization by simply specifying the location of the installer, the <code>-d INSTALLATION_KEY</code> parameter and making sure the current working directory is the directory where you want the few sensor-related files written to disk to reside.</p> <p>A common methodology for Linux is to use <code>init.d</code>, if this is sufficient for your needs, see this sample install script. You can invoke it like this:</p> <pre><code>sudo chmod +x ./lc_linux_installer.sh\nsudo ./lc_linux_installer.sh &lt;PATH_TO_LC_SENSOR&gt; &lt;YOUR_INSTALLATION_KEY&gt;\n</code></pre> <p>You may also pass the value <code>-</code> instead of the <code>INSTALLATION_KEY</code> like: <code>-d -</code>. This will make the installer look for the installation key in an alternate place in the following order:</p> <ul> <li>Environment variable <code>LC_INSTALLATION_KEY</code></li> <li>Text file in current working directory: <code>lc_installation_key.txt</code></li> </ul>"},{"location":"2-sensors-deployment/endpoint-agent/linux/installation/#disabling-netlink","title":"Disabling Netlink","text":"<p>By default, the Linux sensor makes use of Netlink if available. In some rare configurations this auto-detection may be unwanted and Netlink usage can be disabled by setting the environment variable <code>DISABLE_NETLINK</code> to any value on the sensor process.</p>"},{"location":"2-sensors-deployment/endpoint-agent/linux/installation/#uninstalling-the-agent","title":"Uninstalling the Agent","text":"<p>For additional agent uninstall options, see Endpoint Agent Uninstallation</p> <p>Linux agent uninstallation depends on how the sensor was installed. For example, if installed via a Debian package (<code>dpkg</code> file), you should uninstall via the same mechanism. If you installed via the SystemV installation method, please utilize the bottom of this script.</p>"},{"location":"2-sensors-deployment/endpoint-agent/linux/installation/#sensor-command","title":"Sensor Command","text":"<p>The <code>uninstall</code> command does not work for Linux systems. However, there is a chained command that can be run from the Sensor Console:</p> <pre><code> run --shell-command \"service limacharlie stop; rm /bin/rphcp; update-rc.d limacharlie remove -f; rm -rf /etc/init.d/limacharlie; rm /etc/hcp ; rm /etc/hcp_conf; rm /etc/hcp_hbs\"\n</code></pre> <p>The above command removes LimaCharlie and associated files from the system when run remotely. Note that the above command could also be coupled with a rule for automated sensor uninstallation, if necessary.</p>"},{"location":"2-sensors-deployment/endpoint-agent/linux/installation/#debian-systems","title":"Debian Systems","text":"<p>If the sensor was originally installed with the .deb file, this option is the cleanest uninstall method.</p> <pre><code>apt remove limacharlie\n</code></pre>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation-older/","title":"macOS Agent Installation - Older Versions (macOS 10.14 and prior)","text":"<p>This document provides details of how to install, verify, and uninstall the LimaCharlie sensor on macOS (versions 10.14 and prior). We also offer documentation for macOS 10.15 and newer.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation-older/#installer-options","title":"Installer Options","text":"<p>When running the installer from the command line, you can pass the following arguments:</p> <pre><code>-v: display build version.\n-q: quiet; do not display banner.\n-d &lt;INSTALLATION_KEY&gt;: the installation key to use to enroll, no permanent installation.\n-i &lt;INSTALLATION_KEY&gt;: install executable as a service with deployment key.\n-r: uninstall executable as a service.\n-c: uninstall executable as a service and delete identity files.\n-w: executable is running as a macOS service.\n-h: displays the list of accepted arguments.\n</code></pre>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation-older/#installation-flow","title":"Installation Flow","text":"<ol> <li>Download the Sensor installer file</li> <li>Add execute permission to the installer file via the command line</li> </ol> <p>chmod +x hcp_osx_x64_release_4.23.0</p> <ol> <li>Run the installer via the command line. You'll pass the argument -i and your Installation Key.</li> </ol> <p>sudo ./hcp_osx_x64_release_4.23.0 -i YOUR_INSTALLATION_KEY_GOES_HERE</p> <p></p> <p>You can obtain the installation key from the Installation Keys section of the LimaCharlie web application. More information about installation keys.</p> <p>The sensor will be installed as a launchctl service. Installation will trigger the sensors enrollment with the LimaCharlie cloud.</p> <p></p> <ol> <li>You will be prompted to grant permissions for system extensions to be installed.</li> </ol> <p></p> <ol> <li>Click the \"Open System Preferences\" button</li> <li>Unlock the preference pane using the padlock in the bottom left corner, then click the Allow button next to <code>System software from developer \"Refraction Point, Inc\" was blocked from loading.</code></li> </ol> <p></p> <p>The installation is now complete and you should see a message indicating that the installation was successful.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation-older/#verifying-installation","title":"Verifying Installation","text":"<p>To verify that the sensor was installed successfully, you can log into the LimaCharlie web application and see if the device has appeared in the Sensors section. Additionally, you can check the following on the device itself:</p> <p>Ensure the process is running</p> <p>In a Terminal, run the command:</p> <p>sudo launchctl list | grep com.refractionpoint.rphcp</p> <p></p> <p>If the agent is running, this command should return a record as shown above.</p> <p>Ensure the Kernel Extension is loaded</p> <p>You can confirm that the kernel extension is loaded by running the command:</p> <p>kextstat | grep com.refractionpoint.</p> <p></p> <p>If the extension is loaded, this command should return a record as shown above.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation-older/#a-note-on-permissions","title":"A note on permissions","text":"<p>Apple has purposely made installing extensions (like the ones used by LimaCharlie) a process that requires several clicks on macOS. The net effect of this is that the first time the sensor is installed on a macOS system, permissions will need to be granted via System Preferences</p> <p>Currently, the only way to automate the installation is to use an Apple-approved MDM solution. These solutions are often used by large organizations to manage their Mac fleet. If you are using such a solution, see your vendor's documentation on how to add extensions to the allow list which can be applied to your entire fleet.</p> <p>We're aware this is an inconvenience and hope Apple will provide better solutions for security vendors in future.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation-older/#uninstallation-flow","title":"Uninstallation Flow","text":"<p>To uninstall the sensor:</p> <ol> <li>Run the installer via the command line.</li> </ol> <p>You'll pass the argument -c</p> <p>sudo ./hcp_osx_x64_release_4.23.0 -c</p> <p></p> <ol> <li>You should see a message indicating that the uninstallation was successful.</li> </ol> <p></p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation/","title":"macOS Agent Installation - Older Versions (macOS 10.15 Catalina to macOS 14 Sonoma)","text":"<p>This document provides details of how to install, verify, and uninstall the LimaCharlie Endpoint Agent on macOS (versions 10.15 Catalina though to macOS 14 Sonoma). We also offer documentation for macOS 10.14 and prior, and macOS 10.15 and newer.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation/#installer-options","title":"Installer Options","text":"<p>When running the installer from the command line, you can pass the following arguments:</p> <pre><code>-v: display build version.\n-q: quiet; do not display banner.\n-d &lt;INSTALLATION_KEY&gt;: the installation key to use to enroll, no permanent installation.\n-i &lt;INSTALLATION_KEY&gt;: install executable as a service with deployment key.\n-r: uninstall executable as a service.\n-c: uninstall executable as a service and delete identity files.\n-w: executable is running as a macOS service.\n-h: displays the list of accepted arguments.\n</code></pre>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation/#installation-flow","title":"Installation Flow","text":"<ol> <li>Download the Sensor installer file. Installer for: Intel Mac -or- Apple Silicon Mac.</li> <li>Add execute permission to the installer file via the command line</li> </ol> <p>chmod +x lc_sensor</p> <ol> <li>Run the installer via the command line. You'll pass the argument -i and your Installation Key.</li> </ol> <p>sudo ./lc_sensor -i YOUR_INSTALLATION_KEY_GOES_HERE</p> <p></p> <p>You can obtain the installation key from the Installation Keys section of the LimaCharlie web application.</p> <p>The sensor will be installed as a launchctl service. Installation will trigger the sensors enrollment with the LimaCharlie cloud.</p> <p></p> <ol> <li>An application (<code>RPHCP.app</code>) will be installed in the /Applications folder and will automatically launch. You will be prompted to grant permissions for system extensions to be installed.</li> </ol> <p></p> <ol> <li>Click the \"Open System Preferences\" button</li> </ol> <p></p> <ol> <li>Unlock the preference pane using the padlock in the bottom left corner, then click the Allow button next to <code>System software from application \"RPHCP\" was blocked from loading.</code></li> </ol> <p></p> <ol> <li>You'll be prompted to allow the application to Filter Network Content. Click the Allow button.</li> </ol> <p></p> <ol> <li>You'll be prompted to grant Full Disk Access. Check the checkbox next to the RPHCP app in System Preferences -&gt; Privacy -&gt; Full Disk Access</li> </ol> <p></p> <p>The installation is now complete and you should see a message indicating that the installation was successful.</p> <p></p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation/#verifying-installation","title":"Verifying Installation","text":"<p>To verify that the sensor was installed successfully, you can log into the LimaCharlie web application and see if the device has appeared in the Sensors section. Additionally, you can check the following on the device itself:</p> <p>In a Terminal, run the command:</p> <p>sudo launchctl list | grep com.refractionpoint.rphcp</p> <p></p> <p>If the agent is running, this command should return records as shown above.</p> <p>You can also check the /Applications folder and launch the RPHCP.app.</p> <p></p> <p>The application will show a message to indicate if the required permissions have been granted.</p> <p></p> <p>As described in the dialog, the RPHCP.app application must be left in the /Applications folder in order for it to continue operating properly.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation/#a-note-on-permissions","title":"A note on permissions","text":"<p>Apple has purposely made installing extensions (like the ones used by LimaCharlie) a process that requires several clicks on macOS. The net effect of this is that the first time the sensor is installed on a macOS system, permissions will need to be granted via System Preferences</p> <p>Currently, the only way to automate the installation is to use an Apple-approved MDM solution. These solutions are often used by large organizations to manage their Mac fleet. If you are using such a solution, see your vendor's documentation on how to add extensions to the allow list which can be applied to your entire fleet.</p> <p>We're aware this is an inconvenience and hope Apple will provide better solutions for security vendors in future.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation/#uninstallation-flow","title":"Uninstallation Flow","text":"<p>To uninstall the sensor:</p> <ol> <li>Run the installer via the command line. You'll pass the argument -c</li> </ol> <p>sudo ./hcp_osx_x64_release_4.23.0 -c</p> <p></p> <ol> <li>You will be prompted for credentials to modify system extensions. Enteryour password and press OK.</li> </ol> <p></p> <p>The related system extension will be removed and the <code>RPHCP.app</code> will be removed from the /Applications folder.</p> <ol> <li>You should see a message indicating that the uninstallation was successful.</li> </ol> <p></p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/installation/#install-using-mdm-solutions","title":"Install Using MDM Solutions","text":"<p>See our document macOS Agent Installation with MDM Solutions for the Mobile Device Management (MDM) Configuration Profile that can be used to deploy the LimaCharlie agent to an enterprise fleet.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/intune/","title":"macOS Agent Installation via Microsoft Intune","text":"<p>You can deploy the LimaCharlie Sensor for macOS using the MDM provider of your choice. Below are instructions for deploying the LimaCharlie Sensor for macOS using Microsoft Intune.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/intune/#mdm-profile","title":"MDM Profile","text":"<p>Set up the installation script by following these steps:</p> <ol> <li>In the Microsoft Intune admin center, go to Devices \u2192 Manage Devices \u2192 Configuration.</li> </ol> <p></p> <ol> <li> <p>Choose Policies, click the Create button and choose New Policy</p> </li> <li> <p>Set the Platform to be macOS</p> </li> <li> <p>Set the Profile Type to be Templates, then choose the template name \"Custom\"</p> </li> <li> <p>Click Create</p> </li> <li> <p>Enter the custom policy details as follows:</p> </li> <li> <p>Name: LimaCharlie</p> </li> <li> <p>Custom configuration profile name: LimaCharlie</p> </li> <li> <p>Deployment channel: Device channel</p> </li> <li> <p>Configuration profile file: Download and use the LimaCharlie MDM profile.</p> </li> </ol> <p>Set the Assignments to include all users who need the profile installed.</p> <p></p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/intune/#installation-script","title":"Installation Script","text":"<p>Set up the installation script by following these steps:</p> <ol> <li>In the Microsoft Intune admin center, go to Devices \u2192 Manage Devices \u2192 Scripts and remediations.</li> </ol> <p></p> <ol> <li> <p>Choose Platform scripts, click the Add button and choose macOS</p> </li> <li> <p>Set up the script with the following parameters:</p> </li> </ol> <p>Name: Install LimaCharlie</p> <p>Shell script: Download this template shell script; be sure to edit it to include your Installation Key before uploading it in MS Intune.</p> <p>Run script as signed-in user: No</p> <p>Hide script notifications on devices: Yes</p> <p>Script frequency: Not configured</p> <p>Max number of times to retry if script fails: 3</p> <p>Assignments: Set the <code>Included groups</code> to be <code>All Users</code> if you wish all users to get the application to be installed, or simply select the correct group to whom you wish to have LimaCharlie be installed for.</p> <p></p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/jamf/","title":"macOS Agent Installation via Jamf Now","text":"<p>Jamf Now is an MDM solution that provides an easy way to manage Apple devices for small and medium-sized businesses. LimaCharlie sensors can be deployed via Jamf Now for easy app distribution and inventory capabilities.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/jamf/#prerequisites","title":"Prerequisites","text":"<ul> <li>a Jamf Now account;</li> <li>a provisioning profile that grants the necessary pre-authorizations (such as is available here) for deployment on the clients;</li> <li>a LimaCharlie Mac Sensor installer package (<code>.pkg</code>) that's configured as desired for deployment on the clients.</li> </ul>"},{"location":"2-sensors-deployment/endpoint-agent/macos/jamf/#set-up-your-account-on-jamf-now","title":"Set up your account on Jamf Now","text":"<ol> <li>Create a Jamf Now account at https://signup.jamfnow.com, and log in.</li> <li>Choose the \"APNs\" tab in the sidebar, and click \"Get Started\".</li> <li>Click \"Download Certificate Signing Request.plist\" and save the plist.</li> <li>Click Next in the lower right.</li> <li>As per the \"Create an Apple Push Certificate\" checklist shown, click \"Open the Apple Push Certificates Portal\".</li> <li>Log in with your Apple ID.</li> <li>On the \"Apple Push Certificates Portal\" page to which you are redirected, click the green \"Create Certificate\" button.</li> <li>Accept the Terms of Use, and click Continue.</li> <li>On the \"Create a New Push Certificate\" page to which you're redirected, specify the plist you downloaded in step 2 and click Upload.</li> <li>On the \"Confirmation\" page, click Download and save the new PEM certificate file.</li> <li>Navigate back to the Jamf Now page as at step 5, and click Next in the lower right.</li> <li>On the \"Upload Push Certificate\" page, specify the PEM you downloaded in step 10.</li> <li>Under \"Save Your Apple ID\", annotate same as Jamf invites to do so, and click Save.</li> </ol>"},{"location":"2-sensors-deployment/endpoint-agent/macos/jamf/#prepare-the-limacharlie-sensor-installer-package-on-jamf","title":"Prepare the LimaCharlie sensor installer package on Jamf","text":"<p>As a prerequisite you must have on hand a LimaCharlie Sensor installer package (.pkg) that's configured as desired.</p> <ol> <li>Choose the \"Apps\" tab in the Jamf Now sidebar. It will show \"No apps yet, let's fix that.\"</li> <li>Click \"Add an App\".</li> </ol> <p></p> <ol> <li>On the \"Add an App\" page, click \"Upload Your App\" in the top menu.</li> </ol> <p></p> <ol> <li>Drag your LC Sensor package installer onto the page (or click \"browse\" to locate it) to upload it to Jamf.</li> <li>Give the package an appropriate name, and click Done.</li> </ol> <p></p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/jamf/#prepare-the-limacharlie-sensor-provisioning-on-jamf","title":"Prepare the LimaCharlie sensor provisioning on Jamf","text":"<ol> <li>Choose the \"Blueprints\" tab in the Jamf Now sidebar.</li> <li>Click \"Create New Blueprint\" at the top.</li> </ol> <ol> <li>Enter a meaningful Name and Description as prompted, and click Save Blueprint.</li> </ol> <ol> <li>Click on the entry for your new Blueprint.</li> </ol> <ol> <li>On the inner tab bar that appears, click \"Custom Profiles\", and then \"Add a Custom Profile\".</li> </ol> <ol> <li>Drag your LimaCharlie mobileconfig file onto the page (or click \"browse\" to locate it) to upload it to Jamf.</li> </ol> <ol> <li>Click \"Add Custom Profile\" in the lower right.</li> </ol> <ol> <li>On the inner tab bar, click \"Apps\", and then click \"Add App\".</li> </ol> <ol> <li>In the list, enable the \"Install Automatically\" checkbox for with the installer package that you uploaded earlier.</li> </ol> <ol> <li>Click \"Save Changes\" in the lower right.</li> </ol>"},{"location":"2-sensors-deployment/endpoint-agent/macos/jamf/#prepare-jamf-now-to-enroll-devices","title":"Prepare Jamf Now to enroll devices","text":"<ol> <li>Choose the \"Devices\" tab in the Jamf Now sidebar. It will show \"No devices yet, let's fix that.\"</li> <li>Click \"Enable Open Enrollment\".</li> <li>On the \"Open Enrollment\" page, activate the \"Enable Open Enrollment\" checkbox, enter an Access Code as prompted, and click Save Settings.</li> <li>Take note of the indicated enrollment link.</li> </ol>"},{"location":"2-sensors-deployment/endpoint-agent/macos/jamf/#enroll-a-mac-for-management-in-jamf","title":"Enroll a Mac for management in Jamf","text":"<p>The following recipe presumes the use of MacOS 13 (Ventura).</p> <ol> <li>On a subject Mac, visit the enrollment link from step 4 in the section above.</li> <li>Enter the appropriate Access Code and user name, and click Start Enrollment.</li> </ol> <p></p> <ol> <li>Save the \"enroll.mobileconfig\" file that begins to download, and then open it in the Finder by double-clicking.</li> <li> <p>Open the System Settings app and navigate to the newly-installed profile.</p> </li> <li> <p>Choose \"Privacy &amp; Security\".</p> </li> <li>Scroll to the bottom, and under the \"Others\" heading, click \"Profiles\".</li> </ol> <p></p> <ol> <li>Double-click on the \" Profile\".</li> </ol> <p></p> <ol> <li>Click \"Install\u2026\" in the lower left.</li> </ol> <p></p> <ol> <li>Authenticate with the appropriate password when prompted with \"Profiles is trying to enroll you in a remote management (MDM) service\".</li> </ol> <p></p> <ol> <li>Observe that System Settings declares \"This Mac is supervised and managed by \".</li> </ol> <p></p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/jamf/#provision-a-mac-with-the-limacharlie-sensor","title":"Provision a Mac with the LimaCharlie sensor","text":"<ol> <li>Choose the \"Blueprints\" tab in the Jamf Now sidebar.</li> <li>Click the entry for the custom Blueprint you created from Step 6 onward in the \"Prepare the LC sensor package on Jamf\" section above.</li> </ol> <ol> <li>On the inner tab bar that appears, click \"Devices\", and then \"Add a Device\".</li> </ol> <ol> <li>Click on a device you want to provision, and then click \"Add Devices\" in the lower right corner.</li> </ol> <ol> <li> <p>Observe after a few moments that both the provisioning profile and the LimaCharlie sensor have been installed on the subject Mac.</p> </li> <li> <p>The Mac appear in the Jamf Devices list on the Blueprints tab with the label \"Settings applied\". (It may initially appear as \"Settings not applied\"; simply refresh the page.)</p> </li> </ol> <p></p> <ol> <li>On the Mac itself, an additional profile appears in System Settings &gt; Privacy &amp; Security &gt; Profiles.</li> </ol> <p></p> <ol> <li>A \"Background Items Added\" notification is displayed.</li> </ol> <p></p> <ol> <li>The RPHCP.app appears in the Mac's Applications folder, and the rphcp daemon is running.</li> </ol>"},{"location":"2-sensors-deployment/endpoint-agent/macos/mdm-profiles/","title":"macOS Agent Installation - MDM Configuration Profiles","text":"<p>This document provides details of the Mobile Device Management (MDM) Configuration Profile that can be used to deploy the LimaCharlie agent to your enterprise fleet on macOS (versions 10.15 and newer).</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/mdm-profiles/#affected-dialogs","title":"Affected Dialogs","text":"<p>Once the configuration profile is deployed using an approved MDM server, users will not need to provide approval to complete the agent installation. In particular, the following three system approval dialogs will no longer be presented:</p> <p>System Extension </p> <p>Network Filter </p> <p>Full Disk Access </p> <p>Application Installation </p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/mdm-profiles/#configuration-profile-details","title":"Configuration Profile Details","text":"<p>We have provided a sample configuration profile for reference: </p> <p>Download LimaCharlie.mobileconfig sample configuration profile</p> <p>This profile includes the following permissions:</p> <ul> <li>System Extension</li> <li>Full Disk Access</li> <li>Network Content Filter</li> </ul>"},{"location":"2-sensors-deployment/endpoint-agent/macos/mdm-profiles/#silent-installation-preference","title":"Silent Installation Preference","text":"<p>In addition to the MDM profile, you will also want to place the following preference file in the /Library/Preferences folder on the endpoint prior to installation. With this preference file in place the application will provide for a silent installation.</p> <p>The required preference file can be downloaded here: </p> <p>Download com.refractionpoint.rphcp.client.plist preference file (to be placed in the /Library/Preferences folder on the endpoint)</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/mdm-profiles/#installation-scripts","title":"Installation Scripts","text":"<p>We have made a sample installation and uninstallation script available. You can use these with MDM providers to mass install/remove LimaCharlie. Note that the installation script should be edited prior to use as it requires your unique Installation Key to be entered.</p> <p>These scripts will determine the machine architecture (Intel or Apple Silicon), download the appropriate installer, and then perform the installation or uninstallation. They also will automatically add (or remove, for uninstallations) the Silent Installation Preference File.</p> <p>Sample Installation Script</p> <p>Sample Uninstallation Script</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/mdm-profiles/#example-jamf-pro-setup","title":"Example Jamf Pro Setup","text":"<p>While any Apple / user approved MDM provider may be used, we have provided specific instructions for Jamf Pro as a matter of convenience.</p> <ol> <li>Log into Jamf Pro and go to Computers -&gt; Configuration Profiles</li> <li>Add a new profile</li> <li>In the General section choose a name for the profile and set Level to \"Computer Level\"</li> </ol> <p></p> <ol> <li>Add a Privacy Preferences Policy Control configuration and set the parameters as follows:</li> </ol> <p>Identifier: com.refractionpoint.rphcp.extension</p> <p>Identifier Type: Bundle ID</p> <p>Code Requirement: anchor apple generic and identifier \"com.refractionpoint.rphcp.extension\" and (certificate leaf[field.1.2.840.113635.100.6.1.9] /* exists */ or certificate 1[field.1.2.840.113635.100.6.2.6] /* exists */ and certificate leaf[field.1.2.840.113635.100.6.1.13] /* exists */ and certificate leaf[subject.OU] = N7N82884NH)</p> <p>App or Service: SystemPolicyAllFiles</p> <p>Access: Allow</p> <p></p> <ol> <li>Add a System Extensions configuration and set the parameters as follows:</li> </ol> <p>Enter your desired display name</p> <p>System Extension Types: Allowed System Extensions</p> <p>Team Identifier: N7N82884NH</p> <p>Allowed System Extensions: com.refractionpoint.rphcp.extension</p> <p></p> <ol> <li>Add a Content Filter configuration and set the parameters as follows:</li> </ol> <p>Enter your desired filter name</p> <p>Identifier: com.refractionpoint.rphcp.client</p> <p>Filter Order: Firewall</p> <p>Add a Socket Filter with the following details: Socket Filter Bundle Identifier: com.refractionpoint.rphcp.client</p> <p>Socket Filter Designated Requirement anchor apple generic and identifier \"com.refractionpoint.rphcp.client\" and (certificate leaf[field.1.2.840.113635.100.6.1.9] /* exists */ or certificate 1[field.1.2.840.113635.100.6.2.6] /* exists */ and certificate leaf[field.1.2.840.113635.100.6.1.13] /* exists */ and certificate leaf[subject.OU] = N7N82884NH)</p> <p>Add a Network Filter with the following details:</p> <p>Network Filter Bundle Identifier: com.refractionpoint.rphcp.client</p> <p>Network Filter Designated Requirement: anchor apple generic and identifier \"com.refractionpoint.rphcp.client\" and (certificate leaf[field.1.2.840.113635.100.6.1.9] /* exists */ or certificate 1[field.1.2.840.113635.100.6.2.6] /* exists */ and certificate leaf[field.1.2.840.113635.100.6.1.13] /* exists */ and certificate leaf[subject.OU] = N7N82884NH)</p> <p></p> <ol> <li>Deploy the configuration profile to your devices.</li> </ol>"},{"location":"2-sensors-deployment/endpoint-agent/macos/sequoia/","title":"macOS Agent Installation - Latest Versions (macOS 15 Sequoia and newer)","text":"<p>This document provides details of how to install, verify, and uninstall the LimaCharlie Endpoint Agent on macOS (versions 15 Sonoma). We also offer separate documentation for older versions.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/sequoia/#installer-options","title":"Installer Options","text":"<p>When running the installer from the command line, you can pass the following arguments:</p> <pre><code>-v: display build version.\n-q: quiet; do not display banner.\n-d &lt;INSTALLATION_KEY&gt;: the installation key to use to enroll, no permanent installation.\n-i &lt;INSTALLATION_KEY&gt;: install executable as a service with deployment key.\n-r: uninstall executable as a service.\n-c: uninstall executable as a service and delete identity files.\n-w: executable is running as a macOS service.\n-h: displays the list of accepted arguments.\n</code></pre>"},{"location":"2-sensors-deployment/endpoint-agent/macos/sequoia/#installation-flow","title":"Installation Flow","text":"<ol> <li>Download the Sensor installer file. Installer for: Intel Mac -or- Apple Silicon Mac.</li> <li>Add execute permission to the installer file via the command line</li> </ol> <p>chmod +x lc_sensor</p> <ol> <li>Run the installer via the command line. You'll pass the argument -i and your Installation Key.</li> </ol> <p>sudo ./lc_sensor -i YOUR_INSTALLATION_KEY_GOES_HERE</p> <p>You can obtain the installation key from the Installation Keys section of the LimaCharlie web application.</p> <p>The sensor will be installed as a launchctl service. Installation will trigger the sensors enrollment with the LimaCharlie cloud</p> <p></p> <ol> <li>An application (<code>RPHCP.app</code>) will be installed in the /Applications folder and will automatically launch. Note that it may take a few minutes before you see this happened after installation.</li> </ol> <p>You will be prompted to grant permissions for system extensions to be installed. Click the \"Open System Settings\" button</p> <p></p> <ol> <li>Ensure the toggle for \"Allow in the Background\" next to \"Refraction Point, Inc.\" is toggled On.</li> </ol> <p></p> <ol> <li>Click the \"i\" info icon next to \"Endpoint Security Extensions\", then ensure the toggle next to \"RPHCP\" is on.</li> </ol> <p></p> <p></p> <ol> <li>After enabling that toggle you'll need to click the \"Allow\" button to allow RPHCP to filter network content.</li> </ol> <p></p> <ol> <li>You'll be prompted to grant Full Disk Access. Check the checkbox next to the RPHCP app in System Preferences -&gt; Privacy -&gt; Full Disk Access</li> </ol> <p></p> <p></p> <p>The installation is now complete and you should see a message indicating that the installation was successful.</p> <p></p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/sequoia/#verifying-installation","title":"Verifying Installation","text":"<p>To verify that the sensor was installed successfully, you can log into the LimaCharlie web application and see if the device has appeared in the Sensors section. Additionally, you can check the following on the device itself:</p> <p>In a Terminal, run the command:</p> <p>sudo launchctl list | grep com.refractionpoint.rphcp</p> <p></p> <p>If the agent is running, this command should return records as shown above.</p> <p>You can also check the /Applications folder and launch the RPHCP.app.</p> <p></p> <p>You can confirm the network filter was properly installed and enabled by going to System Settings \u2192 Network \u2192 VPN &amp; Filters. You should expect to see \"RPHCP\" in the list with the status showing as Enabled.</p> <p></p> <p>The application will show a message to indicate if the required permissions have been granted.</p> <p></p> <p>As described in the dialog, the RPHCP.app application must be left in the /Applications folder in order for it to continue operating properly.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/sequoia/#a-note-on-permissions","title":"A note on permissions","text":"<p>Apple has purposely made installing extensions (like the ones used by LimaCharlie) a process that requires several clicks on macOS. The net effect of this is that the first time the sensor is installed on a macOS system, permissions will need to be granted via System Preferences</p> <p>Currently, the only way to automate the installation is to use an Apple-approved MDM solution. These solutions are often used by large organizations to manage their Mac fleet. If you are using such a solution, see your vendor's documentation on how to add extensions to the allow list which can be applied to your entire fleet.</p> <p>We're aware this is an inconvenience and hope Apple will provide better solutions for security vendors in future.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/sequoia/#uninstallation-flow","title":"Uninstallation Flow","text":"<p>To uninstall the sensor:</p> <ol> <li>Run the installer via the command line. You'll pass the argument -c</li> </ol> <p>sudo ./hcp_osx_x64_release_4.23.0 -c</p> <p></p> <ol> <li>You will be prompted for credentials to modify system extensions. Enteryour password and press OK.</li> </ol> <p></p> <p>The related system extension will be removed and the <code>RPHCP.app</code> will be removed from the /Applications folder.</p> <ol> <li>You should see a message indicating that the uninstallation was successful.</li> </ol> <p></p> <p>Note: After uninstallation the LimaCharlie sensor along with the related extensions will be removed. macOS requires a reboot to fully unload and remove extensions.</p>"},{"location":"2-sensors-deployment/endpoint-agent/macos/sequoia/#install-using-mdm-solutions","title":"Install Using MDM Solutions","text":"<p>See our document macOS Agent Installation with MDM Solutions for the Mobile Device Management (MDM) Configuration Profile that can be used to deploy the LimaCharlie agent to an enterprise fleet.</p>"},{"location":"2-sensors-deployment/endpoint-agent/vdi/templates/","title":"VDI &amp; Virtual Machine Templates","text":"<p>The LimaCharlie Endpoint Agent can be installed in template-based environments whether they're VMs or VDIs.</p> <p>The methodology is the same as described above, but you need to be careful to stage the Endpoint Agent install properly in your templates.</p> <p>The most common mistake is to install the Sensor directly in the template, and then instantiate the rest of the infrastructure from this template. This will result in \"cloned sensors\", sensors running using the same Sensor ID on different hosts/VMs/Containers.</p> <p>If these occur, a sensor_clone event will be generated as well as an error in your dashboard. If this happens you have two choices:</p> <ol> <li>Fix the installation process and re-deploy.</li> <li>Run a de-duplication process with a Detection &amp; Response rule like this.</li> </ol> <p>Preparing sensors to run properly from templates can be done by creating a special <code>hcp_vdi</code> (macOS and Linux) or <code>hcp_vdi.dat</code> (Windows) file in the relevant configuration directory:</p> <ul> <li>Windows: <code>%SYSTEMROOT%\\system32\\</code></li> <li>macOS: <code>/usr/local/</code></li> <li>Linux: usually <code>/etc/</code> but fundamentally the current working directory of the sensor execution.</li> </ul> <p>The contents of the <code>hcp_vdi</code> file should be a string representation of the second-based epoch timestamp when you want the sensors to begin enrolling. For example if the current time is <code>1696876542</code>, setting a value of <code>1696882542</code> will mean the sensor will only attempt to enroll in 10 minutes in the future. This allows you to install the sensor without risking it enrolling right away before the base image is created.</p> <p>A shortcut for creating this file is to invoke the LimaCharlie EDR binary (like <code>lc_sensor.exe</code>) with the <code>-t</code> option, which will create a <code>hcp_vdi.dat</code> file with a value +1 day. This is usually plenty of time to finish the creation of the base image, submit it to a VDI platform (which often boots up the image) etc. The next day, any machine generated from this base image will start enrolling.</p> <p>Example <code>hcp_vdi.dat</code> file content:</p> <pre><code>1696882542\n</code></pre> <p>Note that if a sensor is already enrolled, the presence of the <code>hcp_vdi</code> file will be completely ignored.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/custom-msi/","title":"Building a custom MSI installer for Windows","text":"<p>Looking for basic installation instructions? See the Windows Agent Installation guide for standard EXE and MSI installation methods.</p> <p>You can white label the LimaCharlie installer for Windows by using an MSI wrapper. By going through this process you can not only brand the installer to show your name / details, but you can also make installation of the Sensor easier for end users. We have provided instructions below on how to use a 3<sup>rd</sup> party tool called exemsi.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/custom-msi/#prerequisites","title":"Prerequisites","text":"<ol> <li>An MSI wrapper application, such as the exemsi application referenced in the instructions below</li> <li>A digital code signing certificate (optional, but highly recommended)</li> </ol> <p>Without a digital code signing certificate the installer will show a warning that it is from an unknown publisher.</p> <p> - vs - </p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/custom-msi/#instructions","title":"Instructions","text":"<ol> <li>Download the LimaCharlie sensor EXE</li> <li>Download the MSI Wrapper application from exemsi.com</li> <li>Install the exemsi application on your computer</li> <li>Launch the exemsi application and go through the EXE to MSI Converter Wizard steps as shown below:</li> </ol> <ol> <li> <p>Select the executable</p> </li> <li> <p>Set the <code>Setup executable input file name</code> to be the LimaCharlie EXE that you'd downloaded</p> </li> <li>Optionally, specify a MSI output file name of your choosing (e.g. Acme_Installer.msi)</li> <li>Set the MSI platform architecture to match the executable (i.e. x86 for 32-bit, and x64 for 64-bit)</li> </ol> <p></p> <ol> <li>Set the visibility in Apps &amp; features</li> </ol> <p></p> <ol> <li>Set the Security and User Context</li> </ol> <p></p> <ol> <li> <p>Specify Application IDs</p> </li> <li> <p>In the Upgrade Code section, click the \"Create New\" button next to generate a code. This will be used to allow uninstallation.</p> </li> </ol> <p></p> <ol> <li> <p>Specify Properties (optional: customize options here to have the installer show your brand)</p> </li> <li> <p>You can change the drop-down menu of each line item from \"Executable\" to \"Manual\" in order to set your own values for the Product Name, Manufacturer, Version, Comments, and Product icon</p> </li> </ol> <p>Original</p> <p></p> <p>Customized</p> <p></p> <ol> <li>Specify More Properties (optional)</li> </ol> <p></p> <ol> <li> <p>Specify Parameters</p> </li> <li> <p>In the \"Install arguments\" box, enter \"-i\", add a space and then enter your installation key</p> </li> <li>-i YOUR_INSTALLATION_KEY_GOES_HERE</li> </ol> <p></p> <p>To provide the option to uninstall, set the Uninstall argument to \"-c\" (note that you do not need to specify your Installation Key for uninstallation).</p> <ol> <li>Actions</li> </ol> <p></p> <ol> <li>Summary</li> </ol> <p></p> <ol> <li>Status</li> </ol> <p></p> <p>Once you have created the MSI package you should sign it using your digital signature. You can learn more about signing the MSI on the exemsi website.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/custom-msi/#experience-when-running-the-msi","title":"Experience when running the MSI","text":"<p>When installing the application using the MSI you'll see your application name in the title bar.</p> <p></p> <p>When inspecting the properties of the MSI you'll see the details you'd specified.</p> <p></p> <p>In the Apps &amp; Features section of Windows, you'll see the application listed under your name.</p> <p></p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/","title":"Windows Agent Installation","text":"<p>This guide walks you through installing the LimaCharlie Endpoint Detection and Response (EDR) sensor on Windows systems. The sensor provides deep visibility into your Windows endpoints, enabling real-time threat detection and response.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#supported-windows-versions","title":"Supported Windows Versions","text":"<p>Desktop: - Windows 7, 8, 8.1, 10, 11</p> <p>Server: - Windows Server 2008 R2, 2012, 2012 R2, 2016, 2019, 2022</p> <p>Architectures: - x64 (64-bit) - Most common - x86 (32-bit) - Legacy systems - ARM64 - Windows on ARM devices</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing the LimaCharlie sensor, ensure you have:</p> <ol> <li>Administrator privileges on the Windows system</li> <li>An Installation Key from your LimaCharlie organization</li> <li>Network access to LimaCharlie cloud services (outbound HTTPS on port 443)</li> </ol>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#getting-your-installation-key","title":"Getting Your Installation Key","text":"<p>An Installation Key is required to enroll your sensor with the LimaCharlie cloud. To obtain your key:</p> <ol> <li>Log in to the LimaCharlie web application</li> <li>Select your organization</li> <li>Navigate to Sensors &gt; Installation Keys in the left sidebar</li> <li>Copy an existing key, or create a new one by clicking Create Installation Key</li> <li>Keep this key ready - you'll need it during installation</li> </ol> <p>For more details on managing keys, see Installation Keys.</p> <p>Tip: Installation keys can have tags associated with them. When a sensor enrolls using a key with tags, those tags are automatically applied to the sensor.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#downloading-the-sensor","title":"Downloading the Sensor","text":"<p>Choose the correct download for your system architecture:</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#executable-exe-downloads","title":"Executable (EXE) Downloads","text":"Architecture Download Link 64-bit (x64) https://downloads.limacharlie.io/sensor/windows/64 32-bit (x86) https://downloads.limacharlie.io/sensor/windows/32 ARM64 https://downloads.limacharlie.io/sensor/windows/arm64 <p>Note: ARM64 Windows devices currently use the x64 sensor running under emulation.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#msi-installer-downloads","title":"MSI Installer Downloads","text":"Architecture Download Link 64-bit (x64) https://downloads.limacharlie.io/sensor/windows/msi64 32-bit (x86) https://downloads.limacharlie.io/sensor/windows/msi32 <p>Note about downloaded filenames: The downloaded file will have a versioned name like <code>hcp_win_x64_release_4.33.23.exe</code>. You can rename it to <code>rphcp.exe</code> for convenience, or use the original filename in commands.</p> <p>How do I know which architecture I need?</p> <p>On Windows 10/11: Go to Settings &gt; System &gt; About and look at System type.</p> <p>On older Windows: Right-click Computer &gt; Properties and check the System type.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#command-line-options","title":"Command-Line Options","text":"<p>When running the installer from the command line, you can use the following options:</p> Option Description <code>-i &lt;KEY&gt;</code> Install as a Windows service with the specified installation key <code>-d &lt;KEY&gt;</code> Run with installation key (temporary, no permanent installation) <code>-r</code> Uninstall the service <code>-c</code> Uninstall the service and delete identity files (clean uninstall) <code>-V</code> Display the sensor version <code>-v</code> Enable verbose logging output <code>-H</code> Verify sensor health and installation <code>-h</code> Display help message"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#installation-methods","title":"Installation Methods","text":""},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#method-1-executable-exe-installation","title":"Method 1: Executable (EXE) Installation","text":"<p>This method is recommended for installing on individual systems.</p> <p>Step 1: Download the appropriate EXE for your architecture (see download links above).</p> <p>Step 2: Open Command Prompt or PowerShell as Administrator.</p> <p>To run as Administrator: Right-click Command Prompt or PowerShell and select Run as administrator.</p> <p>Step 3: Navigate to the folder where you downloaded the installer:</p> <pre><code>cd C:\\Users\\YourUsername\\Downloads\n</code></pre> <p>Step 4: Run the installer with your Installation Key:</p> <pre><code>rphcp.exe -i YOUR_INSTALLATION_KEY_GOES_HERE\n</code></pre> <p>Replace <code>YOUR_INSTALLATION_KEY_GOES_HERE</code> with the actual key you copied from the LimaCharlie web application.</p> <p>Step 5: Wait for the installation to complete. You should see output indicating successful installation and service start.</p> <p>The sensor is now installed and running as a Windows service. It will start automatically when Windows boots.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#method-2-msi-installation","title":"Method 2: MSI Installation","text":"<p>MSI installers are ideal for enterprise deployment using tools like Group Policy, SCCM, or Intune.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#interactive-installation","title":"Interactive Installation","text":"<ol> <li>Download the appropriate MSI for your architecture</li> <li>Double-click the MSI file to launch the installer</li> <li>Follow the installation prompts</li> </ol> <p>Note: The MSI installation will require you to provide the Installation Key. Ensure you have it ready.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#silent-installation-command-line","title":"Silent Installation (Command Line)","text":"<p>For automated deployments, use the following command in an elevated Command Prompt or PowerShell:</p> <pre><code>msiexec /i \"path\\to\\installer.msi\" /qn INSTALLATIONKEY=\"YOUR_INSTALLATION_KEY_GOES_HERE\"\n</code></pre> <p>Example with a specific MSI:</p> <pre><code>msiexec /i \"C:\\Downloads\\hcp_win_x64.msi\" /qn INSTALLATIONKEY=\"YOUR_INSTALLATION_KEY_GOES_HERE\"\n</code></pre> <p>Options explained: - <code>/i</code> - Install the package - <code>/qn</code> - Quiet mode with no user interface - <code>INSTALLATIONKEY</code> - The LimaCharlie installation key for enrollment</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#method-3-powershell-script-automated","title":"Method 3: PowerShell Script (Automated)","text":"<p>This script automates the download and installation process. It detects your system architecture and downloads the correct installer.</p> <p>Note: This script requires PowerShell 3.0 or later. Windows 7 and Server 2008 R2 ship with PowerShell 2.0 by default; you may need to install Windows Management Framework 3.0+ first.</p> <p>Save this script as <code>Install-LimaCharlie.ps1</code>:</p> <pre><code>#Requires -RunAsAdministrator\n&lt;#\n.SYNOPSIS\n    Downloads and installs the LimaCharlie sensor.\n.DESCRIPTION\n    This script detects the system architecture, downloads the appropriate\n    LimaCharlie sensor installer, and installs it as a Windows service.\n.PARAMETER InstallationKey\n    The LimaCharlie installation key for enrollment.\n#&gt;\n\nparam(\n    [Parameter(Mandatory=$true)]\n    [string]$InstallationKey\n)\n\n# Determine system architecture using WMI for accurate detection\n$CpuArch = (Get-CimInstance -ClassName Win32_Processor).Architecture\n# Architecture values: 0 = x86, 9 = x64, 12 = ARM64\n$Arch = switch ($CpuArch) {\n    0  { \"32\" }\n    9  { \"64\" }\n    12 { \"arm64\" }\n    default { if ([Environment]::Is64BitOperatingSystem) { \"64\" } else { \"32\" } }\n}\n\nWrite-Host \"Detected architecture: $Arch\" -ForegroundColor Cyan\n\n# Set download URL and local path\n$InstallerUrl = \"https://downloads.limacharlie.io/sensor/windows/$Arch\"\n$TempDownload = Join-Path $env:TEMP \"lc_sensor_download.exe\"\n$InstallerPath = Join-Path $env:TEMP \"rphcp.exe\"\n\n# Download the installer (filename from server varies, so we normalize it)\nWrite-Host \"Downloading LimaCharlie sensor...\" -ForegroundColor Cyan\ntry {\n    [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12\n    Invoke-WebRequest -Uri $InstallerUrl -OutFile $TempDownload -UseBasicParsing\n    # Rename to consistent filename\n    Move-Item -Path $TempDownload -Destination $InstallerPath -Force\n    Write-Host \"Download complete.\" -ForegroundColor Green\n} catch {\n    Write-Host \"Error downloading installer: $_\" -ForegroundColor Red\n    Remove-Item $TempDownload -Force -ErrorAction SilentlyContinue\n    exit 1\n}\n\n# Install the sensor\nWrite-Host \"Installing LimaCharlie sensor...\" -ForegroundColor Cyan\ntry {\n    $process = Start-Process -FilePath $InstallerPath -ArgumentList \"-i\", $InstallationKey -Wait -PassThru -NoNewWindow\n    if ($process.ExitCode -eq 0) {\n        Write-Host \"Installation successful!\" -ForegroundColor Green\n    } else {\n        Write-Host \"Installation may have encountered issues. Exit code: $($process.ExitCode)\" -ForegroundColor Yellow\n    }\n} catch {\n    Write-Host \"Error during installation: $_\" -ForegroundColor Red\n    exit 1\n}\n\n# Verify installation\nWrite-Host \"Verifying installation...\" -ForegroundColor Cyan\n$service = Get-Service -Name \"rphcpsvc\" -ErrorAction SilentlyContinue\nif ($service -and $service.Status -eq \"Running\") {\n    Write-Host \"LimaCharlie sensor is installed and running.\" -ForegroundColor Green\n} else {\n    Write-Host \"Warning: Service may not be running. Please check manually.\" -ForegroundColor Yellow\n}\n\n# Clean up\nRemove-Item $InstallerPath -Force -ErrorAction SilentlyContinue\n</code></pre> <p>To run the script:</p> <ol> <li>Open PowerShell as Administrator</li> <li>If you haven't already, allow script execution:    <pre><code>Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\n</code></pre></li> <li>Run the script with your Installation Key:    <pre><code>.\\Install-LimaCharlie.ps1 -InstallationKey \"YOUR_INSTALLATION_KEY_GOES_HERE\"\n</code></pre></li> </ol>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, verify that the sensor is running correctly using any of these methods:</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#windows-services-gui","title":"Windows Services GUI","text":"<ol> <li>Press <code>Win + R</code>, type <code>services.msc</code>, and press Enter</li> <li>Scroll down to find LimaCharlie in the list</li> <li>Verify that the Status is Running and Startup Type is Automatic</li> </ol>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#powershell","title":"PowerShell","text":"<p>Run this command to check the service status:</p> <pre><code>Get-Service rphcpsvc | Select-Object Name, Status, StartType\n</code></pre> <p>Expected output: <pre><code>Name     Status StartType\n----     ------ ---------\nrphcpsvc Running Automatic\n</code></pre></p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#command-prompt","title":"Command Prompt","text":"<p>Run this command:</p> <pre><code>sc query rphcpsvc\n</code></pre> <p>Look for <code>STATE : 4  RUNNING</code> in the output.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#verification-script","title":"Verification Script","text":"<p>Save and run this PowerShell script for a quick status check:</p> <p><pre><code># Verify LimaCharlie installation\n$service = Get-Service -Name \"rphcpsvc\" -ErrorAction SilentlyContinue\nif ($null -eq $service) {\n    Write-Host \"LimaCharlie sensor is NOT installed.\" -ForegroundColor Red\n} elseif ($service.Status -eq \"Running\") {\n    Write-Host \"LimaCharlie sensor is installed and running.\" -ForegroundColor Green\n    Write-Host \"  Service Name: $($service.Name)\"\n    Write-Host \"  Display Name: $($service.DisplayName)\"\n    Write-Host \"  Start Type:   $($service.StartType)\"\n} else {\n    Write-Host \"LimaCharlie sensor is installed but NOT running.\" -ForegroundColor Yellow\n    Write-Host \"  Current Status: $($service.Status)\"\n}\n```python\n\n### LimaCharlie Web Application\n\n1. Log in to [app.limacharlie.io](https://app.limacharlie.io)\n2. Navigate to **Sensors** in the left sidebar\n3. Your newly installed sensor should appear in the list within a few minutes\n\n## Troubleshooting\n\n### \"Access Denied\" Error\n\n**Cause:** The installer must be run with Administrator privileges.\n\n**Solution:** Right-click Command Prompt or PowerShell and select **Run as administrator** before running the installer.\n\n### Architecture Mismatch Error\n\n**Cause:** Using a 32-bit installer on a 64-bit system (or vice versa).\n\n**Solution:** Download and use the correct installer for your system architecture. The sensor will display an error message indicating the mismatch.\n\n### Antivirus Blocking Installation\n\n**Cause:** Some antivirus software may flag the sensor installer.\n\n**Solution:**\n1. Temporarily disable your antivirus during installation, OR\n2. Add an exclusion for `rphcp.exe` and `C:\\Windows\\System32\\rphcp.exe`\n3. Contact your antivirus vendor if issues persist\n\n### Firewall Blocking Connection\n\n**Cause:** The sensor cannot reach LimaCharlie cloud services.\n\n**Solution:** Ensure outbound HTTPS (port 443) traffic is allowed to:\n- `*.limacharlie.io`\n\n### Installation Key Errors\n\n**Cause:** The installation key is invalid, expired, or incorrectly copied.\n\n**Solution:**\n1. Verify the key in the LimaCharlie web application\n2. Ensure you copied the entire key without extra spaces\n3. Check that the key hasn't been revoked or expired\n\n### Service Won't Start\n\n**Cause:** Various issues including file permission problems or system configuration.\n\n**Solution:**\n1. Check Windows Event Viewer (Application and System logs) for errors\n2. Ensure the system meets minimum requirements\n3. Try reinstalling with the `-c` flag first to clean up, then install fresh\n\n## Uninstallation\n\n### Using the Executable\n\nRun the installer with the clean uninstall flag:\n</code></pre> rphcp.exe -c <pre><code>This removes the service and deletes all identity files.\n\nTo uninstall but keep identity files (for potential reinstallation):\n</code></pre> rphcp.exe -r <pre><code>### Using the MSI\n\n1. Open **Control Panel** &gt; **Programs** &gt; **Programs and Features**\n2. Find **LimaCharlie** in the list\n3. Click **Uninstall**\n\nOr via command line:\n</code></pre> msiexec /x \"path\\to\\installer.msi\" /qn ```</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#using-limacharlie-console","title":"Using LimaCharlie Console","text":"<p>You can remotely uninstall the sensor from the LimaCharlie web application:</p> <ol> <li>Navigate to the sensor in the Sensors list</li> <li>Open the Console tab</li> <li>Run the command: <code>uninstall</code></li> </ol> <p>For MSI installations, use: <code>uninstall --msi</code></p> <p>For more uninstallation options, see Endpoint Agent Uninstallation.</p>"},{"location":"2-sensors-deployment/endpoint-agent/windows/installation/#next-steps","title":"Next Steps","text":"<p>Now that your sensor is installed, you can:</p> <ul> <li>Configure Detection &amp; Response rules to detect threats</li> <li>Explore Sensor Commands to interact with your endpoints</li> <li>Build a Custom MSI with your branding for enterprise deployment</li> <li>Deploy via Microsoft Intune for large-scale rollout</li> </ul>"},{"location":"2-sensors-deployment/enterprise-deployment/chrome-enterprise/","title":"ChromeOS with Google Chrome Enterprise","text":"<p>You can mass deploy the LimaCharlie Sensor for ChromeOS with Google Workspace and Google Chrome Enterprise.</p>"},{"location":"2-sensors-deployment/enterprise-deployment/chrome-enterprise/#configuration","title":"Configuration","text":"<ol> <li>Log into Google Workspace Admin and go to Devices -&gt; Chrome -&gt; Apps &amp; extensions -&gt; Users &amp; Browsers.</li> <li>In the Users &amp; browsers tab click the \"+\" button in the bottom right, then choose the option to \"Add from Chrome Web Store\".</li> <li>Search for the LimaCharlie Sensor extension and click Select.</li> <li>Click on the LimaCharlie Sensor app to show the installation policy.</li> <li>Set the \"Installation Policy\" to \"Force install\".</li> <li>Set the \"Policy for extensions\" value as follows:</li> </ol> <pre><code>{\n    \"installation_key\": {\n        \"Value\": \"\\\"KEY\\\"\"\n    }\n}\n</code></pre> <p>IMPORTANT: Replace the text \"KEY\" with the actual value of your Installation Key, in particular the Chrome Key which you can obtain from within the LimaCharlie web app.</p> <p>Example </p>"},{"location":"2-sensors-deployment/enterprise-deployment/chrome-enterprise/#verifying-configuration","title":"Verifying Configuration","text":"<p>ChromeOS endpoints should now start appearing within the related LimaCharlie Organization's sensor list.</p> <p>You can verify that the configuration was completed successfully by verifying on an individual endpoint.</p> <ol> <li>Confirm that the LimaCharlie Sensor extension appears in the list of extensions.</li> <li>Verify that the installation key got applied on the endpoint by going to:  <code>chrome://policy</code> and look for the LimaCharlie Sensor. There you should see the Policy name set to <code>installation_key</code> and the Policy Value set with your installation key. The Source should list \"Cloud\".</li> </ol> <p></p>"},{"location":"2-sensors-deployment/enterprise-deployment/intune/","title":"Agent Deployment via Microsoft Intune","text":"<p>Microsoft Intune is a cloud-based endpoint management solution that integrates with Microsoft Azure. It allows for simplified app and device management across a wide range of devices, including mobile devices, desktop computers, and virtual endpoints.</p> <p>Intune can be used to simplify LimaCharlie Sensor deployment within enterprise environments. To add a custom App to Intune, select the <code>+ Add</code> button within the Intune admin center:</p> <p></p> <p>InTune supports Windows and macOS package deployment.</p>"},{"location":"2-sensors-deployment/enterprise-deployment/intune/#windows-deployment-via-intune","title":"Windows Deployment via Intune","text":"<p>Deploying Windows applications via Intune requires creating an Intune application package (<code>.intunewin</code> file extension). To do this, please utilize Microsoft's IntuneWinAppUtil.exe file. Usage and documentation on creating an <code>.intunewin</code> file can be found here.</p> <p>Intune Package Contents</p> <p>Intune packages may need to be created for each Organization, as the Installation Key must be provided at the time of installation.</p> <p>We recommend first creating a custom MSI installer, bundled with the appropriate installation key, and then including that in your <code>.intunewin</code> file.</p> <p>After clicking <code>+ Add</code>, choose <code>Windows app (Win32)</code>:</p> <p></p>"},{"location":"2-sensors-deployment/troubleshooting/non-responding-sensors/","title":"Detecting Sensors No Longer Sending Data","text":""},{"location":"2-sensors-deployment/troubleshooting/non-responding-sensors/#overview","title":"Overview","text":"<p>A common request is to alert an administrator if a Sensor that normally forwards data, stops or fails to send data. This LimaCharlie Playbook is meant to be triggered on a schedule by  rule. It checks for data sent, via the LimaCharlie Python SDK, within a given time window. If no data is sent during the time period, then an alert is generated, one per sensor.</p>"},{"location":"2-sensors-deployment/troubleshooting/non-responding-sensors/#example-playbook-code","title":"Example Playbook Code","text":"<pre><code>import limacharlie\nimport time\n\n# LimaCharlie D&amp;R Rule to trigger this playbook\n# every 30 minutes.\n# detection:\n#   target: schedule\n#   event: 30m_per_org\n#   op: exists\n#   path: /\n# response:\n# - action: extension request\n#   extension name: ext-playbook\n#   extension action: run_playbook\n#   extension request:\n#     name: check-missing-data\n#     credentials: hive://secret/playbook-missing-data-creds\n\nSENSOR_SELECTOR = \"plat == windows and `server` in tags\"\nDATA_WITHIN = 10 * 60 * 1000 # 10 minutes\n\ndef notify_missing_data(sdk: limacharlie.Limacharlie, sensor: limacharlie.Sensor):\n    # TODO: Implement this, but it's optional if all you want is a detection\n    # since those will be generated automatically.\n    pass\n\ndef get_relevant_sensors(sdk: limacharlie.Limacharlie) -&gt; list[limacharlie.Sensor]:\n    sensors = sdk.sensors(selector=SENSOR_SELECTOR)\n    relevant_sensors = []\n    for sensor in sensors:\n        relevant_sensors.append(sensor)\n    return relevant_sensors\n\ndef playbook(sdk: limacharlie.Limacharlie, data: dict) -&gt; dict | None:\n    # Get the sensors we care about.\n    relevant_sensors = get_relevant_sensors(sdk)\n\n    stopped_sensors = []\n\n    # For each sensor, check if we've received data within that time period.\n    for sensor in relevant_sensors:\n        # To do that we will get the data overview and see if a recent time stamp is present.\n        data_overview = sensor.getHistoricOverview(int(time.time() - DATA_WITHIN), int(time.time()))\n        after = int(time.time() * 1000) - DATA_WITHIN\n        for timestamp in data_overview:\n            if timestamp &gt; after:\n                print(f\"Data received for sensor {sensor.sid} at {timestamp}\")\n                break\n        else:\n            print(f\"No data received for sensor {sensor.sid} in the last {DATA_WITHIN} seconds\")\n            notify_missing_data(sdk, sensor)\n            stopped_sensors.append(sensor)\n\n    # Report a detection for stopped sensors.\n    if stopped_sensors:\n        return {\"detection\":{\n            \"stopped_sensors\": [sensor.sid for sensor in stopped_sensors]\n        }}\n    return None\n</code></pre>"},{"location":"2-sensors-deployment/tutorials/defender-logs/","title":"Ingesting Defender Event Logs","text":"<p>The Windows Sensor can listen, alert, and automate based on various Defender events.</p> <p>This is done by ingesting artifacts from the Defender Event Log Source and using Detection &amp; Response rules to take the appropriate action.</p> <p>A config template to alert on the common Defender events of interest is available here. The template can be used in conjunction with Infrastructure Extension or its user interface in the web app.</p> <p>Specifically, the template alerts on the following Defender events:</p> <ul> <li>windows-defender-malware-detected (<code>event ID 1006</code>)</li> <li>windows-defender-history-deleted (<code>event ID 1013</code>)</li> <li>windows-defender-behavior-detected (<code>event ID 1015</code>)</li> <li>windows-defender-activity-detected (<code>event ID 1116</code>)</li> </ul>"},{"location":"2-sensors-deployment/tutorials/linux-audit-logs/","title":"Ingesting Linux Audit Logs","text":"<p>One data source of common interest on Linux systems is the <code>audit.log</code> file. By default, this file stores entries from the Audit system, which contains information about logins, privilege escalations, and other account-related events. You can find more information about Audit Log files here.</p> <p>There are a few techniques to ingest Linux Audit logs into LimaCharlie:</p> <ol> <li>Pull the raw logs using Artifacts and/or the File System navigator (EDR sensors only)</li> <li>Collect the files using Artifact Collection.</li> <li>Stream the raw audit log via a <code>file</code> adapter.</li> </ol> <p>We will explore these techniques in this tutorial. Adapters can also be configured as syslog listeners; that will be covered in another tutorial.</p>"},{"location":"2-sensors-deployment/tutorials/linux-audit-logs/#file-system-browser","title":"File System Browser","text":"<p>Our Windows, Linux, and macOS EDR sensors offer file system navigation capabilities. If you need a single, ad-hoc collection of the <code>auth.log</code>, you can use the File System capability to navigate to <code>/var/log</code>, and download <code>auth.log</code>.</p> <p></p>"},{"location":"2-sensors-deployment/tutorials/linux-audit-logs/#artifact-collection","title":"Artifact Collection","text":"<p>If you don't need to stream Linux Audit log(s), but instead want to maintain a copy of them for posterity, Artifact collection would be your best method. This is an automated collection technique, but won't stream the events to your Timeline.</p> <p>Step 1: Within the Navigation Pane, select <code>Artifact Collection</code>.</p> <p></p> <p>Step 2: Create a simple artifact collection rule for <code>/var/log/auth.log</code>. In this example, we chose a retention period of 30 days; however, you should choose the correct retention period for your use case.</p> <p></p> <p>click Save</p> <p></p> <p>Step 3: Saving the artifact rule will then populate to the appropriate sensor(s), and you should see the <code>auth.log</code> in the Artifacts menu, once it is collected by the Sensor.</p> <p></p> <p>Want more logs?</p> <p>Want more than just the most recent <code>auth.log</code>? Specify a regular expression to capture all archived copies of the log files. However, be careful on retention and make sure you're not unnecessarily duplicating data!</p>"},{"location":"2-sensors-deployment/tutorials/linux-audit-logs/#file-adapter-ingestion","title":"File Adapter Ingestion","text":"<p>It is also possible to deploy a LimaCharlie Adapter pointed to <code>auth.log</code> to collect and stream the events in directly. Note that Adapters will create a separate telemetry \"stream\" - thus, it is recommended to combine file types where possible.</p> <p>Step 1: Create an Installation Key for your adapter and download the appropriate binary.</p> <p>Step 2: On the system(s) to collect logs from, deploy the adapter. We recommend utilizing a configuration file for adapter testing, to allow for tracking of changes. The following is a sample file that will ingest <code>auth.log</code> events as basic text.</p> <pre><code>file:\n  client_options:\n    identity:\n      installation_key: &lt;installation_key&gt;\n      oid: &lt;oid&gt;\n    platform: text\n    sensor_seed_key: audit-log-events\n  file_path: /var/log/auth.log\n  no_follow: false\n</code></pre> <p>More details on configuration files and adapter usage can be found here.</p> <p>Step 3: Run the adapter, providing the <code>file</code> option and the appropriate config file.</p> <p><code>$ ./lc_adapter file /tmp/config.yml</code></p> <p>The adapter should load the config and display options to the terminal.</p> <p>Note: This is not a persistent install; utilize your operating system's init/systemctl capabilities to create a persistent adapter</p> <p>Step 4: Returning to the LimaCharlie web UI, you should start to see events flowing in almost instantaneously.</p> <p></p> <p>Note that a <code>text</code> platform will ingest data as basic text, however you could use formatting options to parse the fields respective to your <code>auth.log</code> format.</p>"},{"location":"2-sensors-deployment/tutorials/macos-unified-logs/","title":"Ingesting MacOS Unified Logs","text":"<p>You can enable real-time MacOS Unified Logs (MUL) ingestion using the LimaCharlie EDR Sensor.</p> <p>First, navigate to the Exfil Control section of LimaCharlie and ensure that <code>MUL</code> events are enabled for your Mac rules.</p> <p></p> <p>Next, navigate to the <code>Artifact Collection</code> section and set up an artifact collection rule for the MacOS Unified Log(s) of interest.</p> <p></p> <p>To ingest MUL real-time events in the timeline, use the <code>mul://[Predicate]</code> format, where the predicate is a standard MacOS MUL predicate. For example, to ingest the Safari logs, you'd use the following pattern:</p> <p><code>mul://process == \"Safari\"</code></p> <p></p> <p>If you ingest MacOS Unified Logs with a <code>mul://</code> pattern, they are streamed in real-time as first-class telemetry alongside the native EDR events, and are included in the flat rate price of the sensor.</p> <p>After you apply those, you should start seeing your MacOS Unified Logs data coming through for your endpoints within 10 minutes. You can verify this by going into the Timeline view and choosing <code>MUL</code> event type.</p>"},{"location":"2-sensors-deployment/tutorials/macos-unified-logs/#endpoint-detection-response","title":"Endpoint Detection &amp; Response","text":"<p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p> <p>In LimaCharlie, Exfil (Event Collection) is a configuration extension that determines which types of events are collected and sent from endpoint agents to the cloud. It controls the data flow, ensuring only specified events are transmitted for monitoring and analysis. To capture specific events, they must be enabled within the Exfil or Event Collection settings.</p>"},{"location":"2-sensors-deployment/tutorials/macos-unified-logs/#related-articles","title":"Related Articles","text":"<ul> <li>Mac Unified Logging</li> </ul>"},{"location":"2-sensors-deployment/tutorials/macos-unified-logs/#whats-next","title":"What's Next","text":"<ul> <li>Log Collection Guide</li> </ul>"},{"location":"2-sensors-deployment/tutorials/sysmon-logs/","title":"Ingesting Sysmon Event Logs","text":"<p>Sysmon can be a valuable addition to any defender's toolkit, given it's verbosity and generous log data. It's worth noting that LimaCharlie's native EDR capabilities mirror much of the same telemetry. However, Sysmon and LimaCharlie can be combined to provide granular coverage across Windows systems.</p> <p>With Sysmon deployed, you can utilize LimaCharlie's native Windows Event Log (WEL) streaming capabilities to bring logs into the Sensor timeline.</p> <ol> <li> <p>Install Sysmon on the endpoint.</p> </li> <li> <p>This can easily be done via LimaCharlie's Payload functionality, with a  rule, or manually.</p> </li> <li>Please note that the LimaCharlie agent must be restarted in order for Sysmon data to show up in the timeline.</li> <li> <p>Example rule to deploy Sysmon via payloads on Windows systems tagged with <code>deploy-sysmon</code>:</p> <p><pre><code>detect:\n  events:\n    - CONNECTED\n  op: and\n  rules:\n    - op: is platform\n      name: windows\n    - op: is tagged\n      tag: deploy-sysmon\nrespond:\n- action: task\n  command: put --payload-name sysmon.exe --payload-path \"C:\\Windows\\Temp\\sysmon.exe\"\n- action: wait\n  duration: 10s\n- action: task\n  command: put --payload-name sysmon-config.xml --payload-path \"C:\\Windows\\Temp\\sysmon-config.xml\"\n- action: wait\n  duration: 10s\n- action: task\n  command: run --shell-command \"C:\\Windows\\Temp\\sysmon.exe -accepteula -i C:\\Windows\\Temp\\sysmon-config.xml\"\n- action: wait\n  duration: 10s\n- action: task\n  command: file_del \"C:\\Windows\\Temp\\sysmon.exe\"\n- action: task\n  command: file_del \"C:\\Windows\\Temp\\sysmon-config.xml\"\n- action: remove tag\n  tag: deploy-sysmon\n- action: task\n  command: restart\n</code></pre> 2. Within the Organization where you wish to collect Sysmon data, go to the <code>Event Collection &gt; Event Collection Rules</code> section.</p> </li> </ol> <p></p> <ol> <li>Ensure that for Windows systems, <code>WEL</code> events are collected.</li> </ol> <p></p> <ol> <li>Go to the <code>Artifact Collection</code> section and add a new collection rule with the following path to bring in all Sysmon events:</li> </ol> <p><code>wel://Microsoft-Windows-Sysmon/Operational:*</code></p> <p></p> <p>Note: You can use tagging or other filters to narrow down the systems that logs are collected from.</p> <p>Event Filtering</p> <p>You can filter events by event ID to import select events. For example:</p> <p><code>wel://Microsoft-Windows-Sysmon/Operational:16</code></p> <p><code>wel://Microsoft-Windows-Sysmon/Operational:25</code></p> <ol> <li>Allow up to 10 minutes for data to come into LimaCharlie after setting up a new Artifact Collection rule. Data will flow in real-time after that point.</li> <li>Navigate to the Timeline view of a Sensor to confirm that Sysmon logs are present. You can search for Event Type <code>WEL</code> and Search for <code>Microsoft-Windows-Sysmon</code> to validate the telemetry.</li> </ol> <p></p>"},{"location":"2-sensors-deployment/tutorials/test-sensor-version/","title":"Test a New Sensor Version","text":"<p>Prior to rolling out a new Sensor version, we recommend testing to ensure everything works as intended within your environment. While we test Sensors before releasing them, we cannot predict every niche use case. We also recommend testing on <code>dev</code> or <code>test</code> systems prior to deployment in production, again, to eliminate any concerns of resource utilization or Sensor operations.</p> <p>Sensor version testing is done via LimaCharlie's tagging functionality.</p> <p>When you tag a Sensor with <code>lc:latest</code>, the sensor version currently assigned to the Organization will be ignored for that specific sensor, and the latest version of the sensor will be used instead. You can apply this tag to a handful of systems to test-deploy the latest version.</p> <p>Alternatively, you can tag a sensor with <code>lc:stable</code>. Similarly, the sensor version currently assigned to the Organization will be ignored for that specific sensor, and the stable version of the sensor will be used instead.</p> <p>You can tag a Sensor by opening the sensors list, selecting a sensor you would like to test, and navigating to the <code>tags</code> field on the sensor <code>Overview</code>.</p> <p></p> <p>Simply type <code>lc:stable</code> and click <code>Update Tags</code>.</p> <p>Note: It can take up to 10 minutes to update the sensor to the tagged version.</p>"},{"location":"2-sensors-deployment/tutorials/update-sensors/","title":"Updating Sensors to the Newest Version","text":"<p>LimaCharlie releases a new version of the Sensor frequently - often every few weeks. However, we give you full control over what sensor version is running in your Organization. Sensors are not updated by default.</p> <p>There are two methods for updating sensors in your organization to the latest version.</p>"},{"location":"2-sensors-deployment/tutorials/update-sensors/#manual-update","title":"Manual Update","text":"<p>Upgrading sensors is done transparently for you once you click the \"Update to Latest\" button, located at <code>Sensors &gt; Deployed Versions</code>.</p> <p></p> <p>The new version should be in effect across the organization within about 20 minutes.</p>"},{"location":"2-sensors-deployment/tutorials/update-sensors/#automated-update","title":"Automated Update","text":"<p>You can also configure sensors in your organization to auto-update to the new version when it's released. To do it, tag applicable (or all) sensors in your fleet with the <code>lc:stable</code> tag (<code>lc:stable</code> tag means that the package it provides rarely changes).</p> <p></p> <p>This will ensure that when a new sensor version is released, it will be in effect across the organization within about 20 minutes.</p>"},{"location":"2-sensors-deployment/tutorials/windows-event-logs/","title":"Ingesting Windows Event Logs","text":"<p>You can enable real-time Windows Event Log (WEL) ingestion using the LimaCharlie EDR Sensor.</p> <p>First, navigate to the Exfil Control section of LimaCharlie and ensure that <code>WEL</code> events are enabled for your Windows rules.</p> <p></p> <p>Next, navigate to the <code>Artifact Collection</code> section and set up an artifact collection rule for the Windows Event Log(s) of interest.</p> <p></p> <p>To ingest WEL real-time events in the timeline, use the <code>wel://[Log Name]</code> format. For example, to ingest the System event log, you'd use the following pattern:</p> <p><code>wel://system:*</code></p> <p></p> <p>Difference between <code>.evtx</code> versus <code>wel://</code> ingestion</p> <p>If you specify the file on disk, via the <code>evtx</code> file extension (as seen in the image above), LimaCharlie will upload the entire Windows Event Log file from disk. This will be represented as a collected artifact, not as real-time events on the sensor's timeline. This method incurs regular artifact ingestion costs for \"Telemetry Sources\" as seen on our pricing page.</p> <p>If you ingest Windows Event Logs with a <code>wel://</code> pattern, they are streamed in real-time as first-class telemetry alongside the native EDR events, and are included in the flat rate price of the sensor.</p> <p>After you apply those, you should start seeing your Windows Event Log data coming through for your endpoints. You can verify this by going into the Timeline view and choosing <code>WEL</code> event type.</p> <p></p>"},{"location":"3-detection-response/","title":"Detection and Response","text":"<p>Build custom detection logic with automated response actions.</p>"},{"location":"3-detection-response/#documentation","title":"Documentation","text":"<ul> <li>Detection and Response Examples - Sample detection rules</li> <li>Detection on Alternate Targets - Detections beyond endpoint events</li> <li>False Positive Rules - Managing false positives</li> <li>Writing and Testing Rules - Rule development guide</li> <li>Stateful Rules - Rules with state tracking</li> <li>Unit Tests - Testing detection rules</li> <li>Replay - Replaying events for testing</li> </ul>"},{"location":"3-detection-response/#see-also","title":"See Also","text":"<ul> <li>Writing Rules</li> <li>Detection Examples</li> <li>Response Actions</li> <li>False Positive Rules</li> <li>LCQL Queries</li> </ul>"},{"location":"3-detection-response/alternate-targets/","title":"Detection on Alternate Targets","text":"<p>Detection &amp; Response rules run against <code>edr</code> events by default, however, there are 7 other targets:</p> <ul> <li><code>detection</code></li> <li><code>deployment</code></li> <li><code>artifact</code></li> <li><code>artifact_event</code></li> <li><code>schedule</code></li> <li><code>audit</code></li> <li><code>billing</code></li> </ul> <p>This article is to give some ideas of what they're used for, and how they're used.</p>"},{"location":"3-detection-response/alternate-targets/#target-detection","title":"Target: detection","text":"<p>You can run rules on detections generated by other rules. This allows you to further filter existing detections and change add a response behavior to certain special cases.</p> <p>In the <code>detection</code> target, the <code>event:</code> or <code>events:</code> specified refer to the <code>name</code> of the detection specified in the original detection's <code>report</code> action.</p> <p>The <code>detection</code> target supports all of the same operators and actions as regular <code>edr</code> rules.</p>"},{"location":"3-detection-response/alternate-targets/#example","title":"Example","text":"<pre><code># Detection\ntarget: detection\nop: and\nrules:\n- op: is\n  path: cat\n  value: virus-total-hit\n- op: is\n  path: routing/hostname\n  value: ceo-laptop\n\n# Response\n- action: extension request\n  extension name: pagerduty\n  extension action: run\n  request:\n    group: '{{ \"lc-alerts\" }}'\n    severity: '{{ \"critical\" }}'\n    component: '{{ \"vip-alert\" }}'\n    summary: '{{ \"Alert on a VIP endpoint.\" }}'\n    source: '{{ \"limacharlie.io\" }}'\n    class: '{{ \"dr-rules\" }}'\n</code></pre> <p>This rule takes a pre-existing detection report named <code>virus-total-hit</code> and sends it to PagerDuty if it occurs on a specific hostname.</p>"},{"location":"3-detection-response/alternate-targets/#target-deployment","title":"Target: deployment","text":"<p>Deployment events relate to sensors connecting to the cloud: <code>enrollment</code>, <code>sensor_clone</code>, <code>sensor_over_quota</code>, <code>deleted_sensor</code>.</p> <p>Take the <code>sensor_clone</code> event as an example. This event can happen when a Sensor is installed in a VM image, leading to duplicate sensor IDs connecting to the cloud. When this is detected we can use this event to automate behavior to de-duplicate the sensor.</p> <p>The <code>deployment</code> target supports all of the same operators and actions as regular <code>edr</code> rules.</p>"},{"location":"3-detection-response/alternate-targets/#example_1","title":"Example","text":"<pre><code># Detection\ntarget: deployment\nevent: sensor_clone\nop: is windows\n\n# Response\n- action: task\n  command: file_del %windir%\\system32\\hcp.dat\n- action: task\n  command: file_del %windir%\\system32\\hcp_hbs.dat\n- action: task\n  command: file_del %windir%\\system32\\hcp_conf.dat\n- action: task\n  command: restart\n</code></pre> <p>This rule de-duplicates sensors on Windows by deleting <code>.dat</code> files specific to the Windows installation and then issuing a <code>restart</code> sensor command.</p> <p>For samples of each <code>deployment</code> event type, see Reference: Platform Events.</p>"},{"location":"3-detection-response/alternate-targets/#target-artifact","title":"Target: artifact","text":"<p>Parsed artifacts can be run through the rule engine as if they were regular <code>edr</code> events, but there are some key differences. Namely, they support a subset of operators and actions, while adding some special parameters.</p>"},{"location":"3-detection-response/alternate-targets/#example_2","title":"Example","text":"<p>This rule will target parsed <code>/var/log/auth.log</code> entries to see if there are are auth failures.</p> <pre><code># Detection\ntarget: artifact\nartifact type: txt\nartifact path: /var/log/auth.log\nop: matches\nre: .*(authentication failure|Failed password).*\npath: /text\ncase sensitive: false\n\n# Response\n- action: report\n  name: Failed Auth\n</code></pre>"},{"location":"3-detection-response/alternate-targets/#supported-operators","title":"Supported Operators","text":"<ul> <li><code>is</code></li> <li><code>and</code></li> <li><code>or</code></li> <li><code>exists</code></li> <li><code>contains</code></li> <li><code>starts with</code></li> <li><code>ends with</code></li> <li><code>is greater than</code></li> <li><code>is lower than</code></li> <li><code>matches</code></li> <li><code>string distance</code></li> </ul>"},{"location":"3-detection-response/alternate-targets/#supported-resources","title":"Supported Resources","text":"<p><code>lookup</code> and <code>external</code> resources are supported within rules just like the <code>edr</code> target.</p>"},{"location":"3-detection-response/alternate-targets/#supported-actions","title":"Supported Actions","text":"<p>The only response action supported for the <code>artifact</code> target is the <code>report</code> action.</p>"},{"location":"3-detection-response/alternate-targets/#special-parameters","title":"Special Parameters","text":"<ul> <li><code>artifact path</code>: matches the start of the artifact's <code>path</code> string, e.g. <code>/auth.log</code></li> <li><code>artifact type</code>: matches the artifact's <code>type</code> string, e.g. <code>pcap</code>, <code>zeek</code>, <code>auth</code>, <code>wel</code></li> <li><code>artifact source</code>: matches the artifact's <code>source</code> string, e.g. <code>hostname-123</code></li> </ul> <p>Note: for duplicate Windows Event Log ingestions, the rule engine will use the log's <code>EventRecordID</code> to ensure a rule will not run more than once over the same record.</p>"},{"location":"3-detection-response/alternate-targets/#target-artifact_event","title":"Target: artifact_event","text":"<p>For unparsed logs, it can be useful to use the <code>ingest</code> and <code>export_complete</code> lifecycle events from the <code>artifact_event</code> target to automate behaviors in response to artifacts.</p> <p>For samples of <code>ingest</code> and <code>export_complete</code>, see Reference: Platform Events.</p>"},{"location":"3-detection-response/alternate-targets/#example_3","title":"Example","text":"<pre><code># Detection\ntarget: artifact_event\nevent: export_complete\nop: starts with\npath: routing/log_type\nvalue: pcap\ncase sensitive: false\n\n# Response\n- action: report\n  name: PCAP Artifact ready to Download\n</code></pre>"},{"location":"3-detection-response/alternate-targets/#target-schedule","title":"Target: schedule","text":"<p>Schedule events are triggered automatically at various intervals per Organization or per Sensor, observable in  rules via the <code>schedule</code> target.</p> <p>For more information, see Reference: Schedule Events</p>"},{"location":"3-detection-response/alternate-targets/#target-audit","title":"Target: audit","text":"<p>Audit events are generated by the LimaCharlie platform and track changes and events from within the platform such as tasking, replays, hive changes, etc. These events can be viewed within the \"Platform Logs\" menu or by viewing events from the <code>audit-logs</code> sensor.</p>"},{"location":"3-detection-response/alternate-targets/#target-billing","title":"Target: billing","text":"<p>Billing events are generated by the LimaCharlie platform and are related to aspects of the platform such as quotas, thresholds, and other cost-associated events. For an example, see the Usage Alerts Extension documentation</p>"},{"location":"3-detection-response/examples/","title":"Detection and Response Examples","text":"<p>The following are sample detection and response rules can help you get started in crafting efficient rules utilizing LimaCharlie's telemetry. In addition to these rules, we also recommend checking out Sigma Rules for more rules.</p>"},{"location":"3-detection-response/examples/#translating-existing-rules","title":"Translating Existing Rules","text":"<p>Before listing examples, it's worth mentioning uncoder.io by SOC Prime is a great resource for learning by analogy. If you're already familiar with another platform for rules or search queries (Sigma, Splunk, Kibana, etc.) you can use uncoder to translate to LimaCharlie's D&amp;R rules.</p> <p>Looking for more?</p> <p>Check out this video that shows you the power of leveraging community resources with LimaCharlie</p>"},{"location":"3-detection-response/examples/#examples","title":"Examples","text":"<p>Note that through limacharlie.io, in order to provide an easier to edit format, the same rule configuration is used but is in YAML format instead. For example:</p> <pre><code># Detection\nop: ends with\nevent: NEW_PROCESS\npath: event/FILE_PATH\nvalue: .scr\n\n# Response\n- action: report\n  name: susp_screensaver\n- action: add tag\n  tag: uses_screensaver\n  ttl: 80000\n</code></pre>"},{"location":"3-detection-response/examples/#wanacry","title":"WanaCry","text":"<p>Simple WanaCry detection and mitigation rule:</p> <pre><code># Detection\nop: ends with\nevent: NEW_PROCESS\npath: event/FILE_PATH\nvalue: wanadecryptor.exe\ncase sensitive: false\n\n# Response\n- action: report\n  name: wanacry\n- action: task\n  command: history_dump\n- action: task\n  command:\n    - deny_tree\n    - &lt;&lt;routing/this&gt;&gt;\n</code></pre>"},{"location":"3-detection-response/examples/#classify-users","title":"Classify Users","text":"<p>Tag any Sensor where the CEO logs in with \"vip\".</p> <pre><code># Detection\nop: is\nevent: USER_OBSERVED\npath: event/USER_NAME\nvalue: stevejobs\ncase sensitive: false\n\n# Response\n- action: add tag\n  tag: vip\n</code></pre>"},{"location":"3-detection-response/examples/#ssh-from-external-ip-address","title":"SSH from External IP Address","text":"<p>The following example looks for connections to/from <code>sshd</code> involving a non-RFC1918 IP Address. Be mindful that this is only looking for network connections, not actual logons, so this could be noisy on an internet-facing system but still indicative of an exposed service.</p> <pre><code># Detection\nevent: NETWORK_CONNECTIONS\nop: and\nrules:\n  - op: ends with\n    path: event/FILE_PATH\n    value: /sshd\n  - op: is public address\n    path: event/NETWORK_ACTIVITY/SOURCE/IP_ADDRESS\n\n # Response\n- action: report\n  name: &gt;-\n    SSH from EXTERNAL IP - {{ index (index .event.NETWORK_ACTIVITY 0) \"SOURCE\" \"IP_ADDRESS\" }}\n</code></pre> <p>The <code>report</code> uses Go Templates to include the offending IP address in the detection name.</p>"},{"location":"3-detection-response/examples/#rdp-from-external-ip-address","title":"RDP from External IP Address","text":"<p>Similar to the above SSH example, this example looks for RDP connections from an external IP address. Be mindful that this is only looking for network connections, not actual logons, so this could be noisy on an internet-facing system but still indicative of an exposed service.</p> <pre><code># Detection\nevent: NETWORK_CONNECTIONS\nop: and\nrules:\n  - op: is\n    path: event/FILE_PATH\n    value: C:\\WINDOWS\\System32\\svchost.exe\n  - op: contains\n    path: event/COMMAND_LINE\n    value: TermService\n  - op: is\n    path: event/NETWORK_ACTIVITY/DESTINATION/PORT\n    value: 3389\n  - op: is public address\n    path: event/NETWORK_ACTIVITY/SOURCE/IP_ADDRESS\n\n# Response\n- action: report\n  name: &gt;-\n    RDP from EXTERNAL IP - {{ index (index .event.NETWORK_ACTIVITY 0) \"SOURCE\" \"IP_ADDRESS\" }}\n</code></pre> <p>The <code>report</code> uses Go Templates to include the offending IP address in the detection name.</p>"},{"location":"3-detection-response/examples/#suspicious-windows-executable-names","title":"Suspicious Windows Executable Names","text":"<pre><code># Detection\nevent: CODE_IDENTITY\nop: matches\npath: event/FILE_PATH\ncase sensitive: false\nre: .*((\\\\.txt)|(\\\\.doc.?)|(\\\\.ppt.?)|(\\\\.xls.?)|(\\\\.zip)|(\\\\.rar)|(\\\\.rtf)|(\\\\.jpg)|(\\\\.gif)|(\\\\.pdf)|(\\\\.wmi)|(\\\\.avi)|( {5}.*))\\\\.exe\n\n# Response\n- action: report\n  name: Executable with suspicious double extension\n</code></pre>"},{"location":"3-detection-response/examples/#disable-an-event-at-the-source","title":"Disable an Event at the Source","text":"<p>Turn off the sending of a specific event to the cloud. Useful to limit some verbose data sources when not needed.</p> <pre><code># Detection\nevent: CONNECTED\nop: is platform\nname: windows\n\n# Response\n- action: task\n  command: exfil_del NEW_DOCUMENT\n</code></pre>"},{"location":"3-detection-response/examples/#windows-event-logs","title":"Windows Event Logs","text":"<p>A simple example of looking for a specific Event ID in WEL events.</p> <pre><code># Detection\nevent: WEL\nop: and\nrules:\n  - op: is\n    path: event/EVENT/System/EventID\n    value: '4625'\n  - op: is\n    path: event/EVENT/System/Channel\n    value: Security\n\n# Response\n- action: report\n  name: Failed Logon\n</code></pre>"},{"location":"3-detection-response/examples/#nested-logic","title":"Nested Logic","text":"<p>An example demonstrating nested boolean logic. This detection looks specifically for the following conditions:  ((<code>4697</code> OR <code>7045</code>) in the <code>System</code> log) OR (<code>4698</code> in the <code>Security</code> log)</p> <pre><code># Detection\nevent: WEL\nop: or\nrules:\n  - op: and\n    rules:\n      - op: is\n        path: event/EVENT/System/Channel\n        value: System\n      - op: or\n        rules:\n          - op: is\n            path: event/EVENT/System/EventID\n            value: '4697'\n          - op: is\n            path: event/EVENT/System/EventID\n            value: '7045'\n  - op: and\n    rules:\n      - op: is\n        path: event/EVENT/System/Channel\n        value: Security\n      - op: is\n        path: event/EVENT/System/EventID\n        value: '4698'\n</code></pre>"},{"location":"3-detection-response/examples/#file-integrity-monitoring","title":"File Integrity Monitoring","text":""},{"location":"3-detection-response/examples/#monitoring-sensitive-directories","title":"Monitoring Sensitive Directories","text":"<p>Make sure the File Integrity Monitoring of some directories is enabled whenever Windows sensors connect.</p> <pre><code># Detection\nevent: CONNECTED\nop: is platform\nname: windows\n\n# Response\n- action: task\n  command: fim_add --pattern 'C:\\*\\Programs\\Startup\\*' --pattern '\\REGISTRY\\*\\Microsoft\\Windows\\CurrentVersion\\Run*'\n</code></pre> <p>Similar example for a Linux web server.</p> <pre><code># Detection\nevent: CONNECTED\nop: is platform\nname: linux\n\n# Response\n- action: task\n  command: fim_add --pattern '/var/www/*'\n</code></pre>"},{"location":"3-detection-response/examples/#fim-hit-detection","title":"FIM Hit Detection","text":"<p>Adding a FIM pattern with <code>fim_add</code> by itself will only cause <code>FIM_HIT</code> events to be generated on the affected system's timeline. To know that we have positive hits on a FIM rule, we want to capture the relevant event and generate a proper Detection.</p> <pre><code># Detection\nevent: FIM_HIT\nop: exists\npath: event/FILE_PATH\n\n# Response\n- action: report\n  name: FIM Hit - {{ .event.FILE_PATH }}\n</code></pre>"},{"location":"3-detection-response/examples/#yara-scanning","title":"YARA Scanning","text":"<p>Resource Utilization</p> <p>Performing CPU intensive actions such as YARA scanning can impact endpoint performance if not optimized. Be sure to always test rules that carry out sensor commands (like the examples below) before deploying at scale in production. Use suppression to prevent runaway conditions.</p> <p>Here are a few examples of using D&amp;R rules to initiate automatic YARA scans on an endpoint. Note that the defined YARA rule must exist in your org before using it in a D&amp;R rule.</p>"},{"location":"3-detection-response/examples/#yara-scan-processes","title":"YARA Scan Processes","text":"<p>This  example looks for <code>NEW_PROCESS</code> events that meet certain criteria, then initiates a YARA scan against the offending process ID in memory. Note, this or a similar D&amp;R rule will also depend on a companion YARA Detection rule.</p> <pre><code># Detection\nevent: NEW_PROCESS\nop: and\nrules:\n  - op: starts with\n    path: event/FILE_PATH\n    value: C:\\Users\\\n  - op: contains\n    path: event/FILE_PATH\n    value: \\Downloads\\\n\n# Response\n## Report is optional, but informative\n- action: report\n  name: Execution from Downloads directory\n## Initiate a sensor command to yara scan the PROCESS_ID\n- action: task\n  command: yara_scan hive://yara/malware-rule --pid \"{{ .event.PROCESS_ID }}\"\n  investigation: Yara Scan Process\n  suppression:\n    is_global: false\n    keys:\n      - '{{ .event.PROCESS_ID }}'\n      - Yara Scan Process\n    max_count: 1\n    period: 1m\n</code></pre> <p>Notice the use of <code>suppression</code> to prevent the same <code>PROCESS_ID</code> from being scanned more than once per minute to prevent a resource runaway situation.</p>"},{"location":"3-detection-response/examples/#yara-scan-files","title":"YARA Scan Files","text":"<p>This  example looks for <code>NEW_DOCUMENT</code> events that meet certain criteria, then initiates a YARA scan against the offending file path. Note, this or a similar D&amp;R rule will also depend on a companion YARA Detection rule.</p> <pre><code># Detection\nevent: NEW_DOCUMENT\nop: and\nrules:\n  - case sensitive: false\n    op: matches\n    path: event/FILE_PATH\n    re: .\\:\\\\(users|windows\\\\temp)\\\\.*\n  - case sensitive: false\n    op: matches\n    path: event/FILE_PATH\n    re: .*\\.(exe|dll)\n\n# Response\n## Report is optional, but informative\n- action: report\n  name: Executable written to Users or Temp (yara scan)\n## Initiate a sensor command to yara scan the FILE_PATH\n- action: task\n  command: yara_scan hive://yara/malware-rule -f \"{{ .event.FILE_PATH }}\"\n  investigation: Yara Scan Executable\n  suppression:\n    is_global: false\n    keys:\n      - '{{ .event.FILE_PATH }}'\n      - Yara Scan Executable\n    max_count: 1\n    period: 1m\n</code></pre> <p>Notice the use of <code>suppression</code> to prevent the same <code>FILE_PATH</code> from being scanned more than once per minute to prevent a resource runaway situation.</p>"},{"location":"3-detection-response/examples/#yara-detections","title":"YARA Detections","text":"<p>Running a YARA scan by itself only sends a <code>YARA_DETECTION</code> event to the affected system's timeline. To know that we have positive hits on a YARA scan, we want to capture the relevant event and generate a proper Detection. The following two examples split out a YARA detection on-disk, versus in-memory. Notice we simply check for the presence of <code>event/PROCESS/*</code> fields to determine if it's a file or process detection, which may have different severities to security teams (dormant malware versus running malware).</p>"},{"location":"3-detection-response/examples/#yara-detection-on-disk-file","title":"YARA Detection On-Disk (file)","text":"<pre><code># Detection\nevent: YARA_DETECTION\nop: and\nrules:\n  - not: true\n    op: exists\n    path: event/PROCESS/*\n  - op: exists\n    path: event/RULE_NAME\n\n# Response\n- action: report\n  name: YARA Detection on Disk - {{ .event.RULE_NAME }}\n- action: add tag\n  tag: yara_detection_disk\n  ttl: 80000\n</code></pre>"},{"location":"3-detection-response/examples/#yara-detection-in-memory-process","title":"YARA Detection In-Memory (process)","text":"<pre><code># Detection\nevent: YARA_DETECTION\nop: and\nrules:\n  - op: exists\n    path: event/RULE_NAME\n  - op: exists\n    path: event/PROCESS/*\n\n# Response\n- action: report\n  name: YARA Detection in Memory - {{ .event.RULE_NAME }}\n- action: add tag\n  tag: yara_detection_memory\n  ttl: 80000\n</code></pre> <p>Both rules will generate a Detection report and add a tag to the system which the detection occurred on.</p>"},{"location":"3-detection-response/examples/#mention-of-an-internal-resource","title":"Mention of an Internal Resource","text":"<p>Look for references to private URLs in proxy logs.</p> <pre><code># Detection\ntarget: artifact\nop: contains\npath: /text\nvalue: /corp/private/info\n\n# Response\n- action: report\n  name: web-proxy-private-url\n</code></pre>"},{"location":"3-detection-response/examples/#de-duplicate-cloned-sensors","title":"De-duplicate Cloned Sensors","text":"<p>Sometimes users install a sensor on a VM image by mistake. This means every time a new instance of the image gets started the same sensor ID (SID) is used for multiple boxes with different names. When detected, LimaCharlie produces a <code>sensor_clone</code> event.</p> <p>We can use these events to deduplicate. This example targets Windows clones.</p> <pre><code># Detection\ntarget: deployment\nevent: sensor_clone\nop: is platform\nname: windows\n\n# Response\n- action: re-enroll\n</code></pre> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p>"},{"location":"3-detection-response/examples/#see-also","title":"See Also","text":"<ul> <li>D&amp;R Rules Overview</li> <li>Detection Operators</li> <li>Response Actions</li> </ul>"},{"location":"3-detection-response/false-positives/","title":"False Positive Rules","text":"<p>To reduce the number of false positives, you may want to create false positive (FP) rules. FP rules filter out detections generated by the <code>report</code> action of detection &amp; response (D&amp;R) rules. These rules apply globally across all rule namespaces and targets.</p> <p>There are multiple ways to create a false positive rule in LimaCharlie web app.</p> <p>Have multiple organizations?</p> <p>Similar to detection &amp; response rules, false positive rules are created on a per tenant level. This means that if you have more than one organization you want to apply the rule to, you will want to:</p> <ul> <li>re-create the same rule in multiple organizations, or</li> <li>using our infrastructure as code functionality, push your FP rules to multiple tenants within seconds.</li> </ul>"},{"location":"3-detection-response/false-positives/#use-cases","title":"Use Cases","text":"<p>The typical use case for FP rules is to add exceptions from some detections that are cross-cutting (for example ignore all detections from a specific host), organization-specific exceptions (like ignoring alerts relating to a custom piece of software used in an organization), or suppressing errors from managed  rules you don't have direct access to.</p>"},{"location":"3-detection-response/false-positives/#structure","title":"Structure","text":"<p>False positive rules are structured roughly the same as the detection part of a D&amp;R rule. The main difference is that instead of a direct event, the rule applies to the content of a detection, as can be seen in the Detections section of the web app.</p> <p>The originating event for the detection can still be accessed at the <code>detect</code> path. This means that if ignoring something based on the event content, we only need to add <code>detect/</code> to the front of the <code>path</code> (see example).</p>"},{"location":"3-detection-response/false-positives/#create-a-false-positive-rule-from-detections","title":"Create a False Positive Rule From Detections","text":"<p>This is the quickest and the most common way to create a FP rule. On every detection, you can click the <code>Mark False Positive</code> button.</p> <p></p> <p>Clicking the button will pre-populate the details of the event and automatically generate a draft false positive rule which you can edit before saving.</p> <p>After the rule is saved, it will appear in the False Positives Rules section and can be edited/deleted there.</p>"},{"location":"3-detection-response/false-positives/#create-a-false-positive-rule-from-scratch","title":"Create a False Positive rule from scratch","text":"<p>While creating FP rule from detections is a common and easy way to reduce the number of false positives, you do not need to wait for the detection to happen before creating a FP rule. The <code>False Positive Rules</code> section under <code>Automation</code> allows you to create a false positive rule from scratch.</p> <p>To create a new false positive rule, click the <code>New Rule</code> button.</p> <p></p> <p>This will open a rule editor allowing you to create a new rule.</p> <p></p> <p>An FP rule is structured with the same format at the detection component of a D&amp;R rule. The main difference is that the rule applies to the content of a detection, as can be seen in the Detections section of the web app.</p> <p>You have the ability to set a rule name as well as an Expiry Date (optional). Setting an expiry date allows you to create a rule that will expire at a certain time.</p> <p>Please note that expiry times must be set in the user's preferred time (not in UTC).</p>"},{"location":"3-detection-response/false-positives/#examples","title":"Examples","text":"<p>Clicking the button will pre-populate the details of the event and automatically generate a draft false positive rule which you can edit before saving. The details about the structure of the false positive rules can be found in our technical documentation.</p>"},{"location":"3-detection-response/false-positives/#suppress-a-specific-detection","title":"Suppress a Specific Detection","text":"<p>Prevent a specific detection:</p> <pre><code>op: is\npath: cat\nvalue: my-detect-name\n</code></pre>"},{"location":"3-detection-response/false-positives/#ignore-detections-for-specific-file-name","title":"Ignore Detections for Specific File Name","text":"<p>Ignore any detection that relates to a file name in any path.</p> <pre><code>op: ends with\npath: detect/event/FILE_PATH\nvalue: this_is_fine.exe\n</code></pre>"},{"location":"3-detection-response/false-positives/#ignore-detections-on-a-specific-host","title":"Ignore Detections on a Specific Host","text":"<p>Any detection originating from a specific host will be ignored.</p> <pre><code>op: is\npath: routing/hostname\nvalue: web-server-2\n</code></pre>"},{"location":"3-detection-response/false-positives/#see-also","title":"See Also","text":"<ul> <li>D&amp;R Rules Overview</li> <li>Writing Rules</li> </ul>"},{"location":"3-detection-response/stateful-rules/","title":"Stateful Rules","text":""},{"location":"3-detection-response/stateful-rules/#overview","title":"Overview","text":"<p>It's recommended to first read Detection &amp; Response rules before diving into stateful rules.</p> <p>In LimaCharlie, a Stateful Rule tracks and remembers the state of past events to make decisions based on historical context. Unlike stateless rules, which evaluate events in isolation, stateful rules can detect patterns over time, such as multiple failed logins within an hour. This enables more complex and accurate detection, allowing users to trigger actions only when specific conditions are met across multiple events or timeframes.</p> <p>Events in LimaCharlie have well-defined relationships to one another using <code>routing/this</code>, <code>routing/parent</code>, <code>routing/target</code>, and can even be implicitly related by occurring in a similar timeframe. The relation context can be useful for writing more complex rules.</p> <p>These are called \"stateful\" rules.</p>"},{"location":"3-detection-response/stateful-rules/#detecting-children-descendants","title":"Detecting Children / Descendants","text":"<p>To detect events in a tree you can use the following parameters:</p> <ul> <li><code>with child</code>: matches children of the initial event</li> <li><code>with descendant</code>: matches descendants (children, grandchildren, etc.) of the initial event</li> </ul> <p>Aside from how deep they match, the <code>with child</code> and <code>with descendant</code> parameters operate identically: they declare a nested stateful rule.</p> <p>For example, let's detect a <code>cmd.exe</code> process spawning a <code>calc.exe</code> process:</p> <pre><code># Detect initial event\nevent: NEW_PROCESS\nop: ends with\npath: event/FILE_PATH\nvalue: cmd.exe\ncase sensitive: false\nwith child: # Wait for child matching this nested rule\n  op: ends with\n  event: NEW_PROCESS\n  path: event/FILE_PATH\n  value: calc.exe\n  case sensitive: false\n</code></pre> <p>Simply put, this will detect:</p> <pre><code>cmd.exe --&gt; calc.exe\n</code></pre> <p>Because it uses <code>with child</code> it will not detect:</p> <pre><code>cmd.exe --&gt; firefox.exe --&gt; calc.exe\n</code></pre> <p>To do that, we could use <code>with descendant</code> instead.</p>"},{"location":"3-detection-response/stateful-rules/#detecting-proximal-events","title":"Detecting Proximal Events","text":"<p>To detect repetition of events close together on the same Sensor, we can use <code>with events</code>.</p> <p>The <code>with events</code> parameter functions very similarly to <code>with child</code> and <code>with descendant</code>: it declares a nested stateful rule.</p> <p>For example, let's detect a scenario where <code>5</code> bad login attempts occur within <code>60</code> seconds.</p> <pre><code>event: WEL\nop: is windows\nwith events:\n  event: WEL\n  op: is\n  path: event/EVENT/System/EventID\n  value: '4625'\n  count: 5\n  within: 60\n</code></pre> <p>The top-level rule filters down meaningful events to <code>WEL</code> ones sent from Windows sensors using the <code>is windows</code> operator, and then it declares a stateful rule inside <code>with events</code>. It uses <code>count</code> and <code>within</code> to declare a suitable timespan to evaluate matching events.</p>"},{"location":"3-detection-response/stateful-rules/#stateful-rules_1","title":"Stateful Rules","text":"<p>Stateful rules \u2014 the rules declared within <code>with child</code>, <code>with descendant</code> or <code>with events</code> \u2014 have full range. They can do anything a normal rule might do, including declaring nested stateful rules or using <code>and</code>/<code>or</code> operators to write more complex rules.</p> <p>Here's a stateful rule that uses <code>and</code> to detect a specific combination of child events:</p> <pre><code>event: NEW_PROCESS\nop: ends with\npath: event/FILE_PATH\nvalue: outlook.exe\ncase sensitive: false\nwith child:\n  op: and\n  rules:\n    - op: ends with\n      event: NEW_PROCESS\n      path: event/FILE_PATH\n      value: chrome.exe\n      case sensitive: false\n    - op: ends with\n      event: NEW_DOCUMENT\n      path: event/FILE_PATH\n      value: .ps1\n      case sensitive: false\n</code></pre> <p>The above example is looking for an <code>outlook.exe</code> process that spawns a <code>chrome.exe</code> process and drops a <code>.ps1</code> (powershell) file to disk. Like this:</p> <pre><code>outlook.exe\n|--+--&gt; chrome.exe\n|--+--&gt; .ps1 file\n</code></pre>"},{"location":"3-detection-response/stateful-rules/#counting-events","title":"Counting Events","text":"<p>Rules declared using <code>with child</code> or <code>with descendant</code> also have the ability to use <code>count</code> and <code>within</code> to help scope the events it will statefully match.</p> <p>For example, a rule that matches on Outlook writing 5 new <code>.ps1</code> documents within 60 seconds:</p> <pre><code>event: NEW_PROCESS\nop: ends with\npath: event/FILE_PATH\nvalue: outlook.exe\ncase sensitive: false\nwith child:\n  op: ends with\n  event: NEW_DOCUMENT\n  path: event/FILE_PATH\n  value: .ps1\n  case sensitive: false\n  count: 5\n  within: 60\n</code></pre>"},{"location":"3-detection-response/stateful-rules/#choosing-event-to-report","title":"Choosing Event to Report","text":"<p>A reported detection will include a copy of the event that was detected. When writing detections that match multiple events, the default behavior will be to include a copy of the initial parent event.</p> <p>In many cases it's more desirable to get the latest event in the chain instead. For this, there's a <code>report latest event: true</code> flag that can be set. Piggy-backing on the earlier example:</p> <pre><code># Detection\nevent: NEW_PROCESS\nop: ends with\npath: event/FILE_PATH\nvalue: outlook.exe\ncase sensitive: false\nreport latest event: true\nwith child:\n  op: and\n  rules:\n    - op: ends with\n      event: NEW_PROCESS\n      path: event/FILE_PATH\n      value: chrome.exe\n      case sensitive: false\n    - op: ends with\n      event: NEW_DOCUMENT\n      path: event/FILE_PATH\n      value: .ps1\n      case sensitive: false\n\n# Response\n- action: report\n  name: Outlook Spawning Chrome &amp; Powershell\n</code></pre> <p>The event returned in the detection will be either the <code>chrome.exe</code> <code>NEW_PROCESS</code> event or the <code>.ps1</code> <code>NEW_DOCUMENT</code> event, whichever was last. Without <code>report latest event: true</code> being set, it would default to including the <code>outlook.exe</code> <code>NEW PROCESS</code> event.</p>"},{"location":"3-detection-response/stateful-rules/#flipping-back-to-stateless","title":"Flipping back to stateless","text":"<p>Since all operators under the <code>with child</code> and <code>with descentant</code> are operating in stateful mode (meaning all the nodes don't have to match a single event, but can match over multiple events), sometimes you want a operator and the operators underneath to flip back to stateless mode where they must match a single event. You can achieve this by setting <code>is stateless: true</code> in the operator like:</p> <pre><code># Detection\nevent: NEW_PROCESS\nop: ends with\npath: event/FILE_PATH\nvalue: outlook.exe\ncase sensitive: false\nreport latest event: true\nwith child:\n  op: and\n  is stateless: true\n  rules:\n    - op: ends with\n      event: NEW_PROCESS\n      path: event/FILE_PATH\n      value: evil.exe\n      case sensitive: false\n    - op: contains\n      event: COMMAND_LINE\n      path: event/FILE_PATH\n      value: something-else\n      case sensitive: false\n</code></pre>"},{"location":"3-detection-response/stateful-rules/#caveats","title":"Caveats","text":""},{"location":"3-detection-response/stateful-rules/#testing-stateful-rules","title":"Testing Stateful Rules","text":"<p>Stateful rules are forward-looking only and changing a rule will reset its state.</p> <p>Practically speaking, this means that if you change a rule that detects <code>excel.exe -&gt; cmd.exe</code>, <code>excel.exe</code> will need to be relaunched while the updated rule is running for it to then begin watching for <code>cmd.exe</code>.</p>"},{"location":"3-detection-response/stateful-rules/#using-events-in-actions","title":"Using Events in Actions","text":"<p>Using <code>report</code> to report a detection works according to the Choosing Event to Report section earlier. Other actions have a subtle difference: they will always observe the latest event in the chain.</p> <p>Consider the <code>excel.exe -&gt; cmd.exe</code> example. The <code>cmd.exe</code> event will be referenced inside the response action if using lookbacks (i.e. <code>&lt;&lt;routing/this&gt;&gt;</code>). If we wanted to end the <code>excel.exe</code> process (and its descendants), we would write a <code>task</code> that references the parent of the current event (<code>cmd.exe</code>):</p> <pre><code>- action: task\n  command: deny_tree &lt;&lt;routing/parent&gt;&gt;\n</code></pre>"},{"location":"3-detection-response/stateful-rules/#see-also","title":"See Also","text":"<ul> <li>D&amp;R Rules Overview</li> <li>Writing Rules</li> </ul>"},{"location":"3-detection-response/unit-tests/","title":"Unit Tests","text":""},{"location":"3-detection-response/unit-tests/#rules-unit-tests","title":"Rules Unit Tests","text":"<p>A D&amp;R rule record can optionally contain unit tests. These tests describe events that should match, and events that should not match. When a D&amp;R rule is updated or created, LimaCharlie will simulate the rules and if the tests fail, an error is produced.</p>"},{"location":"3-detection-response/unit-tests/#structure","title":"Structure","text":"<p>A typical D&amp;R rule looks like:</p> <pre><code>{\n  \"detect\": {...},\n  \"respond\": [\n    {},\n    {}\n  ],\n  \"tests\": {\n    \"match\": [],\n    \"non_match\": []\n  }\n}\n</code></pre> <p>The <code>match</code> and <code>non_match</code> both have the same format: they contain a list of lists of events. Each top list element is a unit test, and the content of a test is a list of events as would be seen by LimaCharlie. The reason for the test to be a list is to accomodate for Stateful Detections which operate across multiple events.</p> <p>Here's an example:</p> <pre><code>{\n  \"tests\": {\n    \"match\": [\n      [{\"event\": ...}, {\"event\": ...}, {\"event\": ...}],\n      [{\"event\": ...}],\n      [{\"event\": ...}]\n    ],\n    \"non_match\": [\n      [{\"event\": ...}, {\"event\": ...}],\n      [{\"event\": ...}]\n    ]\n  }\n}\n</code></pre>"},{"location":"3-detection-response/unit-tests/#example","title":"Example","text":"<pre><code>version: 3\nhives:\n    dr-general:\n        \"CobaltStrike Named Pipe Patterns\":\n            data:\n                detect:\n                    event: WEL\n                    op: and\n                    rules:\n                      - op: and\n                        rules:\n                        - op: or\n                          rules:\n                          - case sensitive: false\n                            op: is\n                            path: event/EVENT/System/_event_id\n                            value: '17'\n                          - case sensitive: false\n                            op: is\n                            path: event/EVENT/System/_event_id\n                            value: '18'\n                        - case sensitive: false\n                          op: is\n                          path: event/EVENT/System/Channel\n                          value: Microsoft-Windows-Sysmon/Operational\n                      - op: or\n                        rules:\n                        - op: or\n                          rules:\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\mojo.5688.8052.183894939787088877\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\mojo.5688.8052.35780273329370473\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\mypipe-f\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\mypipe-h\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\ntsvcs\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\scerpc\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\win_svc\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\spoolss\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\msrpc_\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\win\\msrpc_\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\wkssvc\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\windows.update.manager\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\SearchTextHarvester\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\DserNamePipe\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\PGMessagePipe\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\MsFteWds\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\fullduplex_\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\rpc_\n                        - op: or\n                          rules:\n                          - case sensitive: false\n                            op: is\n                            path: event/EVENT/EventData/PipeName\n                            value: \\demoagent_11\n                          - case sensitive: false\n                            op: is\n                            path: event/EVENT/EventData/PipeName\n                            value: \\demoagent_22\n                        - op: matches\n                          path: event/EVENT/EventData/PipeName\n                          re: \\\\f4c3[0-9a-f]{2}$\n                        - op: matches\n                          path: event/EVENT/EventData/PipeName\n                          re: \\\\f53f[0-9a-f]{2}$\n                        - op: and\n                          rules:\n                          - case sensitive: false\n                            op: starts with\n                            path: event/EVENT/EventData/PipeName\n                            value: \\Winsock2\\CatalogChangeListener-\n                          - case sensitive: false\n                            op: ends with\n                            path: event/EVENT/EventData/PipeName\n                            value: -0,\n                respond:\n                    - action: report\n                      name: CobaltStrike Named Pipe Patterns\n                      metadata:\n                        tags:\n                        - attack.defense_evasion\n                        - attack.privilege_escalation\n                        - attack.t1055\n                        description: Detects the creation of a named pipe with a pattern found in CobaltStrike malleable C2 profiles\n                        status: stable\n                        id: 29206f7e-21fd-448a-9723-5f3272f22eba\n                        references:\n                        - https://svch0st.medium.com/guide-to-named-pipes-and-hunting-for-cobalt-strike-pipes-dc46b2c5f575\n                        - https://gist.github.com/MHaggis/6c600e524045a6d49c35291a21e10752\n                        level: medium\n                        author: Florian Roth, Christian Burkard\n                        falsepositives:\n                        - Chrome instances using the exact same pipe name \"mojo.something\"\n                        logsource: LimaCharlie\n                tests:\n                    match:\n                      # Test 1: CobaltStrike mojo pipe pattern\n                      - - event:\n                            EVENT:\n                              EventData:\n                                EventType: CreatePipe\n                                Image: C:\\Windows\\system32\\rundll32.exe\n                                PipeName: \\mojo.5688.8052.183894939787088877\n                                ProcessGuid: \"{a6385ccd-7fc6-6850-1702-000000001700}\"\n                                ProcessId: \"1234\"\n                                RuleName: \"-\"\n                                User: NT AUTHORITY\\SYSTEM\n                                UtcTime: \"2025-06-17 18:00:00.000\"\n                              System:\n                                Channel: Microsoft-Windows-Sysmon/Operational\n                                Computer: testhost.domain.com\n                                EventID: \"17\"\n                                _event_id: \"17\"\n                          routing:\n                            event_type: WEL\n                            hostname: testhost\n                      # Test 2: CobaltStrike demoagent pipe\n                      - - event:\n                            EVENT:\n                              EventData:\n                                EventType: ConnectPipe\n                                Image: C:\\Windows\\explorer.exe\n                                PipeName: \\demoagent_11\n                                ProcessGuid: \"{a6385ccd-7fc6-6850-1702-000000001700}\"\n                                ProcessId: \"5678\"\n                                RuleName: \"-\"\n                                User: DOMAIN\\user\n                                UtcTime: \"2025-06-17 18:01:00.000\"\n                              System:\n                                Channel: Microsoft-Windows-Sysmon/Operational\n                                Computer: testhost.domain.com\n                                EventID: \"18\"\n                                _event_id: \"18\"\n                          routing:\n                            event_type: WEL\n                            hostname: testhost\n                      # Test 3: Regex pattern f4c3\n                      - - event:\n                            EVENT:\n                              EventData:\n                                EventType: CreatePipe\n                                Image: C:\\temp\\malicious.exe\n                                PipeName: \\f4c3ab\n                                ProcessGuid: \"{a6385ccd-7fc6-6850-1702-000000001700}\"\n                                ProcessId: \"9999\"\n                                RuleName: \"-\"\n                                User: DOMAIN\\user\n                                UtcTime: \"2025-06-17 18:02:00.000\"\n                              System:\n                                Channel: Microsoft-Windows-Sysmon/Operational\n                                Computer: testhost.domain.com\n                                EventID: \"17\"\n                                _event_id: \"17\"\n                          routing:\n                            event_type: WEL\n                            hostname: testhost\n                      # Test 4: Winsock2 CatalogChangeListener pattern\n                      - - event:\n                            EVENT:\n                              EventData:\n                                EventType: ConnectPipe\n                                Image: C:\\Windows\\system32\\svchost.exe\n                                PipeName: \\Winsock2\\CatalogChangeListener-123-0,\n                                ProcessGuid: \"{a6385ccd-7fc6-6850-1702-000000001700}\"\n                                ProcessId: \"1111\"\n                                RuleName: \"-\"\n                                User: NT AUTHORITY\\SYSTEM\n                                UtcTime: \"2025-06-17 18:03:00.000\"\n                              System:\n                                Channel: Microsoft-Windows-Sysmon/Operational\n                                Computer: testhost.domain.com\n                                EventID: \"18\"\n                                _event_id: \"18\"\n                          routing:\n                            event_type: WEL\n                            hostname: testhost\n                    non_match:\n                      # Test 1: SearchIndexer.exe using legitimate pipe NOT in detection patterns\n                      - - event:\n                            EVENT:\n                              EventData:\n                                EventType: ConnectPipe\n                                Image: C:\\WINDOWS\\system32\\SearchIndexer.exe\n                                PipeName: \\SearchFilterHost\n                                ProcessGuid: \"{a6385ccd-7fc6-6850-1702-000000001700}\"\n                                ProcessId: \"11816\"\n                                RuleName: \"-\"\n                                User: NT AUTHORITY\\SYSTEM\n                                UtcTime: \"2025-06-16 20:42:20.099\"\n                              System:\n                                Channel: Microsoft-Windows-Sysmon/Operational\n                                Computer: workstation01.example.com\n                                EventID: \"18\"\n                                _event_id: \"18\"\n                          routing:\n                            event_type: WEL\n                            hostname: workstation01\n                      # Test 2: Different event channel (not Sysmon)\n                      - - event:\n                            EVENT:\n                              EventData:\n                                PipeName: \\mojo.5688.8052.183894939787088877\n                              System:\n                                Channel: Security\n                                EventID: \"18\"\n                                _event_id: \"18\"\n                          routing:\n                            event_type: WEL\n                            hostname: testhost\n                      # Test 3: Wrong event ID (not 17 or 18)\n                      - - event:\n                            EVENT:\n                              EventData:\n                                PipeName: \\demoagent_11\n                              System:\n                                Channel: Microsoft-Windows-Sysmon/Operational\n                                EventID: \"1\"\n                                _event_id: \"1\"\n                          routing:\n                            event_type: WEL\n                            hostname: testhost\n                      # Test 4: Legitimate Windows pipe not in detection patterns\n                      - - event:\n                            EVENT:\n                              EventData:\n                                EventType: ConnectPipe\n                                Image: C:\\Windows\\system32\\lsass.exe\n                                PipeName: \\lsass\n                                ProcessGuid: \"{a6385ccd-7fc6-6850-1702-000000001700}\"\n                                ProcessId: \"700\"\n                                RuleName: \"-\"\n                                User: NT AUTHORITY\\SYSTEM\n                                UtcTime: \"2025-06-17 18:05:00.000\"\n                              System:\n                                Channel: Microsoft-Windows-Sysmon/Operational\n                                Computer: testhost.domain.com\n                                EventID: \"18\"\n                                _event_id: \"18\"\n                          routing:\n                            event_type: WEL\n                            hostname: testhost\n                      # Test 5: Non-WEL event type\n                      - - event:\n                            PROCESS_ID: 1234\n                            FILE_PATH: \\Device\\NamedPipe\\mojo.test\n                          routing:\n                            event_type: NEW_NAMED_PIPE\n                            hostname: testhost\n            usr_mtd:\n                enabled: true\n                expiry: 0\n                tags: []\n                comment: \"Detects the creation of a named pipe with a pattern found in CobaltStrike malleable C2 profiles\"\n</code></pre>"},{"location":"3-detection-response/managed-rulesets/community-rules/","title":"Community Rules","text":"<p>Our Community Rules feature leverages the power of AI to quickly transform a plethora of third-party rules into LimaCharlie syntax so you can make them your own. The process is fast and efficient: Browse thousands of community rules, select one as a starting point, convert it to LimaCharlie syntax with one click, and customize it to your liking.</p>"},{"location":"3-detection-response/managed-rulesets/community-rules/#accessing-the-community-rules","title":"Accessing the Community Rules","text":"<p>To access the Community Rules:</p> <ol> <li>Log into LimaCharlie</li> <li>Select an Organization</li> <li>Click the Automation drop down on the left panel</li> <li>Select Rules</li> <li>Look in the upper right corner of the D&amp;R Rules page for the Add Rule button</li> <li>Click the Add Rule button</li> <li>Look in the upper right corner of the rule creation page for the Community Library button</li> <li>Click the Community Library button</li> </ol> <p>This takes you to the Community Rules search page, and gives you access to thousands of third-party detection rules. The library currently contains detection rules written by Anvilogic, Sigma, Panther, and Okta.</p> <p>Rules are searchable by CVE number, keyword, or pre-defined descriptors (Tags). Searchable tags include attack techniques, MITRE ATT&amp;CK id codes and other key rule identificators.</p> <p></p>"},{"location":"3-detection-response/managed-rulesets/community-rules/#loading-a-community-rule","title":"Loading a Community Rule","text":"<p>Once you find the rule you want to use, import it to the organization by clicking \"Load Rule\", and our AI engine will create it using verified LimaCharlie syntax.</p> <p>This process may take a few seconds so please be patient.</p> <p>Once the rule is ready, it will return you to the Add Rule page in LimaCharlie. The Detect and Response sections of the rule will be filled out with LimaCharlie logic that includes explanatory comments. From here you can manage this rule just as you would any other D&amp;R rule.</p>"},{"location":"3-detection-response/managed-rulesets/community-rules/#digging-deeper","title":"Digging Deeper","text":"<p>As these rules are the property of third parties you may be interested in knowing more about their licensing or source code. This information is accessible through the Community Rules search page. To see these details click on a rule.</p> <p>The example below shows what appears when you click Anvilogic's Potential CVE-2021-44228 - Log4Shell rule</p> <p>Under the rule name you will see the options to load the rule, check its source code, and read additional licensing information. There is also a reference section at the bottom left corner of the window providing links related to the rule.</p> <p></p>"},{"location":"3-detection-response/managed-rulesets/sigma-converter/","title":"Sigma Converter","text":"<p>LimaCharlie is happy to contribute to the Sigma Project by maintaining the LimaCharlie Backend for Sigma, enabling most Sigma rules to be converted to the Detection &amp; Response rule format.</p> <p>A LimaCharlie Service is available to apply many of those converted rules with a single click to an Organization.</p> <p>For cases where you either have your own Sigma rules, or you would like to convert/apply specific rules yourself, the Sigma Converter service described below can help streamline the process.</p>"},{"location":"3-detection-response/managed-rulesets/sigma-converter/#converter-service","title":"Converter Service","text":"<p>The Converter service converts one or many Sigma rules into the LimaCharlie  rule format. It can accomplish this via the following HTTPS endpoints available at https://sigma.limacharlie.io/:</p>"},{"location":"3-detection-response/managed-rulesets/sigma-converter/#single-rule","title":"Single Rule","text":"<p>Endpoint: <code>https://sigma.limacharlie.io/convert/rule</code>  Verb: <code>POST</code>  Form Parameters:</p> <ul> <li><code>rule</code>: the content of a literal Sigma rule to be converted.</li> <li><code>target</code>: optional target within LimaCharlie, one of <code>edr</code> (default) or <code>artifact</code>.    Output Example:</li> </ul> <pre><code>{\n    \"rule\": \"detect:\\n  events:\\n  - NEW_PROCESS\\n  - EXISTING_PROCESS\\n  op: and\\n  rules:\\n  - op: is windows\\n  - op: or\\n    rules:\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: domainlist\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: trustdmp\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: dcmodes\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: adinfo\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: ' dclist '\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: computer_pwdnotreqd\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: objectcategory=\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: -subnets -f\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: name=\\\"Domain Admins\\\"\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: '-sc u:'\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: domainncs\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: dompol\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: ' oudmp '\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: subnetdmp\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: gpodmp\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: fspdmp\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: users_noexpire\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: computers_active\\nrespond:\\n- action: report\\n  metadata:\\n    author: Janantha Marasinghe (https://github.com/blueteam0ps)\\n    description: AdFind continues to be seen across majority of breaches. It is used\\n      to domain trust discovery to plan out subsequent steps in the attack chain.\\n    falsepositives:\\n    - Admin activity\\n    level: high\\n    references:\\n    - https://thedfirreport.com/2020/05/08/adfind-recon/\\n    - https://thedfirreport.com/2021/01/11/trickbot-still-alive-and-well/\\n    - https://www.microsoft.com/security/blog/2021/01/20/deep-dive-into-the-solorigate-second-stage-activation-from-sunburst-to-teardrop-and-raindrop/\\n    tags:\\n    - attack.discovery\\n    - attack.t1482\\n    - attack.t1018\\n  name: AdFind Usage Detection\\n\\n\"\n}\n</code></pre> <p>CURL Example:</p> <pre><code>curl -X POST  https://sigma.limacharlie.io/convert/rule -H 'content-type: application/x-www-form-urlencoded' --data-urlencode \"rule@my-rule-file.yaml\"\n</code></pre>"},{"location":"3-detection-response/managed-rulesets/sigma-converter/#multiple-rules","title":"Multiple Rules","text":"<p>Endpoint: <code>https://sigma.limacharlie.io/convert/repo</code>  Verb: <code>POST</code>  Form Parameters:</p> <ul> <li> <p><code>repo</code>: the source where to access the rules to convert, one of:</p> </li> <li> <p>An HTTPS link to a direct resource like: <code>https://corp.com/my-rules.yaml</code></p> </li> <li> <p>A GitHub link to a file or repo like:</p> <ul> <li><code>https://github.com/SigmaHQ/sigma/blob/master/rules/windows/process_creation/proc_creation_win_ad_find_discovery.yml</code></li> <li><code>https://github.com/SigmaHQ/sigma/blob/master/rules/windows/process_creation</code></li> <li>An Authenticated Resource Locator</li> <li><code>target</code>: optional target within LimaCharlie, one of <code>edr</code> (default) or <code>artifact</code>.</li> </ul> </li> </ul> <p>Output Example:</p> <pre><code>{\n    \"rules\":[\n        {\n            \"file\":\"https://raw.githubusercontent.com/SigmaHQ/sigma/master/rules/windows/process_creation/proc_creation_win_ad_find_discovery.yml\",\"rule\":\"detect:\\n  events:\\n  - NEW_PROCESS\\n  - EXISTING_PROCESS\\n  op: and\\n  rules:\\n  - op: is windows\\n  - op: or\\n    rules:\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: domainlist\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: trustdmp\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: dcmodes\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: adinfo\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: ' dclist '\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: computer_pwdnotreqd\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: objectcategory=\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: -subnets -f\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: name=\\\"Domain Admins\\\"\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: '-sc u:'\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: domainncs\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: dompol\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: ' oudmp '\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: subnetdmp\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: gpodmp\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: fspdmp\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: users_noexpire\\n    - case sensitive: false\\n      op: contains\\n      path: event/COMMAND_LINE\\n      value: computers_active\\nrespond:\\n- action: report\\n  metadata:\\n    author: Janantha Marasinghe (https://github.com/blueteam0ps)\\n    description: AdFind continues to be seen across majority of breaches. It is used\\n      to domain trust discovery to plan out subsequent steps in the attack chain.\\n    falsepositives:\\n    - Admin activity\\n    level: high\\n    references:\\n    - https://thedfirreport.com/2020/05/08/adfind-recon/\\n    - https://thedfirreport.com/2021/01/11/trickbot-still-alive-and-well/\\n    - https://www.microsoft.com/security/blog/2021/01/20/deep-dive-into-the-solorigate-second-stage-activation-from-sunburst-to-teardrop-and-raindrop/\\n    tags:\\n    - attack.discovery\\n    - attack.t1482\\n    - attack.t1018\\n  name: AdFind Usage Detection\\n\\n\"\n        },\n        ...\n    ]\n}\n</code></pre> <p>CURL Example:</p> <pre><code>curl -X POST  https://sigma.limacharlie.io/convert/repo -d \"repo=https://github.com/SigmaHQ/sigma/blob/master/rules/windows/process_creation/proc_creation_win_ad_find_discovery.yml\"\n</code></pre>"},{"location":"3-detection-response/managed-rulesets/soc-prime/","title":"SOC Prime Rules","text":"<p>To use SOC Prime rules in LimaCharlie, start by configuring lists in SOC Prime. You can learn how to do it here.</p> <p>After the lists have been configured, you can finish the configuration in LimaCharlie. Note that currently the SOC Prime API is not available for free users. It is available only for paid users or if they requested a trial.</p> <p>First, enable the <code>socprime</code> add-on on the LimaCharlie marketplace.</p> <p></p> <p>Then, navigate to the Integrations page in your Organization, enter the SOC Prime Key &amp; click <code>Update</code>.</p> <p></p> <p>When the Key is saved, you will get the ability to select the SOC Prime content lists you want to have populated in LimaCharlie as detection &amp; response rules. After selecting the lists &amp; clicking <code>Update</code>, you are all set to start receiving detections based on the SOC Prime lists.</p> <p></p> <p>A detection that comes from the SOC Prime Lists, will have <code>socprime</code> listed as a detection author.</p> <p></p> <p>Note that adding a new rule to a SOC Prime content list that is enabled in LC will see the new rule be applied during next sync (LimaCharlie syncs the SOC Prime rules every 3 hours).</p>"},{"location":"3-detection-response/managed-rulesets/soteria/aws/","title":"Soteria AWS Rules","text":"<p>Soteria's AWS ruleset provides coverage across multiple AWS telemetry streams, including:</p> <ul> <li>AWS CloudTrail</li> <li>AWS GuardDuty</li> </ul>"},{"location":"3-detection-response/managed-rulesets/soteria/aws/#data-access","title":"Data Access","text":"<p>Please note that Soteria won't get access to your data, and you won't be able to see or edit their rules - LimaCharlie acts as a broker between the two parties.</p> <p>To leverage detection logic provided by the ruleset:</p> <ol> <li>Subscribe your tenant to the Soteria AWS ruleset extension.</li> <li>Subscribe your tenant to tor lookup (provided at no cost).</li> <li>Configure AWS CloudTrail and AWS GuardDuty adapters to start collecting AWS audit logs.</li> </ol>"},{"location":"3-detection-response/managed-rulesets/soteria/aws/#enabling-soterias-aws-rules","title":"Enabling Soteria's AWS Rules","text":"<p>Soteria's AWS rules can be activated via two means.</p>"},{"location":"3-detection-response/managed-rulesets/soteria/aws/#activating-via-the-web-ui","title":"Activating via the Web UI","text":"<p>To enable Soteria's AWS ruleset, navigate to the Extensions section of the Add-On Marketplace and search for Soteria. You can also directly select <code>soteria-rules-aws</code>.</p> <p></p> <p>Please note: Pricing may reflect when the screenshot was taken, not the actual pricing</p> <p>Under the Organization dropdown, select a tenant (organization) you want to subscribe to soteria-rules-aws and click Subscribe.</p> <p></p> <p>You can also manage add-ons from the Subscriptions menu under Billing.</p> <p></p>"},{"location":"3-detection-response/managed-rulesets/soteria/aws/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>Alternatively, to manage tenants and LimaCharlie functionality at scale, you can leverage our Infrastructure as Code functionality.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p>"},{"location":"3-detection-response/managed-rulesets/soteria/edr/","title":"Soteria EDR Rules","text":"<p>Soteria's EDR ruleset provides coverage across Windows, Linux, and macOS. You can check the dynamic MITRE ATT&amp;CK mapping here:</p> <ul> <li>All rules</li> <li>Windows</li> <li>Linux</li> <li>macOS</li> </ul>"},{"location":"3-detection-response/managed-rulesets/soteria/edr/#data-access","title":"Data access","text":"<p>Please note that Soteria won't get access to your data, and you won't be able to see or edit their rules - LimaCharlie acts as a broker between the two parties.</p> <p>The following events are utilized by Soteria rules. Please ensure that they are configured within your Organization:</p> <ul> <li><code>CODE_IDENTITY</code></li> <li><code>DNS_REQUEST</code></li> <li><code>EXISTING_PROCESS</code></li> <li><code>FILE_CREATE</code></li> <li><code>FILE_MODIFIED</code></li> <li><code>MODULE_LOAD</code></li> <li><code>NETWORK_CONNECTIONS</code></li> <li><code>NEW_DOCUMENT</code></li> <li><code>NEW_NAMED_PIPE</code></li> <li><code>NEW_PROCESS</code></li> <li><code>REGISTRY_WRITE</code></li> <li><code>REGISTRY_CREATE</code></li> <li><code>SENSITIVE_PROCESS_ACCESS</code></li> <li><code>THREAD_INJECTION</code></li> </ul> <p>This can also be done in the Add-ons Marketplace.</p>"},{"location":"3-detection-response/managed-rulesets/soteria/edr/#enabling-soterias-edr-rules","title":"Enabling Soteria's EDR Rules","text":"<p>Soteria's EDR rules can be activated via two means.</p>"},{"location":"3-detection-response/managed-rulesets/soteria/edr/#activating-via-the-web-ui","title":"Activating via the Web UI","text":"<p>To enable Soteria's EDR ruleset, navigate to the Extensions section of the Add-On Marketplace and search for Soteria. You can also directly select <code>soteria-rules-edr</code>.</p> <p></p> <p>Please note: Pricing may reflect when the screenshot was taken, not the actual pricing</p> <p>Under the Organization dropdown, select a tenant (organization) you want to subscribe to Soteria rules and click Subscribe.</p> <p></p> <p>You can also manage add-ons from the Subscriptions menu under Billing.</p> <p></p>"},{"location":"3-detection-response/managed-rulesets/soteria/edr/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>Alternatively, to manage tenants and LimaCharlie functionality at scale, you can leverage our Infrastructure as Code functionality.</p>"},{"location":"3-detection-response/managed-rulesets/soteria/m365/","title":"Soteria M365 Rules","text":"<p>Soteria's O365 ruleset provides coverage across O365 (aka M365) telemetry streams. The ruleset is designed for in-depth analysis of the Office 365 ecosystem which includes:</p> <ul> <li>Teams</li> <li>Word</li> <li>Excel</li> <li>PowerPoint</li> <li>Outlook</li> <li>OneDrive</li> <li>...and other productivity applications.</li> </ul> <p>Data access</p> <p>Please note that Soteria won't get access to your data, and you won't be able to see or edit their rules - LimaCharlie acts as a broker between the two parties.</p> <p>To leverage detection logic provided by the ruleset:</p> <ol> <li>Subscribe your tenant to the Soteria Office 365 ruleset extension</li> <li>Subscribe your tenant to tor lookup (provided at no cost).</li> <li>Configure Office 365 Sensor to start collecting Office 365 audit logs.</li> </ol>"},{"location":"3-detection-response/managed-rulesets/soteria/m365/#enabling-soterias-o365-rules","title":"Enabling Soteria's O365 Rules","text":"<p>Soteria's O365 rules can be activated via two means.</p>"},{"location":"3-detection-response/managed-rulesets/soteria/m365/#activating-via-the-web-ui","title":"Activating via the Web UI","text":"<p>To enable Soteria's O365 ruleset, navigate to the Extensions section of the Add-On Marketplace and search for Soteria. You can also directly select <code>soteria-rules-o365</code>.</p> <p></p> <p>Please note: Pricing may reflect when the screenshot was taken, not the actual pricing</p> <p>Under the Organization dropdown, select a tenant (organization) you want to subscribe to Soteria O365 rules and click Subscribe.</p> <p></p> <p>You can also manage add-ons from the Subscriptions menu under Billing.</p> <p></p>"},{"location":"3-detection-response/managed-rulesets/soteria/m365/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>Alternatively, to manage tenants and LimaCharlie functionality at scale, you can leverage our Infrastructure as Code functionality.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p> <p>LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.</p>"},{"location":"3-detection-response/tutorials/threat-feed-rule/","title":"Create a D&amp;R Rule Using a Threat Feed","text":"<p>A common use case for rules is to use them to compare telemetry against known malicious IPs, domain names, or file hashes via threat feeds. With LimaCharlie, it is easy to leverage public threat feeds or create your own.</p> <p>To configure a threat feed, it must first be enabled within the Add-ons Marketplace. First, select a threat feed from the plethora available for free. In the following example, we will enable <code>crimeware-ips</code>.</p> <p></p> <p>Select <code>Subscribe</code>, which will make the feed available to the respective Organization.</p> <p>Once subscribed, you can write a D&amp;R rule to detect whenever there is a match to an IP within the threat feed. Navigate to <code>D&amp;R Rules</code> within the web application main page, and select <code>+ New Rule</code>. Begin your rule with the following template:</p> <pre><code>event: NETWORK_CONNECTIONS\nop: lookup\npath: event/NETWORK_ACTIVITY/?/IP_ADDRESS\nresource: hive://lookup/crimeware-ips\n</code></pre>"},{"location":"3-detection-response/tutorials/threat-feed-rule/#additional-telemetry-points","title":"Additional Telemetry Points","text":"<p>Configure a lookup based on file hash:</p> <pre><code>op: lookup\nevent: CODE_IDENTITY\npath: event/HASH\nresource: hive://lookup/my-hash-lookup\n</code></pre> <p>Configure a lookup based on domain name(s):</p> <pre><code>op: lookup\nevent: DNS_REQUEST\npath: event/DOMAIN_NAME\nresource: hive://lookup/my-dns-lookup\n</code></pre>"},{"location":"3-detection-response/tutorials/writing-testing-rules/","title":"Writing and Testing Rules","text":"<p>Detection &amp; Response () Rules are similar to Google Cloud Functions or AWS Lambda. They allow you to push D&amp;R rules to the LimaCharlie cloud where the rules will be applied in real-time to data coming from the sensors.</p> <p>D&amp;R rules can also be applied to Artifact Collection, but for now we will focus on the simple case where it is applied to Sensor events.</p> <p>For a full list of all rule operators and detailed documentation see the Detection and Response section.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#life-of-a-rule","title":"Life of a Rule","text":"<p>D&amp;R rules are generally applied on a per-event basis. When the rule is applied, the \"detection\" component of the rule is processed to determine if it matches. If there is a match, the \"response\" component is applied.</p> <p>The detection is processed one step at a time, starting at the root of the detection. If the root matches, the rule is considered to be matching.</p> <p>The detection component is composed of \"nodes\", where each node has an operator describing the logical evaluation. Most operators are simple, like <code>is</code>, <code>starts with</code> etc. These simple nodes can be combined with Boolean (true/false) logic using the <code>and</code> and <code>or</code> operators, which themselves reference a series of nodes. The <code>and</code> node matches if all the sub-nodes match, while the <code>or</code> node matches if any one of the sub-nodes matches.</p> <p>When evaluating an <code>or</code>, as soon as the first matching sub-node is found, the rest of the sub-nodes are skipped since they will have no impact on the final matching state of the \"or\". Similarly, failure of a sub-node in an \"and\" node will immediately terminate its evaluation.</p> <p>If the \"detection\" component is matched, then the \"response\" evaluation begins.</p> <p>The \"response\" component is a list of actions that should be taken. When an action refers to a sensor, that sensor is assumed to be the sensor the event being evaluated is coming from.</p> <p>The best general strategy for D&amp;R rules is to put the parts of the rule most likely to eliminate the event at the beginning of the rule, so that LC may move on to the next event as quickly as possible.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#introduction","title":"Introduction","text":""},{"location":"3-detection-response/tutorials/writing-testing-rules/#goal","title":"Goal","text":"<p>The goal of is code lab will be to create a D&amp;R rule to detect the MITRE ATT&amp;CK framework Control Panel Items execution.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#services-used","title":"Services Used","text":"<p>This code lab will use the Replay service to validate and test the rule prior to pushing it to production.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#setup-and-requirements","title":"Setup and Requirements","text":"<p>This code lab assumes you have access to a Linux host (MacOS terminal with <code>brew</code>). This code lab also assumes you have \"owner\" access to an LC Organization. If you don't have one already, create one, this code lab is compatible with the free tier that comes with all organizations.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#install-cli","title":"Install CLI","text":"<p>Interacting with LC can always be done via the web app but day to day operations and automation can be done via the Command Line Interface (CLI). This will make following this code lab easier.</p> <p>Install the CLI: <code>pip install limacharlie --user</code>. If you don't have <code>pip</code> installed, install it, the exact instructions will depend on your Linux distribution.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#create-rest-api-key","title":"Create REST API Key","text":"<p>We need to create an API key we can use in the CLI to authenticate with LC. To do so, go to the REST API section of the web app.</p> <ol> <li>In the REST API section, click the \"+\" button in the top right of the page.</li> <li>Give your key a name.</li> <li>For simplicity, click the \"Select All\" button to enable all permissions. Obviously this would not be a recommended in a production environment,</li> <li>Click the copy-to-clipboard button for the new key and take note of it (pasting it in a temporary text note for example).</li> <li>Back on the REST API page, copy the \"Organization ID\" at the top of the page and keep note of it like the API key in the previous step.</li> </ol> <p>The Organization ID (OID) identifies uniquely your organization while the API key grants specific permissions to this organization.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#login-to-the-cli","title":"Login to the CLI","text":"<p>Back in your terminal, log in with your credentials: <code>limacharlie login</code>.</p> <ol> <li>When asked for the Organization ID, paste your OID from the previous step.</li> <li>When asked for a name for this access, you can leave it blank to set the default credentials.</li> <li>When asked for the secret API key, enter the key you got from the previous step.</li> </ol> <p>You're done! If you issue a <code>limacharlie dr list</code> you should not get any errors.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#draft-rule","title":"Draft Rule","text":"<p>To draft our rule, open your preferred text editor and save the rule to a file, we'll call it <code>T1196.rule</code>. The format of a rule is YAML, if you are unfamiliar with it, there is benefit to spending a few minutes getting familiar. It won't take long as it is not overly complex.</p> <p>For our rules based on the T1196 technique, we need to apply the following constraints:</p> <ol> <li>It only applies to Windows.</li> <li>The event is a module (DLL for example on Windows) loading.</li> <li>The module loading ends with <code>.cpl</code> (control panel extension).</li> <li>The module is loading from outside of the <code>C:\\windows\\</code> directory.</li> </ol> <p>LC supports a lot of different event types, this means that the first thing we should strive to do to try to make the rule fail as quickly as possible is to filter all events we don't care about.</p> <p>In this case, we only care about CODE_IDENTITY events. We also know that our rule will use more than one criteria, and those criteria will be AND-ed together because we only want to match when they all match.</p> <pre><code>op: and\nevent: CODE_IDENTITY\nrules:\n  -\n</code></pre> <p>The above sets up the criteria #2 preceding it, with the AND-ing that will follow. Since the AND is at the top of our rule, and it has an <code>event:</code> clause, it will ensure that any event processed by this rule but is NOT a <code>CODE_IDENTITY</code> event will be skipped over right away.</p> <p>Next, we should look at the other criteria, and add them to the <code>rules:</code> list, which are all the sub-nodes that will be AND-ed together.</p> <p>Criteria #1 was to limit to Windows, that's easy:</p> <pre><code>op: and\nevent: CODE_IDENTITY\nrules:\n  - op: is windows\n  -\n</code></pre> <p>Next up is criteria #3 and #4. Both of those can be determined using the <code>FILE_PATH</code> component of the <code>CODE_IDENTITY</code> event. If you are unure what those events look like, the best way to get a positive confirmation of the structure is simply to open the Historic View, start a new process on that specific host and look for the relevant event. If we were to do this on a Windows host, we'd get an example like this one:</p> <pre><code>{\n    \"routing\": {\n        \"parent\": \"...\",\n        \"this\": \"...\",\n        \"hostname\": \"WIN-...\",\n        \"event_type\": \"CODE_IDENTITY\",\n        \"event_time\": 1567438408423,\n        \"ext_ip\": \"XXX.176.XX.148\",\n        \"event_id\": \"11111111-1111-1111-1111-111111111111\",\n        \"oid\": \"11111111-1111-1111-1111-111111111111\",\n        \"plat\": 268435456,\n        \"iid\": \"11111111-1111-1111-1111-111111111111\",\n        \"sid\": \"11111111-1111-1111-1111-111111111111\",\n        \"int_ip\": \"172.XX.223.XXX\",\n        \"arch\": 2,\n        \"tags\": [\n            \"...\"\n        ],\n        \"moduleid\": 2\n    },\n    \"ts\": \"2019-09-02 15:33:28\",\n    \"event\": {\n        \"HASH_MD5\": \"7812c2c0a46d1f0a1cf8f2b23cd67341\",\n        \"HASH\": \"d1d59eefe1aeea20d25a848c2c4ee4ffa93becaa3089745253f9131aedc48515\",\n        \"ERROR\": 0,\n        \"FILE_INFO\": \"10.0.17134.1\",\n        \"HASH_SHA1\": \"000067ac70f0e38f46ce7f93923c6f5f06ecef7b\",\n        \"SIGNATURE\": {\n            \"FILE_CERT_IS_VERIFIED_LOCAL\": 1,\n            \"CERT_SUBJECT\": \"C=US, S=Washington, L=Redmond, O=Microsoft Corporation, CN=Microsoft Windows\",\n            \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\setupcln.dll\",\n            \"FILE_IS_SIGNED\": 1,\n            \"CERT_ISSUER\": \"C=US, S=Washington, L=Redmond, O=Microsoft Corporation, CN=Microsoft Windows Production PCA 2011\"\n        },\n        \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\setupcln.dll\"\n    }\n}\n</code></pre> <p>This means what we want is to apply rules to the <code>event/FILE_PATH</code>. First part, #3 is easy, we just want to test for the <code>event/FILE_PATH</code> ends in <code>.cpl</code>, we can do this using the <code>ends with</code> operator.</p> <p>Most operators will use a <code>path</code> and a <code>value</code>. General convention is the <code>path</code> describes how to get to a value we want to compare within the event. So <code>event/FILE_PATH</code> says \"starting in the <code>event</code> then get the <code>FILE_PATH</code>. The <code>value</code> generally represents a value we want to compare to the element found in the <code>path</code>. How it is compared depends on the operator.</p> <pre><code>op: and\nevent: CODE_IDENTITY\nrules:\n  - op: is windows\n  - op: ends with\n    path: event/FILE_PATH\n    value: .cpl\n</code></pre> <p>That was easy, but we're missing a critical component! By default, D&amp;R rules operate in a case sensitive mode. This means that the above node we added will match <code>.cpl</code> but will NOT match <code>.cPl</code>. To fix this, we just add the <code>case sensitive: false</code> statement.</p> <pre><code>op: and\nevent: CODE_IDENTITY\nrules:\n  - op: is windows\n  - op: ends with\n    path: event/FILE_PATH\n    value: .cpl\n    case sensitive: false\n  -\n</code></pre> <p>Finally, we want to make sure the <code>event/FILE_PATH</code> is NOT in the <code>windows</code> directory. To do this, we will use a regular expression with a <code>matches</code> operator. But in this case, we want to EXCLUDE the paths that include the <code>windows</code> directory, so we want to \"invert\" the match. We can do this with the <code>not: true</code> statement.</p> <pre><code>op: and\nevent: CODE_IDENTITY\nrules:\n  - op: is windows\n  - op: ends with\n    path: event/FILE_PATH\n    value: .cpl\n    case sensitive: false\n  - op: matches\n    path: event/FILE_PATH\n    re: ^.\\:\\\\windows\\\\\n    case sensitive: false\n    not: true\n</code></pre> <p>Here we go, we're done drafting our first rule.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#validate-rule","title":"Validate Rule","text":"<p>What we want to do now is validate the rule. If the rule validates, it doesn't mean it's correct, it just means that the structure is correct, the operators we use are known, etc. It's the first pass at detecting possible formatting issues or typos.</p> <p>To validate, we will simply leverage the Replay service. This service can be used to test rules or replay historical events against a rule. In this case however, we just want to start by validating.</p> <p>Up until now we focused on the \"detection\" part of the rule. But a full rule also contains a \"response\" component. So before we proceed, we'll add this structure. For a response, we will use a simple <code>action: report</code>. The <code>report</code> creates a \"detection\" (alert).</p> <pre><code>detect:\n  op: and\n  event: CODE_IDENTITY\n  rules:\n    - op: is windows\n    - op: ends with\n      path: event/FILE_PATH\n      value: .cpl\n      case sensitive: false\n    - op: matches\n      path: event/FILE_PATH\n      re: ^.\\:\\\\windows\\\\\n      case sensitive: false\n      not: true\nrespond:\n  - action: report\n    name: T1196\n</code></pre> <p>Now validate: <code>limacharlie replay --validate --rule-content T1196.rule</code></p> <p>After a few seconds, you should see a response with <code>success: true</code> if the rule validates properly.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#test-rule","title":"Test rule","text":""},{"location":"3-detection-response/tutorials/writing-testing-rules/#test-plan","title":"Test Plan","text":"<p>Now that we know our rule is generally sound, we need to test it against some events.</p> <p>Our test plan will take the following approach:</p> <ol> <li>Test a positive (a <code>.cpl</code> loading outside of <code>windows</code>).</li> <li> <p>Test a negative for the major criteria:</p> </li> <li> <p>Test a non-<code>.cpl</code> loading outside of <code>windows</code> does not match.</p> </li> <li>Test a <code>.cpl</code> loading within <code>windows</code> does not match.</li> <li>Test on historical data.</li> </ol> <p>With this plan, #1 and #2 lend themselves well to unit tests while #3 can be done more holistically by using Replay to run historical events through the rule and evaluate if there are any false positives.</p> <p>This may be excessive for you, or for certain rules which are very simple, we leave that evaluation to you. For the sake of this code lab, we will do a light version to demonstrate how to do tests.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#testing-a-single-event","title":"Testing a Single Event","text":"<p>To test #1 and #2, let's just create some synthetic events. It's always better to use real-world samples, but we'll leave that up to you.</p> <p>Take the event sample we had in the \"Draft Rule\" section and copy it to two new files we will name <code>positive.json</code>, <code>negative-1.json</code> and <code>negative-2.json</code>.</p> <p>Modify the <code>positive.json</code> file by renaming the <code>FILE_PATH</code> at the bottom from <code>\"C:\\\\Windows\\\\System32\\\\setupcln.dll\"</code> to <code>\"C:\\\\temp\\\\System32\\\\setupcln.cpl\"</code> so that the event now describes a <code>.cpl</code> loading in the <code>temp</code> directory, which we should detect.</p> <p>Then modify the <code>negative-1.json</code> file by changing the same <code>.dll</code> to <code>.cpl</code>. This should NOT match because the path is still in the <code>windows</code> directory.</p> <p>Then modify the <code>negative-2.json</code> file by changing the <code>windows</code> directory to <code>temp</code>. This should still NOT match because it's not a <code>.cpl</code>.</p> <p>Now we can run our 3 samples against the rule using Replay,</p> <p><code>limacharlie replay --rule-content T1196.rule --events positive.json</code> should output a result indicating the event matched (by actioning the <code>report</code>) like:</p> <pre><code>{\n  \"num_evals\": 4,\n  \"eval_time\": 0.00020599365234375,\n  \"num_events\": 1,\n  \"responses\": [\n    {\n      \"report\": {\n        \"source\": \"11111111-1111-1111-1111-111111111111.11111111-1111-1111-1111-111111111111.11111111-1111-1111-1111-111111111111.10000000.2\",\n        \"routing\": {\n...\n</code></pre> <p><code>limacharlie replay --rule-content T1196.rule --events negative-1.json</code> should output a result indicating the event did NOT match like:</p> <pre><code>{\n  \"num_evals\": 4,\n  \"eval_time\": 0.00011777877807617188,\n  \"num_events\": 1,\n  \"responses\": [],\n  \"errors\": []\n}\n</code></pre> <p><code>limacharlie replay --rule-content T1196.rule --events negative-2.json</code> be the same as <code>negative-1.json</code>.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#testing-historical-data","title":"Testing Historical Data","text":"<p>The final test is to run the rule against historical data. If you are not using an organization on the free tier, note that the Replay API is billed on usage. In the following step we will run against all historical data from the organization, so if your organization is not on the free tier and it is large, there may be non-trivial costs associated.</p> <p>Running our rule against the last week of data is simple:</p> <p><code>limacharlie replay --rule-content T1196.rule --entire-org --last-seconds 604800</code></p> <p>No matches should look like that:</p> <pre><code>{\n  \"num_evals\": 67354,\n  \"eval_time\": 1107.2150619029999,\n  \"num_events\": 222938,\n  \"responses\": [],\n  \"errors\": []\n}\n</code></pre>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#moving-to-unit-tests","title":"Moving to Unit Tests","text":"<p>Once your rule is done and you've evaluated various events for matches, you can move these to D&amp;R Rules Unit Tests so that the tests are run during rule update.</p>"},{"location":"3-detection-response/tutorials/writing-testing-rules/#publish-rule","title":"Publish Rule","text":"<p>Now is the time to push the new rule to production, the easy part.</p> <p>Simply run <code>limacharlie dr add --rule-name T1196 --rule-file T1196.rule</code> and confirm it is operational by running <code>limacharlie dr list</code>.</p>"},{"location":"4-data-queries/","title":"Query Console","text":"<p>Query and analyze your security telemetry using LimaCharlie Query Language (LCQL).</p>"},{"location":"4-data-queries/#documentation","title":"Documentation","text":"<ul> <li>LCQL Examples - Example queries for common use cases</li> <li>Query Console UI - Using the web-based query interface</li> <li>Query with CLI - Running queries from the command line</li> </ul>"},{"location":"4-data-queries/#see-also","title":"See Also","text":"<ul> <li>LCQL Examples</li> <li>Query Console UI</li> <li>D&amp;R Rules</li> </ul>"},{"location":"4-data-queries/lcql-examples/","title":"LCQL Examples","text":"<p>LimaCharlie Query Language (LCQL) lets you write well-structured queries to search across telemetry within LimaCharlie. The following examples can help you perform targeted searches or hunts across your telemetry, as well as modify them to build your own. Example queries are sorted by source, however can be adjusted for your environment.</p> <p>Got a Unique Query?</p> <p>If you've written a unique query or have one you'd like to share with the community, please join us in the LimaCharlie Community!</p>"},{"location":"4-data-queries/lcql-examples/#general-queries","title":"General Queries","text":"<p>Search all event types across all Windows sytems for a particular string showing up in any field. <code>-24h | plat == windows | * | event/* contains 'psexec'</code></p>"},{"location":"4-data-queries/lcql-examples/#github-telemetry","title":"GitHub Telemetry","text":"<p>GitHub logs can be an excellent source of telemetry to identify potential repository or account abuse or misuse. When ingested properly, GitHub log data can be observed via <code>plat == github</code>.</p>"},{"location":"4-data-queries/lcql-examples/#github-protected-branch-override","title":"GitHub Protected Branch Override","text":"<p>Show me all the GitHub branch protection override (force pushing to repo without all approvals) in the past 12h that came from a user outside the United States, with the repo, user and number of infractions.</p> <p><code>-12h | plat == github | protected_branch.policy_override | event/public_repo is false and event/actor_location/country_code is not \"us\" | event/repo as repo event/actor as actor COUNT(event) as count GROUP BY(repo actor)</code></p> <p>which could result in:</p> actor count repo mXXXXXXa 11 acmeCorpCodeRep/customers aXXXXXXb 11 acmeCorpCodeRep/analysis cXXXXXXd 3 acmeCorpCodeRep/devops"},{"location":"4-data-queries/lcql-examples/#network-telemetry","title":"Network Telemetry","text":"<p>Network details recorded on endpoints, such as new connections or DNS requests, allow for combined insight. We can also query this data for aggregate details, and display data in an easily-consumed manner.</p>"},{"location":"4-data-queries/lcql-examples/#domain-count","title":"Domain Count","text":"<p>Show me all domains resolved by Windows hosts that contain \"google\" in the last 10 minutes and the number of times each was resolved.</p> <p><code>-10m | plat == windows | DNS_REQUEST | event/DOMAIN_NAME contains 'google' | event/DOMAIN_NAME as domain COUNT(event) as count GROUP BY(domain)</code></p> <p>which could result in:</p> count domain 14 logging.googleapis.com 36 logging-alv.googleapis.com"},{"location":"4-data-queries/lcql-examples/#domain-prevalence","title":"Domain Prevalence","text":"<p>Show me all domains resolved by Windows hosts that contain \"google\" in the last 10 minutes and the number of unique Sensors that have resolved them.</p> <p><code>-10m | plat == windows | DNS_REQUEST | event/DOMAIN_NAME contains 'google' | event/DOMAIN_NAME as domain COUNT_UNIQUE(routing/sid) as count GROUP BY(domain)</code></p> <p>which could result in:</p> count domain 4 logging.googleapis.com 3 logging-alv.googleapis.com"},{"location":"4-data-queries/lcql-examples/#process-activity","title":"Process Activity","text":""},{"location":"4-data-queries/lcql-examples/#unsigned-binaries","title":"Unsigned Binaries","text":"<p>Grouped and counted. <code>-24h | plat == windows | CODE_IDENTITY | event/SIGNATURE/FILE_IS_SIGNED != 1 | event/FILE_PATH as Path event/HASH as Hash event/ORIGINAL_FILE_NAME as OriginalFileName COUNT_UNIQUE(Hash) as Count GROUP BY(Path Hash OriginalFileName)</code></p>"},{"location":"4-data-queries/lcql-examples/#process-command-line-args","title":"Process Command Line Args","text":"<p><code>-1h | plat == windows | NEW_PROCESS EXISTING_PROCESS | event/COMMAND_LINE contains \"psexec\" | event/FILE_PATH as path event/COMMAND_LINE as cli routing/hostname as host</code></p>"},{"location":"4-data-queries/lcql-examples/#stack-children-by-parent","title":"Stack Children by Parent","text":"<p><code>-12h | plat == windows | NEW_PROCESS | event/PARENT/FILE_PATH contains \"cmd.exe\" | event/PARENT/FILE_PATH as parent event/FILE_PATH as child COUNT_UNIQUE(event) as count GROUP BY(parent child)</code></p>"},{"location":"4-data-queries/lcql-examples/#windows-event-log-wel","title":"Windows Event Log (WEL)","text":"<p>When ingested with EDR telemetry, or as a separate Adapter, <code>WEL</code> type events are easily searchable via LimaCharlie. Sample queries are organized alphabetically, with threat/technique details provided where applicable.</p>"},{"location":"4-data-queries/lcql-examples/#comspec-in-service-path","title":"%COMSPEC% in Service Path","text":"<p><code>-12h | plat == windows | WEL | event/EVENT/System/EventID == \"7045\" and event/EVENT/EventData/ImagePath contains \"COMSPEC\"</code></p>"},{"location":"4-data-queries/lcql-examples/#overpass-the-hash","title":"Overpass-the-Hash","text":"<p><code>-12h | plat == windows | WEL | event/EVENT/System/EventID == \"4624\" and event/EVENT/EventData/LogonType == \"9\" and event/EVENT/EventData/AuthenticationPackageName == \"Negotiate\" and event/EVENT/EventData/LogonProcess == \"seclogo\"</code></p>"},{"location":"4-data-queries/lcql-examples/#taskkill-from-a-non-system-account","title":"Taskkill from a Non-System Account","text":"<p>Requires process auditing to be enabled</p> <p><code>-12h | plat == windows | WEL | event/EVENT/System/EventID == \"4688\" and event/EVENT/EventData/NewProcessName contains \"taskkill\" and event/EVENT/EventData/SubjectUserName not ends with \"!\"</code></p>"},{"location":"4-data-queries/lcql-examples/#logons-by-specific-logontype","title":"Logons by Specific LogonType","text":"<p><code>-24h | plat == windows | WEL | event/EVENT/System/EventID == \"4624\" AND event/EVENT/EventData/LogonType == \"10\"</code></p>"},{"location":"4-data-queries/lcql-examples/#stackcount-all-logontypes-by-user","title":"Stack/Count All LogonTypes by User","text":"<p><code>-24h | plat == windows | WEL | event/EVENT/System/EventID == \"4624\" | event/EVENT/EventData/LogonType AS LogonType event/EVENT/EventData/TargetUserName as UserName COUNT_UNIQUE(event) as Count GROUP BY(UserName LogonType)</code></p>"},{"location":"4-data-queries/lcql-examples/#failed-logons","title":"Failed Logons","text":"<p><code>-1h | plat==windows | WEL | event/EVENT/System/EventID == \"4625\" | event/EVENT/EventData/IpAddress as SrcIP event/EVENT/EventData/LogonType as LogonType event/EVENT/EventData/TargetUserName as Username event/EVENT/EventData/WorkstationName as SrcHostname</code></p>"},{"location":"4-data-queries/lcql-examples/#see-also","title":"See Also","text":"<ul> <li>LCQL Overview</li> <li>Query Console</li> <li>EDR Events</li> </ul>"},{"location":"4-data-queries/query-cli/","title":"Query with CLI","text":"<p>The command line interface found in the Python CLI/SDK can be invoked like <code>limacharlie query</code> once installed (<code>pip install limacharlie</code>).</p>"},{"location":"4-data-queries/query-cli/#context","title":"Context","text":"<p>To streamline day to day usage, the first 3 components of the query are set seperatly and remain between queries.  These 3 component can be set through the following commands:</p> <ol> <li><code>set_time</code> to set the timeframe of the query, like <code>set_time -3h</code> based on the ParseDuration() strings.</li> <li><code>set_sensors</code> to set the sensors who's data is queried, like <code>set_sensors plat == windows</code>, based on the sensor selector grammar.</li> <li><code>set_events</code> to set the events that should be queried, space separated like <code>NEW_PROCESS DNS_REQUEST</code>. This command supports tab completion.</li> </ol> <p>Once set, you can specify the last component(s): the Filter, and the Projection.</p> <p>Several other commands are avaible to make your job easier:</p> <ul> <li><code>set_limit_event</code> to set a maximum number of events to scan during the query.</li> <li><code>set_output</code> to mirror the queries and their results to a file.</li> <li><code>set_format</code> to display results either in <code>json</code> or <code>table</code>.</li> <li><code>stats</code> to display the total costs incurred from the queries during this session.</li> </ul>"},{"location":"4-data-queries/query-cli/#querying","title":"Querying","text":""},{"location":"4-data-queries/query-cli/#paged-mode","title":"Paged Mode","text":"<p>The main method of running a query as described above (in paged mode) is to use the <code>q</code> (for \"query\") command.</p> <p>Paged mode means that an initial subset of the results will be returned (usually in the 1000s of elements) and if you want to fetch more of the results, you can use the <code>n</code> (for \"next\") command to fetch the next page.</p> <p>Some queries cannot be done in paged mode, like queries that do aggregation or queries that use a stateful filter (like <code>with child</code>). In those cases, all results over the entire timeline are computed.</p> <p>For example: <code>q event/DOMAIN_NAME contains 'google' | event/DOMAIN_NAME as domain COUNT_UNIQUE(routing/sid) as count GROUP BY(domain)</code></p> <p>This command supports tab completion for elements of the query, like <code>event/DO</code> + \"tab\" will suggest <code>event/DOMAIN_NAME</code> or other relevant elements that exist as part of the schema.</p>"},{"location":"4-data-queries/query-cli/#non-paged-mode","title":"Non Paged Mode","text":"<p>You can also force a full query over all the data (no paging) by using the \"query all\" (<code>qa</code>) command like:</p> <p><code>qa event/DOMAIN_NAME contains 'google' | event/DOMAIN_NAME as domain COUNT_UNIQUE(routing/sid) as count GROUP BY(domain)</code></p>"},{"location":"4-data-queries/query-cli/#dry-run","title":"Dry Run","text":"<p>To simulate running a query, use the <code>dryrun</code> command. This will query the LimaCharlie API and return to you an aproximate worst case cost for the query (assuming you fetch all pages over its entire time range).</p> <p>For example: <code>dryrun event/COMMAND_LINE contains \"powershell\" and event/FILE_PATH not contains \"powershell\"</code></p>"},{"location":"4-data-queries/query-console-ui/","title":"Query Console UI","text":"<p>To view and operate the Query Console, the following permissions are required:</p> <ul> <li><code>insight.evt.get</code> for search</li> <li><code>org.get</code> for schema service access</li> <li><code>query.set</code> for saving queries</li> <li><code>query.get</code> for reading a list of queries (if you don't have this set you will see an error saying you need <code>query.get.mtd</code>, but this is the permission you need)</li> <li><code>query.del</code> for editing or deleting queries (editing is creating a new one and removing the old one)</li> </ul>"},{"location":"4-data-queries/query-console-ui/#ui-element-overview","title":"UI Element Overview","text":"<ol> <li>Source: Select Events (everything that had been injected from endpoints and XDR sources, default), Detections, or Platform Audit events as the data source for the search.</li> <li> <p>Query editor: Enter a LimaCharlie Query Language (LCQL) query to include:</p> </li> <li> <p>Sensor Selector - precisely define the sensors that produced the desired events.</p> </li> <li>Event Type - filter results to only return specific types of events.</li> <li>Filter - the actual query filter using individual fields and operations on top of them.</li> <li>Projections (optional) - control output columns, sort results via <code>ORDER BY</code> and/or aggregate the data with <code>GROUP BY</code> , <code>COUNT</code>, <code>COUNT_UNIQUE</code>  and more. See LCQL reference and Examples for details.</li> <li>Time period: Set the searchable time period using three options: last [time period],  around [time frame], and absolute \"from start\u2192to finish\".</li> </ol> <p></p> <ul> <li> <p>Enter a time <code>16:00</code>, or day and time <code>2025-01-16 08:52:54</code>, using most common time formats.  For example:</p> <ul> <li>From <code>33m</code> to <code>now</code> - last 33 minutes</li> <li>Around <code>2025-01-16 08:52:54</code> +- <code>15 minutes</code> - 15 minutes before and after the specified time stamp</li> <li>From <code>10am</code> to <code>1:30pm</code></li> </ul> <p>Note: All times are shown according to the timezone selected by the user in User Settings. 4. Available Fields: Managed data exploration</p> </li> <li> <p>Schema fields - a list of all the fields associated with ingested events.</p> </li> <li>Event types - event types present in the returned portion of the query. As more data is churned to complete the specified time frame more event types may appear.</li> <li> <p>Query fields - event fields present in the portion of the result already fetched by the query,  with a count of total occurrences. Clicking on the event field opens a details panel. From here you can add a term to the query.</p> <p>    4. Table columns: control the columns displayed in Table View.</p> </li> </ul> <p>Note: While the schema fields are always available, the event types and query fields are only shown for portion of the time frame searched so far.  As more data is churned in the background (to complete your selected time frame), more event types and fields may appear. 5. Query status: Shows the state of your query in real time, highlighting any existing syntax errors or providing a cost estimate if the query is properly formed.</p> <p>As the query runs the status displays progress, query status, and a running total of the cost accrued.</p> <p>Query cost estimation: Queries are charged by the amount of data churned, measured and billed per one million events evaluated. This estimation shows the \"at most\" cost of a query for the selected time range. Only retrieved data is chargeable.</p> <p>Performance tuning: The better tuned the query, the faster the search and lower the cost. Using Sensor Selector and Event Type to precisely target the desired telemetry will increase search speeds and lower costs. 6. Histogram:</p> <p>When a search is run, a histogram appears below the query field showing the distribution of events over time. The portion with a vertical bar chart represents results  that have been retrieved so far. The non-bar chart portion shows the total number of events in the selected time frame. The histogram shows the progress of the search through the time frame.  As you paginate through the search, more events are evaluated, and more bars appear to signify the progress through the time frame. 7. Search results: displays results in two views, timeline and table. Timeline view shows matching events with the most recent on top.  Table view provides a way to sort results into desired columns. Find the desired field in Query Fields and use the <code>pin</code> icon to add it as a column.</p> <ol> <li>A Tab Columns section appears in the Fields sidebar when table view is selected. Columns can be viewed or removed here.</li> <li>Event Details allows you to click on an event and perform applicable event actions like Build a D&amp;R Rule.</li> <li>Download all the events you've retrieved in a .ndjson format. The automatic download of the entire time range is coming soon.</li> </ol> <p> 8. Saving Queries and Query Library. A query can be saved in your private user library or shared via an org library. Use the library to browse queries and load the desired one to the query editor.</p>"},{"location":"4-data-queries/query-console-ui/#whats-next","title":"What's Next","text":"<ul> <li>LimaCharlie Query Language</li> </ul>"},{"location":"4-data-queries/template-strings/","title":"Template Strings and Transforms","text":"<p>Many areas of LimaCharlie support template strings and transforms.</p> <p>A template string allows you to customize the value of a configuration based on the context. For example to adjust the Detection Name a D&amp;R rule to include a value from the detection itself. Transforms can also be used to select, modify, or remove fields upon data ingestion from an Adapter.</p> <p>A transform allows you to change the shape of JSON data in flight to suit better your usage. This can mean moving, renaming, removing and adding fields in JSON. For example, it can allow you to create an Output that works with <code>DNS_REQUEST</code> events, but outputs only specific fields from the event.</p>"},{"location":"4-data-queries/template-strings/#template-strings","title":"Template Strings","text":"<p>Template strings in LimaCharlie use the format defined by \"text templates\" found here. A useful guide provided by Hashicorp is also available here.</p> <p>The most basic example for a D&amp;R rule customizing the detection name looks like this:</p> <pre><code>- action: report\n  name: Evil executable on {{ .routing.hostname }}\n</code></pre> <p>Template strings also support some LimaCharlie-specific functions:</p> <ul> <li><code>token</code>: applies an MD5 hashing function on the value provided.</li> <li><code>anon</code>: applies an MD5 hashing function on a secret seed value, plus the value provided.</li> <li><code>json</code>: marshals the input into a JSON string representation.</li> <li><code>prettyjson</code>: same as <code>json</code> but with indentation and newlines.</li> <li><code>parsetime</code>: parse a time format to another.</li> <li><code>split</code>: split a string based on a seperator param.</li> <li><code>join</code>: join a list into a string joined by another string.</li> <li><code>replace</code>: replace all string into the other.</li> <li><code>base</code>: return the file name in a file path.</li> <li><code>dir</code>: return the base directory path from a file path.</li> </ul> <p>The <code>token</code> and <code>anon</code> functions can be used to partially anonymize data anywhere a template string is supported, for example:</p> <pre><code>- action: report\n  name: 'User {{token .event.USER_NAME }} accessed a website against policy.'\n</code></pre> <p>Other examples:</p> <ul> <li><code>Full Data: {{prettyjson .event.OBJECT }}</code></li> <li><code>Original time:{{parsetime \"{\\\"from\\\":\\\"2006/01/02 15:04:05\\\", \\\"to\\\":\\\"2006-01-02 15:04:05 MST\\\"}\" .event.timestamp}}</code></li> <li><code>Packages: {{join \",\" .event.PACKAGES}}</code></li> </ul>"},{"location":"4-data-queries/template-strings/#template-strings-and-adapter-transforms","title":"Template Strings and Adapter Transforms","text":"<p>Template strings can also be used with in conjunction the <code>client_options.mapping.transform</code> option in Adapter configuration. These allow you to modify data prior to ingestion, having control over what fields get ingested and resulting field names.</p> <p>The following options are available in Adapter configurations:</p> <ul> <li><code>+</code> to add a field</li> <li><code>-</code> to remove a field</li> </ul> <p>Both support template strings, meaning you can add/remove values from the JSON data to replace/supplement other fields.</p> <p>For example, if we had the following data:</p> <pre><code>{ \"event\":\n  \"webster\" : {\n     \"a\" : 1,\n     \"b\" : 2,\n     \"d\" : 3\n    }\n  }\n}\n</code></pre> <p>And we wanted to rename the <code>d</code> value to <code>c</code> on ingestion, remove the d value, and add a field called <code>hostname</code>, we could use the following configuration:</p> <pre><code>...\n   client_options:\n     mapping:\n       transform:\n         +c : '{{ .webster.d }}',\n         -d: nil,\n         +hostname : '{{ \"my-computer\" }}',\n</code></pre> <p>The resulting event to be ingested would be:</p> <pre><code>{ \"event\":\n  \"webster\" : {\n     \"a\" : 1,\n     \"b\" : 2,\n     \"c\" : 3\n    },\n    \"hostname\" : \"my-computer\"\n  }\n}\n</code></pre>"},{"location":"4-data-queries/template-strings/#transforms","title":"Transforms","text":"<p>With Transforms, you specify a JSON object that describes the transformation.</p> <p>This object is in the shape of the final JSON you would like to transform to.</p> <p>Key names are the literal key names in the output. Values support one of 3 types:</p> <ol> <li>Template Strings, as described above. In this case, the template string will be generated and placed at the same place as the key in the transform object.</li> <li>A <code>gjson</code> selector. The selector syntaxt is defined here. It makes it possible to select subsets of input object and map it within the resulting object as defined by the transform.</li> <li>Other JSON objects which will be present in the output.</li> </ol> <p>Let's look at an example, let's say this is the Input to our transform:</p> <pre><code>{\n    \"event\": {\n        \"EVENT\": {\n            \"EventData\": {\n                \"AuthenticationPackageName\": \"NTLM\",\n                \"FailureReason\":             \"%%2313\",\n                \"IpAddress\":                 \"34.64.101.177\",\n                \"IpPort\":                    \"0\",\n                \"KeyLength\":                 \"0\",\n                \"LmPackageName\":             \"-\",\n                \"LogonProcessName\":          \"NtLmSsp\",\n                \"LogonType\":                 \"3\",\n                \"ProcessId\":                 \"0x0\",\n                \"ProcessName\":               \"-\",\n                \"Status\":                    \"0xc000006d\",\n                \"SubStatus\":                 \"0xc0000064\",\n                \"SubjectDomainName\":         \"-\",\n                \"SubjectLogonId\":            \"0x0\",\n                \"SubjectUserName\":           \"-\",\n                \"SubjectUserSid\":            \"S-1-0-0\",\n                \"TargetDomainName\":          \"\",\n                \"TargetUserName\":            \"ADMINISTRADOR\",\n                \"TargetUserSid\":             \"S-1-0-0\",\n                \"TransmittedServices\":       \"-\",\n                \"WorkstationName\":           \"-\",\n            },\n            \"System\": {\n                \"Channel\":  \"Security\",\n                \"Computer\": \"demo-win-2016\",\n                \"Correlation\": {\n                    \"ActivityID\": \"{F207C050-075F-0001-AFE1-ED1F3897D801}\",\n                },\n                \"EventID\":       \"4625\",\n                \"EventRecordID\": \"2832700\",\n                \"Execution\": {\n                    \"ProcessID\": \"572\",\n                    \"ThreadID\":  \"2352\",\n                },\n                \"Keywords\": \"0x8010000000000000\",\n                \"Level\":    \"0\",\n                \"Opcode\":   \"0\",\n                \"Provider\": {\n                    \"Guid\": \"{54849625-5478-4994-A5BA-3E3B0328C30D}\",\n                    \"Name\": \"Microsoft-Windows-Security-Auditing\",\n                },\n                \"Security\": \"\",\n                \"Task\":     \"12544\",\n                \"TimeCreated\": {\n                    \"SystemTime\": \"2022-07-15T22:48:24.996361600Z\",\n                },\n                \"Version\": \"0\",\n            },\n        },\n    },\n    \"routing\": {\n        \"arch\":       2,\n        \"did\":        \"b97e9d00-ca17-4afe-a9cf-27c3468d5901\",\n        \"event_id\":   \"f24679e5-5484-4ca1-bee2-bfa09a5ba3db\",\n        \"event_time\": 1657925305984,\n        \"event_type\": \"WEL\",\n        \"ext_ip\":     \"35.184.178.65\",\n        \"hostname\":   \"demo-win-2016.c.lc-demo-infra.internal\",\n        \"iid\":        \"7d23bee6-aaaa-aaaa-aaaa-c8e8cca132a1\",\n        \"int_ip\":     \"10.128.0.2\",\n        \"moduleid\":   2,\n        \"oid\":        \"8cbe27f4-aaaa-aaaa-aaaa-138cd51389cd\",\n        \"plat\":       268435456,\n        \"sid\":        \"bb4b30af-ff11-4ff4-836f-f014ada33345\",\n        \"tags\": [\n            \"edr\",\n            \"lc:stable\",\n        ],\n        \"this\": \"c5e16360c71baf3492f2dcd962d1eeb9\",\n    },\n    \"ts\": \"2022-07-15 22:48:25\",\n}\n</code></pre> <p>And this is our Transform definition:</p> <pre><code>{\n    \"message\": \"Interesting event from {{ .routing.hostname }}\",  // a format string\n    \"from\":    \"{{ \\\"limacharlie\\\" }}\",                           // a format string with only a literal value\n    \"dat\": {                                                      // define a sub-object in the output\n        \"raw\": \"event.EVENT.EventData\"                            // a \"raw\" key where we map a specific object from the input\n    },\n    \"anon_ip\": \"{{anon .routing.int_ip }}\",                       // an anonymized version of the internal IP\n    \"ts\":   \"routing.event_time\",                                 // map a specific simple value\n    \"nope\": \"does.not.exist\"                                      // map a value that is not present\n}\n</code></pre> <p>Then the resulting Output would be:</p> <pre><code>{\n    \"dat\": {\n        \"raw\": {\n            \"AuthenticationPackageName\": \"NTLM\",\n            \"FailureReason\": \"%%2313\",\n            \"IpAddress\": \"34.64.101.177\",\n            \"IpPort\": \"0\",\n            \"KeyLength\": \"0\",\n            \"LmPackageName\": \"-\",\n            \"LogonProcessName\": \"NtLmSsp\",\n            \"LogonType\": \"3\",\n            \"ProcessId\": \"0x0\",\n            \"ProcessName\": \"-\",\n            \"Status\": \"0xc000006d\",\n            \"SubStatus\": \"0xc0000064\",\n            \"SubjectDomainName\": \"-\",\n            \"SubjectLogonId\": \"0x0\",\n            \"SubjectUserName\": \"-\",\n            \"SubjectUserSid\": \"S-1-0-0\",\n            \"TargetDomainName\": \"\",\n            \"TargetUserName\": \"ADMINISTRADOR\",\n            \"TargetUserSid\": \"S-1-0-0\",\n            \"TransmittedServices\": \"-\",\n            \"WorkstationName\": \"-\"\n        }\n    },\n    \"from\": \"limacharlie\",\n    \"message\": \"Interesting event from demo-win-2016.c.lc-demo-infra.internal\",\n    \"nope\": null,\n    \"ts\": 1657925305984,\n    \"anon_ip\": \"e80b5017098950fc58aad83c8c14978e\"\n}\n</code></pre>"},{"location":"4-data-queries/template-strings/#transforming-output-data","title":"Transforming Output Data","text":"<p>When passing events to an output, you have the option to transform the original event in multiple ways. When creating an output, Custom Transforms are applied in the CUSTOM TRANSFORM area of the screenshot below. In this example we are transforming a detection event to pass via a custom webhook to a web application.</p> <p></p>"},{"location":"4-data-queries/template-strings/#examples","title":"Examples","text":""},{"location":"4-data-queries/template-strings/#extracting-fields-from-telemetry","title":"Extracting Fields from Telemetry","text":"<p>Let's say you have the following 4625 failed logon and you want to send similar events to an output, but only certain fields.</p> <pre><code>{\n  \"event\": {\n    \"EVENT\": {\n      \"EventData\": {\n        \"AuthenticationPackageName\": \"NTLM\",\n        \"FailureReason\": \"%%2313\",\n        \"IpAddress\": \"142.99.21.14\",\n        # &lt;extra fields removed&gt;\n        \"TargetUserName\": \"administrator\",\n        \"WorkstationName\": \"D-483\"\n      },\n      \"System\": {\n        \"Channel\": \"Security\",\n        \"Computer\": \"demo-win-2016\",\n        # &lt;extra fields removed&gt;\n        \"EventID\": \"4625\",\n        \"EventRecordID\": \"22690646\",\n        # &lt;extra fields removed&gt;\n        \"TimeCreated\": {\n          \"SystemTime\": \"2024-01-23T17:30:07.345840000Z\"\n        },\n        \"Version\": \"0\",\n        \"_event_id\": \"4625\"\n      }\n    }\n  },\n  \"routing\": {\n    # &lt;extra fields removed&gt;\n    \"event_type\": \"WEL\",\n    \"hostname\": \"win-2016.corp.internal\",\n     # &lt;extra fields removed&gt;\n    \"tags\": [\n      \"windows\"\n    ],\n    \"this\": \"8873fb9fcb26e2c0d4299ce765aff77d\"\n  },\n  \"ts\": \"2024-01-23 17:29:33\"\n}\n</code></pre> <p>The following Output Transform would extract only the <code>IpAddress</code>, <code>TargetUserName</code>, <code>EventID</code>, and <code>SystemTime</code> the event was created. Notice, the newly mapped field names can be whatever you want.</p> <pre><code>{\n    \"Source IP\": \"event.EVENT.EventData.IpAddress\",\n    \"Username\": \"event.EVENT.EventData.TargetUserName\",\n    \"Event ID\": \"event.EVENT.System.EventID\",\n    \"Happened at\": \"event.EVENT.System.TimeCreated.SystemTime\"\n}\n</code></pre> <p>The following example outputs text and specified fields using Template Strings.</p> <pre><code>{\n  \"text\": \"Failed logon by {{ .event.EVENT.EventData.TargetUserName }} on {{ .routing.hostname }}\"\n}\n</code></pre> <p>The above example would generate the following output using the provided sample WEL.</p> <pre><code>{\n  \"text\": \"Failed logon by administrator on win-2016.corp.internal\"\n}\n</code></pre>"},{"location":"4-data-queries/template-strings/#output-as-string-passthrough","title":"Output as String / Passthrough","text":"<p>The <code>custom_transform</code> in outputs can also be used to output pure text (non-JSON) from LimaCharlie. This is useful if, for example, you are ingesting syslog data, and want to forward this syslog data as-is to something else.</p> <p>This is accomplished by specifying a Template String in the <code>custom_transform</code> field instead of a Transform. In those cases, when LimaCharlie determines the <code>custom_transform</code> string is not a valid Transform, it will interpret it as a Template String like:</p> <pre><code>{\n    \"custom_transform\": \"{{ .event.text }}\"\n}\n</code></pre> <p>or</p> <pre><code>{\n    \"custom_transform\": \"some text {{json .event.some_field }}\"\n}\n</code></pre>"},{"location":"4-data-queries/template-strings/#custom-modifiers","title":"Custom Modifiers","text":"<p>Beyond the built-in modifiers for <code>gjson</code> (as seen in their playground, LimaCharlie also implements several new modifiers:</p> <ul> <li><code>parsejson</code>: this modifier takes no arguments, it takes in as input a string that represents a JSON object and outputs the decoded JSON object.</li> <li><code>extract</code>: this modifier takes a single argument, <code>re</code> which is a regular expression that uses \"named capture groups\" (as defined in the re2 documentation). The group names become the keys of the output JSON object with the matching values.</li> <li><code>parsetime</code>: this modifier takes two arguments, <code>from</code> and <code>to</code>. It will convert an input string from a given time format (as defined in the Go <code>time</code> library format here) and outputs the resulting time in the <code>to</code> format. Beyond the time constants from the previous link, LimaCharlie also supports a <code>from</code> format of:</li> <li><code>epoch_s</code>: a second based epoch timestamp</li> <li><code>epoch_ms</code>: a millisecond based epoch timestamp</li> </ul> <p>For example: The transform:</p> <pre><code>{\n  \"new_ts\": \"ts|@parsetime:{\\\"from\\\":\\\"2006-01-02 15:04:05\\\", \\\"to\\\":\\\"Mon, 02 Jan 2006 15:04:05 MST\\\"}\",\n  \"user\": \"origin|@extract:{\\\"re\\\":\\\".*@(?P&lt;domain&gt;.+)\\\"}\",\n  \"ctx\": \"event.EVENT.exec_context|@parsejson\"\n}\n</code></pre> <p>applied to:</p> <pre><code>{\n  \"ts\": \"2023-05-10 22:35:48\",\n  \"origin\": \"someuser@gmail.com\",\n  \"event\": {\n    \"EVENT\": {\n      \"exec_context\": \"{\\\"some\\\": \\\"embeded value\\\"}\"\n    }\n  }\n}\n</code></pre> <p>would result in:</p> <pre><code>{\n  \"new_ts\": \"Wed, 10 May 2023 22:35:48 UTC\",\n  \"user\": {\n    \"domain\": \"gmail.com\\\"\"\n  },\n  \"ctx\": {\n    \"some\": \"embeded value\"\n  }\n}\n</code></pre>"},{"location":"4-data-queries/template-transforms/","title":"Template Strings and Transforms","text":"<p>Many areas of LimaCharlie support template strings and transforms.</p> <p>A template string allows you to customize the value of a configuration based on the context. For example to adjust the Detection Name a D&amp;R rule to include a value from the detection itself. Transforms can also be used to select, modify, or remove fields upon data ingestion from an Adapter.</p> <p>A transform allows you to change the shape of JSON data in flight to suit better your usage. This can mean moving, renaming, removing and adding fields in JSON. For example, it can allow you to create an Output that works with <code>DNS_REQUEST</code> events, but outputs only specific fields from the event.</p>"},{"location":"4-data-queries/template-transforms/#template-strings","title":"Template Strings","text":"<p>Template strings in LimaCharlie use the format defined by \"text templates\" found here. A useful guide provided by Hashicorp is also available here.</p> <p>The most basic example for a D&amp;R rule customizing the detection name looks like this:</p> <pre><code>- action: report\n  name: Evil executable on {{ .routing.hostname }}\n</code></pre> <p>Template strings also support some LimaCharlie-specific functions:</p> <ul> <li><code>token</code>: applies an MD5 hashing function on the value provided.</li> <li><code>anon</code>: applies an MD5 hashing function on a secret seed value, plus the value provided.</li> <li><code>json</code>: marshals the input into a JSON string representation.</li> <li><code>prettyjson</code>: same as <code>json</code> but with indentation and newlines.</li> <li><code>parsetime</code>: parse a time format to another.</li> <li><code>split</code>: split a string based on a seperator param.</li> <li><code>join</code>: join a list into a string joined by another string.</li> <li><code>replace</code>: replace all string into the other.</li> <li><code>base</code>: return the file name in a file path.</li> <li><code>dir</code>: return the base directory path from a file path.</li> </ul> <p>The <code>token</code> and <code>anon</code> functions can be used to partially anonymize data anywhere a template string is supported, for example:</p> <pre><code>- action: report\n  name: 'User {{token .event.USER_NAME }} accessed a website against policy.'\n</code></pre> <p>Other examples:</p> <ul> <li><code>Full Data: {{prettyjson .event.OBJECT }}</code></li> <li><code>Original time:{{parsetime \"{\\\"from\\\":\\\"2006/01/02 15:04:05\\\", \\\"to\\\":\\\"2006-01-02 15:04:05 MST\\\"}\" .event.timestamp}}</code></li> <li><code>Packages: {{join \",\" .event.PACKAGES}}</code></li> </ul>"},{"location":"4-data-queries/template-transforms/#template-strings-and-adapter-transforms","title":"Template Strings and Adapter Transforms","text":"<p>Template strings can also be used with in conjunction the <code>client_options.mapping.transform</code> option in Adapter configuration. These allow you to modify data prior to ingestion, having control over what fields get ingested and resulting field names.</p> <p>The following options are available in Adapter configurations:</p> <ul> <li><code>+</code> to add a field</li> <li><code>-</code> to remove a field</li> </ul> <p>Both support template strings, meaning you can add/remove values from the JSON data to replace/supplement other fields.</p> <p>For example, if we had the following data:</p> <pre><code>{ \"event\":\n  \"webster\" : {\n     \"a\" : 1,\n     \"b\" : 2,\n     \"d\" : 3\n    }\n  }\n}\n</code></pre> <p>And we wanted to rename the <code>d</code> value to <code>c</code> on ingestion, remove the d value, and add a field called <code>hostname</code>, we could use the following configuration:</p> <pre><code>...\n   client_options:\n     mapping:\n       transform:\n         +c : '{{ .webster.d }}',\n         -d: nil,\n         +hostname : '{{ \"my-computer\" }}',\n</code></pre> <p>The resulting event to be ingested would be:</p> <pre><code>{ \"event\":\n  \"webster\" : {\n     \"a\" : 1,\n     \"b\" : 2,\n     \"c\" : 3\n    },\n    \"hostname\" : \"my-computer\"\n  }\n}\n</code></pre>"},{"location":"4-data-queries/template-transforms/#transforms","title":"Transforms","text":"<p>With Transforms, you specify a JSON object that describes the transformation.</p> <p>This object is in the shape of the final JSON you would like to transform to.</p> <p>Key names are the literal key names in the output. Values support one of 3 types:</p> <ol> <li>Template Strings, as described above. In this case, the template string will be generated and placed at the same place as the key in the transform object.</li> <li>A <code>gjson</code> selector. The selector syntaxt is defined here. It makes it possible to select subsets of input object and map it within the resulting object as defined by the transform.</li> <li>Other JSON objects which will be present in the output.</li> </ol> <p>Let's look at an example, let's say this is the Input to our transform:</p> <pre><code>{\n    \"event\": {\n        \"EVENT\": {\n            \"EventData\": {\n                \"AuthenticationPackageName\": \"NTLM\",\n                \"FailureReason\":             \"%%2313\",\n                \"IpAddress\":                 \"34.64.101.177\",\n                \"IpPort\":                    \"0\",\n                \"KeyLength\":                 \"0\",\n                \"LmPackageName\":             \"-\",\n                \"LogonProcessName\":          \"NtLmSsp\",\n                \"LogonType\":                 \"3\",\n                \"ProcessId\":                 \"0x0\",\n                \"ProcessName\":               \"-\",\n                \"Status\":                    \"0xc000006d\",\n                \"SubStatus\":                 \"0xc0000064\",\n                \"SubjectDomainName\":         \"-\",\n                \"SubjectLogonId\":            \"0x0\",\n                \"SubjectUserName\":           \"-\",\n                \"SubjectUserSid\":            \"S-1-0-0\",\n                \"TargetDomainName\":          \"\",\n                \"TargetUserName\":            \"ADMINISTRADOR\",\n                \"TargetUserSid\":             \"S-1-0-0\",\n                \"TransmittedServices\":       \"-\",\n                \"WorkstationName\":           \"-\",\n            },\n            \"System\": {\n                \"Channel\":  \"Security\",\n                \"Computer\": \"demo-win-2016\",\n                \"Correlation\": {\n                    \"ActivityID\": \"{F207C050-075F-0001-AFE1-ED1F3897D801}\",\n                },\n                \"EventID\":       \"4625\",\n                \"EventRecordID\": \"2832700\",\n                \"Execution\": {\n                    \"ProcessID\": \"572\",\n                    \"ThreadID\":  \"2352\",\n                },\n                \"Keywords\": \"0x8010000000000000\",\n                \"Level\":    \"0\",\n                \"Opcode\":   \"0\",\n                \"Provider\": {\n                    \"Guid\": \"{54849625-5478-4994-A5BA-3E3B0328C30D}\",\n                    \"Name\": \"Microsoft-Windows-Security-Auditing\",\n                },\n                \"Security\": \"\",\n                \"Task\":     \"12544\",\n                \"TimeCreated\": {\n                    \"SystemTime\": \"2022-07-15T22:48:24.996361600Z\",\n                },\n                \"Version\": \"0\",\n            },\n        },\n    },\n    \"routing\": {\n        \"arch\":       2,\n        \"did\":        \"b97e9d00-ca17-4afe-a9cf-27c3468d5901\",\n        \"event_id\":   \"f24679e5-5484-4ca1-bee2-bfa09a5ba3db\",\n        \"event_time\": 1657925305984,\n        \"event_type\": \"WEL\",\n        \"ext_ip\":     \"35.184.178.65\",\n        \"hostname\":   \"demo-win-2016.c.lc-demo-infra.internal\",\n        \"iid\":        \"7d23bee6-aaaa-aaaa-aaaa-c8e8cca132a1\",\n        \"int_ip\":     \"10.128.0.2\",\n        \"moduleid\":   2,\n        \"oid\":        \"8cbe27f4-aaaa-aaaa-aaaa-138cd51389cd\",\n        \"plat\":       268435456,\n        \"sid\":        \"bb4b30af-ff11-4ff4-836f-f014ada33345\",\n        \"tags\": [\n            \"edr\",\n            \"lc:stable\",\n        ],\n        \"this\": \"c5e16360c71baf3492f2dcd962d1eeb9\",\n    },\n    \"ts\": \"2022-07-15 22:48:25\",\n}\n</code></pre> <p>And this is our Transform definition:</p> <pre><code>{\n    \"message\": \"Interesting event from {{ .routing.hostname }}\",  // a format string\n    \"from\":    \"{{ \\\"limacharlie\\\" }}\",                           // a format string with only a literal value\n    \"dat\": {                                                      // define a sub-object in the output\n        \"raw\": \"event.EVENT.EventData\"                            // a \"raw\" key where we map a specific object from the input\n    },\n    \"anon_ip\": \"{{anon .routing.int_ip }}\",                       // an anonymized version of the internal IP\n    \"ts\":   \"routing.event_time\",                                 // map a specific simple value\n    \"nope\": \"does.not.exist\"                                      // map a value that is not present\n}\n</code></pre> <p>Then the resulting Output would be:</p> <pre><code>{\n    \"dat\": {\n        \"raw\": {\n            \"AuthenticationPackageName\": \"NTLM\",\n            \"FailureReason\": \"%%2313\",\n            \"IpAddress\": \"34.64.101.177\",\n            \"IpPort\": \"0\",\n            \"KeyLength\": \"0\",\n            \"LmPackageName\": \"-\",\n            \"LogonProcessName\": \"NtLmSsp\",\n            \"LogonType\": \"3\",\n            \"ProcessId\": \"0x0\",\n            \"ProcessName\": \"-\",\n            \"Status\": \"0xc000006d\",\n            \"SubStatus\": \"0xc0000064\",\n            \"SubjectDomainName\": \"-\",\n            \"SubjectLogonId\": \"0x0\",\n            \"SubjectUserName\": \"-\",\n            \"SubjectUserSid\": \"S-1-0-0\",\n            \"TargetDomainName\": \"\",\n            \"TargetUserName\": \"ADMINISTRADOR\",\n            \"TargetUserSid\": \"S-1-0-0\",\n            \"TransmittedServices\": \"-\",\n            \"WorkstationName\": \"-\"\n        }\n    },\n    \"from\": \"limacharlie\",\n    \"message\": \"Interesting event from demo-win-2016.c.lc-demo-infra.internal\",\n    \"nope\": null,\n    \"ts\": 1657925305984,\n    \"anon_ip\": \"e80b5017098950fc58aad83c8c14978e\"\n}\n</code></pre>"},{"location":"4-data-queries/template-transforms/#transforming-output-data","title":"Transforming Output Data","text":"<p>When passing events to an output, you have the option to transform the original event in multiple ways. When creating an output, Custom Transforms are applied in the CUSTOM TRANSFORM area of the screenshot below. In this example we are transforming a detection event to pass via a custom webhook to a web application.</p> <p></p>"},{"location":"4-data-queries/template-transforms/#examples","title":"Examples","text":""},{"location":"4-data-queries/template-transforms/#extracting-fields-from-telemetry","title":"Extracting Fields from Telemetry","text":"<p>Let's say you have the following 4625 failed logon and you want to send similar events to an output, but only certain fields.</p> <pre><code>{\n  \"event\": {\n    \"EVENT\": {\n      \"EventData\": {\n        \"AuthenticationPackageName\": \"NTLM\",\n        \"FailureReason\": \"%%2313\",\n        \"IpAddress\": \"142.99.21.14\",\n        # &lt;extra fields removed&gt;\n        \"TargetUserName\": \"administrator\",\n        \"WorkstationName\": \"D-483\"\n      },\n      \"System\": {\n        \"Channel\": \"Security\",\n        \"Computer\": \"demo-win-2016\",\n        # &lt;extra fields removed&gt;\n        \"EventID\": \"4625\",\n        \"EventRecordID\": \"22690646\",\n        # &lt;extra fields removed&gt;\n        \"TimeCreated\": {\n          \"SystemTime\": \"2024-01-23T17:30:07.345840000Z\"\n        },\n        \"Version\": \"0\",\n        \"_event_id\": \"4625\"\n      }\n    }\n  },\n  \"routing\": {\n    # &lt;extra fields removed&gt;\n    \"event_type\": \"WEL\",\n    \"hostname\": \"win-2016.corp.internal\",\n     # &lt;extra fields removed&gt;\n    \"tags\": [\n      \"windows\"\n    ],\n    \"this\": \"8873fb9fcb26e2c0d4299ce765aff77d\"\n  },\n  \"ts\": \"2024-01-23 17:29:33\"\n}\n</code></pre> <p>The following Output Transform would extract only the <code>IpAddress</code>, <code>TargetUserName</code>, <code>EventID</code>, and <code>SystemTime</code> the event was created. Notice, the newly mapped field names can be whatever you want.</p> <pre><code>{\n    \"Source IP\": \"event.EVENT.EventData.IpAddress\",\n    \"Username\": \"event.EVENT.EventData.TargetUserName\",\n    \"Event ID\": \"event.EVENT.System.EventID\",\n    \"Happened at\": \"event.EVENT.System.TimeCreated.SystemTime\"\n}\n</code></pre> <p>The following example outputs text and specified fields using Template Strings.</p> <pre><code>{\n  \"text\": \"Failed logon by {{ .event.EVENT.EventData.TargetUserName }} on {{ .routing.hostname }}\"\n}\n</code></pre> <p>The above example would generate the following output using the provided sample WEL.</p> <pre><code>{\n  \"text\": \"Failed logon by administrator on win-2016.corp.internal\"\n}\n</code></pre>"},{"location":"4-data-queries/template-transforms/#output-as-string-passthrough","title":"Output as String / Passthrough","text":"<p>The <code>custom_transform</code> in outputs can also be used to output pure text (non-JSON) from LimaCharlie. This is useful if, for example, you are ingesting syslog data, and want to forward this syslog data as-is to something else.</p> <p>This is accomplished by specifying a Template String in the <code>custom_transform</code> field instead of a Transform. In those cases, when LimaCharlie determines the <code>custom_transform</code> string is not a valid Transform, it will interpret it as a Template String like:</p> <pre><code>{\n    \"custom_transform\": \"{{ .event.text }}\"\n}\n</code></pre> <p>or</p> <pre><code>{\n    \"custom_transform\": \"some text {{json .event.some_field }}\"\n}\n</code></pre>"},{"location":"4-data-queries/template-transforms/#custom-modifiers","title":"Custom Modifiers","text":"<p>Beyond the built-in modifiers for <code>gjson</code> (as seen in their playground, LimaCharlie also implements several new modifiers:</p> <ul> <li><code>parsejson</code>: this modifier takes no arguments, it takes in as input a string that represents a JSON object and outputs the decoded JSON object.</li> <li><code>extract</code>: this modifier takes a single argument, <code>re</code> which is a regular expression that uses \"named capture groups\" (as defined in the re2 documentation). The group names become the keys of the output JSON object with the matching values.</li> <li><code>parsetime</code>: this modifier takes two arguments, <code>from</code> and <code>to</code>. It will convert an input string from a given time format (as defined in the Go <code>time</code> library format here) and outputs the resulting time in the <code>to</code> format. Beyond the time constants from the previous link, LimaCharlie also supports a <code>from</code> format of:</li> <li><code>epoch_s</code>: a second based epoch timestamp</li> <li><code>epoch_ms</code>: a millisecond based epoch timestamp</li> </ul> <p>For example: The transform:</p> <pre><code>{\n  \"new_ts\": \"ts|@parsetime:{\\\"from\\\":\\\"2006-01-02 15:04:05\\\", \\\"to\\\":\\\"Mon, 02 Jan 2006 15:04:05 MST\\\"}\",\n  \"user\": \"origin|@extract:{\\\"re\\\":\\\".*@(?P&lt;domain&gt;.+)\\\"}\",\n  \"ctx\": \"event.EVENT.exec_context|@parsejson\"\n}\n</code></pre> <p>applied to:</p> <pre><code>{\n  \"ts\": \"2023-05-10 22:35:48\",\n  \"origin\": \"someuser@gmail.com\",\n  \"event\": {\n    \"EVENT\": {\n      \"exec_context\": \"{\\\"some\\\": \\\"embeded value\\\"}\"\n    }\n  }\n}\n</code></pre> <p>would result in:</p> <pre><code>{\n  \"new_ts\": \"Wed, 10 May 2023 22:35:48 UTC\",\n  \"user\": {\n    \"domain\": \"gmail.com\\\"\"\n  },\n  \"ctx\": {\n    \"some\": \"embeded value\"\n  }\n}\n</code></pre>"},{"location":"4-data-queries/events/","title":"Events","text":"<p>Event types and telemetry data.</p>"},{"location":"4-data-queries/events/#documentation","title":"Documentation","text":"<ul> <li>Event Schemas - Event structure and field definitions</li> <li>Template Strings and Transforms - Data transformation</li> </ul>"},{"location":"4-data-queries/events/sysmon-comparison/","title":"Sysmon Comparison","text":"<p>System Monitor, or \"Sysmon\", is a Windows server and device driver that monitors and logs operating system activity. It is part of the Sysinternals toolkit. More information on Sysmon can be found here.</p> <p>Many organizations deploy Sysmon and structure their detection events around Sysmon-specific event logs, which can offer granular insight into operating system changes. LimaCharlie's EDR telemetry can offer similar events, allowing you to write detections against these events directly.</p> <p>A comparison of LimaCharlie vs. Sysmon is as follows:</p> Sysmon Event LimaCharlie Event Event ID 1 (Process Creation) NEW_PROCESS Event ID 3 (Network Connection) NEW_*_CONNECTION Event ID 5 (Process terminated) TERMINATE_PROCESS Event ID 6 (Driver Loaded) MODULE_LOAD, CODE_IDENTITY, DRIVER_CHANGE Event ID 7 (Image loaded) MODULE_LOAD, CODE_IDENTITY Event ID 8 (Create remote thread) NEW_REMOTE_THREAD Event ID 10 (ProcessAccess) REMOTE_PROCESS_HANDLE Event ID 11 (FileCreate) FILE_CREATE Event ID 12 (RegistryEvent object create and delete) REGISTRY_CREATE, REGISTRY_DELETE Event ID 13 (RegisterEvent value set) REGISTRY_WRITE Event ID 14 (RegistryEvent rename) REGISTRY_CREATE Event ID 17 (PipeEvent Created) NEW_NAMED_PIPE Event ID 18 (PipeEvent Connected) OPEN_NAMED_PIPE <p>Why not both? \u00af*(\u30c4)*/\u00af</p> <p>Note, LC's Endpoint Agent is easily able to consume Sysmon events as well.</p>"},{"location":"4-data-queries/events/sysmon-comparison/#executable-tracking","title":"Executable Tracking","text":"<p>Recent updates to Sysmon also include the ability to capture and store information about binaries identified on a system. You can replicate this functionality with LimaCharlie with BinLib. More information on that can be found here.</p>"},{"location":"4-data-queries/tutorials/bigquery-looker-studio/","title":"Building Reports with BigQuery + Looker Studio","text":"<p>LimaCharlie does not include reporting by default, however our granular and customizable Output options allow you to push data to any source and use third-party tools for reporting. In this tutorial, we'll push a subset of LimaCharlie EDR telemetry to BigQuery and analyze our data using Google's Looker Studio. We'll be doing the work in the web UI, however this could also be done via the API.</p> <p>For this example, we will aggregate and analyze Windows processes making network connections.</p>"},{"location":"4-data-queries/tutorials/bigquery-looker-studio/#preparing-bigquery","title":"Preparing BigQuery","text":"<p>Within your project of choice, begin by creating a new dataset. For the purposes of this tutorial, I'm going to create a dataset named <code>windows_process_details</code>. Within this dataset, I'll create a table named <code>network_connections</code>.</p> <p>Let's examine this hierarchy for a moment:</p> <pre><code>\u251c\u2500\u2500 limacharlie-bq-testing    # project\n\u2502   \u251c\u2500\u2500 windows_process_details    # dataset\n\u2502   \u2502   \u251c\u2500\u2500 network_connections    # table\n</code></pre> <p>The nice part about this type of hierarchy is that I can build out multiple tables of process details within the same dataset, and then link/analyze them as needed. We'll focus on the <code>network_connections</code> data for now, but we could also look at exporting other process details into the same dataset.</p> <p></p> <p>Within the Google Cloud Console, we also want to create a Service Account and gather an API key. More details on that can be found here.</p> <p>Copy the API key and keep it somewhere safe, we'll need to configure it in the output.</p>"},{"location":"4-data-queries/tutorials/bigquery-looker-studio/#creating-the-bigquery-output","title":"Creating the BigQuery Output","text":"<p>Creating an Output within LimaCharlie is straightforward. Navigate to <code>Outputs</code> in the web UI, select <code>Add Output</code>, and select <code>Events</code>.</p> <p>Note:</p> <p>We want to export raw events in this case - however, we'll use filters to export only the events of interest to BigQuery.</p> <p>Within the Output Destination menu, select <code>Google Cloud BigQuery</code>. You'll be prompted with a configuration menu; expand the <code>Advanced Options</code>, as we'll need those too.</p> <p>The following values must be provided in order for the Output to work:</p> <ul> <li>Name (choose your own name)</li> <li>Dataset (from the previous section)</li> <li>Table (from the previous section)</li> <li>Project (from the previous section)</li> <li>Secret Key (the API key from the GCP service account)</li> </ul> <p>Where to Store the Secret?</p> <p>The secret key for this output can be inserted directly in the web app helper, however we recommend keeping secrets in the Secret hive for centralized management.</p> <p>Within the <code>Advanced Options</code>, we'll need to provide the following details:</p> <ul> <li>Custom Transform - we don't want to include all the details from the <code>NETWORK_CONNECTIONS</code> event. For this output, we are interested in processes making network connections and the users associated with them. Thus, we'll apply the following transform to pare this down:</li> </ul> <pre><code>{\n  \"hostname\": \"routing.hostname\",\n  \"command_line\": \"event.COMMAND_LINE\",\n  \"user\": \"event.USER_NAME\"\n}\n</code></pre> <p>Within the <code>Specific Event Types</code> field, we'll specify only <code>NETWORK_CONNECTIONS</code>. This is another way to pare down the number of events processed and exported.</p> <p>Finally, we'll also specify a tag of <code>windows</code>, ensuring we only capture Windows systems (per our tagging - your tags may differ). Based on the values provided and discussed, here's a screenshot of the Output configuration (minus the API key):</p> <p></p> <p>Save the output details, and then check <code>View Samples</code> in the Outputs menu to see if you're successfully seeing events.</p> <p></p>"},{"location":"4-data-queries/tutorials/bigquery-looker-studio/#analyzing-events-in-bigquery-looker-studio","title":"Analyzing Events in BigQuery + Looker Studio","text":"<p>Navigating back to BigQuery, we can see some initial events flowing in:</p> <p></p> <p>Let's hop over to Looker Studio. Create a Blank Report, and select <code>BigQuery</code> in the <code>Connect to Data</code> menu.</p> <p></p> <p>Select the Project, Dataset, and Table of interest, and click <code>Add</code>.</p> <p></p> <p>Looker Studio may prompt you about permissions of connected data. However, once connected, we'll be able to see a starter table with aggregate details from our <code>network_connections</code> table.</p> <p></p> <p>And that's it! From here, you can manipulate and move around the data as needed. You can also blend with another table, allowing you to combine multiple data points.</p> <p>Reports can also be styled, additional statistics generated, etc. The following example continues to pull on the basic data we exported to provide some unique insights:</p> <p></p>"},{"location":"5-integrations/","title":"Integrations","text":"<p>Connect LimaCharlie with your existing security infrastructure through outputs, extensions, and API integrations.</p>"},{"location":"5-integrations/#outputs","title":"Outputs","text":"<p>Stream telemetry and detections to external destinations:</p> <ul> <li>Amazon S3</li> <li>Splunk</li> <li>Elastic</li> <li>Google BigQuery</li> <li>Webhook</li> <li>And more...</li> </ul>"},{"location":"5-integrations/#extensions","title":"Extensions","text":"<p>Expand LimaCharlie capabilities:</p> <ul> <li>LimaCharlie Extensions: Git Sync, Reliable Tasking, YARA Manager</li> <li>Third-Party: Velociraptor, Zeek, Hayabusa, Atomic Red Team</li> <li>Cloud CLI: AWS, Azure, GCP, Okta integrations</li> </ul> <p>Browse all extensions</p>"},{"location":"5-integrations/#api-integrations","title":"API Integrations","text":"<p>Enrich your detections with threat intelligence:</p> <ul> <li>VirusTotal</li> <li>GreyNoise</li> <li>Hybrid Analysis</li> </ul>"},{"location":"5-integrations/#services","title":"Services","text":"<ul> <li>Replay - Historical data replay for testing</li> <li>Dumper - Memory acquisition service</li> </ul>"},{"location":"5-integrations/#see-also","title":"See Also","text":"<ul> <li>Outputs Overview</li> <li>Extensions</li> <li>API Integrations</li> </ul>"},{"location":"5-integrations/add-ons/","title":"Add-Ons","text":"<p>Expand platform capabilities with integrations and extensions.</p>"},{"location":"5-integrations/add-ons/#documentation","title":"Documentation","text":"<ul> <li>Developer Grant Program - Developer resources</li> </ul>"},{"location":"5-integrations/add-ons/#sections","title":"Sections","text":"<ul> <li>API Integrations - Third-party service integrations</li> <li>Extensions - Platform extensions</li> </ul>"},{"location":"5-integrations/api-integrations/","title":"API Integrations","text":"<p>Connect to external threat intelligence and security services.</p>"},{"location":"5-integrations/api-integrations/#available-integrations","title":"Available Integrations","text":"<ul> <li>AlphaMountain</li> <li>EchoTrail</li> <li>GreyNoise</li> <li>Hybrid Analysis</li> <li>IP Geolocation</li> <li>Pangea</li> <li>VirusTotal</li> </ul>"},{"location":"5-integrations/api-integrations/alphamountain/","title":"alphaMountain","text":"<p>There are three alphaMountain API integrations that can be subscribed with the appropriate API keys. When enabled and configured, alphaMountain resources can be used as an API-based lookup.</p>"},{"location":"5-integrations/api-integrations/alphamountain/#alphamountain-category","title":"alphaMountain Category","text":"<p>Returns categorization for Internet URIs, generated by alphaMountain's own statistical and neural network models. For more information on alphaMountain's categories, visit this page.</p>"},{"location":"5-integrations/api-integrations/alphamountain/#alphamountain-popularity","title":"alphaMountain Popularity","text":"<p>Returns the popularity of a domain, as measured by a combination of page-rank, daily traffic bandwidth, total number of requests, and passive DNS activity for a given hostname. For more information, visit this page.</p>"},{"location":"5-integrations/api-integrations/alphamountain/#alphamountain-threat","title":"alphaMountain Threat","text":"<p>Returns threat ratings for Internet URIs, generated by alphaMountain's own statistical and neural network models, cross-validated by a variety of sources as appropriate. For more information, visit this page.</p>"},{"location":"5-integrations/api-integrations/alphamountain/#detection-response-rule","title":"Detection &amp; Response Rule","text":"<p>The following is an example rule that pulls domain names from DNS_REQUEST events and performs a lookup using alphaMountain's category API.</p> <pre><code>event: DNS_REQUEST\nop: lookup\npath: event/DOMAIN_NAME\nresource: lcr://api/alphamountain-category\n</code></pre> <p>The data returned is in JSON format, and includes the API response and a threatYeti URL, which is appended by LimaCharlie. For example:</p> <pre><code>{\n  \"api_alphamountain-category\": {\n    \"categories\": [\n      34\n    ],\n    \"confidence\": 0.90371,\n    \"scope\": \"domain\",\n    \"threatyeti_url\": \"https://www.threatyeti.com/search?q=logging-alv.googleapis.com\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/api-integrations/echotrail/","title":"EchoTrail","text":"<p>EchoTrail is an API service that allows you to perform a lookup of a file name or hash value. EchoTrail will return a summary of statistical details that describes the behavior of the submitted value, as observed from their sensors over time.</p> <p>LimaCharlie has an integration available for EchoTrail's <code>insights</code> API lookup, accepting one of the following:</p> <ul> <li>MD5 Hash</li> <li>SHA256 Hash</li> <li>Windows filename with extension</li> </ul>"},{"location":"5-integrations/api-integrations/echotrail/#detection-response-rule","title":"Detection &amp; Response Rule","text":"<p>The following detection and response rule utilizes a file name from a <code>NEW_PROCESS</code> event to query the EchoTrail <code>insights</code> API:</p> <pre><code>event: NEW_PROCESS\nop: lookup\npath: event/FILE_PATH\nresource: lcr://api/echotrail-insights\n</code></pre> <p>EchoTrail's response data includes the following:</p> <pre><code>{\n  \"rank\": 24,\n  \"host_prev\": \"94.4\",\n  \"eps\": \"96.07\",\n  \"paths\": [\n    [\n      \"C:\\\\Windows\\\\System32\",\n      \"99.92\"\n    ],\n    [\n      \"C:\\\\WINDOWS\\\\System32\",\n      \"0.07\"\n    ],\n    [\n      \"C:\\\\Windows\\\\SysWOW64\",\n      \"0.00\"\n    ],\n    [\n      \"C:\\\\Users\\\\...\",\n      \"0.00\"\n    ],\n    [\n      \"C:\\\\Windows\\\\Temp\\\\...\",\n      \"0.00\"\n    ],\n    [\n      \"C:\\\\...\",\n      \"0.00\"\n    ]\n  ],\n  \"parents\": [\n    [\n      \"services.exe\",\n      \"99.65\"\n    ],\n    [\n      \"MsMpEng.exe\",\n      \"0.35\"\n    ],\n    [\n      \"rpcnet.exe\",\n      \"0.00\"\n    ],\n    [\n      \"svchost.exe\",\n      \"0.00\"\n    ],\n    [\n      \"MRT.exe\",\n      \"0.00\"\n    ],\n    [\n      \"cmd.exe\",\n      \"0.00\"\n    ],\n    [\n      \"consent.exe\",\n      \"0.00\"\n    ],\n    [\n      \"explorer.exe\",\n      \"0.00\"\n    ],\n    [\n      \"python.exe\",\n      \"0.00\"\n    ],\n    [\n      \"MRT-KB890830.exe\",\n      \"0.00\"\n    ]\n  ],\n  \"children\": [\n    [\n      \"WmiPrvSE.exe\",\n      \"12.44\"\n    ],\n    [\n      \"wmiprvse.exe\",\n      \"7.96\"\n    ],\n    [\n      \"backgroundTaskHost.exe\",\n      \"7.76\"\n    ],\n    [\n      \"taskhostw.exe\",\n      \"6.76\"\n    ],\n    [\n      \"backgroundtaskhost.exe\",\n      \"4.96\"\n    ],\n    [\n      \"dllhost.exe\",\n      \"4.58\"\n    ],\n    [\n      \"RuntimeBroker.exe\",\n      \"3.95\"\n    ],\n    [\n      \"runtimebroker.exe\",\n      \"3.48\"\n    ],\n    [\n      \"spatialaudiolicensesrv.exe\",\n      \"2.47\"\n    ],\n    [\n      \"werfault.exe\",\n      \"1.65\"\n    ],\n    [\n      \"GoogleUpdate.exe\",\n      \"1.62\"\n    ],\n    [\n      \"wermgr.exe\",\n      \"1.55\"\n    ],\n    [\n      \"gpupdate.exe\",\n      \"1.44\"\n    ],\n    [\n      \"filecoauth.exe\",\n      \"1.40\"\n    ],\n    [\n      \"FCHelper64.exe\",\n      \"1.26\"\n    ],\n    [\n      \"HxTsr.exe\",\n      \"1.20\"\n    ],\n    [\n      \"googleupdate.exe\",\n      \"1.15\"\n    ],\n    [\n      \"TiWorker.exe\",\n      \"1.08\"\n    ],\n    [\n      \"audiodg.exe\",\n      \"1.05\"\n    ],\n    [\n      \"tiworker.exe\",\n      \"0.96\"\n    ]\n  ],\n  \"grandparents\": [\n    [\n      \"wininit.exe\",\n      \"99.89\"\n    ],\n    [\n      \"services.exe\",\n      \"0.11\"\n    ],\n    [\n      \"explorer.exe\",\n      \"0.00\"\n    ],\n    [\n      \"cmd.exe\",\n      \"0.00\"\n    ],\n    [\n      \"userinit.exe\",\n      \"0.00\"\n    ],\n    [\n      \"svchost.exe\",\n      \"0.00\"\n    ],\n    [\n      \"Windows-KB890830-x64-V5.72-delta.exe\",\n      \"0.00\"\n    ],\n    [\n      \"Windows-KB890830-x64-V5.71-delta.exe\",\n      \"0.00\"\n    ],\n    [\n      \"Windows-KB890830-x64-V5.70-delta.exe\",\n      \"0.00\"\n    ],\n    [\n      \"Windows-KB890830-x64-V5.69-delta.exe\",\n      \"0.00\"\n    ],\n    [\n      \"Windows-KB890830-x64-V5.65.exe\",\n      \"0.00\"\n    ],\n    [\n      \"Windows-KB890830-x64-V5.62-delta.exe\",\n      \"0.00\"\n    ],\n    [\n      \"Windows-KB890830-x64-V5.58-delta.exe\",\n      \"0.00\"\n    ],\n    [\n      \"Windows-KB890830-x64-V5.57-delta.exe\",\n      \"0.00\"\n    ]\n  ],\n  \"network\": [\n    [\n      \"443\",\n      \"45.89\"\n    ],\n    [\n      \"80\",\n      \"32.37\"\n    ],\n    [\n      \"5353\",\n      \"2.71\"\n    ],\n    [\n      \"53\",\n      \"1.17\"\n    ],\n    [\n      \"5355\",\n      \"0.61\"\n    ],\n    [\n      \"1900\",\n      \"0.31\"\n    ],\n    [\n      \"54188\",\n      \"0.17\"\n    ],\n    [\n      \"3702\",\n      \"0.16\"\n    ],\n    [\n      \"54189\",\n      \"0.07\"\n    ],\n    [\n      \"67\",\n      \"0.06\"\n    ],\n    [\n      \"547\",\n      \"0.05\"\n    ],\n    [\n      \"53240\",\n      \"0.05\"\n    ],\n    [\n      \"59298\",\n      \"0.05\"\n    ],\n    [\n      \"53242\",\n      \"0.05\"\n    ],\n    [\n      \"53241\",\n      \"0.04\"\n    ],\n    [\n      \"53048\",\n      \"0.04\"\n    ],\n    [\n      \"62120\",\n      \"0.04\"\n    ],\n    [\n      \"64473\",\n      \"0.03\"\n    ],\n    [\n      \"58569\",\n      \"0.03\"\n    ],\n    [\n      \"50531\",\n      \"0.03\"\n    ]\n  ],\n  \"description\": \"Svchost.exe is the name for services that run from dynamic-linked libraries (DLLs). The Service Host Process acts like a shell for loading services from DLL files. Those services are partitioned into groups and each group is run in a different instance of the Service Host Process. This prevents problems in one instance from affecting other instances. That is also why you will see multiple instances of svchost.exe running at the same time.\",\n  \"intel\": \"It is normal to see many svchost processes running on a single machine. It usually has elevated privileges and a tremendous amount of trust from Windows and third-party applications, leading to its abuse during a variety of attacks. Automated, opportunistic malware as well as manual, targeted tools commonly abuse this process in a few ways:\\n\\nName masquerading - More common to commodity, non-targeted attacks, malware will disguise itself as an svchost process by changing one or more characters in the name (e.g. svch0st, svchosts, scvhost, suchost, svchost32, etc.). These tend to be simple to identify by a human, but they can be more complicated to detect by algorithms or automated detection solutions if they are more than one character off the true name \"svchost.\"\\n\\nPath masquerading - Not uncommon to commodity malware but more common to targeted attack scenarios, malware or other tools used abused malicious purposes may disguise itself with an \"svchost.exe\" filename but located in a directory of the attacker's choosing. It is not a legitimate svchost process. The legitimate svchost will always run from C:\\\\Windows\\\\System32 or C:\\\\Windows\\\\SysWOW64. If \"svchost.exe\" is running from any other directory, it is worth investigation. With endpoint process data, each running process' path is simple to examine and, hence, simple to detect svchost path abuse.\\n\\nProcess migration - This type of abuse is more common to targeted or advanced attacks. Rather than running a malicious tool with the name \"svchost.exe,\" process migration allows an attacker to use a legitimate, currently running svchost process to effect their objectives. This typically occurs after privileged remote access is already gained to a system through a malicious remote administration tool (RAT). This sort of svchost abuse may be identifiable by uncommon behaviors of svchost, such as its launching of unusual executables, accessing unusual websites or IP addresses, performing host or network reconnaissance, or some combination thereof.\\n\",\n  \"truncated\": {\n    \"paths\": 5,\n    \"parents\": 10,\n    \"grandparents\": 13,\n    \"children\": 1328,\n    \"network\": 32667,\n    \"filenames\": 1\n  },\n  \"filenames\": [\n    [\n      \"svchost.exe\",\n      \"100.00\"\n    ]\n  ]\n}\n</code></pre>"},{"location":"5-integrations/api-integrations/greynoise/","title":"GreyNoise","text":"<p>GreyNoise collects, analyzes, and labels data on IP addresses that scan the Internet and often saturate security tools with noise. By querying IP addresses against GreyNoise, teams can spend less time on irrelevant or harmless activity and focus on targeted and/or emerging threats.</p> <p>LimaCharlie offers integrations with two GreyNoise API lookups:</p> <ul> <li> <p>IP Context</p> </li> <li> <p>Get more information about a given IP address. Returns time ranges, IP metadata (network owner, ASN, reverse DNS pointer, country), associated actors, activity tags, and raw port scan and web request information.</p> </li> <li> <p>RIOT IP Lookups</p> </li> <li> <p>RIOT identifies IPs from known benign services and organizations that commonly cause false positives in network security and threat intelligence products. The collection of IPs in RIOT is continually curated and verified to provide accurate results.</p> </li> </ul>"},{"location":"5-integrations/api-integrations/greynoise/#ip-context","title":"IP Context","text":"<pre><code>{\n  \"api_greynoise-noise-context\": {\n    \"ip\": \"35.184.178.65\",\n    \"seen\": false\n  }\n}\n</code></pre>"},{"location":"5-integrations/api-integrations/greynoise/#riot-ip-lookup","title":"RIOT IP Lookup","text":"<pre><code>{\n  \"ip\": \"8.8.8.8\",\n  \"noise\": false,\n  \"riot\": true,\n  \"classification\": \"benign\",\n  \"name\": \"Google Public DNS\",\n  \"link\": \"https://viz.greynoise.io/riot/8.8.8.8\",\n  \"last_seen\": \"2023-08-02\",\n  \"message\": \"Success\"\n}\n</code></pre>"},{"location":"5-integrations/api-integrations/hybrid-analysis/","title":"Hybrid Analysis","text":"<p>Hybrid Analysis, aka Falcon Sandbox, is a powerful, free malware analysis service for the community that detects and analyzes unknown threats. Hybrid Analysis has its own unique approach, and offers both public-facing and private team-based sandboxing capabilities.</p> <p>LimaCharlie integrates with the following Hybrid Analysis API calls:</p> <ul> <li>Overview</li> <li>Search</li> </ul>"},{"location":"5-integrations/api-integrations/hybrid-analysis/#detection-response-rules","title":"Detection &amp; Response Rules","text":""},{"location":"5-integrations/api-integrations/hybrid-analysis/#overview","title":"Overview","text":"<p>The Search API accepts a SHA256 value, and provides an extensive overview of a hash (if previously observed by the platform).</p> <p>Rule:</p> <p>The following D&amp;R rule</p> <pre><code>event: NEW_PROCESS\nop: lookup\npath: event/HASH\nresource: lcr://api/hybrid-analysis-overview\n</code></pre> <p>Response Data:</p> <pre><code>{\n \u00a0\"result\": {\n \u00a0 \u00a0\"analysis_start_time\": \"2023-07-17T18:31:04+00:00\",\n \u00a0 \u00a0\"architecture\": \"WINDOWS\",\n \u00a0 \u00a0\"children_in_progress\": 0,\n \u00a0 \u00a0\"children_in_queue\": 0,\n \u00a0 \u00a0\"last_file_name\": \"cmd.exe\",\n \u00a0 \u00a0\"last_multi_scan\": \"2023-07-17T18:31:09+00:00\",\n \u00a0 \u00a0\"multiscan_result\": 0,\n \u00a0 \u00a0\"other_file_name\": [\n \u00a0 \u00a0 \u00a0\"Utilman.exe\",\n \u00a0 \u00a0 \u00a0\"file\",\n \u00a0 \u00a0 \u00a0\"kiss.exe\",\n \u00a0 \u00a0 \u00a0\"osk.exe\",\n \u00a0 \u00a0 \u00a0\"sethc.exe\",\n \u00a0 \u00a0 \u00a0\"utilman.exe\"\n \u00a0 \u00a0],\n \u00a0 \u00a0\"related_children_hashes\": [],\n \u00a0 \u00a0\"related_parent_hashes\": [\n \u00a0 \u00a0 \u00a0\"c502bd80423e10dcc4b59fe4b523acb5ce0bd07748f73c7bdc6c797883b8a417\"\n \u00a0 \u00a0],\n \u00a0 \u00a0\"related_reports\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"environment_id\": 100,\n \u00a0 \u00a0 \u00a0 \u00a0\"error_origin\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"error_type\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"job_id\": \"627e3011d695730f2c3ad419\",\n \u00a0 \u00a0 \u00a0 \u00a0\"sha256\": \"c502bd80423e10dcc4b59fe4b523acb5ce0bd07748f73c7bdc6c797883b8a417\",\n \u00a0 \u00a0 \u00a0 \u00a0\"state\": \"SUCCESS\",\n \u00a0 \u00a0 \u00a0 \u00a0\"verdict\": \"no verdict\"\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0],\n \u00a0 \u00a0\"reports\": [\n \u00a0 \u00a0 \u00a0\"58593319aac2edc56d351531\",\n \u00a0 \u00a0 \u00a0\"5a34f2a27ca3e13531789a95\",\n \u00a0 \u00a0 \u00a0\"5f196598eac13102deff3d42\",\n \u00a0 \u00a0 \u00a0\"64b588e7e14d64e6a60b2130\",\n \u00a0 \u00a0 \u00a0\"5965d8027ca3e10ec737634f\",\n \u00a0 \u00a0 \u00a0\"60251a499b1b3016bb674fb4\",\n \u00a0 \u00a0 \u00a0\"637f3600a3d94f1ecc7c1800\"\n \u00a0 \u00a0],\n \u00a0 \u00a0\"scanners\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"anti_virus_results\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"error_message\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"CrowdStrike Falcon Static Analysis (ML)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"percent\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"positives\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"progress\": 100,\n \u00a0 \u00a0 \u00a0 \u00a0\"status\": \"clean\",\n \u00a0 \u00a0 \u00a0 \u00a0\"total\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"anti_virus_results\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"error_message\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Metadefender\",\n \u00a0 \u00a0 \u00a0 \u00a0\"percent\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"positives\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"progress\": 100,\n \u00a0 \u00a0 \u00a0 \u00a0\"status\": \"clean\",\n \u00a0 \u00a0 \u00a0 \u00a0\"total\": 27\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"anti_virus_results\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"error_message\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"VirusTotal\",\n \u00a0 \u00a0 \u00a0 \u00a0\"percent\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"positives\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"progress\": 100,\n \u00a0 \u00a0 \u00a0 \u00a0\"status\": \"clean\",\n \u00a0 \u00a0 \u00a0 \u00a0\"total\": 75\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0],\n \u00a0 \u00a0\"scanners_v2\": {\n \u00a0 \u00a0 \u00a0\"bfore_ai\": null,\n \u00a0 \u00a0 \u00a0\"clean_dns\": null,\n \u00a0 \u00a0 \u00a0\"crowdstrike_ml\": {\n \u00a0 \u00a0 \u00a0 \u00a0\"anti_virus_results\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"error_message\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"CrowdStrike Falcon Static Analysis (ML)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"percent\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"progress\": 100,\n \u00a0 \u00a0 \u00a0 \u00a0\"status\": \"clean\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0\"metadefender\": {\n \u00a0 \u00a0 \u00a0 \u00a0\"anti_virus_results\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"error_message\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Metadefender\",\n \u00a0 \u00a0 \u00a0 \u00a0\"percent\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"positives\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"progress\": 100,\n \u00a0 \u00a0 \u00a0 \u00a0\"status\": \"clean\",\n \u00a0 \u00a0 \u00a0 \u00a0\"total\": 27\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0\"scam_adviser\": null,\n \u00a0 \u00a0 \u00a0\"urlscan_io\": null,\n \u00a0 \u00a0 \u00a0\"virustotal\": {\n \u00a0 \u00a0 \u00a0 \u00a0\"error_message\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"VirusTotal\",\n \u00a0 \u00a0 \u00a0 \u00a0\"percent\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"positives\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"progress\": 100,\n \u00a0 \u00a0 \u00a0 \u00a0\"status\": \"clean\",\n \u00a0 \u00a0 \u00a0 \u00a0\"total\": 75\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0},\n \u00a0 \u00a0\"sha256\": \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2\",\n \u00a0 \u00a0\"size\": 232960,\n \u00a0 \u00a0\"submit_context\": [],\n \u00a0 \u00a0\"tags\": [],\n \u00a0 \u00a0\"threat_score\": null,\n \u00a0 \u00a0\"type\": \"PE32+ executable (console) x86-64, for MS Windows\",\n \u00a0 \u00a0\"type_short\": [\n \u00a0 \u00a0 \u00a0\"peexe\",\n \u00a0 \u00a0 \u00a0\"64bits\",\n \u00a0 \u00a0 \u00a0\"executable\"\n \u00a0 \u00a0],\n \u00a0 \u00a0\"url_analysis\": false,\n \u00a0 \u00a0\"verdict\": \"no specific threat\",\n \u00a0 \u00a0\"vx_family\": null,\n \u00a0 \u00a0\"whitelisted\": false\n \u00a0}\n}\n</code></pre>"},{"location":"5-integrations/api-integrations/hybrid-analysis/#search","title":"Search","text":"<p>The Search lookup provides a basic lookup of a hash value. This look accepts one of the following values:</p> <ul> <li>MD5</li> <li>SHA1</li> <li>SHA256</li> </ul> <p>D&amp;R Rule:</p> <pre><code>event: NEW_PROCESS\nop: lookup\npath: event/HASH\nresource: lcr://api/hybrid-analysis-search\n</code></pre> <p>Response Data:</p> <pre><code>[\n \u00a0{\n \u00a0 \u00a0\"classification_tags\": [],\n \u00a0 \u00a0\"tags\": [],\n \u00a0 \u00a0\"submissions\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"64b588e7e14d64e6a60b2131\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2023-07-17T18:31:03+00:00\"\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0],\n \u00a0 \u00a0\"machine_learning_models\": [],\n \u00a0 \u00a0\"crowdstrike_ai\": {\n \u00a0 \u00a0 \u00a0\"executable_process_memory_analysis\": [],\n \u00a0 \u00a0 \u00a0\"analysis_related_urls\": []\n \u00a0 \u00a0},\n \u00a0 \u00a0\"job_id\": \"64b588e7e14d64e6a60b2130\",\n \u00a0 \u00a0\"environment_id\": 160,\n \u00a0 \u00a0\"environment_description\": \"Windows 10 64 bit\",\n \u00a0 \u00a0\"size\": 232960,\n \u00a0 \u00a0\"type\": \"PE32+ executable (console) x86-64, for MS Windows\",\n \u00a0 \u00a0\"type_short\": [\n \u00a0 \u00a0 \u00a0\"peexe\",\n \u00a0 \u00a0 \u00a0\"64bits\",\n \u00a0 \u00a0 \u00a0\"executable\"\n \u00a0 \u00a0],\n \u00a0 \u00a0\"target_url\": null,\n \u00a0 \u00a0\"state\": \"SUCCESS\",\n \u00a0 \u00a0\"error_type\": null,\n \u00a0 \u00a0\"error_origin\": null,\n \u00a0 \u00a0\"submit_name\": \"cmd.exe\",\n \u00a0 \u00a0\"md5\": \"f4f684066175b77e0c3a000549d2922c\",\n \u00a0 \u00a0\"sha1\": \"99ae9c73e9bee6f9c76d6f4093a9882df06832cf\",\n \u00a0 \u00a0\"sha256\": \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2\",\n \u00a0 \u00a0\"sha512\": \"fe8f0593cc335ad28eb90211bc4ff01a3d2992cffb3877d04cefede9ef94afeb1a7d7874dd0c0ae04eaf8308291d5a4d879e6ecf6fe2b8d0ff1c3ac7ef143206\",\n \u00a0 \u00a0\"ssdeep\": \"3072:bkd4COZG6/A1tO1Y6TbkX2FtynroeJ/MEJoSsasbLLkhyjyGe:bkuC9+Af0Y6TbbFtkoeJk1KsfLXm\",\n \u00a0 \u00a0\"imphash\": \"3062ed732d4b25d1c64f084dac97d37a\",\n \u00a0 \u00a0\"entrypoint\": \"0x140015190\",\n \u00a0 \u00a0\"entrypoint_section\": \".text\",\n \u00a0 \u00a0\"image_base\": \"0x140000000\",\n \u00a0 \u00a0\"subsystem\": \"Windows Cui\",\n \u00a0 \u00a0\"image_file_characteristics\": [\n \u00a0 \u00a0 \u00a0\"EXECUTABLE_IMAGE\",\n \u00a0 \u00a0 \u00a0\"LARGE_ADDRESS_AWARE\"\n \u00a0 \u00a0],\n \u00a0 \u00a0\"dll_characteristics\": [\n \u00a0 \u00a0 \u00a0\"GUARD_CF\",\n \u00a0 \u00a0 \u00a0\"TERMINAL_SERVER_AWARE\",\n \u00a0 \u00a0 \u00a0\"DYNAMIC_BASE\",\n \u00a0 \u00a0 \u00a0\"NX_COMPAT\",\n \u00a0 \u00a0 \u00a0\"HIGH_ENTROPY_VA\"\n \u00a0 \u00a0],\n \u00a0 \u00a0\"major_os_version\": 10,\n \u00a0 \u00a0\"minor_os_version\": 0,\n \u00a0 \u00a0\"av_detect\": 0,\n \u00a0 \u00a0\"vx_family\": null,\n \u00a0 \u00a0\"url_analysis\": false,\n \u00a0 \u00a0\"analysis_start_time\": \"2023-07-17T18:31:04+00:00\",\n \u00a0 \u00a0\"threat_score\": null,\n \u00a0 \u00a0\"interesting\": false,\n \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0\"verdict\": \"no specific threat\",\n \u00a0 \u00a0\"certificates\": [],\n \u00a0 \u00a0\"is_certificates_valid\": false,\n \u00a0 \u00a0\"certificates_validation_message\": \"No signature was present in the subject. (0x800b0100)\",\n \u00a0 \u00a0\"domains\": [],\n \u00a0 \u00a0\"compromised_hosts\": [],\n \u00a0 \u00a0\"hosts\": [],\n \u00a0 \u00a0\"total_network_connections\": 0,\n \u00a0 \u00a0\"total_processes\": 1,\n \u00a0 \u00a0\"total_signatures\": 99,\n \u00a0 \u00a0\"extracted_files\": [],\n \u00a0 \u00a0\"file_metadata\": null,\n \u00a0 \u00a0\"processes\": [],\n \u00a0 \u00a0\"mitre_attcks\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Execution\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Shared Modules\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1129\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1129\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Execution\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Native API\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 10,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Execution\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Windows Command Shell\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1059.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1059/003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Command and Scripting Interpreter\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1059\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1059\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Persistence\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Windows Service\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1543.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1543/003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Create or Modify System Process\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1543\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1543\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Persistence\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Create or Modify System Process\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1543\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1543\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Persistence\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Registry Run Keys / Startup Folder\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1547.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1547/001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Boot or Logon Autostart Execution\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1547\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1547\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Privilege Escalation\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Windows Service\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1543.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1543/003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Create or Modify System Process\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1543\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1543\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Privilege Escalation\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Token Impersonation/Theft\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134/001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Access Token Manipulation\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Privilege Escalation\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Create or Modify System Process\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1543\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1543\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Privilege Escalation\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Create Process with Token\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134.002\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134/002\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Access Token Manipulation\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Privilege Escalation\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Dynamic-link Library Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055/001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Process Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Privilege Escalation\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Thread Execution Hijacking\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055/003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Process Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Privilege Escalation\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Process Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Privilege Escalation\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Registry Run Keys / Startup Folder\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1547.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1547/001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Boot or Logon Autostart Execution\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1547\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1547\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Privilege Escalation\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Extra Window Memory Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055.011\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055/011\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Process Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Obfuscated Files or Information\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1027\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1027\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Match Legitimate Name or Location\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1036.005\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1036/005\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Masquerading\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1036\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1036\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Debugger Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1622\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1622\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"File and Directory Permissions Modification\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1222\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1222\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Token Impersonation/Theft\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134/001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Access Token Manipulation\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Timestomp\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1070.006\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1070/006\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Indicator Removal\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1070\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1070\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Modify Registry\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1112\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1112\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 4,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Disable or Modify Tools\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1562.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1562/001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Impair Defenses\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1562\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1562\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Create Process with Token\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134.002\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134/002\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Access Token Manipulation\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Dynamic-link Library Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055/001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Process Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Thread Execution Hijacking\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055/003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Process Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Process Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"File Deletion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1070.004\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1070/004\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Indicator Removal\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1070\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1070\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Direct Volume Access\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1006\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1006\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Time Based Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1497.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1497/003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Virtualization/Sandbox Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1497\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1497\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Software Packing\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1027.002\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1027/002\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Obfuscated Files or Information\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1027\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1027\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Defense Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Extra Window Memory Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055.011\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055/011\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Process Injection\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Credential Access\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Credential API Hooking\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1056.004\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1056/004\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Input Capture\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1056\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1056\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"File and Directory Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 7,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Process Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1057\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1057\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 4,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Query Registry\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1012\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1012\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 4,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"System Service Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1007\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1007\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"System Information Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1082\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1082\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 9,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"System Language Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1614.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1614/001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"System Location Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1614\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1614\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Debugger Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1622\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1622\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"System Owner/User Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1033\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1033\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"System Network Connections Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1049\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1049\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"System Network Configuration Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1016\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1016\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Network Share Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1135\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1135\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"System Location Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1614\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1614\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"System Time Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1124\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1124\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Time Based Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1497.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1497/003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Virtualization/Sandbox Evasion\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1497\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1497\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Lateral Movement\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Lateral Tool Transfer\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1570\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1570\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Collection\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Credential API Hooking\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1056.004\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1056/004\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Input Capture\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1056\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1056\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Collection\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Local Data Staging\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1074.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1074/001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": {\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Data Staged\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1074\",\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1074\"\n \u00a0 \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Command and Control\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Application Layer Protocol\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1071\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1071\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Command and Control\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Ingress Tool Transfer\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1105\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1105\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Exfiltration\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Scheduled Transfer\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1029\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1029\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Impact\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"Service Stop\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1489\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1489\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0],\n \u00a0 \u00a0\"network_mode\": \"default\",\n \u00a0 \u00a0\"signatures\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"api-7\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 6,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Loads modules at runtime\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" loaded module \\\"KERNEL32\\\" at base e8360000\\n \\\"cmd.exe\\\" loaded module \\\"API-MS-WIN-CORE-STRING-L1-1-0\\\" at base e5170000\\n \\\"cmd.exe\\\" loaded module \\\"API-MS-WIN-CORE-DATETIME-L1-1-1\\\" at base e5170000\\n \\\"cmd.exe\\\" loaded module \\\"API-MS-WIN-CORE-LOCALIZATION-OBSOLETE-L1-2-0\\\" at base e5170000\\n \\\"cmd.exe\\\" loaded module \\\"%WINDIR%\\\\SYSTEM32\\\\IMM32.DLL\\\" at base e5be0000\\n \\\"cmd.exe\\\" loaded module \\\"API-MS-WIN-CORE-SYNCH-L1-2-0\\\" at base e5170000\\n \\\"cmd.exe\\\" loaded module \\\"API-MS-WIN-CORE-FIBERS-L1-1-1\\\" at base e5170000\\n \\\"cmd.exe\\\" loaded module \\\"API-MS-WIN-CORE-LOCALIZATION-L1-2-1\\\" at base e5170000\\n \\\"cmd.exe\\\" loaded module \\\"%WINDIR%\\\\TEMP\\\\VXOLE64.DLL\\\" at base d3ef0000\\n \\\"cmd.exe\\\" loaded module \\\"KERNEL32.DLL\\\" at base e8360000\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"API Call\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1129\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1129\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"api-175\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 6,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Calls an API typically used to load libraries\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" called \\\"LoadLibrary\\\" with a parameter api-ms-win-core-synch-l1-2-0 (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"LoadLibrary\\\" with a parameter api-ms-win-core-fibers-l1-1-1 (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"LoadLibrary\\\" with a parameter api-ms-win-core-localization-l1-2-1 (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"LoadLibrary\\\" with a parameter kernel32 (UID: 00000000-00004716)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"API Call\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1129\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1129\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"api-176\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 6,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Calls an API typically used to retrieve function addresses\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter InitializeCriticalSectionEx (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter FlsAlloc (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter FlsSetValue (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter FlsGetValue (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter LCMapStringEx (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter FlsFree (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter InitOnceExecuteOnce (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter CreateEventExW (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter CreateSemaphoreW (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter CreateSemaphoreExW (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter CreateThreadpoolTimer (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter SetThreadpoolTimer (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter WaitForThreadpoolTimerCallbacks (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter CloseThreadpoolTimer (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter CreateThreadpoolWait (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter SetThreadpoolWait (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter CloseThreadpoolWait (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter FlushProcessWriteBuffers (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter FreeLibraryWhenCallbackReturns (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter GetCurrentProcessorNumber (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter CreateSymbolicLinkW (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter GetCurrentPackageId (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter GetTickCount64 (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter GetFileInformationByHandleEx (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter SetFileInformationByHandle (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter GetSystemTimePreciseAsFileTime (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter InitializeConditionVariable (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter WakeConditionVariable (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter WakeAllConditionVariable (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter SleepConditionVariableCS (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter InitializeSRWLock (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter AcquireSRWLockExclusive (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter TryAcquireSRWLockExclusive (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter ReleaseSRWLockExclusive (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter SleepConditionVariableSRW (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter CreateThreadpoolWork (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter SubmitThreadpoolWork (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter CloseThreadpoolWork (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter CompareStringEx (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter GetLocaleInfoEx (UID: 00000000-00004716)\\n \\\"cmd.exe\\\" called \\\"GetProcAddress\\\" with a parameter AreFileApisANSI (UID: 00000000-00004716)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"API Call\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"module-10\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 10,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Loads the RPC (Remote Procedure Call) module DLL\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" loaded module \\\"%WINDIR%\\\\System32\\\\rpcrt4.dll\\\" at E8420000\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Loaded Module\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1129\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1129\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"module-9\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 10,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Loads the Bcrypt module DLL\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" loaded module \\\"%WINDIR%\\\\System32\\\\bcryptprimitives.dll\\\" at E55D0000\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Loaded Module\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1027\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1027\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"registry-25\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Reads information about supported languages\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" (Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\NLS\\\\CUSTOMLOCALE\\\"; Key: \\\"EN-US\\\")\\n \\\"cmd.exe\\\" (Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\NLS\\\\EXTENDEDLOCALE\\\"; Key: \\\"EN-US\\\")\\n \\\"cmd.exe\\\" (Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\NLS\\\\LOCALE\\\"; Key: \\\"00000409\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Registry Access\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1082\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1082\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-101\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to execute Windows APIs\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API (Indicator: \\\"SetConsoleInputExeNameW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"IsDebuggerPresent\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"CopyFileExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetThreadUILanguage\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"NtQueryInformationProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RtlCreateUnicodeStringFromAsciiz\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RtlNtStatusToDosError\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"NtSetInformationProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RtlFreeUnicodeString\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RtlDosPathNameToRelativeNtPathName_U_WithStatus\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"NtSetInformationFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RtlReleaseRelativeName\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"NtQueryVolumeInformationFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"NtOpenFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RtlFindLeastSignificantBit\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RtlDosPathNameToNtPathName_U\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"NtFsControlFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RtlFreeHeap\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RtlCaptureContext\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RtlLookupFunctionEntry\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RtlVirtualUnwind\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"CopyFileW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"ReadFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetThreadLocale\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FindFirstFileW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetConsoleScreenBufferInfo\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"HeapFree\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetFullPathNameW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FindNextFileW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetConsoleOutputCP\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetStdHandle\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetCPInfo\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetFilePointer\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FindClose\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"CreateFileW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"MultiByteToWideChar\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetLastError\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FillConsoleOutputCharacterW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"ReadConsoleW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"CloseHandle\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"ReleaseSRWLockShared\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"HeapAlloc\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FlushConsoleInputBuffer\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"WriteConsoleW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetProcAddress\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"AcquireSRWLockShared\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetFileSize\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetProcessHeap\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetModuleHandleW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"WideCharToMultiByte\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetFileType\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetConsoleCursorPosition\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RevertToSelf\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"VirtualQuery\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetLocalTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetLocaleInfoW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetUserDefaultLCID\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FileTimeToSystemTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FileTimeToLocalFileTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetLocalTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetTimeFormatW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SystemTimeToFileTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetSystemTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetDateFormatW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetNumaHighestNodeNumber\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetCommandLineW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetConsoleMode\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetEnvironmentVariableW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetEnvironmentVariableW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FreeEnvironmentStringsW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetConsoleMode\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetEnvironmentStringsW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetEnvironmentStringsW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetStartupInfoW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RegQueryValueExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"NeedCurrentDirectoryForExePathW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetLastError\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RegDeleteValueW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"InitializeProcThreadAttributeList\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"CreateProcessAsUserW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RegOpenKeyExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetErrorMode\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetConsoleTitleW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetFileAttributesW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RegSetValueExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RegEnumKeyExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"UpdateProcThreadAttribute\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RegCreateKeyExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"DeleteProcThreadAttributeList\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"ReadProcessMemory\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"CreateProcessW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RegDeleteKeyExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RegCloseKey\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"LoadLibraryExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"MoveFileWithProgressW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"LocalFree\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"MoveFileExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetConsoleTitleW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetVolumeInformationW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SearchPathW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"WriteFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GlobalAlloc\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GlobalFree\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetFilePointerEx\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetConsoleCtrlHandler\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"EnterCriticalSection\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"TryAcquireSRWLockExclusive\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"ExpandEnvironmentStringsW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetModuleFileNameW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"LeaveCriticalSection\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"InitializeCriticalSection\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetVersion\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"ReleaseSRWLockExclusive\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetWindowsDirectoryW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetFileAttributesExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetDriveTypeW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetCurrentThreadId\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"HeapSetInformation\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"OpenThread\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"VirtualFree\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"VirtualAlloc\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"HeapSize\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"HeapReAlloc\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"DuplicateHandle\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FlushFileBuffers\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetACP\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FormatMessageW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetConsoleTextAttribute\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"ScrollConsoleScreenBufferW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FillConsoleOutputAttribute\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"CreateDirectoryW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetFileTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetEndOfFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetFileAttributesW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"DeleteFileW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"TerminateProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"WaitForSingleObject\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetCurrentDirectoryW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetExitCodeProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetCurrentDirectoryW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetFileInformationByHandleEx\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"RemoveDirectoryW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"CompareFileTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"DeviceIoControl\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetFileSecurityW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetSecurityDescriptorOwner\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetDiskFreeSpaceExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"FindFirstFileExW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"ResumeThread\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetThreadGroupAffinity\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetNumaNodeProcessorMaskEx\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetThreadLocale\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"CreateHardLinkW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetVolumePathNameW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"CreateSymbolicLinkW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"Sleep\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"UnhandledExceptionFilter\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetUnhandledExceptionFilter\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetCurrentProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"QueryPerformanceCounter\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetCurrentProcessId\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetSystemTimeAsFileTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"GetTickCount\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"lstrcmpiW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"lstrcmpW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"SetProcessAffinityMask\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"NtOpenProcessToken\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"NtQueryInformationToken\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"NtClose\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"NtOpenThreadToken\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"DelayLoadFailureHook\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API (Indicator: \\\"Beep\\\"; Source: \\\"00000000-00004716.00000000.77972.48F50000.00000002.mdmp, 00000000-00004716.00000001.79890.48F50000.00000002.mdmp, 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetConsoleInputExeNameW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"IsDebuggerPresent\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"CopyFileExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetThreadUILanguage\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"NtQueryInformationProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RtlCreateUnicodeStringFromAsciiz\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RtlNtStatusToDosError\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"NtSetInformationProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RtlFreeUnicodeString\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RtlDosPathNameToRelativeNtPathName_U_WithStatus\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"NtSetInformationFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RtlReleaseRelativeName\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"NtQueryVolumeInformationFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"NtOpenFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RtlFindLeastSignificantBit\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RtlDosPathNameToNtPathName_U\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"NtFsControlFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RtlFreeHeap\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RtlCaptureContext\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RtlLookupFunctionEntry\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RtlVirtualUnwind\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"CopyFileW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"ReadFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetThreadLocale\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FindFirstFileW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetConsoleScreenBufferInfo\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"HeapFree\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetFullPathNameW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FindNextFileW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetConsoleOutputCP\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetStdHandle\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetCPInfo\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetFilePointer\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FindClose\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"CreateFileW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"MultiByteToWideChar\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetLastError\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FillConsoleOutputCharacterW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"ReadConsoleW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"CloseHandle\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"ReleaseSRWLockShared\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"HeapAlloc\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FlushConsoleInputBuffer\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"WriteConsoleW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetProcAddress\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"AcquireSRWLockShared\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetFileSize\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetProcessHeap\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetModuleHandleW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"WideCharToMultiByte\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetFileType\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetConsoleCursorPosition\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RevertToSelf\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"VirtualQuery\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetLocalTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetLocaleInfoW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetUserDefaultLCID\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FileTimeToSystemTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FileTimeToLocalFileTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetLocalTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetTimeFormatW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SystemTimeToFileTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetSystemTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetDateFormatW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetNumaHighestNodeNumber\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetCommandLineW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetConsoleMode\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetEnvironmentVariableW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetEnvironmentVariableW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FreeEnvironmentStringsW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetConsoleMode\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetEnvironmentStringsW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetEnvironmentStringsW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetStartupInfoW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RegQueryValueExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"NeedCurrentDirectoryForExePathW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetLastError\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RegDeleteValueW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"InitializeProcThreadAttributeList\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"CreateProcessAsUserW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RegOpenKeyExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetErrorMode\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetConsoleTitleW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetFileAttributesW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RegSetValueExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RegEnumKeyExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"UpdateProcThreadAttribute\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RegCreateKeyExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"DeleteProcThreadAttributeList\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"ReadProcessMemory\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"CreateProcessW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RegDeleteKeyExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RegCloseKey\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"LoadLibraryExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"MoveFileWithProgressW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"LocalFree\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"MoveFileExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetConsoleTitleW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetVolumeInformationW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SearchPathW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"WriteFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GlobalAlloc\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GlobalFree\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetFilePointerEx\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetConsoleCtrlHandler\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"EnterCriticalSection\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"TryAcquireSRWLockExclusive\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"ExpandEnvironmentStringsW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetModuleFileNameW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"LeaveCriticalSection\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"InitializeCriticalSection\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetVersion\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"ReleaseSRWLockExclusive\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetWindowsDirectoryW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetFileAttributesExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetDriveTypeW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetCurrentThreadId\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"HeapSetInformation\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"OpenThread\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"VirtualFree\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"VirtualAlloc\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"HeapSize\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"HeapReAlloc\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"DuplicateHandle\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FlushFileBuffers\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetACP\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FormatMessageW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetConsoleTextAttribute\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"ScrollConsoleScreenBufferW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FillConsoleOutputAttribute\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"CreateDirectoryW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetFileTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetEndOfFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetFileAttributesW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"DeleteFileW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"TerminateProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"WaitForSingleObject\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetCurrentDirectoryW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetExitCodeProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetCurrentDirectoryW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetFileInformationByHandleEx\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"RemoveDirectoryW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"CompareFileTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"DeviceIoControl\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetFileSecurityW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetSecurityDescriptorOwner\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetDiskFreeSpaceExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"FindFirstFileExW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"ResumeThread\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetThreadGroupAffinity\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetNumaNodeProcessorMaskEx\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetThreadLocale\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"CreateHardLinkW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetVolumePathNameW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"CreateSymbolicLinkW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"Sleep\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"UnhandledExceptionFilter\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetUnhandledExceptionFilter\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetCurrentProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"QueryPerformanceCounter\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetCurrentProcessId\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetSystemTimeAsFileTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"GetTickCount\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"lstrcmpiW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"lstrcmpW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"SetProcessAffinityMask\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"NtOpenProcessToken\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"NtQueryInformationToken\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"NtClose\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"NtOpenThreadToken\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API (Indicator: \\\"DelayLoadFailureHook\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-7\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains PDB pathways\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.pdb\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-240\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to execute an application (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"ShellExecuteWorker\\\" (Indicator: \\\"ShellExecute\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"ShellExecuteWorker\\\" (Indicator: \\\"ShellExecute\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-315\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to create/open files (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"NtOpenFile\\\" (Indicator: \\\"NtOpenFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"CreateFileW\\\" (Indicator: \\\"CreateFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtOpenFile\\\" (Indicator: \\\"NtOpenFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"CreateFileW\\\" (Indicator: \\\"CreateFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-220\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to create/control drivers (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"NtFsControlFile\\\" (Indicator: \\\"FsControlFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"DeviceIoControl\\\" (Indicator: \\\"DeviceIoControl\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtFsControlFile\\\" (Indicator: \\\"FsControlFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"DeviceIoControl\\\" (Indicator: \\\"DeviceIoControl\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1543.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1543/003\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-319\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to set/get the last-error code for a calling thread (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetLastError\\\" (Indicator: \\\"GetLastError\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"SetLastError\\\" (Indicator: \\\"SetLastError\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetLastError\\\" (Indicator: \\\"GetLastError\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"SetLastError\\\" (Indicator: \\\"SetLastError\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-272\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve/open a process (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetProcessHeap\\\" (Indicator: \\\"GetProcessHeap\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtOpenProcessToken\\\" (Indicator: \\\"OpenProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetProcessHeap\\\" (Indicator: \\\"GetProcessHeap\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"NtOpenProcessToken\\\" (Indicator: \\\"OpenProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1057\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1057\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-206\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve the command-line string for the current process (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetCommandLineW\\\" (Indicator: \\\"GetCommandLine\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetCommandLineW\\\" (Indicator: \\\"GetCommandLine\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1059.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1059/003\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-204\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to create a new process (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"CreateProcessAsUserW\\\" (Indicator: \\\"CreateProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"CreateProcessW\\\" (Indicator: \\\"CreateProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"CreateProcessAsUserW\\\" (Indicator: \\\"CreateProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"CreateProcessW\\\" (Indicator: \\\"CreateProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-307\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to create/load registry keys (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"RegCreateKeyExW\\\" (Indicator: \\\"RegCreateKey\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"RegCreateKeyExW\\\" (Indicator: \\\"RegCreateKey\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1112\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1112\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-345\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to disable/close registry key (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"RegCloseKey\\\" (Indicator: \\\"RegCloseKey\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"RegCloseKey\\\" (Indicator: \\\"RegCloseKey\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1112\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1112\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-322\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to move file or directory (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"MoveFileWithProgressW\\\" (Indicator: \\\"MoveFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"MoveFileExW\\\" (Indicator: \\\"MoveFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"MoveFileWithProgressW\\\" (Indicator: \\\"MoveFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"MoveFileExW\\\" (Indicator: \\\"MoveFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1570\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1570\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-161\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve/modify process thread (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"OpenThread\\\" (Indicator: \\\"OpenThread\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"ResumeThread\\\" (Indicator: \\\"ResumeThread\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtOpenThreadToken\\\" (Indicator: \\\"OpenThread\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"OpenThread\\\" (Indicator: \\\"OpenThread\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"ResumeThread\\\" (Indicator: \\\"ResumeThread\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"NtOpenThreadToken\\\" (Indicator: \\\"OpenThread\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-423\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to create directories (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"CreateDirectoryW\\\" (Indicator: \\\"CreateDirectory\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"CreateDirectoryW\\\" (Indicator: \\\"CreateDirectory\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1074.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1074/001\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-120\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains registry location strings\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"Software\\\\Microsoft\\\\Command Processor\\\" in Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\n \\\"Software\\\\Policies\\\\Microsoft\\\\Windows\\\\System\\\" in Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\n \\\"Software\\\\Classes\\\" in Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\n \\\"\\\\Registry\\\\Machine\\\\System\\\\CurrentControlSet\\\\Control\\\\Keyboard Layout\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"Software\\\\Microsoft\\\\RegEdt32\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"SOFTWARE\\\\\\\\MICROSOFT\\\\\\\\CLOCK\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"Software\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\Devices\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"SOFTWARE\\\\\\\\MICROSOFT\\\\\\\\WINDOWS NT\\\\\\\\CURRENTVERSION\\\\\\\\EXTENSIONS\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"SOFTWARE\\\\\\\\MICROSOFT\\\\\\\\CHARMAP\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"SOFTWARE\\\\\\\\MICROSOFT\\\\\\\\WINDOWS NT\\\\\\\\CURRENTVERSION\\\\\\\\NETWORK\\\\\\\\PERSISTENT CONNECTIONS\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"Software\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\PrinterPorts\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"SOFTWARE\\\\\\\\MICROSOFT\\\\\\\\WINDOWS NT\\\\\\\\CURRENTVERSION\\\\\\\\TRUETYPE\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"SOFTWARE\\\\\\\\MICROSOFT\\\\\\\\WINDOWS NT\\\\\\\\CURRENTVERSION\\\\\\\\TWAIN\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"SOFTWARE\\\\\\\\MICROSOFT\\\\\\\\WINDOWS HELP\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"Software\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\Windows\\\" in Source: 00000000-00004716.00000000.77972.48F50000.00000002.mdmp\\n 00000000-00004716.00000001.79890.48F50000.00000002.mdmp\\n 00000000-00004716.00000002.81813.48F50000.00000002.mdmp\\n \\\"Software\\\\Microsoft\\\\Command Processor\\\" in Source: 00000000-00004716.00000000.77972.49307000.00000002.mdmp\\n 00000000-00004716.00000001.79890.49307000.00000002.mdmp\\n 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\n \\\"Software\\\\Policies\\\\Microsoft\\\\Windows\\\\System\\\" in Source: 00000000-00004716.00000000.77972.49307000.00000002.mdmp\\n 00000000-00004716.00000001.79890.49307000.00000002.mdmp\\n 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\n \\\"Software\\\\Classes\\\" in Source: 00000000-00004716.00000000.77972.49307000.00000002.mdmp\\n 00000000-00004716.00000001.79890.49307000.00000002.mdmp\\n 00000000-00004716.00000002.81813.49307000.00000002.mdmp\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1012\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1012\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-157\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Matched Compiler/Packer signature (DIE)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" was detected as \\\"Microsoft Visual C/C++\\\" \u00a0and name: \\\"Compiler\\\"\\n \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" was detected as \\\"Microsoft Linker\\\" \u00a0and name: \\\"Linker\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1027\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1027\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-93\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"PE file has a high image base\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" has high imagebase \u00a0\\\"0x140000000\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-154\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"File contains dynamic base/NX flags\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" has flags like \u00a0IMAGE_DLLCHARACTERISTICS_GUARD_CF\\n IMAGE_DLLCHARACTERISTICS_TERMINAL_SERVER_AWARE\\n IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE\\n IMAGE_DLLCHARACTERISTICS_NX_COMPAT\\n IMAGE_DLLCHARACTERISTICS_HIGH_ENTROPY_VA\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-96\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"PE file entrypoint instructions\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" file has an entrypoint instructions - \\\"sub\\trsp, 0x28,call\\t0x1400156b4,add\\trsp, 0x28,jmp\\t0x140014fc0,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,nop\\tword ptr [rax + rax],cmp\\trcx, qword ptr [rip + 0x19e41],jne\\t0x1400151d9,rol\\trcx, 0x10,test\\tcx, 0xffff,jne\\t0x1400151d5,ret\\t,ror\\trcx, 0x10,jmp\\t0x140015220,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,int3\\t,push\\trbx,sub\\trsp, 0x20,mov\\trbx, rcx,xor\\tecx, ecx,\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-80\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"PE file contains executable sections\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" has an executable section named \\\".text\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-95\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"PE file contains writable sections\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" has an writable section named \\\".data\\\"\\n \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" has an writable section named \\\".didat\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-146\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"PE file contains Debug data directory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" has Debug data directory \\\"IMAGE_DIRECTORY_ENTRY_DEBUG\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-103\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to delay the execution of current thread\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Sleep at 61526-1-0000000140015190\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1497.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1497/003\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-625\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"References Windows filepaths for DLLs (possible dropped files)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Observed system executable string:\\\"C:\\\\windows\\\\temp\\\\VxSSL64.dll\\\" [Source: 00000000-00004716.00000000.77972.67BF0000.00000020.mdmp\\n 00000000-00004716.00000001.79890.67BF0000.00000020.mdmp\\n 00000000-00004716.00000002.81813.67BF0000.00000020.mdmp]\\n Observed system executable string:\\\"C:\\\\WINDOWS\\\\system32\\\\sxsoa.dll\\\" [Source: 00000000-00004716.00000000.77972.67C20000.00000002.mdmp\\n 00000000-00004716.00000001.79890.67C20000.00000002.mdmp\\n 00000000-00004716.00000002.81813.67C20000.00000002.mdmp]\\n Observed system executable string:\\\"C:\\\\WINDOWS\\\\system32\\\\GdiPlus.dll\\\" [Source: 00000000-00004716.00000000.77972.67C20000.00000002.mdmp\\n 00000000-00004716.00000001.79890.67C20000.00000002.mdmp\\n 00000000-00004716.00000002.81813.67C20000.00000002.mdmp]\\n Observed system executable string:\\\"C:\\\\WINDOWS\\\\system32\\\\comctl32.dll\\\" [Source: 00000000-00004716.00000000.77972.67C20000.00000002.mdmp\\n 00000000-00004716.00000001.79890.67C20000.00000002.mdmp\\n 00000000-00004716.00000002.81813.67C20000.00000002.mdmp]\\n Observed system executable string:\\\"C:\\\\WINDOWS\\\\system32\\\\sxsoaps.dll\\\" [Source: 00000000-00004716.00000000.77972.67C20000.00000002.mdmp\\n 00000000-00004716.00000001.79890.67C20000.00000002.mdmp\\n 00000000-00004716.00000002.81813.67C20000.00000002.mdmp]\\n Observed system executable string:\\\"C:\\\\WINDOWS\\\\system32\\\\comctl32.dll.mui\\\" [Source: 00000000-00004716.00000000.77972.67C20000.00000002.mdmp\\n 00000000-00004716.00000001.79890.67C20000.00000002.mdmp\\n 00000000-00004716.00000002.81813.67C20000.00000002.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\SYSTEM32\\\\ntdll.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\KERNEL32.DLL\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\msvcrt.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\KERNELBASE.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\windows\\\\temp\\\\VxSSL64.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\WS2_32.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\"C:\\\\windows\\\\temp\\\\VxOle64.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000000.77972.69E40000.00000020.mdmp\\n 00000000-00004716.00000000.77972.69E70000.00000002.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69E40000.00000020.mdmp\\n 00000000-00004716.00000001.79890.69E70000.00000002.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69E40000.00000020.mdmp\\n 00000000-00004716.00000002.81813.69E70000.00000002.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\RPCRT4.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\SYSTEM32\\\\FLTLIB.DLL\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\"C:\\\\WINDOWS\\\\SYSTEM32\\\\gdi32full.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\ucrtbase.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\USER32.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\ADVAPI32.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\ole32.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\GDI32.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\gdi32full.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\combase.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\msvcp_win.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\\n Observed system executable string:\\\":\\\\WINDOWS\\\\System32\\\\sechost.dll\\\" [Source: 00000000-00004716.00000000.77972.69D30000.00000004.mdmp\\n 00000000-00004716.00000001.79890.69D30000.00000004.mdmp\\n 00000000-00004716.00000002.81813.69D30000.00000004.mdmp]\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1083\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Unusual Characteristics\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"registry-26\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Reads the windows installation language\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" (Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\NLS\\\\LANGUAGE GROUPS\\\"; Key: \\\"1\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Registry Access\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1614.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1614/001\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Installation/Persistence\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"api-126\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 6,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Tries to access non-existent files (executable)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" trying to access non-existent file \\\"C:\\\\FLTLIB.DLL\\\"\\n \\\"cmd.exe\\\" trying to access non-existent file \\\"C:\\\\NETMSG.DLL\\\"\\n \\\"cmd.exe\\\" trying to access non-existent file \\\"C:\\\\netmsg.dll\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"API Call\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1083\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Installation/Persistence\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"api-263\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 6,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Touches files\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" trying to touch file \\\"C:\\\\FLTLIB.DLL\\\"\\n \\\"cmd.exe\\\" trying to touch file \\\"C:\\\\Windows\\\\System32\\\\fltLib.dll\\\"\\n \\\"cmd.exe\\\" trying to touch file \\\"C:\\\\Windows\\\\System32\\\\KernelBase.dll\\\"\\n \\\"cmd.exe\\\" trying to touch file \\\"C:\\\\windows\\\\temp\\\\VxOle64.dll\\\"\\n \\\"cmd.exe\\\" trying to touch file \\\"C:\\\\Windows\\\\System32\\\\imm32.dll\\\"\\n \\\"cmd.exe\\\" trying to touch file \\\"C:\\\\WINDOWS\\\\system32\\\\IMM32.DLL\\\"\\n \\\"cmd.exe\\\" trying to touch file \\\"C:\\\\EN-US\\\\CMD.EXE.MUI\\\"\\n \\\"cmd.exe\\\" trying to touch file \\\"C:\\\\EN\\\\CMD.EXE.MUI\\\"\\n \\\"cmd.exe\\\" trying to touch file \\\"C:\\\\cmd.exe\\\"\\n \\\"cmd.exe\\\" trying to touch file \\\"C:\\\\Windows\\\\System32\\\\oleaut32.dll\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"API Call\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1083\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Installation/Persistence\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"api-235\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 6,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Queries basic information of the specified process\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" queries basic process information of the \u00a0\\\"C:\\\\cmd.exe\\\" (UID: 4716)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"API Call\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1057\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1057\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Installation/Persistence\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"registry-177\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Opens registry keys\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\SESSION MANAGER\\\\SEGMENT HEAP\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\SESSION MANAGER\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKLM\\\\SOFTWARE\\\\MICROSOFT\\\\WINDOWS NT\\\\CURRENTVERSION\\\\IMAGE FILE EXECUTION OPTIONS\\\\CONHOST.EXE\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\SERVICES\\\\BAM\\\\USERSETTINGS\\\\S-1-5-21-735145574-3570218355-1207367261-1001\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\SESSION MANAGER\\\\BAM\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\SAFEBOOT\\\\OPTION\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\SRP\\\\GP\\\\DLL\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKLM\\\\SOFTWARE\\\\POLICIES\\\\MICROSOFT\\\\WINDOWS\\\\SAFER\\\\CODEIDENTIFIERS\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKCU\\\\SOFTWARE\\\\POLICIES\\\\MICROSOFT\\\\WINDOWS\\\\SAFER\\\\CODEIDENTIFIERS\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\FILESYSTEM\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\NLS\\\\SORTING\\\\VERSIONS\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKCU\\\\CONTROL PANEL\\\\DESKTOP\\\\MUICACHED\\\\MACHINELANGUAGECONFIGURATION\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKLM\\\\SOFTWARE\\\\POLICIES\\\\MICROSOFT\\\\MUI\\\\SETTINGS\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKCU\\\\SOFTWARE\\\\POLICIES\\\\MICROSOFT\\\\CONTROL PANEL\\\\DESKTOP\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"OPEN\\\"; Path: \\\"HKCU\\\\CONTROL PANEL\\\\DESKTOP\\\\LANGUAGECONFIGURATION\\\"; Key: \\\"\\\"; Value: \\\"\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Registry Access\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1012\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1012\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Installation/Persistence\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"registry-172\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Queries registry keys\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\SESSION MANAGER\\\"; Key: \\\"RESOURCEPOLICIES\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\SERVICES\\\\BAM\\\\USERSETTINGS\\\\S-1-5-21-735145574-3570218355-1207367261-1001\\\"; Key: \\\"\\\\DEVICE\\\\HARDDISKVOLUME2\\\\WINDOWS\\\\SYSTEM32\\\\CONHOST.EXE\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SOFTWARE\\\\POLICIES\\\\MICROSOFT\\\\WINDOWS\\\\SAFER\\\\CODEIDENTIFIERS\\\"; Key: \\\"TRANSPARENTENABLED\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\FILESYSTEM\\\"; Key: \\\"LONGPATHSENABLED\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\NLS\\\\SORTING\\\\VERSIONS\\\"; Key: \\\"\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKCU\\\\CONTROL PANEL\\\\DESKTOP\\\"; Key: \\\"PREFERREDUILANGUAGES\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKCU\\\\CONTROL PANEL\\\\DESKTOP\\\\MUICACHED\\\"; Key: \\\"MACHINEPREFERREDUILANGUAGES\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SOFTWARE\\\\MICROSOFT\\\\WINDOWS\\\\CURRENTVERSION\\\\SIDEBYSIDE\\\"; Key: \\\"PREFEREXTERNALMANIFEST\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\SESSION MANAGER\\\"; Key: \\\"SAFEDLLSEARCHMODE\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\LSA\\\\FIPSALGORITHMPOLICY\\\"; Key: \\\"ENABLED\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\LSA\\\"; Key: \\\"FIPSALGORITHMPOLICY\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\LSA\\\\FIPSALGORITHMPOLICY\\\"; Key: \\\"MDMENABLED\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SOFTWARE\\\\MICROSOFT\\\\OLE\\\"; Key: \\\"PAGEALLOCATORUSESYSTEMHEAP\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SOFTWARE\\\\MICROSOFT\\\\OLE\\\"; Key: \\\"PAGEALLOCATORSYSTEMHEAPISPRIVATE\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SOFTWARE\\\\MICROSOFT\\\\OLE\\\"; Key: \\\"AGGRESSIVEMTATESTING\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SOFTWARE\\\\MICROSOFT\\\\WINDOWS NT\\\\CURRENTVERSION\\\\GRE_INITIALIZE\\\"; Key: \\\"DISABLEMETAFILES\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKCU\\\\CONTROL PANEL\\\\DESKTOP\\\"; Key: \\\"ENABLEPERPROCESSSYSTEMDPI\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SOFTWARE\\\\MICROSOFT\\\\WINDOWS NT\\\\CURRENTVERSION\\\\COMPATIBILITY32\\\"; Key: \\\"CMD\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\CONTROL\\\\CMF\\\\CONFIG\\\"; Key: \\\"SYSTEM\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SOFTWARE\\\\MICROSOFT\\\\WINDOWS NT\\\\CURRENTVERSION\\\\WINDOWS\\\"; Key: \\\"LOADAPPINIT_DLLS\\\"; Value: \\\"\\\")\\n \\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKCU\\\\SOFTWARE\\\\POLICIES\\\\MICROSOFT\\\\WINDOWS\\\\SYSTEM\\\"; Key: \\\"DISABLECMD\\\"; Value: \\\"\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Registry Access\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1012\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1012\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Installation/Persistence\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-310\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to load modules (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"LoadLibraryExW\\\" (Indicator: \\\"LoadLibrary\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"LoadLibraryExW\\\" (Indicator: \\\"LoadLibrary\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Installation/Persistence\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-443\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains registry location which perform auto-execute functionality\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found string \\\"Software\\\\Microsoft\\\\Command Processor\\\" (Indicator: \\\"software\\\\microsoft\\\\command processor\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found string \\\"Software\\\\Microsoft\\\\Command Processor\\\" (Indicator: \\\"software\\\\microsoft\\\\command processor\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1547.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1547/001\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Detection/Stealthyness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-304\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to modify registry key/value (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"RegSetValueExW\\\" (Indicator: \\\"RegSetValue\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"RegSetValueExW\\\" (Indicator: \\\"RegSetValue\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1112\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1112\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Detection/Stealthyness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-318\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to load/free library (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"LoadLibraryExW\\\" (Indicator: \\\"LoadLibrary\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"LoadLibraryExW\\\" (Indicator: \\\"LoadLibrary\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055/001\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Detection/Stealthyness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-92\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to inject code into another process (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"VirtualFree\\\" (Indicator: \\\"VirtualFree\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"VirtualAlloc\\\" (Indicator: \\\"VirtualAlloc\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"VirtualFree\\\" (Indicator: \\\"VirtualFree\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"VirtualAlloc\\\" (Indicator: \\\"VirtualAlloc\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Detection/Stealthyness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-409\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to set file time (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"SetFileTime\\\" (Indicator: \\\"SetFileTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"SetFileTime\\\" (Indicator: \\\"SetFileTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1070.006\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1070/006\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Detection/Stealthyness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-226\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to delay execution by waiting for signal/timeout (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"WaitForSingleObject\\\" (Indicator: \\\"WaitForSingleObject\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"WaitForSingleObject\\\" (Indicator: \\\"WaitForSingleObject\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Detection/Stealthyness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-306\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to impersonate access tokens (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"NtOpenProcessToken\\\" (Indicator: \\\"OpenProcessToken\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtOpenThreadToken\\\" (Indicator: \\\"OpenThreadToken\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtOpenProcessToken\\\" (Indicator: \\\"OpenProcessToken\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"NtOpenThreadToken\\\" (Indicator: \\\"OpenThreadToken\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134/001\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Detection/Stealthyness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"memorydump-8\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 20,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Found PE header in memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found PE header \\\"MZ\\\" - Source: \\\"00000000-00004716.00000000.77972.492E0000.00000002.mdmp\\\")\\n Found PE header \\\"MZ\\\" - Source: \\\"00000000-00004716.00000001.79890.492E0000.00000002.mdmp\\\")\\n Found PE header \\\"MZ\\\" - Source: \\\"00000000-00004716.00000002.81813.492E0000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Memory Dumps\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1055\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1055\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Reverse Engineering\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-183\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to check debugger is running (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"IsDebuggerPresent\\\" (Indicator: \\\"IsDebuggerPresent\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtQueryInformationProcess\\\" (Indicator: \\\"NtQueryInformationProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"QueryPerformanceCounter\\\" (Indicator: \\\"QueryPerformanceCounter\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetTickCount\\\" (Indicator: \\\"GetTickCount\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1622\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1622\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Reverse Engineering\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-148\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to register a top-level exception handler (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"UnhandledExceptionFilter\\\" (Indicator: \\\"UnhandledExceptionFilter\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"SetUnhandledExceptionFilter\\\" (Indicator: \\\"SetUnhandledExceptionFilter\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"SetUnhandledExceptionFilter\\\" (Indicator: \\\"UnhandledExceptionFilter\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1622\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1622\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"registry-78\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to read software policies\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" (Path: \\\"HKLM\\\\SOFTWARE\\\\POLICIES\\\\MICROSOFT\\\\WINDOWS\\\\SAFER\\\\CODEIDENTIFIERS\\\"; Key: \\\"TRANSPARENTENABLED\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Registry Access\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1082\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1082\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-222\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve network parameters of a computer (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"WNetGetConnectionWStub\\\" (Indicator: \\\"NetGetConnection\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"WNetGetConnectionWStub\\\" (Indicator: \\\"NetGetConnection\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1016\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1016\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-89\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve information about the current system (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"RtlNtStatusToDosError\\\" (Indicator: \\\"RtlNtStatusToDosError\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"ExpandEnvironmentStringsW\\\" (Indicator: \\\"ExpandEnvironmentStrings\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"RtlNtStatusToDosError\\\" (Indicator: \\\"RtlNtStatusToDosError\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"ExpandEnvironmentStringsW\\\" (Indicator: \\\"ExpandEnvironmentStrings\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1082\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1082\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-162\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve volume information (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"NtQueryVolumeInformationFile\\\" (Indicator: \\\"NtQueryVolumeInformationFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetVolumeInformationW\\\" (Indicator: \\\"GetVolumeInformation\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtQueryVolumeInformationFile\\\" (Indicator: \\\"NtQueryVolumeInformationFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetVolumeInformationW\\\" (Indicator: \\\"GetVolumeInformation\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1082\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1082\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-201\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to query system locale (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetLocaleInfoW\\\" (Indicator: \\\"GetLocaleInfo\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetUserDefaultLCID\\\" (Indicator: \\\"GetUserDefaultLCID\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetLocaleInfoW\\\" (Indicator: \\\"GetLocaleInfo\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetUserDefaultLCID\\\" (Indicator: \\\"GetUserDefaultLCID\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1614\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1614\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-249\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve file time (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"FileTimeToSystemTime\\\" (Indicator: \\\"FileTimeToSystemTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"FileTimeToLocalFileTime\\\" (Indicator: \\\"FileTimeToLocalFileTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"SystemTimeToFileTime\\\" (Indicator: \\\"SystemTimeToFileTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetSystemTimeAsFileTime\\\" (Indicator: \\\"GetSystemTimeAsFileTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"FileTimeToSystemTime\\\" (Indicator: \\\"FileTimeToSystemTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"FileTimeToLocalFileTime\\\" (Indicator: \\\"FileTimeToLocalFileTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"SystemTimeToFileTime\\\" (Indicator: \\\"SystemTimeToFileTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetSystemTimeAsFileTime\\\" (Indicator: \\\"GetSystemTimeAsFileTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1070.006\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1070/006\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-365\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to perform scheduled transfer (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetLocalTime\\\" (Indicator: \\\"GetLocalTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetSystemTime\\\" (Indicator: \\\"GetSystemTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetSystemTimeAsFileTime\\\" (Indicator: \\\"GetSystemTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetLocalTime\\\" (Indicator: \\\"GetLocalTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetSystemTime\\\" (Indicator: \\\"GetSystemTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetSystemTimeAsFileTime\\\" (Indicator: \\\"GetSystemTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1029\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1029\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-247\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve machine time (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetLocalTime\\\" (Indicator: \\\"GetLocalTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetSystemTime\\\" (Indicator: \\\"GetSystemTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetSystemTimeAsFileTime\\\" (Indicator: \\\"GetSystemTime\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetLocalTime\\\" (Indicator: \\\"GetLocalTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetSystemTime\\\" (Indicator: \\\"GetSystemTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetSystemTimeAsFileTime\\\" (Indicator: \\\"GetSystemTime\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1124\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1124\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-167\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve the contents of the STARTUPINFO structure (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetStartupInfoW\\\" (Indicator: \\\"GetStartupInfo\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1543\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1543\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-171\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve the OS information (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetVersion\\\" (Indicator: \\\"GetVersion\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetVersion\\\" (Indicator: \\\"GetVersion\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1082\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1082\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-312\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve path in which Windows is installed (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetWindowsDirectoryW\\\" (Indicator: \\\"GetWindowsDirectory\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetWindowsDirectoryW\\\" (Indicator: \\\"GetWindowsDirectory\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1083\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-193\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to query volume/memory size (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetDiskFreeSpaceExW\\\" (Indicator: \\\"GetDiskFreeSpace\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetDiskFreeSpaceExW\\\" (Indicator: \\\"GetDiskFreeSpace\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1082\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1082\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-194\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains the ability to enumerate volumes (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetVolumePathNameW\\\" (Indicator: \\\"GetVolumePathName\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetVolumePathNameW\\\" (Indicator: \\\"GetVolumePathName\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1006\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1006\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"api-103\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 6,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Calls an API typically used for taking snapshot of the specified processes\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" called \\\"CreateToolhelp32Snapshot\\\" with parameters {\\\"dwFlags\\\": \\\"4\\\"\\n \\\"th32ProcessID\\\": \\\"0\\\"}\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"API Call\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1057\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1057\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-85\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to enumerate process and/or its information (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"NtQueryInformationProcess\\\" (Indicator: \\\"QueryInformationProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetModuleHandleW\\\" (Indicator: \\\"GetModuleHandle\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetEnvironmentStringsW\\\" (Indicator: \\\"GetEnvironmentStrings\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetCurrentProcess\\\" (Indicator: \\\"GetCurrentProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetCurrentProcessId\\\" (Indicator: \\\"GetCurrentProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtQueryInformationProcess\\\" (Indicator: \\\"QueryInformationProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetModuleHandleW\\\" (Indicator: \\\"GetModuleHandle\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetEnvironmentStringsW\\\" (Indicator: \\\"GetEnvironmentStrings\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetCurrentProcess\\\" (Indicator: \\\"GetCurrentProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetCurrentProcessId\\\" (Indicator: \\\"GetCurrentProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1057\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1057\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-121\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve usernames and/or user information (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"NtQueryInformationProcess\\\" (Indicator: \\\"NtQueryInformationProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"LookupAccountSidWStub\\\" (Indicator: \\\"LookupAccountSid\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtOpenProcessToken\\\" (Indicator: \\\"NtOpenProcessToken\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtOpenProcessToken\\\" (Indicator: \\\"OpenProcessToken\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtQueryInformationToken\\\" (Indicator: \\\"NtQueryInformationToken\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtOpenThreadToken\\\" (Indicator: \\\"NtOpenThreadToken\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtQueryInformationProcess\\\" (Indicator: \\\"NtQueryInformationProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"LookupAccountSidWStub\\\" (Indicator: \\\"LookupAccountSid\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"NtOpenProcessToken\\\" (Indicator: \\\"NtOpenProcessToken\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"NtOpenProcessToken\\\" (Indicator: \\\"OpenProcessToken\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"NtQueryInformationToken\\\" (Indicator: \\\"NtQueryInformationToken\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"NtOpenThreadToken\\\" (Indicator: \\\"NtOpenThreadToken\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1033\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1033\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-534\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to read files (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"ReadFile\\\" (Indicator: \\\"ReadFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"ReadFile\\\" (Indicator: \\\"ReadFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1083\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-83\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to enumerate files on disk (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"FindFirstFileW\\\" (Indicator: \\\"FindFirstFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"FindNextFileW\\\" (Indicator: \\\"FindNextFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"FindFirstFileExW\\\" (Indicator: \\\"FindFirstFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"FindFirstFileW\\\" (Indicator: \\\"FindFirstFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"FindNextFileW\\\" (Indicator: \\\"FindNextFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"FindFirstFileExW\\\" (Indicator: \\\"FindFirstFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1083\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-317\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve address of exported function from a DLL (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetProcAddress\\\" (Indicator: \\\"GetProcAddress\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetProcAddress\\\" (Indicator: \\\"GetProcAddress\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-207\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve file and directory information (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetFileSize\\\" (Indicator: \\\"GetFileSize\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetFileAttributesW\\\" (Indicator: \\\"GetFileAttributes\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetFileAttributesExW\\\" (Indicator: \\\"GetFileAttributes\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetCurrentDirectoryW\\\" (Indicator: \\\"GetCurrentDirectory\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetFileInformationByHandleEx\\\" (Indicator: \\\"GetFileInformationByHandle\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetFileSize\\\" (Indicator: \\\"GetFileSize\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetFileAttributesW\\\" (Indicator: \\\"GetFileAttributes\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetFileAttributesExW\\\" (Indicator: \\\"GetFileAttributes\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetCurrentDirectoryW\\\" (Indicator: \\\"GetCurrentDirectory\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetFileInformationByHandleEx\\\" (Indicator: \\\"GetFileInformationByHandle\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1083\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-427\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve a module handle (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetModuleHandleW\\\" (Indicator: \\\"GetModuleHandle\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetModuleHandleW\\\" (Indicator: \\\"GetModuleHandle\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1082\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1082\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-107\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve the host's architecture (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetEnvironmentVariableW\\\" (Indicator: \\\"GetEnvironmentVariable\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetEnvironmentVariableW\\\" (Indicator: \\\"GetEnvironmentVariable\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1082\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1082\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-229\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to query registry keys (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"RegQueryValueExW\\\" (Indicator: \\\"RegQueryValue\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"RegOpenKeyExW\\\" (Indicator: \\\"RegOpenKey\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"RegEnumKeyExW\\\" (Indicator: \\\"RegEnumKey\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"RegQueryValueExW\\\" (Indicator: \\\"RegQueryValue\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"RegOpenKeyExW\\\" (Indicator: \\\"RegOpenKey\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"RegEnumKeyExW\\\" (Indicator: \\\"RegEnumKey\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1012\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1012\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-164\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve the fully qualified path of module (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetModuleFileNameW\\\" (Indicator: \\\"GetModuleFileName\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetModuleFileNameW\\\" (Indicator: \\\"GetModuleFileName\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-80\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to determine disk drive type (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetDriveTypeW\\\" (Indicator: \\\"GetDriveType\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetDriveTypeW\\\" (Indicator: \\\"GetDriveType\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1082\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1082\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Spyware/Information Retrieval\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-205\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to retrieve the time elapsed since the system was started (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"GetTickCount\\\" (Indicator: \\\"GetTickCount\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetTickCount\\\" (Indicator: \\\"GetTickCount\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1497.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1497/003\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Network Related\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-3\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Found potential URL in binary/memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Heuristic match: \\\"fD9.tH\\\"\\n Pattern match: \\\"http://schemas.microsoft.com/SMI/2005/WindowsSettings\\\"\\n Heuristic match: \\\"(s.IL\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1071\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1071\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Network Related\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-257\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to enumerate network resources (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"WNetGetConnectionWStub\\\" (Indicator: \\\"NetGetConnection\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"WNetAddConnection2WStub\\\" (Indicator: \\\"NetAddConnection\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"WNetGetConnectionWStub\\\" (Indicator: \\\"NetGetConnection\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"WNetAddConnection2WStub\\\" (Indicator: \\\"NetAddConnection\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1049\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1049\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Network Related\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-113\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to provide information and utilities for managing network resources (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"WNetCancelConnection2WStub\\\" (Indicator: \\\"WNetCancelConnection\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1135\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1135\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"System Security\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"registry-173\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Queries services related registry keys\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" (Access type: \\\"QUERYVAL\\\"; Path: \\\"HKLM\\\\SYSTEM\\\\CONTROLSET001\\\\SERVICES\\\\BAM\\\\USERSETTINGS\\\\S-1-5-21-735145574-3570218355-1207367261-1001\\\"; Key: \\\"\\\\DEVICE\\\\HARDDISKVOLUME2\\\\WINDOWS\\\\SYSTEM32\\\\CONHOST.EXE\\\"; Value: \\\"\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Registry Access\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1007\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1007\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"System Security\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-426\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to modify file attributes (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"NtSetInformationFile\\\" (Indicator: \\\"SetInformationFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtSetInformationFile\\\" (Indicator: \\\"NtSetInformationFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"SetFileAttributesW\\\" (Indicator: \\\"SetFileAttributes\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"NtSetInformationFile\\\" (Indicator: \\\"SetInformationFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"NtSetInformationFile\\\" (Indicator: \\\"NtSetInformationFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"SetFileAttributesW\\\" (Indicator: \\\"SetFileAttributes\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1222\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1222\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"System Security\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-114\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to obtains specified information about the security of a file or directory (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"RevertToSelf\\\" (Indicator: \\\"RevertToSelf\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetFileSecurityW\\\" (Indicator: \\\"GetFileSecurityW\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"GetSecurityDescriptorOwner\\\" (Indicator: \\\"GetSecurityDescriptorOwner\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"RevertToSelf\\\" (Indicator: \\\"RevertToSelf\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetFileSecurityW\\\" (Indicator: \\\"GetFileSecurityW\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"GetSecurityDescriptorOwner\\\" (Indicator: \\\"GetSecurityDescriptorOwner\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134/001\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"System Security\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-230\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to delete registry key/value (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"RegDeleteValueW\\\" (Indicator: \\\"RegDeleteValue\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"RegDeleteKeyExW\\\" (Indicator: \\\"RegDeleteKey\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"RegDeleteValueW\\\" (Indicator: \\\"RegDeleteValue\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"RegDeleteKeyExW\\\" (Indicator: \\\"RegDeleteKey\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1112\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1112\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"System Security\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-402\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to modify process attributes (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"InitializeProcThreadAttributeList\\\" (Indicator: \\\"InitializeProcThreadAttributeList\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"UpdateProcThreadAttribute\\\" (Indicator: \\\"UpdateProcThreadAttribute\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"InitializeProcThreadAttributeList\\\" (Indicator: \\\"InitializeProcThreadAttributeList\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"UpdateProcThreadAttribute\\\" (Indicator: \\\"UpdateProcThreadAttribute\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1562.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1562/001\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"System Security\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-168\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to create process with token (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"CreateProcessAsUserW\\\" (Indicator: \\\"CreateProcessAsUser\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134.002\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134/002\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"System Security\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-535\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to write files (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"WriteFile\\\" (Indicator: \\\"WriteFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"WriteFile\\\" (Indicator: \\\"WriteFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1105\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1105\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"System Security\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-308\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to delete files/directories (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"DeleteFileW\\\" (Indicator: \\\"DeleteFile\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"RemoveDirectoryW\\\" (Indicator: \\\"RemoveDirectory\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"DeleteFileW\\\" (Indicator: \\\"DeleteFile\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\\n Found reference to API \\\"RemoveDirectoryW\\\" (Indicator: \\\"RemoveDirectory\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1070.004\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1070/004\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"System Security\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-316\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to terminate a process (API string)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found reference to API \\\"TerminateProcess\\\" (Indicator: \\\"TerminateProcess\\\"; File: \\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\")\\n Found reference to API \\\"TerminateProcess\\\" (Indicator: \\\"TerminateProcess\\\"; Source: \\\"00000000-00004716.00000000.77972.49307000.00000002.mdmp, 00000000-00004716.00000001.79890.49307000.00000002.mdmp, 00000000-00004716.00000002.81813.49307000.00000002.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1489\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1489\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"System Security\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-87\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Imports system security related APIs\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Observed import api \\\"GetFileSecurityW\\\" which can \\\"Obtains specified information about the security of a file or directory\\\" [Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin]\\n Observed import api \\\"GetSecurityDescriptorOwner\\\" which can \\\"Retrieves the owner information from a security descriptor\\\" [Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin]\\n Observed import api \\\"RevertToSelf\\\" which can \\\"Terminates the impersonation of a client application\\\" [Source: 935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin]\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1134.001\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1134/001\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"System Security\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-474\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to access device drivers\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Found string \\\"\\\\Device\\\\HarddiskVolume2\\\\cmd.exe\\\" (Indicator: \\\"\\\\Device\\\\\\\"; Source: \\\"00000000-00004716.00000000.77972.69D30000.00000004.mdmp, 00000000-00004716.00000001.79890.69D30000.00000004.mdmp, 00000000-00004716.00000002.81813.69D30000.00000004.mdmp\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1543.003\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1543/003\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"External Systems\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"avtest-1\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 12,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 10,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Sample was identified as clean by Antivirus engines\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"0/71 Antivirus vendors marked sample as malicious (0% detection rate)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"External System\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"suspicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-92\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 5,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"PE file has unusual entropy resources\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" has resource with unusual entropy \u00a0\\\"RT_ICON:7.85051980666\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1027.002\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1027/002\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"suspicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Unusual Characteristics\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"hooks-8\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 11,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 10,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Installs hooks/patches the running process\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.exe\\\" wrote bytes \\\"e0e8c4d7f97f0000\\\" to virtual address \\\"0x4932E000\\\" (part of module \\\"CMD.EXE\\\")\\n \\\"cmd.exe\\\" wrote bytes \\\"a09d036a5b010000608e036a5b01000090b7016a5b010000a090036a5b010000508d016a5b010000502e016a5b01000020c4036a5b01000070bb036a5b01000080bc036a5b0100004078046a5b010000a0ba036a5b0100000088036a5b010000\\\" to virtual address \\\"0xE7D74030\\\" (part of module \\\"GDI32.DLL\\\")\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hook Detection\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1056.004\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1056/004\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"suspicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Unusual Characteristics\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-1\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Imports suspicious APIs\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"UnhandledExceptionFilter\\n GetDriveTypeW\\n GetFileAttributesW\\n GetFileSize\\n CreateDirectoryW\\n DeleteFileW\\n WriteFile\\n FindNextFileW\\n FindFirstFileW\\n FindFirstFileExW\\n GetFileAttributesExW\\n CreateFileW\\n DeviceIoControl\\n CopyFileW\\n GetProcAddress\\n LoadLibraryExW\\n GetModuleFileNameW\\n GetModuleHandleW\\n VirtualAlloc\\n ReadProcessMemory\\n GetCommandLineW\\n TerminateProcess\\n CreateProcessW\\n GetStartupInfoW\\n CreateProcessAsUserW\\n RegCreateKeyExW\\n RegDeleteValueW\\n RegCloseKey\\n RegEnumKeyExW\\n RegOpenKeyExW\\n RegDeleteKeyExW\\n Sleep\\n GetTickCount\\n NtQueryInformationToken\\n NtQueryInformationProcess\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1106\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1106\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"suspicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Reverse Engineering\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-6\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"PE file has unusual entropy sections\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \".didat with unusual entropies 0.907093089296\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1027.002\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1027/002\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"malicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Detection/Stealthyness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"target-94\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 9,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Found a system process name at an unusual pathway\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Process \\\"cmd.exe\\\" has a system process name but is not located in a Windows (sub-)directory (UID: 00000000-00004716)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Monitored Target\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1036.005\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/techniques/T1036/005\"\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0]\n \u00a0},\n \u00a0{\n \u00a0 \u00a0\"classification_tags\": [],\n \u00a0 \u00a0\"tags\": [],\n \u00a0 \u00a0\"submissions\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"60f5dadb3ddbd71a493b4e50\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"file\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2021-07-19T20:04:43+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"60e87e8ed717cf14e5771f4f\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"file\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2021-07-09T16:51:26+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5f196598c665454d4960c94d\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"file\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2020-07-23T10:25:28+00:00\"\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0],\n \u00a0 \u00a0\"machine_learning_models\": [],\n \u00a0 \u00a0\"crowdstrike_ai\": {\n \u00a0 \u00a0 \u00a0\"executable_process_memory_analysis\": [],\n \u00a0 \u00a0 \u00a0\"analysis_related_urls\": []\n \u00a0 \u00a0},\n \u00a0 \u00a0\"job_id\": null,\n \u00a0 \u00a0\"environment_id\": null,\n \u00a0 \u00a0\"environment_description\": \"Static Analysis\",\n \u00a0 \u00a0\"size\": 232960,\n \u00a0 \u00a0\"type\": \"PE32+ executable (console) x86-64, for MS Windows\",\n \u00a0 \u00a0\"type_short\": [\n \u00a0 \u00a0 \u00a0\"peexe\",\n \u00a0 \u00a0 \u00a0\"64bits\",\n \u00a0 \u00a0 \u00a0\"executable\"\n \u00a0 \u00a0],\n \u00a0 \u00a0\"target_url\": null,\n \u00a0 \u00a0\"state\": \"SUCCESS\",\n \u00a0 \u00a0\"error_type\": null,\n \u00a0 \u00a0\"error_origin\": null,\n \u00a0 \u00a0\"submit_name\": \"file\",\n \u00a0 \u00a0\"md5\": \"f4f684066175b77e0c3a000549d2922c\",\n \u00a0 \u00a0\"sha1\": \"99ae9c73e9bee6f9c76d6f4093a9882df06832cf\",\n \u00a0 \u00a0\"sha256\": \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2\",\n \u00a0 \u00a0\"sha512\": \"fe8f0593cc335ad28eb90211bc4ff01a3d2992cffb3877d04cefede9ef94afeb1a7d7874dd0c0ae04eaf8308291d5a4d879e6ecf6fe2b8d0ff1c3ac7ef143206\",\n \u00a0 \u00a0\"ssdeep\": null,\n \u00a0 \u00a0\"imphash\": null,\n \u00a0 \u00a0\"entrypoint\": null,\n \u00a0 \u00a0\"entrypoint_section\": null,\n \u00a0 \u00a0\"image_base\": null,\n \u00a0 \u00a0\"subsystem\": null,\n \u00a0 \u00a0\"image_file_characteristics\": [],\n \u00a0 \u00a0\"dll_characteristics\": [],\n \u00a0 \u00a0\"major_os_version\": null,\n \u00a0 \u00a0\"minor_os_version\": null,\n \u00a0 \u00a0\"av_detect\": 0,\n \u00a0 \u00a0\"vx_family\": null,\n \u00a0 \u00a0\"url_analysis\": false,\n \u00a0 \u00a0\"analysis_start_time\": \"2020-07-23T10:25:28+00:00\",\n \u00a0 \u00a0\"threat_score\": null,\n \u00a0 \u00a0\"interesting\": false,\n \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0\"verdict\": \"no specific threat\",\n \u00a0 \u00a0\"certificates\": [],\n \u00a0 \u00a0\"is_certificates_valid\": null,\n \u00a0 \u00a0\"certificates_validation_message\": null,\n \u00a0 \u00a0\"domains\": [],\n \u00a0 \u00a0\"compromised_hosts\": [],\n \u00a0 \u00a0\"hosts\": [],\n \u00a0 \u00a0\"total_network_connections\": 0,\n \u00a0 \u00a0\"total_processes\": 0,\n \u00a0 \u00a0\"total_signatures\": 0,\n \u00a0 \u00a0\"extracted_files\": [],\n \u00a0 \u00a0\"file_metadata\": null,\n \u00a0 \u00a0\"processes\": [],\n \u00a0 \u00a0\"mitre_attcks\": [],\n \u00a0 \u00a0\"network_mode\": \"default\",\n \u00a0 \u00a0\"signatures\": []\n \u00a0},\n \u00a0{\n \u00a0 \u00a0\"classification_tags\": [],\n \u00a0 \u00a0\"tags\": [],\n \u00a0 \u00a0\"submissions\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"60195513efa3090ef70210f9\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"utilman.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2021-02-02T13:35:15+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5fd594e5fbef250536222759\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2020-12-13T04:13:25+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5f75727102a5f179cd29069e\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2020-10-01T06:08:49+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5ec0ceb2d7ce6a2712303213\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"Utilman.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2020-05-17T05:42:10+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5e53273fb30de355842896a2\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2020-02-24T01:30:39+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5d288eb0038838a74cfa9906\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-07-12T13:44:16+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5d2500bd0288388e538437b1\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-07-09T21:01:49+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5cbea1b4038838399c0365ff\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-04-23T05:25:08+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5c35e7b37ca3e11e9f79e9a4\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"sethc.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-01-09T06:23:15-06:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5c35cef37ca3e1571e6b9436\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"sethc.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-01-09T04:37:39-06:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5c35cdce7ca3e1550a1e6a92\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"sethc.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-01-09T04:32:46-06:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5b577fba7ca3e13656490373\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-07-24T14:36:26-05:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5b5601b37ca3e171691d73e2\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-07-23T11:26:27-05:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5b0e04857ca3e14c8f62c6fb\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-05-29T20:55:17-05:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5ad854a47ca3e1453f07bc82\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-04-19T03:34:44-05:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5ab269537ca3e101fb04a953\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-03-21T09:16:51-05:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5ab0cffe7ca3e12af23357d3\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-03-20T04:10:22-05:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5a94e29e7ca3e122510713e2\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-02-26T22:46:22-06:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5a26f15e7ca3e1169435c782\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2017-12-05T13:19:58-06:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5a26f0c47ca3e1158b6ee0e2\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2017-12-05T13:17:24-06:00\"\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0],\n \u00a0 \u00a0\"machine_learning_models\": [],\n \u00a0 \u00a0\"crowdstrike_ai\": {\n \u00a0 \u00a0 \u00a0\"executable_process_memory_analysis\": [],\n \u00a0 \u00a0 \u00a0\"analysis_related_urls\": []\n \u00a0 \u00a0},\n \u00a0 \u00a0\"job_id\": \"58593319aac2edc56d351531\",\n \u00a0 \u00a0\"environment_id\": 100,\n \u00a0 \u00a0\"environment_description\": \"Windows 7 32 bit\",\n \u00a0 \u00a0\"size\": 232960,\n \u00a0 \u00a0\"type\": \"PE32+ executable (console) x86-64, for MS Windows\",\n \u00a0 \u00a0\"type_short\": [\n \u00a0 \u00a0 \u00a0\"peexe\",\n \u00a0 \u00a0 \u00a0\"64bits\",\n \u00a0 \u00a0 \u00a0\"executable\"\n \u00a0 \u00a0],\n \u00a0 \u00a0\"target_url\": null,\n \u00a0 \u00a0\"state\": \"SUCCESS\",\n \u00a0 \u00a0\"error_type\": null,\n \u00a0 \u00a0\"error_origin\": null,\n \u00a0 \u00a0\"submit_name\": \"cmd.exe\",\n \u00a0 \u00a0\"md5\": \"f4f684066175b77e0c3a000549d2922c\",\n \u00a0 \u00a0\"sha1\": \"99ae9c73e9bee6f9c76d6f4093a9882df06832cf\",\n \u00a0 \u00a0\"sha256\": \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2\",\n \u00a0 \u00a0\"sha512\": \"fe8f0593cc335ad28eb90211bc4ff01a3d2992cffb3877d04cefede9ef94afeb1a7d7874dd0c0ae04eaf8308291d5a4d879e6ecf6fe2b8d0ff1c3ac7ef143206\",\n \u00a0 \u00a0\"ssdeep\": \"3072:bkd4COZG6/A1tO1Y6TbkX2FtynroeJ/MEJoSsasbLLkhyjyGe:bkuC9+Af0Y6TbbFtkoeJk1KsfLXm\",\n \u00a0 \u00a0\"imphash\": \"3062ed732d4b25d1c64f084dac97d37a\",\n \u00a0 \u00a0\"entrypoint\": \"0x140015190\",\n \u00a0 \u00a0\"entrypoint_section\": \".text\",\n \u00a0 \u00a0\"image_base\": null,\n \u00a0 \u00a0\"subsystem\": null,\n \u00a0 \u00a0\"image_file_characteristics\": [],\n \u00a0 \u00a0\"dll_characteristics\": [],\n \u00a0 \u00a0\"major_os_version\": null,\n \u00a0 \u00a0\"minor_os_version\": null,\n \u00a0 \u00a0\"av_detect\": 0,\n \u00a0 \u00a0\"vx_family\": null,\n \u00a0 \u00a0\"url_analysis\": false,\n \u00a0 \u00a0\"analysis_start_time\": \"2020-02-24T01:30:48+00:00\",\n \u00a0 \u00a0\"threat_score\": 30,\n \u00a0 \u00a0\"interesting\": false,\n \u00a0 \u00a0\"threat_level\": 3,\n \u00a0 \u00a0\"verdict\": \"no verdict\",\n \u00a0 \u00a0\"certificates\": [],\n \u00a0 \u00a0\"is_certificates_valid\": null,\n \u00a0 \u00a0\"certificates_validation_message\": null,\n \u00a0 \u00a0\"domains\": [],\n \u00a0 \u00a0\"compromised_hosts\": [],\n \u00a0 \u00a0\"hosts\": [],\n \u00a0 \u00a0\"total_network_connections\": 0,\n \u00a0 \u00a0\"total_processes\": 1,\n \u00a0 \u00a0\"total_signatures\": 14,\n \u00a0 \u00a0\"extracted_files\": [],\n \u00a0 \u00a0\"file_metadata\": null,\n \u00a0 \u00a0\"processes\": [],\n \u00a0 \u00a0\"mitre_attcks\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"System Time Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1124\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/wiki/Technique/T1124\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"File and Directory Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/wiki/Technique/T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0],\n \u00a0 \u00a0\"network_mode\": \"default\",\n \u00a0 \u00a0\"signatures\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-7\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains PDB pathways\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.pdb\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Reverse Engineering\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-4\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to register a top-level exception handler (often used as anti-debugging trick)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"SetUnhandledExceptionFilter@api-ms-win-core-errorhandling-l1-1-1.dll at 43727-268-00000001400151E4\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-49\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to query the system locale\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"GetUserDefaultLCID@api-ms-win-core-localization-l1-2-1.dll at 43727-287-00000001400069BC\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-2\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to query machine time\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-284-0000000140002BA0\\n GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-285-000000014001F53C\\n GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-296-00000001400020C8\\n GetLocalTime@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-993-000000014001F6C3\\n GetSystemTimeAsFileTime@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-599-00000001400156B4\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1124\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/wiki/Technique/T1124\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-3\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to query the machine version\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"GetVersion@api-ms-win-core-sysinfo-l1-2-1.dll at 43727-439-0000000140001008\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-37\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to query volume size\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"GetDiskFreeSpaceExW@api-ms-win-core-file-l1-2-1.dll at 43727-485-000000014002542C\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/wiki/Technique/T1083\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-31\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Possibly tries to detect the presence of a debugger\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-314-000000014000BC30\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-316-0000000140008FA0\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-270-000000014000B4A0\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-271-000000014000B530\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-277-0000000140011840\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-297-000000014000E278\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-298-000000014000E2EC\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-305-0000000140005C6C\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-661-00000001400016F0\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-331-0000000140014D2C\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-355-0000000140005954\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-366-00000001400032FC\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-383-000000014000D360\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-441-000000014000D110\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-511-000000014000B170\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-523-000000014000BCE0\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-588-0000000140006418\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-596-000000014001168C\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-605-0000000140014190\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 43727-607-0000000140014044\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Network Related\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-3\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 10,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Found potential URL in binary/memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Pattern match: \\\"http://schemas.microsoft.com/SMI/2005/WindowsSettings\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"External Systems\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"avtest-1\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 12,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 10,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Sample was identified as clean by Antivirus engines\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"0/68 Antivirus vendors marked sample as malicious (0% detection rate)\\n 0/22 Antivirus vendors marked sample as malicious (0% detection rate)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"External System\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"suspicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Unusual Characteristics\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-60\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 10,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"PE file contains unusual section name\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" has a section named \\\".didat\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"suspicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Unusual Characteristics\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-1\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Imports suspicious APIs\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"UnhandledExceptionFilter\\n GetDriveTypeW\\n GetFileAttributesW\\n GetFileSize\\n CreateDirectoryW\\n DeleteFileW\\n WriteFile\\n FindNextFileW\\n FindFirstFileW\\n FindFirstFileExW\\n GetFileAttributesExW\\n CreateFileW\\n DeviceIoControl\\n CopyFileW\\n GetProcAddress\\n LoadLibraryExW\\n GetModuleFileNameW\\n GetModuleHandleW\\n VirtualAlloc\\n ReadProcessMemory\\n GetCommandLineW\\n TerminateProcess\\n CreateProcessW\\n GetStartupInfoW\\n CreateProcessAsUserW\\n RegCreateKeyExW\\n RegDeleteValueW\\n RegCloseKey\\n RegEnumKeyExW\\n RegOpenKeyExW\\n RegDeleteKeyExW\\n Sleep\\n GetTickCount\\n NtQueryInformationToken\\n NtQueryInformationProcess\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"suspicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Detection/Stealthyness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-42\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Possibly tries to hide a process launching it with different user credentials\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"CreateProcessAsUserW@api-ms-win-core-processthreads-l1-1-2.dll at 43727-828-000000014000EFFE\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"malicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-21\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 8,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to start/interact with device drivers\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"DeviceIoControl@api-ms-win-core-io-l1-1-1.dll at 43727-611-0000000140013690\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"malicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Unusual Characteristics\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-22\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 5,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains native function calls\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"NtFsControlFile@ntdll.dll at 43727-309-00000001400268C4\\n NtCancelSynchronousIoFile@ntdll.dll at 43727-532-00000001400227A0\\n NtOpenThreadToken@ntdll.dll at 43727-585-00000001400029C0\\n NtQueryInformationToken@ntdll.dll at 43727-586-0000000140002A84\\n NtQueryInformationToken@ntdll.dll at 43727-587-0000000140002AD4\\n NtQueryInformationProcess@ntdll.dll at 43727-630-0000000140004480\\n NtOpenFile@ntdll.dll at 43727-643-00000001400042DC\\n NtQueryVolumeInformationFile@ntdll.dll at 43727-644-00000001400043D8\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0]\n \u00a0},\n \u00a0{\n \u00a0 \u00a0\"classification_tags\": [],\n \u00a0 \u00a0\"tags\": [],\n \u00a0 \u00a0\"submissions\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5f85aeb7dbdeb607bb5e34eb\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"kiss.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2020-10-13T13:42:15+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5d8b4dbf028838d6417f6d53\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-09-25T11:21:35+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5d8b4db702883891837f6b95\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-09-25T11:21:27+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5d4846eb0288385a279299b7\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-08-05T15:10:35+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5d250066038838da118437b2\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-07-09T21:00:22+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5ce828c5038838ca61130390\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-05-24T17:24:21+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5cb263840388384184827cf6\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"sethc.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2019-04-13T22:32:36+00:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5b69b6167ca3e129e233b695\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-08-07T10:09:10-05:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5b576e3e7ca3e1632e094913\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-07-24T13:21:50-05:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5b576ce57ca3e15a46380635\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-07-24T13:16:05-05:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5ab0d1057ca3e12dbd5d09f2\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-03-20T04:14:45-05:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5a7c75817ca3e13c9b2ebf52\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2018-02-08T10:06:25-06:00\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"submission_id\": \"5a34f2a27ca3e13531789a94\",\n \u00a0 \u00a0 \u00a0 \u00a0\"filename\": \"cmd.exe\",\n \u00a0 \u00a0 \u00a0 \u00a0\"url\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"created_at\": \"2017-12-16T04:17:06-06:00\"\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0],\n \u00a0 \u00a0\"machine_learning_models\": [],\n \u00a0 \u00a0\"crowdstrike_ai\": {\n \u00a0 \u00a0 \u00a0\"executable_process_memory_analysis\": [],\n \u00a0 \u00a0 \u00a0\"analysis_related_urls\": []\n \u00a0 \u00a0},\n \u00a0 \u00a0\"job_id\": \"5a34f2a27ca3e13531789a95\",\n \u00a0 \u00a0\"environment_id\": 120,\n \u00a0 \u00a0\"environment_description\": \"Windows 7 64 bit\",\n \u00a0 \u00a0\"size\": 232960,\n \u00a0 \u00a0\"type\": \"PE32+ executable (console) x86-64, for MS Windows\",\n \u00a0 \u00a0\"type_short\": [\n \u00a0 \u00a0 \u00a0\"peexe\",\n \u00a0 \u00a0 \u00a0\"64bits\",\n \u00a0 \u00a0 \u00a0\"executable\"\n \u00a0 \u00a0],\n \u00a0 \u00a0\"target_url\": null,\n \u00a0 \u00a0\"state\": \"SUCCESS\",\n \u00a0 \u00a0\"error_type\": null,\n \u00a0 \u00a0\"error_origin\": null,\n \u00a0 \u00a0\"submit_name\": \"cmd.exe\",\n \u00a0 \u00a0\"md5\": \"f4f684066175b77e0c3a000549d2922c\",\n \u00a0 \u00a0\"sha1\": \"99ae9c73e9bee6f9c76d6f4093a9882df06832cf\",\n \u00a0 \u00a0\"sha256\": \"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2\",\n \u00a0 \u00a0\"sha512\": \"fe8f0593cc335ad28eb90211bc4ff01a3d2992cffb3877d04cefede9ef94afeb1a7d7874dd0c0ae04eaf8308291d5a4d879e6ecf6fe2b8d0ff1c3ac7ef143206\",\n \u00a0 \u00a0\"ssdeep\": \"3072:bkd4COZG6/A1tO1Y6TbkX2FtynroeJ/MEJoSsasbLLkhyjyGe:bkuC9+Af0Y6TbbFtkoeJk1KsfLXm\",\n \u00a0 \u00a0\"imphash\": \"3062ed732d4b25d1c64f084dac97d37a\",\n \u00a0 \u00a0\"entrypoint\": \"0x140015190\",\n \u00a0 \u00a0\"entrypoint_section\": \".text\",\n \u00a0 \u00a0\"image_base\": null,\n \u00a0 \u00a0\"subsystem\": null,\n \u00a0 \u00a0\"image_file_characteristics\": [],\n \u00a0 \u00a0\"dll_characteristics\": [],\n \u00a0 \u00a0\"major_os_version\": null,\n \u00a0 \u00a0\"minor_os_version\": null,\n \u00a0 \u00a0\"av_detect\": 0,\n \u00a0 \u00a0\"vx_family\": null,\n \u00a0 \u00a0\"url_analysis\": false,\n \u00a0 \u00a0\"analysis_start_time\": \"2019-09-25T11:21:32+00:00\",\n \u00a0 \u00a0\"threat_score\": 30,\n \u00a0 \u00a0\"interesting\": false,\n \u00a0 \u00a0\"threat_level\": 3,\n \u00a0 \u00a0\"verdict\": \"no verdict\",\n \u00a0 \u00a0\"certificates\": [],\n \u00a0 \u00a0\"is_certificates_valid\": null,\n \u00a0 \u00a0\"certificates_validation_message\": null,\n \u00a0 \u00a0\"domains\": [],\n \u00a0 \u00a0\"compromised_hosts\": [],\n \u00a0 \u00a0\"hosts\": [],\n \u00a0 \u00a0\"total_network_connections\": 0,\n \u00a0 \u00a0\"total_processes\": 1,\n \u00a0 \u00a0\"total_signatures\": 14,\n \u00a0 \u00a0\"extracted_files\": [],\n \u00a0 \u00a0\"file_metadata\": null,\n \u00a0 \u00a0\"processes\": [],\n \u00a0 \u00a0\"mitre_attcks\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"File and Directory Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/wiki/Technique/T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"tactic\": \"Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"technique\": \"System Time Discovery\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1124\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/wiki/Technique/T1124\",\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"malicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers_count\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"suspicious_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers_count\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"informative_identifiers\": [],\n \u00a0 \u00a0 \u00a0 \u00a0\"parent\": null\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0],\n \u00a0 \u00a0\"network_mode\": \"default\",\n \u00a0 \u00a0\"signatures\": [\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-7\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains PDB pathways\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"cmd.pdb\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Reverse Engineering\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-4\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to register a top-level exception handler (often used as anti-debugging trick)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"SetUnhandledExceptionFilter@api-ms-win-core-errorhandling-l1-1-1.dll at 12264-268-00000001400151E4\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-31\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Possibly tries to detect the presence of a debugger\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-314-000000014000BC30\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-316-0000000140008FA0\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-270-000000014000B4A0\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-271-000000014000B530\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-277-0000000140011840\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-331-0000000140014D2C\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-297-000000014000E278\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-298-000000014000E2EC\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-305-0000000140005C6C\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-383-000000014000D360\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-355-0000000140005954\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-366-00000001400032FC\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-441-000000014000D110\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-511-000000014000B170\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-523-000000014000BCE0\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-588-0000000140006418\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-596-000000014001168C\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-605-0000000140014190\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-623-00000001400123F0\\n GetProcessHeap@api-ms-win-core-heap-l1-2-0.dll at 12264-607-0000000140014044\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-37\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to query volume size\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"GetDiskFreeSpaceExW@api-ms-win-core-file-l1-2-1.dll at 12264-485-000000014002542C\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1083\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/wiki/Technique/T1083\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-2\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to query machine time\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-284-0000000140002BA0\\n GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-285-000000014001F53C\\n GetSystemTime@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-296-00000001400020C8\\n GetSystemTimeAsFileTime@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-599-00000001400156B4\\n GetLocalTime@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-993-000000014001F6C3\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": \"T1124\",\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": \"https://attack.mitre.org/wiki/Technique/T1124\"\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-3\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to query the machine version\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"GetVersion@api-ms-win-core-sysinfo-l1-2-1.dll at 12264-439-0000000140001008\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Environment Awareness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-49\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to query the system locale\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"GetUserDefaultLCID@api-ms-win-core-localization-l1-2-1.dll at 12264-287-00000001400069BC\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Network Related\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"string-3\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 10,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Found potential URL in binary/memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"Pattern match: \\\"http://schemas.microsoft.com/SMI/2005/WindowsSettings\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"File/Memory\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"informative\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"External Systems\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"avtest-1\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 12,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 10,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Sample was identified as clean by Antivirus engines\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"0/16 Antivirus vendors marked sample as malicious (0% detection rate)\\n 0/70 Antivirus vendors marked sample as malicious (0% detection rate)\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"External System\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"suspicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Unusual Characteristics\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-60\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 10,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"PE file contains unusual section name\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"\\\"935c1861df1f4018d698e8b65abfa02d7e9037d8f68ca3c2065b6ca165d44ad2.bin\\\" has a section named \\\".didat\\\"\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"suspicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Unusual Characteristics\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"static-1\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 0,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Imports suspicious APIs\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"UnhandledExceptionFilter\\n GetDriveTypeW\\n GetFileAttributesW\\n GetFileSize\\n CreateDirectoryW\\n DeleteFileW\\n WriteFile\\n FindNextFileW\\n FindFirstFileW\\n FindFirstFileExW\\n GetFileAttributesExW\\n CreateFileW\\n DeviceIoControl\\n CopyFileW\\n GetProcAddress\\n LoadLibraryExW\\n GetModuleFileNameW\\n GetModuleHandleW\\n VirtualAlloc\\n ReadProcessMemory\\n GetCommandLineW\\n TerminateProcess\\n CreateProcessW\\n GetStartupInfoW\\n CreateProcessAsUserW\\n RegCreateKeyExW\\n RegDeleteValueW\\n RegCloseKey\\n RegEnumKeyExW\\n RegOpenKeyExW\\n RegDeleteKeyExW\\n Sleep\\n GetTickCount\\n NtQueryInformationToken\\n NtQueryInformationProcess\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Static Parser\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"suspicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Anti-Detection/Stealthyness\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-42\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 3,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Possibly tries to hide a process launching it with different user credentials\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"CreateProcessAsUserW@api-ms-win-core-processthreads-l1-1-2.dll at 12264-828-000000014000EFFE\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"malicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"General\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-21\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 8,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains ability to start/interact with device drivers\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"DeviceIoControl@api-ms-win-core-io-l1-1-1.dll at 12264-611-0000000140013690\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0},\n \u00a0 \u00a0 \u00a0{\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level\": 2,\n \u00a0 \u00a0 \u00a0 \u00a0\"threat_level_human\": \"malicious\",\n \u00a0 \u00a0 \u00a0 \u00a0\"category\": \"Unusual Characteristics\",\n \u00a0 \u00a0 \u00a0 \u00a0\"identifier\": \"stream-22\",\n \u00a0 \u00a0 \u00a0 \u00a0\"type\": 1,\n \u00a0 \u00a0 \u00a0 \u00a0\"relevance\": 5,\n \u00a0 \u00a0 \u00a0 \u00a0\"name\": \"Contains native function calls\",\n \u00a0 \u00a0 \u00a0 \u00a0\"description\": \"NtFsControlFile@ntdll.dll at 12264-309-00000001400268C4\\n NtCancelSynchronousIoFile@ntdll.dll at 12264-532-00000001400227A0\\n NtOpenProcessToken@ntdll.dll at 12264-585-00000001400029C0\\n NtQueryInformationToken@ntdll.dll at 12264-586-0000000140002A84\\n NtQueryInformationToken@ntdll.dll at 12264-587-0000000140002AD4\\n NtSetInformationProcess@ntdll.dll at 12264-630-0000000140004480\\n NtOpenFile@ntdll.dll at 12264-643-00000001400042DC\\n NtQueryVolumeInformationFile@ntdll.dll at 12264-644-00000001400043D8\",\n \u00a0 \u00a0 \u00a0 \u00a0\"origin\": \"Hybrid Analysis Technology\",\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"capec_id\": null,\n \u00a0 \u00a0 \u00a0 \u00a0\"attck_id_wiki\": null\n \u00a0 \u00a0 \u00a0}\n \u00a0 \u00a0]\n \u00a0}\n]\n</code></pre>"},{"location":"5-integrations/api-integrations/ip-geolocation/","title":"IP Geolocation","text":"<p>No Subscription Required</p> <p>LimaCharlie provides access to this integration free of charge for all users, so no additional subscription is required.</p> <p>With the <code>ip-geo</code> add-on subscribed, it can be used as an API-based lookup.</p> <pre><code>event: CONNECTED\nop: lookup\nresource: lcr://api/ip-geo\npath: routing/ext_ip\nmetadata_rules:\n  op: is\n  value: true\n  path: country/is_in_european_union\n</code></pre> <p>Step-by-step, this rule will do the following:</p> <ul> <li>Upon seeing a <code>CONNECTED</code> event, retrieve the <code>routing/ext_ip</code> value and send it to MaxMind via the <code>api/ip-geo</code> resource</li> <li>Upon receiving a response from <code>api/ip-geo</code>, evaluate it using <code>metadata_rules</code> to see if the country associated with the IP is located in the EU</li> </ul> <p>The format of the metadata returned is documented here and looks like this:</p> <pre><code>{\n  \"country\": {\n    \"geoname_id\": 2750405,\n    \"iso_code\": \"NL\",\n    \"is_in_european_union\": true,\n    \"names\": {\n      \"ru\": \"\\u041d\\u0438\\u0434\\u0435\\u0440\\u043b\\u0430\\u043d\\u0434\\u044b\",\n      \"fr\": \"Pays-Bas\",\n      \"en\": \"Netherlands\",\n      \"de\": \"Niederlande\",\n      \"zh-CN\": \"\\u8377\\u5170\",\n      \"pt-BR\": \"Holanda\",\n      \"ja\": \"\\u30aa\\u30e9\\u30f3\\u30c0\\u738b\\u56fd\",\n      \"es\": \"Holanda\"\n    }\n  },\n  \"location\": {\n    \"latitude\": 52.3824,\n    \"accuracy_radius\": 100,\n    \"time_zone\": \"Europe/Amsterdam\",\n    \"longitude\": 4.8995\n  },\n  \"continent\": {\n    \"geoname_id\": 6255148,\n    \"code\": \"EU\",\n    \"names\": {\n      \"ru\": \"\\u0415\\u0432\\u0440\\u043e\\u043f\\u0430\",\n      \"fr\": \"Europe\",\n      \"en\": \"Europe\",\n      \"de\": \"Europa\",\n      \"zh-CN\": \"\\u6b27\\u6d32\",\n      \"pt-BR\": \"Europa\",\n      \"ja\": \"\\u30e8\\u30fc\\u30ed\\u30c3\\u30d1\",\n      \"es\": \"Europa\"\n    }\n  },\n  \"registered_country\": {\n    \"geoname_id\": 2750405,\n    \"iso_code\": \"NL\",\n    \"is_in_european_union\": true,\n    \"names\": {\n      \"ru\": \"\\u041d\\u0438\\u0434\\u0435\\u0440\\u043b\\u0430\\u043d\\u0434\\u044b\",\n      \"fr\": \"Pays-Bas\",\n      \"en\": \"Netherlands\",\n      \"de\": \"Niederlande\",\n      \"zh-CN\": \"\\u8377\\u5170\",\n      \"pt-BR\": \"Holanda\",\n      \"ja\": \"\\u30aa\\u30e9\\u30f3\\u30c0\\u738b\\u56fd\",\n      \"es\": \"Holanda\"\n    }\n  }\n}\n</code></pre> <p>The geolocation data comes from GeoLite2 data created by MaxMind.</p>"},{"location":"5-integrations/api-integrations/pangea/","title":"Pangea","text":"<p>Pangea is a collection of API-based security services that can quickly be added to enrich data. Pangea is designed make it easy to add security into an application, but also perform lookups for various data types.</p> <p>LimaCharlie supports the following Pangea lookups:</p> <ul> <li>Domain</li> <li>Check malicious behavior on a domain</li> <li>File</li> <li>Check for malicious behavior on a file</li> <li>IP</li> <li>Check for malicious behavior on an IP</li> <li>URL</li> <li>Retrieve an intelligence report</li> <li>User</li> <li>Checks to see if any PII data or credentials have been exposed by an attack.</li> </ul>"},{"location":"5-integrations/api-integrations/pangea/#api-keys","title":"API Keys","text":"<p>Subscription Required</p> <p>A Pangea subscription is required to utilize this service. Pangea offers a $5 monthly credit for development purposes, provided the account balance is not negative.</p> <p>The Pangea API key (known as a token within the Pangea platform) is added via the integrations menu within LimaCharlie.</p> <p>The API key follows this format:</p> <pre><code>domain/token\n</code></pre> <p>Example:</p> <pre><code>aws.us.pangea.cloud/pts_7kb33fyz313372vuu5zgnotarealtoken\n</code></pre>"},{"location":"5-integrations/api-integrations/pangea/#domain","title":"Domain","text":"<p>The Domain Intel service allows you to retrieve intelligence about known domain names, giving you insight into the reputation of a domain.</p>"},{"location":"5-integrations/api-integrations/pangea/#rule","title":"Rule","text":"<pre><code>event: DNS_REQUEST\nop: lookup\npath: event/DOMAIN_NAME\nresource: lcr://api/pangea-domain-reputation\n</code></pre>"},{"location":"5-integrations/api-integrations/pangea/#api-response-data","title":"API Response Data","text":"<pre><code>{\n  \"api_pangea-domain-reputation\": {\n    \"category\": [\n      \"zerolist\"\n    ],\n    \"score\": 0,\n    \"verdict\": \"benign\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/api-integrations/pangea/#file-reputation","title":"File Reputation","text":"<p>The File Intel service enables you to submit a file's hash and get the file's attributes back - giving you insight into the disposition of the file.</p>"},{"location":"5-integrations/api-integrations/pangea/#dr-rule","title":"D&amp;R Rule","text":"<pre><code>event: NEW_PROCESS\nop: lookup\npath: event/HASH\nresource: lcr://api/pangea-file-reputation\n</code></pre>"},{"location":"5-integrations/api-integrations/pangea/#api-response-data_1","title":"API Response Data","text":"<pre><code>{\n  \"api_pangea-file-reputation\": {\n    \"category\": [\n      \"\"\n    ],\n    \"score\": 0,\n    \"verdict\": \"benign\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/api-integrations/pangea/#ip-reputation","title":"IP Reputation","text":"<p>The IP Intel service allows you to retrieve security information about known IP addresses that have been collected across the internet for several decades, giving you insight into the reputation of an IP.</p>"},{"location":"5-integrations/api-integrations/pangea/#dr-rule_1","title":"D&amp;R Rule","text":"<pre><code>event: DNS_REQUEST\nop: lookup\npath: routing/ext_ip\nresource: lcr://api/pangea-ip-reputation\n</code></pre>"},{"location":"5-integrations/api-integrations/pangea/#api-response-data_2","title":"API Response Data","text":"<pre><code>{\n  \"api_pangea-ip-reputation\": {\n    \"category\": [],\n    \"score\": -1,\n    \"verdict\": \"unknown\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/api-integrations/pangea/#url-reputation","title":"URL Reputation","text":"<p>The URL Intel service allows you to retrieve intelligence about known URLs, giving you insight into the reputation of a URL.</p>"},{"location":"5-integrations/api-integrations/pangea/#dr-rule_2","title":"D&amp;R Rule","text":"<pre><code>event: HTTP_REQUEST\nop: lookup\npath: event/URL\nresource: lcr://api/pangea-url-reputation\n</code></pre>"},{"location":"5-integrations/api-integrations/pangea/#api-response-data_3","title":"API Response Data","text":"<pre><code>{\n  \"api_pangea-url-reputation\": {\n    \"category\": [],\n    \"score\": 0,\n    \"verdict\": \"benign\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/api-integrations/pangea/#user","title":"User","text":"<p>The User Intel service allows you to check a large repository of breach data to see if a user's Personally Identifiable Data (PII) or credentials have been compromised.</p>"},{"location":"5-integrations/api-integrations/pangea/#dr-rule_3","title":"D&amp;R Rule","text":"<pre><code>event: USER_OBSERVED\nop: lookup\npath: event/USER_NAME\nresource: lcr://api/pangea-user-reputation\n</code></pre>"},{"location":"5-integrations/api-integrations/pangea/#api-response-data_4","title":"API Response Data","text":"<pre><code>{\n  \"api_pangea-user-reputation\": {\n    \"breach_count\": 0,\n    \"found_in_breach\": false\n  }\n}\n</code></pre>"},{"location":"5-integrations/api-integrations/virustotal/","title":"VirusTotal","text":""},{"location":"5-integrations/api-integrations/virustotal/#api-keys","title":"API Keys","text":"<p>The VirusTotal API key is added via the integrations menu within LimaCharlie.</p>"},{"location":"5-integrations/api-integrations/virustotal/#usage","title":"Usage","text":"<p>With the <code>vt</code> add-on subscribed and a VirusTotal API Key configured in the Integrations page, VirusTotal can be used as an API-based lookup.</p> <pre><code>event: CODE_IDENTITY\nop: lookup\npath: event/HASH\nresource: lcr://api/vt\nmetadata_rules:\n  op: is greater than\n  value: 1\n  path: /\n  length of: true\n</code></pre> <p>Step-by-step, this rule will do the following:</p> <ul> <li>Upon seeing a <code>CODE_IDENTITY</code> event, retrieve the <code>event/HASH</code> value and send it to VirusTotal via the <code>api/vt</code> resource.</li> <li>Upon receiving a response from <code>api/vt</code>, evaluate it using <code>metadata_rules</code> to see if the length of the response is greater than 1 (in this case meaning that more than 1 vendor reporting a hash is bad).</li> </ul>"},{"location":"5-integrations/api-integrations/virustotal/#related-articles","title":"Related Articles","text":"<ul> <li>VirusTotal Integration</li> <li>Extensions</li> </ul>"},{"location":"5-integrations/extensions/","title":"Extensions","text":"<p>Purpose-built tools for specific security workflows.</p>"},{"location":"5-integrations/extensions/#documentation","title":"Documentation","text":"<ul> <li>Using Extensions - Extension usage guide</li> </ul>"},{"location":"5-integrations/extensions/#see-also","title":"See Also","text":"<ul> <li>Using Extensions</li> <li>Building Extensions</li> </ul>"},{"location":"5-integrations/extensions/using-extensions/","title":"Using Extensions","text":""},{"location":"5-integrations/extensions/using-extensions/#components","title":"Components","text":"<p>Extensions can be interacted with using two main components:</p>"},{"location":"5-integrations/extensions/using-extensions/#configurations","title":"Configurations","text":"<p>Extension Configurations are records in Hive. Each Extension has its configuration in the Hive record of the same name in the <code>extension_configuration</code> Hive.</p> <p>These configurations are manipulated by simply storing the value in the record, LimaCharlie takes care of validating and notifying the Extension with the new value.</p> <p>Configurations are a great way of storing rarely-written settings for an Extension without the developer of the Extension having to manage secure storage for it.</p> <p>The structure of the configuration for a given Extension is published by the Extension via its \"schema\".</p> <p>Schemas are available through the Schema API or the LimaCharlie CLI: <code>limacharlie extension get_schema --help</code>.</p>"},{"location":"5-integrations/extensions/using-extensions/#requests","title":"Requests","text":"<p>Requests are, as the name implies, direct individual requests to an Extension. A request contains an \"action\" and a \"payload\" (JSON object) to be sent to the Extension. Some requests can be flagged to have the Extension impersonate the requester (identity and permissions) during execution.</p> <p>The \"action\" and \"payload\" entirely depends on the Extension it is destined to. The list of actions and individual payload structures available for an Extension is documented by each Extension using the \"schema\" they publish.</p> <p>Schemas are available through the Schema API or the LimaCharlie CLI: <code>limacharlie extension get_schema --help</code>.</p>"},{"location":"5-integrations/extensions/using-extensions/#interacting","title":"Interacting","text":""},{"location":"5-integrations/extensions/using-extensions/#interactively","title":"Interactively","text":"<p>The LimaCharlie webapp automatically displays a machine-generated user interface for each Extension based on the schema it publishes.</p>"},{"location":"5-integrations/extensions/using-extensions/#automation","title":"Automation","text":"<p>Detection &amp; Response Rules, the main automation mechanism in LimaCharlie can interact with Extensions using the <code>extension request</code> action in the Response component.</p>"},{"location":"5-integrations/extensions/using-extensions/#api","title":"API","text":"<p>Extensions can be interacted with using a few different APIs:</p> <ul> <li>Getting the schema for an Extension: https://api.limacharlie.io/static/swagger/#/Extension-Schema</li> <li>Making requests to an Extension: https://api.limacharlie.io/static/swagger/#/Extension-Request</li> </ul> <p>LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.</p>"},{"location":"5-integrations/extensions/cloud-cli/1password/","title":"1Password","text":"<p>The 1Password CLI brings 1Password to the terminal, allowing you to interact with a 1Password instance from LimaCharlie.</p> <p>This Extension makes use of 1Password's native CLI, which can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/1password/#1password-account-types","title":"1Password Account Types","text":"<p>Please note that some 1Password functionality is limited to 1Password Business. Please validate you have the correct type of account(s) to ensure that commands run.</p>"},{"location":"5-integrations/extensions/cloud-cli/1password/#example","title":"Example","text":"<p>Returns a list of all items the account has read access to by default.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    cloud: '{{ \"op\" }}'\n    command_line: '{{ \"item list\" }}'\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/1password/#credentials","title":"Credentials","text":"<p>To utilize 1Password's automated CLI capabilities, you will need to create and utilize a Service Account. More information can be found here.</p> <ul> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>serviceAccountToken\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/aws/","title":"AWS","text":"<p>AWS CLI is a unified tool that provides a consistent interface for interacting with AWS from the command line. With this component of the Cloud CLI Extension, you can interact with AWS directly from LimaCharlie.</p> <p>This extension makes use of AWS's native CLI tool, which can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/aws/#example","title":"Example","text":"<p>The following example would execute in response to AWS telemetry that 1) met certain criteria and 2) had an <code>instance_id</code> for an EC2 instance(s). The following response action would utilize the <code>.event.instance_id</code> to stop the corresponding EC2 instances.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    tool: '{{ \"aws\" }}'\n    command_tokens:\n      - ec2\n      - stop-instances\n      - '--instance-ids'\n      - '{{ .event.instance_id  }}'\n      - '--region'\n      - us-east-1\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/aws/#credentials","title":"Credentials","text":"<p>To utilize AWS CLI capabilities, you will need:</p> <ul> <li>You will need an AWS access key ID and AWS secret access key</li> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>accessKeyID/secretAccessKey\n</code></pre> <p>Documentation on creating and managing AWS access keys and other IAM components can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/azure/","title":"Azure","text":"<p>The Azure CLI is a set of commands used to create and manage Azure resources. With this component of the Cloud CLI Extension, you can interact with Azure directly from LimaCharlie.</p> <p>This extension makes use of the Azure CLI, which can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/azure/#example","title":"Example","text":"<p>The following example returns a list of virtual machines and their respective details in Azure.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    tool: '{{ \"az\" }}'\n    command_line: '{{ \"vm list\" }}'\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/azure/#credentials","title":"Credentials","text":"<p>To utilize the Azure CLI, you will need:</p> <ul> <li>An application and a service principal with the appropriate permissions and a client secret</li> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>appID/clientSecret/tenantID\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/digitalocean/","title":"DigitalOcean","text":"<p>The DigitalOcean CLI, or <code>doctl</code>, is the official CLI for the DigitalOcean API. With this component of the Cloud CLI Extension, you can interact with DigitalOcean directly from LimaCharlie.</p> <p>This extension makes use of DigitalOcean's official CLI tool, which can be found here. Reference documentation can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/digitalocean/#example","title":"Example","text":"<p>The following example of a response action will enumerate a list of compute droplets within a DigitalOcean instance.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    tool: '{{ \"doctl\" }}'\n    command_line: '{{ \"compute droplet list\" }}'\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/digitalocean/#credentials","title":"Credentials","text":"<p>To utilize <code>doctl</code> capabilities, you will need:</p> <ul> <li>A personal access token. More information on this can be found here.</li> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>personalAccessToken\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/github/","title":"GitHub","text":"<p>The GitHub CLI is a tool that brings GitHub to the terminal, allowing you to interact with and control Git accounts, repositories, organizations, and users from the CLI. With this component of the Cloud CLI Extension, you can interact with GitHub directly from LimaCharlie.</p> <p>This extension makes use of the GitHub CLI, which can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/github/#example","title":"Example","text":"<p>The following example returns a list of GitHub organizations.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    cloud: '{{ \"gh\" }}'\n    command_line: '{{ \"org list\" }}'\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/github/#credentials","title":"Credentials","text":"<p>To utilize the GitHub CLI, you will need:</p> <ul> <li>A personal access token</li> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>access_token\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/google-cloud/","title":"Google Cloud","text":"<p>The Google Cloud command line interface, or gcloud CLI, allows you to create and manage Google Cloud resources and services directly on the command line. With this component of the Cloud CLI Extension, you can interact with Google Cloud directly from LimaCharlie.</p> <p>This extension makes use of Google Cloud's native CLI tool, which can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/google-cloud/#example","title":"Example","text":"<p>The following example stops the specified GCP compute instance.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    tool: '{{ \"gcloud\" }}'\n    command_tokens:\n      - compute\n      - instances\n      - stop\n      - '{{ .routing.hostname }}'\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/google-cloud/#credentials","title":"Credentials","text":"<p>To utilize Google Cloud CLI capabilities, you will need:</p> <ul> <li>A GCP service account JSON key. More information on service account keys can be found here.</li> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>{\n    \"type\": \"\",\n    \"project_id\": \"\",\n    \"private_key_id\": \"\",\n    \"private_key\": \"\",\n    \"client_email\": \"\",\n    \"client_id\": \"\",\n    \"auth_uri\": \"\",\n    \"token_uri\": \"\",\n    \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n    \"client_x509_cert_url\": \"\",\n    \"universe_domain\": \"googleapis.com\"\n}\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/microsoft365/","title":"Microsoft 365","text":"<p>The CLI for Microsoft 365 is a tool created to help manage Microsoft 365 tenant(s) and SharePoint framework projects. With this component of the Cloud CLI Extension, you can interact with a Microsoft 365 tenant(s) directly from LimaCharlie.</p> <p>This extension makes use of the PnP Microsoft 365 CLI, which can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/microsoft365/#example","title":"Example","text":"<p>The following example disables the user account with the provided user ID.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    cloud: '{{ \"m365\" }}'\n    command_tokens:\n      - entra\n      - user\n      - set\n      - '--id'\n      - '{{ .event.user_id  }}'\n      - '--accountEnabled'\n      - false\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/microsoft365/#credentials","title":"Credentials","text":"<ul> <li>Per the Microsoft 365 CLI documentation, there are multiple login or authentication mechanisms available. The current LimaCharlie implementation utilizes a client secret for authentication. More information on provisioning client secrets can be found here.</li> <li>Upon invocation, LimaCharlie will first run the <code>m365 login</code> command with the credentials provided.</li> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>appID/clientSecret/tenantID\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/","title":"Okta","text":"<p>The Okta CLI allows you to interact with your Okta instance(s) via the command line. With this component of the Cloud CLI Extension, you can interact with Okta directly from LimaCharlie.</p> <p>This extension makes use of the Okta CLI, which can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example","title":"Example","text":"<p>The following example returns a list of registered Okta applications.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    cloud: '{{ \"okta\" }}'\n    command_line: '{{ \"apps\" }}'\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#credentials","title":"Credentials","text":"<p>To make use of the Okta CLI, you will need:</p> <ul> <li>An API key. More information about provisioning an API key can be found here.</li> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>okta_domain/api_key\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#available-commands","title":"Available Commands","text":"<p>All \"USERID\" fields require the Okta User ID, not the user's name</p>"},{"location":"5-integrations/extensions/cloud-cli/okta/#get-user-details","title":"Get User Details","text":"<p>Fetches a user from your Okta organization.</p>"},{"location":"5-integrations/extensions/cloud-cli/okta/#command","title":"Command","text":"<pre><code>user get USERID\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-input","title":"Example Input","text":"<pre><code>user get 00untroxqpl08VcNC5d7\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-output","title":"Example Output","text":"<pre><code>{\n  \"_links\": {\n    \"deactivate\": {\n      \"href\": \"https://dev-8675309.okta.com/api/v1/users/00up0nl0lftw7331WSz/lifecycle/deactivate\",\n      \"method\": \"POST\"\n    },\n    \"schema\": {\n      \"href\": \"https://dev-8675309.okta.com/api/v1/meta/schemas/user/otyn3jlrawrlmageyL2d7\"\n    },\n    \"self\": {\n      \"href\": \"https://dev-8675309.okta.com/api/v1/users/00up0nl0lftw7331WSz\"\n    },\n    \"type\": {\n      \"href\": \"https://dev-8675309.okta.com/api/v1/meta/types/user/otyn3jlrawrlmageyL2d7\"\n    },\n    \"unsuspend\": {\n      \"href\": \"https://dev-8675309.okta.com/api/v1/users/00up0nl0lftw7331WSz/lifecycle/unsuspend\",\n      \"method\": \"POST\"\n    }\n  },\n  \"activated\": \"2025-03-13T17:37:33Z\",\n  \"created\": \"2025-03-13T17:37:33Z\",\n  \"credentials\": {\n    \"password\": {},\n    \"provider\": {\n      \"name\": \"OKTA\",\n      \"type\": \"OKTA\"\n    }\n  },\n  \"id\": \"00up0nl0lftw7331WSz\",\n  \"lastUpdated\": \"2025-03-14T13:37:10Z\",\n  \"passwordChanged\": \"2025-03-13T17:37:33Z\",\n  \"profile\": {\n    \"email\": \"fake.user@limacharlie.com\",\n    \"firstName\": \"Fake\",\n    \"lastName\": \"User\",\n    \"login\": \"fake.user@limacharlie.com\",\n    \"mobilePhone\": null,\n    \"secondEmail\": null\n  },\n  \"status\": \"ACTIVE\",\n  \"statusChanged\": \"2025-03-14T13:37:10Z\",\n  \"type\": {\n    \"id\": \"otyn3jlrwwlmageyL2d7\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#get-list-of-users","title":"Get List of Users","text":"<p>Lists users that do not have a status of \"DEPROVISIONED\" (by default), up to the maximum (200 for most orgs), with pagination in most cases. A subset of users can be returned that match a supported filter expression or search criteria.</p> <p>This command takes an optional filter. If no filter is provided, all users are returned. For more information on Okta's query filters, visit https://developer.okta.com/docs/reference/user-query/#filter-users</p>"},{"location":"5-integrations/extensions/cloud-cli/okta/#command_1","title":"Command","text":"<pre><code>user list OPTIONAL_FILTER\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-input_1","title":"Example Input","text":"<pre><code>user list\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-output_1","title":"Example Output","text":"<pre><code>[\n  {\n    \"_links\": {\n      \"self\": {\n        \"href\": \"https://dev-8675309.okta.com/api/v1/users/00un2JpnNwheWSzOe5d7\"\n      }\n    },\n    \"created\": \"2025-01-31T12:26:30Z\",\n    \"credentials\": {\n      \"password\": {},\n      \"provider\": {\n        \"name\": \"OKTA\",\n        \"type\": \"OKTA\"\n      }\n    },\n    \"id\": \"00up0nl0lftw7331WSz\",\n    \"lastLogin\": \"2025-03-14T13:36:13Z\",\n    \"lastUpdated\": \"2025-02-10T15:33:00Z\",\n    \"passwordChanged\": \"2025-02-10T15:33:00Z\",\n    \"profile\": {\n      \"email\": \"fake.user@limacharlie.com\",\n      \"firstName\": \"Fake\",\n      \"lastName\": \"User\",\n      \"login\": \"fake.user@limacharlie.com\",\n      \"mobilePhone\": null,\n      \"secondEmail\": null\n    },\n    \"status\": \"ACTIVE\",\n    \"statusChanged\": \"2025-02-10T15:33:00Z\",\n    \"type\": {\n      \"id\": \"otyn2jpriwmLdgaiL5d7\"\n    }\n  }\n]\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#deactivate-user","title":"Deactivate User","text":"<p>Deactivates a user.</p> <p>This operation can only be performed on users that do not have a \"DEPROVISIONED\" status.</p>"},{"location":"5-integrations/extensions/cloud-cli/okta/#command_2","title":"Command","text":"<pre><code>user deactivate USERID\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-input_2","title":"Example Input","text":"<pre><code>user deactivate 00up0nl0lftw7331WSz\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-output_2","title":"Example Output","text":"<pre><code>None\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#activate-user","title":"Activate User","text":"<p>Activates a user.</p> <p>This operation can only be performed on users with a \"STAGED\" status.</p>"},{"location":"5-integrations/extensions/cloud-cli/okta/#command_3","title":"Command","text":"<pre><code>user activate USERID\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-input_3","title":"Example Input","text":"<pre><code>user activate 00up0nl0lftw7331WSz\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-output_3","title":"Example Output","text":"<pre><code>None\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#expire-user-password","title":"Expire User Password","text":"<p>This operation transitions the user to the status of \"PASSWORD_EXPIRED\" so that the user is required to change their password at their next login.</p>"},{"location":"5-integrations/extensions/cloud-cli/okta/#command_4","title":"Command","text":"<pre><code>user expire-password USERID\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-input_4","title":"Example Input","text":"<pre><code>user expire-password 00up0nl0lftw7331WSz\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-output_4","title":"Example Output","text":"<pre><code>None\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#suspend-user","title":"Suspend User","text":"<p>Suspends a user. The user will have a status of \"SUSPENDED\" when the process is complete.</p> <p>This operation can only be performed on users with an \"ACTIVE\" status.</p>"},{"location":"5-integrations/extensions/cloud-cli/okta/#command_5","title":"Command","text":"<pre><code>user suspend USERID\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-input_5","title":"Example Input","text":"<pre><code>user suspend 00up0nl0lftw7331WSz\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-output_5","title":"Example Output","text":"<pre><code>None\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#unsuspend-user","title":"Unsuspend User","text":"<p>Unsuspends a user and returns them to the \"ACTIVE\" state. This operation can only be performed on users that have a \"SUSPENDED\" status.</p> <p>This operation can only be performed on users that have a \"SUSPENDED\" status.</p>"},{"location":"5-integrations/extensions/cloud-cli/okta/#command_6","title":"Command","text":"<pre><code>user unsuspend USERID\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-input_6","title":"Example Input","text":"<pre><code>user unsuspend 00up0nl0lftw7331WSz\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-output_6","title":"Example Output","text":"<pre><code>None\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#unlock-user","title":"Unlock User","text":"<p>Unlocks a user with a \"LOCKED_OUT\" status and returns them to \"ACTIVE\" status. Users will be able to login with their current password.</p>"},{"location":"5-integrations/extensions/cloud-cli/okta/#command_7","title":"Command","text":"<pre><code>user unlock USERID\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-input_7","title":"Example Input","text":"<pre><code>user unlock 00up0nl0lftw7331WSz\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/okta/#example-output_7","title":"Example Output","text":"<pre><code>None\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/sdm/","title":"StrongDM","text":"<p>The StrongDM CLI allows you to manage your StrongDM platform(s) via the command-line. With this component of the Cloud CLI Extension, you can interact with StrongDM's directly from LimaCharlie.</p> <p>More information about the StrongDM CLI can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/sdm/#example","title":"Example","text":"<p>The following response action returns a list of all users in your Organization.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    cloud: '{{ \"sdm\" }}'\n    command_line: '{{ \"admin users list\" }}'\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/sdm/#credentials","title":"Credentials","text":"<p>To utilize StrongDM's CLI capabilities, you will need:</p> <ul> <li>An admin or service account token. More information on provisioning this token can be found here.</li> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>token\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/sublime/","title":"Sublime","text":"<p>The Sublime Security CLI brings the power of Sublime's email platform to the command-line. With this component of the Cloud CLI Extension, you can interact with Sublime's email platform directly from LimaCharlie.</p> <p>This extension makes use of Tailscale's native CLI, which can be found here. The CLI is a Python package - the source code can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/sublime/#example","title":"Example","text":"<p>The following response action returns information about the currently authentication Sublime Security user.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    cloud: '{{ \"sublime\" }}'\n    command_line: '{{ \"me\" }}'\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/sublime/#credentials","title":"Credentials","text":"<p>To utilize Sublime's CLI capabilities, you will need:</p> <ul> <li>You will need an API key. More information about provisioning an API key can be found here.</li> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>api_key\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/tailscale/","title":"Tailscale","text":"<p>The Tailscale CLI brings Tailscale's powerful software-defined networking, based on WireGuard, to the command line. This Extension allows you to interact with a Tailscale network(s) from LimaCharlie.</p> <p>This extension makes use of Tailscale's native CLI, which can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/tailscale/#example","title":"Example","text":"<p>Returns the current Tailscale status.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    cloud: '{{ \"tailscale\" }}'\n    command_line: '{{ \"status --json\" }}'\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/tailscale/#credentials","title":"Credentials","text":"<p>To utilize Tailscale's CLI capabilities, you will need:</p> <ul> <li>An auth key</li> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>authKey\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/tailscale/#command-line-interface","title":"Command-line Interface","text":"<p>LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.</p>"},{"location":"5-integrations/extensions/cloud-cli/vultr/","title":"Vultr","text":"<p>The Vultr CLI, or <code>vultr-cli</code>, is the official CLI for the Vultr API. With this component of the Cloud CLI Extension, you can interact with Vultr directly from LimaCharlie.</p> <p>This extension makes use of Vultr's official CLI tool, which can be found here. Reference documentation can be found here.</p>"},{"location":"5-integrations/extensions/cloud-cli/vultr/#example","title":"Example","text":"<p>The following example of a response action will enumerate a list of instance within a Vultr account.</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-cloud-cli\n  extension request:\n    cloud: '{{ \"vultr-cli\" }}'\n    command_line: '{{ \"instance list\" }}'\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/cloud-cli/vultr/#credentials","title":"Credentials","text":"<p>To utilize <code>vultr-cli</code> capabilities, you will need:</p> <ul> <li>A personal access token. To create one, click here.</li> <li>Your access token will need to have access control open to IPv6   </li> <li>Create a secret in the secrets manager in the following format:</li> </ul> <pre><code>personalAccessToken\n</code></pre>"},{"location":"5-integrations/extensions/labs/ai-agent-engine/","title":"AI Agent Engine [LABS]","text":"<p>The AI Agent Engine Extension allows you to easily codify and execute AI Agents within the context of your Organization with access to the LimaCharlie APIs for investigation, remediation and automation.</p> <p>The AI Agent definition themselves are managed in the <code>ai_agent</code> Hive Configurations and can be managed across tenants using the Infrastructure as Code extension. This hive requires the <code>ai_agent.*</code> permissions.</p> <p>The execution of an AI Agent can be triggered through the following means:</p> <ol> <li>Interactively in the web app by going to the Extensions section for the AI Agent Engine extension.</li> <li>By issuing an <code>extension request</code> action through a D&amp;R rule.</li> <li>By issuing an extension request on the API directly: https://api.limacharlie.io/static/swagger/#/Extensions/createExtensionRequest</li> <li>By issuing an extension request through the Python CLI/SDK or Golang SDK, which means they're also available to Playbooks.</li> </ol> <p>This means agents can be invoked in a fully automated fashion based on events, detections, audit messages or any other target of  rules. But it can also be used in an ad-hoc fashion triggered manually.</p>"},{"location":"5-integrations/extensions/labs/ai-agent-engine/#usage","title":"Usage","text":"<p>When invoking an AI Agent, all you need is the playbook name as defined in Hive and an initial message. Optionally, an AI Agent can also receive a JSON dictionary object as parameters, this is useful when passing the AI Agent additional context like a detection or event from a D&amp;R rule.</p> <p>Interactions with the agent are associated with a given (Interactive) Session ID (ISID). A Session ID is like a ChatGPT session where all the context is available to the agent. Starting a new session returns an <code>isid</code> and the <code>get_session</code> action requires an <code>isid</code>.</p> <p>Common tips:</p> <ul> <li>Specify only the subset of tools you want your AI to use, otherwise it may do things you didn't expect or take initiative in ways you don't intend.</li> <li>Make the AI as specialized as possible, tell it exactly what you want it to do, processes and how you want to get the response (markdown, JSON etc).</li> <li>Give the AI examples, adding more details and examples to the <code>instructions</code> help greatly.</li> </ul> <p>The credentials provided to the engine are simply a LimaCharlie API key, we recommend storing it in a secret and referencing as <code>hive://secret/my-lc-creds</code>.</p>"},{"location":"5-integrations/extensions/labs/ai-agent-engine/#actions","title":"Actions","text":""},{"location":"5-integrations/extensions/labs/ai-agent-engine/#start_session","title":"start_session","text":"<p>Start a new AI Agent session, specifying all the detailed parameters (see AI Agent Structure below that are both the Agent Definition parameters and the <code>start_session</code> parameters).</p>"},{"location":"5-integrations/extensions/labs/ai-agent-engine/#list_tools","title":"list_tools","text":"<p>List all the tools available to be called by the agent along with their categories that can be used to customize agents.</p>"},{"location":"5-integrations/extensions/labs/ai-agent-engine/#dr-rule-example","title":"D&amp;R rule example","text":"<p>Here is an example D&amp;R rule starting a new invocation of a playbook.</p> <pre><code>- action: extension request\n  extension name: ext-ai-agent-engine\n  extension action: start_session\n  extension request:\n    agent_definition: '{{ \"my-agent-name\" }}'\n    message: You're a cyber security expert, summarize this detection: {...}\n</code></pre>"},{"location":"5-integrations/extensions/labs/ai-agent-engine/#python-example","title":"Python example","text":"<pre><code># Import LC SDK\nimport limacharlie\nimport json\n# Instantiate the SDK with default creds.\nlc = limacharlie.Manager()\n# Instantiate the Extension manager object.\next = limacharlie.Extension(lc)\n\n# Issue a request to the \"ext-ai-agent-engine\" extension for the \"my-agent-name\" agent.\nresponse = ext.request(\"ext-ai-agent-engine\", \"start_session\", {\n    \"agent_definition\": \"my-agent-name\",\n    \"message\": \"You're a cyber security expert, summarize this detection: {...}\"\n})\n\nfor msg in response['data']['responses']:\n  print(f\"AI says: {json.dumps(msg, indent=2)}\")\n</code></pre>"},{"location":"5-integrations/extensions/labs/ai-agent-engine/#ai-agent-structure","title":"AI Agent structure","text":""},{"location":"5-integrations/extensions/labs/ai-agent-engine/#example-ai-agent-definition","title":"Example AI Agent Definition","text":"<p>The following is a sample AI Agent definition that simply aims at summarizing detections.</p> <pre><code>{\n  \"name\": \"my-agent\",\n  \"description\": \"Some agent that does something...\",\n  \"credentials\": \"hive://secret/ai-creds\", // These credentials will be used when accessing LimaCharlie APIs.\n  // Instructions are the core system behavior for the AI\n  \"instructions\": \"You are a cybersecurity expert system who's job it is to summarize detections/alerts for SOC analysts. Output as markdown. Include detailed technical context about the alert and if MITRE techniques are mentioned, summarize them. Also include what next steps of the investigation should be. The audience of the report is a cyber security team at a medium sized enterprise.\",\n  \"max_iterations\": 10, // If the AI makes tool calls to the LC API or LC Sensors, this limits the number of iterations the AI is called.\n  \"allowed_tools\": [\n    \"get_sensor_info\" // List of tool categories (see list_tools or the Available Tools section below).\n  ]\n}\n</code></pre>"},{"location":"5-integrations/extensions/labs/ai-agent-engine/#available-tools","title":"Available Tools","text":"<p>The tools available to the AI Agents are the same ones available from the official LimaCharlie MCP Server.</p>"},{"location":"5-integrations/extensions/labs/ai-agent-engine/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>Not currently available, coming up.</p>"},{"location":"5-integrations/extensions/labs/ai-agent-engine/#billing","title":"Billing","text":"<p>The AI Agent Engine is billed per token processed, including initial messages, prompt and response.</p>"},{"location":"5-integrations/extensions/labs/ai-agent-engine/#privacy","title":"Privacy","text":"<p>Currently, the model in use is the commercial Gemini models.</p> <p>Although the models may change (and eventually Bring-Your-Own-Model), these models will never use your data to train more models and LimaCharlie never uses the data to train models.</p>"},{"location":"5-integrations/extensions/labs/playbook/","title":"Playbook [LABS]","text":"<p>LimaCharlie LABS</p> <p>The Playbook Extension allows you to execute Python playbooks within the context of your Organization in order to automate tasks and customize more complex detections.</p> <p>The playbooks themselves are managed in the playbook Hive Configurations and can be managed across tenants using the Infrastructure as Code extension.</p> <p>The execution of a playbook can be triggered through the following means:</p> <ol> <li>Interactively in the web app by going to the Extensions section for the Playbook extension.</li> <li>By issuing an <code>extension request</code> action through a D&amp;R rule.</li> <li>By issuing an extension request on the API directly: https://api.limacharlie.io/static/swagger/#/Extensions/createExtensionRequest</li> <li>By issuing an extension request through the Python CLI/SDK or Golang SDK.</li> </ol> <p>This means playbooks can be issued in a fully automated fashion based on events, detections, audit messages or any other target of D&amp;R rules. But it can also be used in an ad-hoc fashion triggered manually.</p>"},{"location":"5-integrations/extensions/labs/playbook/#enabling-extension","title":"Enabling Extension","text":"<p>The Playbook extension can be enabled by subscribing your organization to the ext-playbook add-on.</p> <p></p>"},{"location":"5-integrations/extensions/labs/playbook/#accessing-playbooks","title":"Accessing Playbooks","text":"<p>Playbooks are created, modified, and deleted via the Playbooks option located within the Automation menu.</p> <p>Note: If you are unable to see the Playbooks option, ensure your user account has the appropriate permissions enabled.</p> <p></p> <p></p>"},{"location":"5-integrations/extensions/labs/playbook/#usage","title":"Usage","text":"<p>When invoking a playbook, all you need is the playbook name as defined in Hive. Optionally, a playbook can also receive a JSON dictionary object as parameters, this is useful when triggering a playbook from a D&amp;R rule and you want to pass some context, or when passing context interactively.</p>"},{"location":"5-integrations/extensions/labs/playbook/#dr-rule-example","title":"D&amp;R rule example","text":"<p>Here is an example D&amp;R rule starting a new invocation of a playbook.</p> <pre><code>- action: extension request\n  extension name: ext-playbook\n  extension action: run_playbook\n  extension request:\n    name: '{{ \"my-playbook\" }}'\n    credentials: '{{ \"hive://secret/my-api-key\" }}'\n    data:\n      some: event.FILE_PATH\n      for_the: '{{ \"running of the playbook\" }}'\n</code></pre>"},{"location":"5-integrations/extensions/labs/playbook/#python-example","title":"Python example","text":"<pre><code># Import LC SDK\nimport limacharlie\n# Instantiate the SDK with default creds.\nlc = limacharlie.Manager()\n# Instantiate the Extension manager object.\next = limacharlie.Extension(lc)\n\n# Issue a request to the \"ext-playbook\" extension.\nresponse = ext.request(\"ext-playbook\", \"run_playbook\", {\n    \"name\": \"my-playbook\",\n    \"credentials\": \"hive://secret/my-playbook-api-key\",\n    \"data\": {\n        \"some\": \"data\"\n    }\n})\n\n# The returned data from the playbook.\nprint(response)\n</code></pre>"},{"location":"5-integrations/extensions/labs/playbook/#playbook-structure","title":"Playbook structure","text":"<p>A playbook is a normal python script. The only required component is a top level function called <code>playbook</code> which takes 2 arguments:</p> <ul> <li><code>sdk</code>: an instance of the LC Python SDK ( <code>limacharlie.Manager()</code> ) pre-authenticated to the relevant Organization based on the credentials provided, if any, <code>None</code> otherwise.</li> <li><code>data</code>: the optional JSON dictionary provided as context to your playbook.</li> </ul> <p>The function must return a dictionary with the following optional keys:</p> <ol> <li><code>data</code>: a dictionary of data to return to the caller</li> <li><code>error</code>: an error message (string) to return to the caller</li> <li><code>detection</code>: a dictionary to use as detection</li> <li><code>cat</code>: a string to use as the category of the detection, if <code>detection</code> is specified.</li> </ol> <p>This allows your playbook to return information about its execution, return data, errors or generate a detection. The python <code>print()</code> statement is not currently being returned to the caller or otherwise accessible, so you will want to use the <code>data</code> in order to return information about the execution of your playbook.</p>"},{"location":"5-integrations/extensions/labs/playbook/#example-playbook","title":"Example playbook","text":"<p>The following is a sample playbook that sends a webhook to an external product with a secret stored in LimaCharlie, and it returns the data as the response from the playbook.</p> <pre><code>import limacharlie\nimport json\nimport urllib.request\n\ndef playbook(sdk, data):\n  # Get the secret we need from LimaCharlie.\n  mySecret = limacharlie.Hive(sdk, \"secret\").get(\"my-secret-name\").data[\"secret\"]\n\n  # Send the Webhook.\n  request = urllib.request.Request(\"https://example.com/webhook\", data=json.dumps(data).encode('utf-8'), headers={\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {mySecret}\"\n  }, method=\"POST\")\n\n  try:\n    with urllib.request.urlopen(request) as response:\n      response_body = response.read().decode('utf-8')\n      # Parse the JSON response\n      parsed_response = json.loads(response_body)\n  except Exception as e:\n    # Some error occured, let the caller/LC know.\n    return {\n      \"error\": str(e),\n    }\n\n  # Return the data to the caller/LC.\n  return {\n    \"data\": parsed_response,\n  }\n</code></pre>"},{"location":"5-integrations/extensions/labs/playbook/#example-playbook-with-custom-detection-category","title":"Example playbook with custom detection category","text":"<p>When a playbook generates a detection, you can customize the detection category name that appears in the UI by setting the <code>cat</code> field at the top level of the return dictionary. This is particularly useful when you want detections from different playbooks to have descriptive names instead of the generic \"playbook-detection\".</p> <p>The following example checks if a server sensor has missed a check-in and creates a detection with a custom category name:</p> <p><pre><code>import limacharlie\n\ndef playbook(sdk, data):\n  if not sdk:\n    return {\"error\": \"LC API key required\"}\n\n  # Check for sensors that haven't checked in recently\n  import time\n  current_time = time.time()\n  threshold = 3600  # 1 hour in seconds\n\n  missing_sensors = []\n  for sensor in sdk.sensors():\n    info = sensor.getInfo()\n    last_seen = info.get('last_seen', 0)\n    if (current_time - last_seen) &gt; threshold:\n      missing_sensors.append({\n        \"sid\": info['sid'],\n        \"hostname\": info.get('hostname', 'unknown')\n      })\n\n  if missing_sensors:\n    # Return a detection with a custom category name\n    # The 'cat' field MUST be at the top level, not inside 'detection'\n    return {\n      \"detection\": {\n        \"summary\": f\"Found {len(missing_sensors)} sensors missing check-in\",\n        \"missing_sensors\": missing_sensors\n      },\n      \"cat\": \"Server-Sensor-Missing-Check-In\"\n    }\n\n  # No issues found\n  return {\n    \"data\": {\"status\": \"all sensors checked in\"}\n  }\n```python\n\n**Important:** The `cat` field must be placed at the **top level** of the return dictionary, alongside `detection`, not inside it. When this playbook creates a detection, it will appear in the Detections UI with the category name \"Server-Sensor-Missing-Check-In\" instead of the default \"playbook-detection\".\n\n**Without `cat`:** Detection appears as \"playbook-detection \u2192 ext_playbook\"\n\n**With `cat`:** Detection appears as \"Server-Sensor-Missing-Check-In \u2192 ext_playbook\"\n\n### Execution environment\n\nPlaybooks contents are cached for short periods of time ( on the order of 10 seconds ) in the cloud.\n\nPlaybooks are instantiated on demand and the instance is reused for an undefined amount of time.\n\nPlaybook code only executes during the main call to the `playbook` function, background on-going running is not supported.\n\nThe execution environment is provisioned on a per-Organization basis, meaning all your playbooks may execute within the same container, but NEVER on a container used by another Organization.\n\nAlthough you have access to the local environment, this environment is ephemeral and can be wiped at any moment in between executions so you should take care that your playbook is self contained and doesn't assume pre-existing conditions.\n\nA single execution of a playbook is limited to 10 minutes.\n\nThe current execution environment is based on the default libraries provided by the `python:slim` Dockerhub official container plus the following packages:\n\n* Python\n  + `weasyprint`\n  + `flask`\n  + `gunicorn`\n  + `flask`\n  + `limacharlie` (LimaCharlie SDK/CLI)\n  + `lcextension` (LimaCharlie Extension SDK)\n  + `scikit-learn` (Python Machine Learning kit)\n  + `jinja2`\n  + `markdown`\n  + `pillow`\n* NodeJS\n* AI\n  + Claude Code (`claude`) CLI tool\n  + Codex (`codex`) CLI tool\n  + Gemini CLI (`gemini`) CLI tool\n\nCustom packages and execution environment tweaks are not available in self-serve mode, but they *may* be available on demand, get in touch with us at support@limacharlie.io.\n\n## Infrastructure as Code\n\nExample:\n</code></pre> hives:     playbook:         my-playbook:             data:                 python: |-                     def playbook(sdk, data):                         if not sdk:                             return {\"error\": \"LC API key required to list sensors\"}                         return {                             \"data\": {                                 \"sensors\": [s.getInfo() for s in sdk.sensors()]                             }                         }             usr_mtd:                 enabled: true                 expiry: 0                 tags: []                 comment: \"\" ```</p>"},{"location":"5-integrations/extensions/labs/playbook/#billing","title":"Billing","text":"<p>Playbooks are billed per seconds of total execution time.</p>"},{"location":"5-integrations/extensions/limacharlie/artifact/","title":"Artifact","text":"<p>The Artifact Extension provides low-level collection capabilities which can be configured to run automatically via Detection &amp; Response rules, Sensor collections, or pushed via REST API. When enabled, an Artifact Collection menu will be available within the LimaCharlie web UI.</p> <p>Billing for Artifacts</p> <p>Note that while the Artifact extension is free to enable, ingested artifacts do incur a charge. Please refer to pricing details to confirm Artifact ingestion and retention costs.</p>"},{"location":"5-integrations/extensions/limacharlie/artifact/#enabling-the-artifact-extension","title":"Enabling the Artifact Extension","text":"<p>To enable the Artifact extension, navigate to the Artifact extension page in the marketplace. Select the Organization you wish to enable the extension for, and select Subscribe.</p> <p></p> <p>After clicking Subscribe, the Artifact extension should be available almost immediately.</p> <p>Note that the Artifact extension first requires enabling of the Reliable Tasking extension. You can find more on that extension here.</p>"},{"location":"5-integrations/extensions/limacharlie/artifact/#using-the-artifact-extension","title":"Using the Artifact Extension","text":"<p>When enabled, you will see an Artifact Collection option under Sensors menu for the respective organization.</p> <p></p> <p>Within the Artifact Collection page, you can configure:</p> <ul> <li>Artifact collection rules for files.</li> <li>Artifact collection rules to stream Windows Event Log (WEL) events.</li> <li>Artifact collection rules to stream Mac Unified Log (MUL) events.</li> <li>PCAP capture rules to capture network traffic (Only available on Linux)</li> </ul> <p>The following screenshot provides examples of capturing Windows Security and Sysmon Windows Event Logs via Artifact Collection. Rather than using an Adapter, capturing WEL events via the <code>wel://</code> pattern adds the corresponding events to the sensor telemetry, creating a real-time stream of Windows Event Log data. However, you can also specify the pattern to collect the specific <code>.evtx</code> files.</p> <p>More information on Artifact collections can be found here.</p> <p></p>"},{"location":"5-integrations/extensions/limacharlie/binlib/","title":"BinLib","text":"<p>Binary Library, or \"BinLib\", is a collection of executable binaries (such as EXE or ELF files) that have been observed within your environment. If enabled, this Extension helps you build your own private collection of observed executables for subsequent analysis and searching.</p> <p>When LimaCharlie observes a binary and path for the first time a <code>CODE_IDENTITY</code> event is generated. The metadata from this event is stored within <code>binlib</code>, and is available for searching, tagging, and downloading. Additionally, you can run YARA scans against observed binaries.</p>"},{"location":"5-integrations/extensions/limacharlie/binlib/#enabling-binlib","title":"Enabling BinLib","text":"<p>BinLib requires subscribing to the <code>ext-reliable-tasking</code> Extension in order to function properly. This can be enabled in the Add-ons marketplace.</p> <p>BinLib can be a powerful additional to your detection and response capabilities. Analysts can:</p> <ul> <li>Look for historical evidence of malicious binaries</li> <li>Tag previously-observed files for data enrichment (i.e. MITRE ATT&amp;CK Techniques)</li> <li>Compare observed hashes to known good or known bad lists</li> <li>YARA scan and auto-tag for integration in detection &amp; response rules</li> </ul>"},{"location":"5-integrations/extensions/limacharlie/binlib/#usage","title":"Usage","text":"<p>First, subscribe your tenant to the BinLib extension.</p> <p></p> <p>To perform one of the following operations against your own library, choose the command and select Run Request.</p> <p>The BinLib page in the web app offers an easy way to get started with some of the core requests exposed by the extension: Check Hash, Search, and Yara Scan.</p> <p></p>"},{"location":"5-integrations/extensions/limacharlie/binlib/#check_hash","title":"check_hash","text":"<p>Accepted Values: MD5, SHA1, SHA256</p> <p>The <code>check_hash</code> operation lets you search to see if a particular hash has been observed in your Organization. Output includes a boolean if the hash was found and three hash values, if available.</p> <p>Sample Output:</p> <pre><code>{\n  \"data\": {\n    \"found\": true,\n    \"md5\": \"e977bded5d4198d4895ac75150271158\",\n    \"sha1\": \"9e2b05f142c35448c9bc48c40a732d632485c719\",\n    \"sha256\": \"2f5d0c6159b194d6f0f2eae0b7734708368a23aebf9af4db9293865b57ffcaeb\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/binlib/#get_hash_data","title":"get_hash_data","text":"<p>Accepted Values: MD5, SHA1, SHA256</p> <p>Careful Downloading Binaries</p> <p>LimaCharlie does not filter the binaries observed by your organization. You must exercise caution if downloading a malicious file. We recommend downloading potential malicious binaries to an isolated analysis system.</p> <p>The <code>get_hash_data</code> operation provides a link to the raw data for the hash of interest, allowing you to download the resulting binary file (if previously observed within your environment).</p> <p>Sample Output:</p> <pre><code>{\n  \"data\": {\n    \"download_url\": \"https://storage.googleapis.com/lc-library-bin/b_2f5d0c...\",\n    \"found\": true,\n    \"md5\": \"e977bded5d4198d4895ac75150271158\",\n    \"sha1\": \"9e2b05f142c35448c9bc48c40a732d632485c719\",\n    \"sha256\": \"2f5d0c6159b194d6f0f2eae0b7734708368a23aebf9af4db9293865b57ffcaeb\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/binlib/#get_hash_metadata","title":"get_hash_metadata","text":"<p>Accepted Values: MD5, SHA1, SHA256</p> <p>The <code>get_hash_metadata</code> operation obtains the metadata for a hash of interest, including signing details, file type, and additional hashes.</p> <pre><code>{\n  \"data\": {\n    \"found\": true,\n    \"md5\": \"e977bded5d4198d4895ac75150271158\",\n    \"metadata\": {\n      \"imp_hash\": \"c105252faa9163fd63fb81bb334c61bf\",\n      \"res_company_name\": \"Google LLC\",\n      \"res_file_description\": \"Google Chrome Installer\",\n      \"res_product_name\": \"Google Chrome Installer\",\n      \"res_product_version\": \"113.0.5672.127\",\n      \"sha256\": \"2f5d0c6159b194d6f0f2eae0b7734708368a23aebf9af4db9293865b57ffcaeb\",\n      \"sig_authentihash\": \"028f24e2c1fd42a3edaf0dcf8a59afe39201fa7d3bb5804dca8559fde41b3f34\",\n      \"sig_issuer\": \"US, DigiCert Trusted G4 Code Signing RSA4096 SHA384 2021 CA1\",\n      \"sig_serial\": \"0e4418e2dede36dd2974c3443afb5ce5\",\n      \"sig_subject\": \"US, California, Mountain View, Google LLC, Google LLC\",\n      \"size\": 5155608,\n      \"type\": \"pe\"\n    },\n    \"sha1\": \"9e2b05f142c35448c9bc48c40a732d632485c719\",\n    \"sha256\": \"2f5d0c6159b194d6f0f2eae0b7734708368a23aebf9af4db9293865b57ffcaeb\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/binlib/#search","title":"search","text":"<p>The <code>search</code> operation searches the library for binary data points, including or other than a known hash.</p> <p>Searchable fields include:</p> <ul> <li>imp_hash</li> <li>res_company_name</li> <li>res_file_description</li> <li>res_product_name</li> <li>sha256</li> <li>sig_authentihash</li> <li>sig_hash</li> <li>sig_issuer</li> <li>sig_subject</li> <li>size</li> <li>type</li> </ul> <p>Note that search criteria are ANDed. Binaries must meet ALL criteria to be returned.</p> <p>Search results can be downloaded as a CSV.</p> <p></p>"},{"location":"5-integrations/extensions/limacharlie/binlib/#tag","title":"tag","text":"<p>The <code>tag</code> operation allows you to add tag(s) to a hash, allowing for additional classification within binlib.</p> <p>The below example Tags the Google Installer with the <code>google</code> tag.</p> <p></p> <p>Successful tagging yields an <code>updated</code> event:</p> <pre><code>{\n  \"data\": {\n    \"found\": true,\n    \"md5\": \"e977bded5d4198d4895ac75150271158\",\n    \"sha1\": \"9e2b05f142c35448c9bc48c40a732d632485c719\",\n    \"sha256\": \"2f5d0c6159b194d6f0f2eae0b7734708368a23aebf9af4db9293865b57ffcaeb\",\n    \"updated\": true\n  }\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/binlib/#untag","title":"untag","text":"<p>The <code>untag</code> operation removes a tag from a binary.</p>"},{"location":"5-integrations/extensions/limacharlie/binlib/#yara-scan","title":"YARA scan","text":"<p>The <code>yara_scan</code> operation lets you run YARA scans across observed files. Scans require:</p> <ul> <li>Criteria or hash to filter files to be scanned</li> <li>Rule name(s) or rule(s)</li> </ul> <p>You also have the option to tag hits on match.</p> <p>Note that search criteria are ANDed. Binaries must meet ALL criteria to be returned.</p> <p></p>"},{"location":"5-integrations/extensions/limacharlie/binlib/#automating","title":"Automating","text":"<p>Here are some examples of useful rules that could be used to automate interactions with Binlib.</p>"},{"location":"5-integrations/extensions/limacharlie/binlib/#scan-all-acquired-files-with-yara","title":"Scan all acquired files with Yara","text":"<p>This rule will automatically scan all acquired files in binlib with a Yara rule:</p> <pre><code>detect:\n\nevent: acquired\nop: is tagged\ntag: ext:binlib\n\nrespond:\n\n- action: report\n  name: binlib-test\n- action: extension request\n  extension action: yara_scan\n  extension name: binlib\n  extension request:\n    hash: '{{ .event.sha256 }}'\n    rule_names:\n      - yara_rule_name_here\n</code></pre> <p>and this rule will alert on matches:</p> <pre><code>detect:\n\nevent: yara_scan\nop: exists\npath: event/matches/hash\n\nrespond:\n\n- action: report\n  name: YARA Match via Binlib\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/dumper/","title":"Dumper","text":"<p>The Dumper Extension provides the ability to do dumping of several forensic artifacts on Windows hosts. It supports a single action, which is to dump.</p> <p>It supports multiple targets -- <code>memory</code> to dump the memory of the host, and <code>mft</code> to dump the MFT of the file system to CSV. The extension then automates the ingestion of the resulting dump (and dump metadata) to LimaCharlie's Artifact Ingestion system where it can be downloaded or analyzed, and where you can create rules to automate detections of characteristics of those dumps.</p>"},{"location":"5-integrations/extensions/limacharlie/dumper/#usage","title":"Usage","text":"<p>When enabled, dumper will be added to the Extensions view inside your Organization. It will accept the following parameters:</p> <ul> <li><code>sid</code> - a Sensor ID for the host to perform the memory dump</li> <li><code>target</code> - memory or mft</li> <li><code>retention</code> - the number of days the memory dump should be retained for (default is 30)</li> <li><code>ignore_cert</code> - ignore cert errors for payload and collection purposes (default <code>false</code>)</li> </ul> <p>Upon submission of a request, the extension will perform a full memory dump of a host and upload the resulting dumps to LimaCharlie's artifact ingestion system and delete the local dumps afterwards.</p> <p>Dumper requests can also be made via D&amp;R rules. Here is is example of a D&amp;R rule action that makes a request to Dumper:</p> <pre><code>- action: extension request\n  extension name: ext-dumper\n  extension action: request_dump\n  extension request:\n    target: memory\n    sid: &lt;&lt;routing.sid&gt;&gt;\n    retention: 30 #default 30\n    ignore_cert: true # default false\n</code></pre> <p>Notes:</p> <p>The dumper extension does not currently validate that the host has enough available disc space for the memory dump. Although the dumper extension is free, the resulting memory dumps uploaded to LimaCharlie are subject to external logs pricing. This add-on relies on other paid resources (payloads) billed based on usage.</p>"},{"location":"5-integrations/extensions/limacharlie/epp/","title":"Endpoint Protection","text":""},{"location":"5-integrations/extensions/limacharlie/epp/#overview","title":"Overview","text":"<p>The Endpoint Protection (EPP) management in LimaCharlie enables users to view the status of existing EPP solutions (including Windows Free Defender), manage parameters of the deployment and unify alerting from the deployment at scale. This makes it perfect for teams wanting a unified view of the EPP solution, or service providers looking to offer Managed EPP to their customers at scale.</p> <p>The only requirement is for the LimaCharlie agent to be deployed and the EPP Extension enabled (free).</p> <p>Once deployed, EPP can be used natively along with the rest of LimaCharlie's automation and routing capabilities.</p>"},{"location":"5-integrations/extensions/limacharlie/epp/#how-it-works","title":"How it Works","text":"<p>LimaCharlie Endpoint Protection integrates with third-party EDR solutions to provide a better view of security operations and extend agent's capabilities. Currently this extension applies to:</p> <ul> <li>Microsoft Windows Defender</li> </ul> <p>The LimaCharlie agent communicates with Windows Defender to determine its status, transfer events, and trigger remediation commands. LimaCharlie Endpoint Protection codifies the best practices of collecting events and alerting on detections. When enabled, this extension creates a starter set of  rules. In addition to alerting, these rules can be customized to better align with the operational complexity of user's environments. The LC Endpoint Protection extension provides a reliable and cost efficient way of securing endpoints at scale.</p> <p>The Endpoint Protection add-on requires agent version <code>4.33.5</code> or higher.</p>"},{"location":"5-integrations/extensions/limacharlie/epp/#enabling-and-configuring-endpoint-protection","title":"Enabling and configuring Endpoint Protection","text":"<p>To enable Endpoint Protection, first ensure LimaCharlie Endpoint Agent version is 4.33.5 and above, update if necessary.</p> <p>Navigate to the Endpoint Protection extension page in the Add-Ons marketplace. Choose the target Organization and select <code>Subscribe</code>.</p> <p></p> <p>Once subscribed, you can see the Endpoint Protection in the list of Extensions.</p> <p></p> <p>The Endpoint Protection extension does two things once both sync settings are enabled:</p> <ol> <li> <p>Creates an artifact collection rule named <code>defender-log-streaming</code></p> </li> <li> <p>This rule adds a WEL pattern that collects MS Defender logs, <code>wel://Microsoft-Windows-Windows Defender/Operational:*</code> so that LimaCharlie receives the events the Defender produces.</p> <p>Note</p> <p>If you already have Defender logs coming in via the Artifact extension, you can uncheck the <code>Sync Extension Config</code> box to avoid duplicating entries. 2. Creates D&amp;R rules</p> </li> <li> <p>Generates several D&amp;R rules that alert on various detections and actions taken by Defender.</p> </li> <li>To apply the Artifact extension configuration and D&amp;R rules, click <code>Apply Configuration</code>.</li> </ol> <p>When the SYNC toggles are on, the collection rules and D&amp;R rules are continuously synchronized with LimaCharlie library of best practices.</p> <p>Once the extension is enabled, it also extends the Web UI with Endpoint Protection functionality, as described below.</p>"},{"location":"5-integrations/extensions/limacharlie/epp/#using-the-endpoint-protection-extension","title":"Using the Endpoint Protection extension","text":"<p>Endpoint Protection capabilities are used in three ways.</p> <p>Verify Protection</p> <p>Select a Windows Sensor in the organization. In the Sensor Overview, there is a new section, \"Endpoint Protection\" that shows the current protection status. Verify that Defender is listed as active on the sensor.</p> <p></p> <p>Perform Scan</p> <p>Select a Windows Sensor.</p> <p>Click on File System. Select the folder, and click on the scan icon  <code>Scan with EPP</code></p> <p>Endpoint Protection Commands</p> <p>Select a Windows Sensor. Open the Sensor Console As you type \"epp\" you'll see the available commands. Try <code>epp_status</code>  - it will return the status.</p> <p>Events required in Exfil config</p> <p>The EPP solution relies on some new events. They are now defaults, and the extension adds them to existing orgs. In rare case you may need to add them manually to Sensor / Event Collection / Event Collection or your Infra As Code. Here is the list:</p> <pre><code>EPP_STATUS_REP,EPP_LIST_EXCLUSIONS_REP,EPP_ADD_EXCLUSION_REP,EPP_REM_EXCLUSION_REP,\nEPP_LIST_QUARANTINE_REP,EPP_SCAN_REP\n</code></pre> <p>For reference, this is a list of Endpoint Protection commands:</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"5-integrations/extensions/limacharlie/exfil/","title":"Exfil (Event Collection)","text":"<p>The Exfil Extension helps manage which real-time events get sent from EDR sensors to LimaCharlie. By default, LimaCharlie Sensors send events to the cloud based on a standard profile. This extension exposes those profiles for customization. The Exfil extension allows you to customize Event Collection from LimaCharlie Sensors, as well as mitigate sensors with high I/O or large detection and response rulesets.</p> <p>Event Collection Rule Synchronization</p> <p>Please note that Exfil (or Event Collection) rule configurations are synchronized with sensors every few minutes.</p>"},{"location":"5-integrations/extensions/limacharlie/exfil/#enabling-the-exfil-extension","title":"Enabling the Exfil Extension","text":"<p>To enable the Exfil extension, navigate to the Exfil extension page in the marketplace. Select the Organization you wish to enable the extension for, and select Subscribe.</p> <p></p> <p>After clicking subscribe, the Exfil extension should be available almost immediately.</p>"},{"location":"5-integrations/extensions/limacharlie/exfil/#using-the-exfil-extension","title":"Using the Exfil Extension","text":"<p>Once the extension is enabled, you will see an Event Collection option under Sensors in the LimaCharlie web UI.</p> <p></p> <p>There are three rule options within the Exfil extension:</p> <ul> <li>Event Collection Rules manage events sent by the Sensor to the LimaCharlie cloud.</li> <li>Performance Rules are useful for high I/O servers, but may impact event accuracy. This feature is available only on Windows Sensors.</li> <li> <p>Watch Rules allow for conditional operators for an event, allowing you to specify a list of sensors to help manage high-volume events. Conditional operators for Watch Rule events include:</p> </li> <li> <p>The event itself, such as <code>MODULE_LOAD</code>.</p> </li> <li>The path within the event component to be evaluated, such as <code>FILE_PATH</code>.</li> <li>The operator to evaluate or compare that should be done between the path and the value.</li> <li>The value to be used in comparison with the operator.</li> </ul> <p>A sample Watch Rule might be</p> <pre><code>Event: MODULE_LOAD\nPath: FILE_PATH\nOperator: ends with\nValue: wininet.dll\n</code></pre> <p>The above rule would configures the sensor(s) to send only <code>MODULE_LOAD</code> events where the <code>FILE_PATH</code> ends with the value <code>wininet.dll</code>.</p> <p>Performance Rules</p> <p>Performance rules, applied via tag to a set of Sensors, are useful for high I/O systems. These rules can be set via the web application or REST API.</p>"},{"location":"5-integrations/extensions/limacharlie/exfil/#throughput-limits","title":"Throughput Limits","text":"<p>Enabling every event for Exfil can produce an exceedingly large amount of traffic. Our first recommendation would be to optimize events required for detection &amp; response rules, in order to ensure that all rules are active. We'd also recommend prioritizing events that contribute to outputs, such as forwarded <code>DNS_REQUESTS</code>.</p> <p>LimaCharlie attempts to process all events in real-time. However, if events fall behind, they are enqueued to a certain limit. If that limit is reached (e.g. in the case of a long, sustained burst or enabling all events at the same time), the queue may eventually get dropped. In that event, an error is emitted to the platform logs.</p> <p>Seeing event collection errors is a sign you may need to do one of the following:</p> <ol> <li>Reduce the population of events collected.</li> <li>Reduce the number of  rules you run or rule complexity.</li> <li>Adopt a selective subset of events by utilizing Watch Rules that only bring back events with specific values.</li> <li>Enable the IR mode (below).</li> </ol>"},{"location":"5-integrations/extensions/limacharlie/exfil/#afterburner","title":"Afterburner","text":"<p>Before a backlogged queue is dropped, LimaCharlie attempts to increase performance by entering a special mode we call \"afterburner.\" This mode tries to address one of the common scenarios that can lead to a large influx of data: spammy processes starting over and over. This happens in situations such as the building of software, in which executables like <code>devenv.exe</code> or <code>git</code> can be called hundreds of times per second. The afterburner mode attempts to (1) de-duplicate those processes and (2) assess only each one through the D&amp;R rules and Outputs.</p>"},{"location":"5-integrations/extensions/limacharlie/exfil/#ir-mode","title":"IR Mode","text":"<p>The afterburner mode does not address all possible causes or situations. To help with this, LimaCharlie offers \"IR mode.\" This mode is enabled by tagging a LimaCharlie sensor with the tag <code>ir</code>. The goal of \"IR mode\" is to provide a solution for users who want to record a very large number of events, but do not need to run D&amp;R rules over all of them. When enabled, \"IR mode\" will not de-duplicate events. Furthermore, D&amp;R rules will only be run against the follow event types:</p> <ol> <li><code>CODE_IDENTITY</code></li> <li><code>DNS_REQUEST</code></li> <li><code>NETWORK_CONNECTIONS</code></li> <li><code>NEW_PROCESS</code></li> </ol> <p>IR mode is designed to give a balance between recording all events, while maintaining basic D&amp;R rule capabilities.</p>"},{"location":"5-integrations/extensions/limacharlie/exfil/#actions-via-rest-api","title":"Actions via REST API","text":"<p>The following REST API actions can be sent to interact with the Exfil extension:</p> <p>List Rules</p> <pre><code>{\n  \"action\": \"list_rules\"\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/exfil/#event-collection-rules","title":"Event Collection Rules","text":"<p>Add Event Collection Rule</p> <pre><code>{\n  \"action\": \"add_event_rule\",\n  \"name\": \"windows-vip\",\n  \"events\": [\n    \"NEW_TCP4_CONNECTION\",\n    \"NEW_TCP6_CONNECTION\"\n  ],\n  \"tags\": [\n    \"vip\"\n  ],\n  \"platforms\": [\n    \"windows\"\n  ]\n}\n</code></pre> <p>Remove Event Collection Rule</p> <pre><code>{\n  \"action\": \"remove_event_rule\",\n  \"name\": \"windows-vip\"\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/exfil/#watch-rules","title":"Watch Rules","text":"<p>Add Watch Rule</p> <pre><code>{\n  \"action\": \"add_watch\",\n  \"name\": \"wininet-loading\",\n  \"event\": \"MODULE_LOAD\",\n  \"operator\": \"ends with\",\n  \"value\": \"wininet.dll\",\n  \"path\": [\n    \"FILE_PATH\"\n  ],\n  \"tags\": [\n    \"server\"\n  ],\n  \"platforms\": [\n    \"windows\"\n  ]\n}\n</code></pre> <p>Remove Watch Rule</p> <pre><code>{\n  \"action\": \"remove_watch\",\n  \"name\": \"wininet-loading\"\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/exfil/#performance-rules","title":"Performance Rules","text":"<p>Add Performance Rule</p> <pre><code>{\n  \"action\": \"add_perf_rule\",\n  \"name\": \"sql-servers\",\n  \"tags\": [\n    \"sql\"\n  ],\n  \"platforms\": [\n    \"windows\"\n  ]\n}\n</code></pre> <p>Remove Performance Rule</p> <pre><code>{\n  \"action\": \"remove_perf_rule\",\n  \"name\": \"sql-servers\"\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/git-sync/","title":"Git Sync","text":"<p>The Git Sync Extension is a tool that automates the management of Infrastructure-as-Code (IaC) configurations. It simplifies the process of deploying and managing infrastructure by synchronizing changes between a Git repository and target organizations.</p> <p>Key features:</p> <ul> <li>Centralized Configuration: Stores all IaC configurations in a single Git repository.</li> <li>Recurring Apply: Can automatically sync IaC changes between Git and LC organizations at regular intervals.</li> <li>Recurring Export: Can automatically export IaC from LC organizations to GitHub at regular intervals.</li> <li>Export Request: Allows you to export the configuration of an Organization into the Git repository.</li> <li>Automated Deployment: Helps automate the deployment process, reducing manual effort.</li> <li>MSSP**-Friendly:** Designed to accommodate multiple organizations within a single repository, allowing for global configurations to be shared between orgs.</li> <li>Flexible Configuration: Allows for customization and additional configuration directories.</li> <li>Transparent Operations: Tracks operations through an extension Sensor.</li> </ul> <p>By using <code>ext-git-sync</code>, you can streamline your IaC workflows, improve consistency, and reduce the risk of errors.</p>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#use-cases","title":"Use Cases","text":""},{"location":"5-integrations/extensions/limacharlie/git-sync/#sync-from-git","title":"Sync FROM Git","text":"<p>If you have a properly structured git repository containing org configurations, the extension can sync the running org configurations with the contents of the configs in git.</p> <p></p>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#export-to-git","title":"Export TO Git","text":"<p>Assuming you have an empty git repository, you can configure the extension to export the current org configuration to the repository. It will be placed in an <code>exports</code> subdirectory.</p> <p></p>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#git-repo-structure","title":"Git Repo Structure","text":"<p>For applying org configs from a git repository, the repo must adhere to the following structure. The root of the repository must contain an <code>orgs</code> directory with <code>[org-id]</code> child directories, each containing an <code>index.yaml</code> .</p> <pre><code>.\n\u2514\u2500\u2500 orgs [required]\n    \u2514\u2500\u2500 a326700d-3cd7-49d1-ad08-20b396d8549d [required]\n        \u2514\u2500\u2500 index.yaml [required]\n</code></pre> <p>The <code>index.yaml</code> determines which other files in the repo are included in the configuration for this org.</p> <p>For instance, assume all of the configurations for this org were unique to this org and could be nested inside of the org's directory.</p> <pre><code>.\n\u2514\u2500\u2500 orgs\n    \u2514\u2500\u2500 a326700d-3cd7-49d1-ad08-20b396d8549d\n        \u251c\u2500\u2500 extensions.yaml\n        \u251c\u2500\u2500 hives\n        \u2502   \u251c\u2500\u2500 cloud_sensor.yaml\n        \u2502   \u251c\u2500\u2500 dr-general.yaml\n        \u2502   \u251c\u2500\u2500 dr-managed.yaml\n        \u2502   \u251c\u2500\u2500 dr-service.yaml\n        \u2502   \u251c\u2500\u2500 extension_config.yaml\n        \u2502   \u251c\u2500\u2500 fp.yaml\n        \u2502   \u251c\u2500\u2500 lookup.yaml\n        \u2502   \u251c\u2500\u2500 query.yaml\n        \u2502   \u251c\u2500\u2500 secret.yaml\n        \u2502   \u2514\u2500\u2500 yara.yaml\n        \u251c\u2500\u2500 index.yaml\n        \u251c\u2500\u2500 installation_keys.yaml\n        \u251c\u2500\u2500 org_values.yaml\n        \u251c\u2500\u2500 outputs.yaml\n        \u2514\u2500\u2500 resources.yaml\n</code></pre> <p>Notice that all configurations for this org are contained within the org's own directory. In this case, the <code>index.yaml</code> would simply contain references to the relative path of this org's configuration files. See below for an example of the contents of <code>index.yaml</code> for this use case.</p> <pre><code>version: 3\ninclude:\n    - extensions.yaml\n    - hives/fp.yaml\n    - outputs.yaml\n    - resources.yaml\n    - hives/query.yaml\n    - hives/yara.yaml\n    - hives/dr-managed.yaml\n    - hives/lookup.yaml\n    - hives/dr-service.yaml\n    - org_values.yaml\n    - installation_keys.yaml\n    - hives/secret.yaml\n    - hives/cloud_sensor.yaml\n    - hives/dr-general.yaml\n    - hives/extension_config.yaml\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#sharing-configurations-across-multiple-orgs","title":"Sharing configurations across multiple orgs","text":"<p>Now, assume you have a global rule set you want to apply across many orgs. You could structure the repo similar to the example below.</p> <pre><code>.\n\u251c\u2500\u2500 hives\n\u2502   \u251c\u2500\u2500 dr-general.yaml\n\u2502   \u2514\u2500\u2500 yara.yaml\n\u2514\u2500\u2500 orgs\n    \u251c\u2500\u2500 7e41e07b-c44c-43a3-b78d-41f34204789d\n    \u2502   \u2514\u2500\u2500 index.yaml\n    \u251c\u2500\u2500 a326700d-3cd7-49d1-ad08-20b396d8549d\n    \u2502   \u2514\u2500\u2500 index.yaml\n    \u2514\u2500\u2500 cb639126-e0bc-4563-a577-2e559c0610b2\n        \u2514\u2500\u2500 index.yaml\n</code></pre> <p>The corresponding <code>index.yaml</code> at each org level would look similar to the following</p> <pre><code>version: 3\ninclude:\n    - ../../hives/yara.yaml\n    - ../../hives/dr-general.yaml\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#exporting-configurations","title":"Exporting configurations","text":"<p>Configuration exports will be placed in a separate <code>exports</code> subdirectory to avoid overwriting configurations that are pushed across multiple organizations.</p> <pre><code>.\n\u2514\u2500\u2500 exports\n    \u2514\u2500\u2500 orgs\n        \u2514\u2500\u2500 a326700d-3cd7-49d1-ad08-20b396d8549d\n            \u251c\u2500\u2500 extensions.yaml\n            \u251c\u2500\u2500 hives\n            \u2502   \u251c\u2500\u2500 cloud_sensor.yaml\n            \u2502   \u251c\u2500\u2500 dr-general.yaml\n            \u2502   \u251c\u2500\u2500 dr-managed.yaml\n            \u2502   \u251c\u2500\u2500 dr-service.yaml\n            \u2502   \u251c\u2500\u2500 extension_config.yaml\n            \u2502   \u251c\u2500\u2500 fp.yaml\n            \u2502   \u251c\u2500\u2500 lookup.yaml\n            \u2502   \u251c\u2500\u2500 query.yaml\n            \u2502   \u251c\u2500\u2500 secret.yaml\n            \u2502   \u2514\u2500\u2500 yara.yaml\n            \u251c\u2500\u2500 index.yaml\n            \u251c\u2500\u2500 installation_keys.yaml\n            \u251c\u2500\u2500 org_values.yaml\n            \u251c\u2500\u2500 outputs.yaml\n            \u2514\u2500\u2500 resources.yaml\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#setting-up-git-sync-with-github","title":"Setting up Git Sync with Github","text":"<p>This guide walks you through the process of configuring Git synchronization between GitHub and LimaCharlie, allowing for automated deployment and version control of your security configurations.</p>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#step-0-making-a-git-sync-specific-ssh-key","title":"Step 0: Making a Git Sync specific SSH Key","text":"<ul> <li>First create the directory</li> </ul> <p><code>mkdir -p ~/.ssh/gitsync</code></p> <ul> <li>Set appropriate permissions for the directory</li> </ul> <p><code>chmod 700 ~/.ssh/gitsync</code></p> <ul> <li>Now generate the SSH key</li> </ul> <p><code>ssh-keygen -t ed25519 -C \"limacharlie-gitsync\" -f ~/.ssh/gitsync/id_ed25519</code></p>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#step-1-generate-github-deploy-keys","title":"Step 1: Generate GitHub Deploy Keys","text":"<ol> <li>Navigate to your GitHub repository</li> <li>Click on the Settings tab</li> <li>In the left sidebar, select Deploy keys</li> <li>Click the Add deploy key button</li> <li>Enter a descriptive title for your key (e.g., \"LimaCharlie Git Sync Integration\")</li> <li>Paste your public SSH key into the \"Key\" field</li> <li>Important: Check the box for Allow write access</li> <li>Click Add key to save</li> </ol>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#step-2-store-ssh-private-key-in-limacharlie","title":"Step 2: Store SSH Private Key in LimaCharlie","text":"<ol> <li>Log in to your LimaCharlie account</li> <li>Navigate to the Secret Manager section of your Organization</li> <li>Click Create New Secret</li> <li>Choose a descriptive name for your secret (e.g., \"github-deploy-key\")</li> <li>Paste the private part of your SSH key into the value field</li> <li>Save the secret</li> </ol>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#step-3-configure-git-sync-in-limacharlie","title":"Step 3: Configure Git Sync in LimaCharlie","text":"<ol> <li>Navigate to the Git Sync section in LimaCharlie</li> <li>Under the SSH Key section, select Secret Manager</li> <li>From the dropdown menu, select the secret you created in Step 2</li> <li>Set the user name to <code>git</code></li> <li>Copy the SSH URL from your GitHub repository (found on the repository's main page, under Code)</li> <li>Paste the SSH URL into the repository URL field in LimaCharlie</li> <li>Configure the branch name (required)</li> <li>Select the push and pull options which allow you to specify which items to push to or pull from Git configurations.</li> <li>Optionally, select push and pull schedules if you wish to regularly sync or export your Infrastructure as Code configurations to and from LimaCharlie. This will create D&amp;R rules on the backend that kick off the push and pull actions on the selected schedule/interval.</li> <li>Click save settings.</li> </ol>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#step-4-verify-integration","title":"Step 4: Verify Integration","text":"<ol> <li> <p>Perform a test commit to your GitHub repository by clicking \"Push to Git\" in the upper right corner.</p> </li> <li> <p>Verify that your configuration has been pushed to Github.</p> </li> </ol>"},{"location":"5-integrations/extensions/limacharlie/git-sync/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter synchronization issues:</p> <ul> <li>Verify that the deploy key has proper write permissions</li> <li>Ensure the correct SSH URL format is used (should begin with <code>git@github.com:</code>)</li> <li>Check that the private key in Secret Manager matches the public key added to GitHub</li> </ul> <p>Infrastructure</p>"},{"location":"5-integrations/extensions/limacharlie/infrastructure/","title":"Infrastructure","text":"<p>The Infrastructure Extension allows you to perform infrastructure-as-code (IaC) modifications to your Organization. IaC modifications can be made in the web UI or via the LimaCharlie CLI tool. Users can create new organizations from known templates or maintain a common configuration across multiple organizations.</p> <p>Scaling Organization Management</p> <p>If you're an managed service company or need to manage a large number of Organizations, consider LimaCharlie's MSSP setup. You can find more information about this here.</p>"},{"location":"5-integrations/extensions/limacharlie/infrastructure/#enabling-the-infrastructure-extension","title":"Enabling the Infrastructure Extension","text":"<p>To enable the Infrastructure extension, navigate to the Infrastructure extension page in the marketplace. Select the organization you wish to enable the extension for, and select Subscribe.</p> <p></p> <p>After clicking Subscribe, the Infrastructure extension should be available almost immediately.</p> <p>Where to start?</p> <p>IaC can be a powerful tool for rapidly deploying and managing Organizations within LimaCharlie. To help you discover more possibilities, we have provided several example templates/configurations here.</p>"},{"location":"5-integrations/extensions/limacharlie/infrastructure/#using-the-infrastructure-extension","title":"Using the Infrastructure Extension","text":"<p>Once enabled, you will see an Infrastructure as Code option under the Organization Settings within the LimaCharlie web UI. The extension also becomes available via the REST API.</p> <p></p> <p>Within the Infrastructure As Code module, you can:</p> <ul> <li>Apply a New Config to an existing organization. Changes are made additively, and are good for merging new configuration parameters into your organization.</li> <li>Edit the Entire Configuration for an existing organization. This is your current configuration, and can be modified directly in the web UI.</li> <li>Perform Fetch, Push, or Push-from-file operations.</li> </ul> <p></p>"},{"location":"5-integrations/extensions/limacharlie/infrastructure/#actions-via-rest-api","title":"Actions via REST API","text":"<p>The REST interface for the Infrastructure extension mimics the CLI tool. The following REST API actions can be sent to interact with the Infrastructure extension:</p> <pre><code>{\n  \"params\": {\n    \"sync_artifacts\": {\n      \"type\": \"bool\",\n      \"desc\": \"applies to artifacts\"\n    },\n    \"is_force\": {\n      \"type\": \"bool\",\n      \"desc\": \"make the org an exact copy of the configuration provided.\"\n    },\n    \"is_dry_run\": {\n      \"type\": \"bool\",\n      \"desc\": \"do not apply config, just simulate.\"\n    },\n    \"sync_integrity\": {\n      \"type\": \"bool\",\n      \"desc\": \"applies to integrity\"\n    },\n    \"action\": {\n      \"is_required\": true,\n      \"values\": [\n        \"push\",\n        \"fetch\"\n      ],\n      \"type\": \"enum\",\n      \"desc\": \"action to take.\"\n    },\n    \"sync_org_values\": {\n      \"type\": \"bool\",\n      \"desc\": \"applies to org_values\"\n    },\n    \"sync_resources\": {\n      \"type\": \"bool\",\n      \"desc\": \"applies to resources\"\n    },\n    \"config\": {\n      \"type\": \"str\",\n      \"desc\": \"configuration to apply.\"\n    },\n    \"config_source\": {\n      \"type\": \"str\",\n      \"desc\": \"ARL where configs to apply are located.\"\n    },\n    \"ignore_inaccessible\": {\n      \"desc\": \"ignore resources which are inaccessible like locked or segmented.\",\n      \"type\": \"bool\"\n    },\n    \"sync_fp\": {\n      \"type\": \"bool\",\n      \"desc\": \"applies to fp\"\n    },\n    \"sync_exfil\": {\n      \"desc\": \"applies to exfil\",\n      \"type\": \"bool\"\n    },\n    \"sync_dr\": {\n      \"type\": \"bool\",\n      \"desc\": \"applies to dr\"\n    },\n    \"sync_outputs\": {\n      \"type\": \"bool\",\n      \"desc\": \"applies to outputs\"\n    },\n    \"config_root\": {\n      \"type\": \"str\",\n      \"desc\": \"file name of the root config within config_source to apply.\"\n    }\n  }\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/infrastructure/#related-articles","title":"Related Articles","text":"<ul> <li>Integrity</li> </ul>"},{"location":"5-integrations/extensions/limacharlie/integrity/","title":"Integrity","text":"<p>The Integrity Extension helps you manage all aspects of file or registry integrity monitoring (FIM and RIM, respectively). This extension automates integrity checks of file system and registry values through pattern-based rules.</p>"},{"location":"5-integrations/extensions/limacharlie/integrity/#enabling-the-integrity-extension","title":"Enabling the Integrity Extension","text":"<p>To enable the Integrity extension, navigate to the Integrity extension page in the marketplace. Select the Organization you wish to enable the extension for, and select Subscribe.</p> <p></p> <p>After clicking Subscribe, the Infrastructure extension should be available almost immediately.</p>"},{"location":"5-integrations/extensions/limacharlie/integrity/#using-the-integrity-extension","title":"Using the Integrity Extension","text":"<p>Once enabled, you will see an File/Reg Integrity option under Automation within the LimaCharlie web UI.</p> <p></p> <p>Selecting this option allows you to customize File &amp; Registry Integrity Monitoring rules, as seen in the screenshot below.</p> <p></p> <p>Selecting Add Monitoring Rule will allow you to create a FIM or RIM rule, specifying a platform, Tag(s), and pattern(s).</p> <p></p>"},{"location":"5-integrations/extensions/limacharlie/integrity/#rule-patterns","title":"Rule Patterns","text":"<p>Patterns are file or registry patterns and support wildcards (*, ?, +). Windows directory separators (backslash, <code>\"\\\"</code>) must be escape with a double-slash <code>\"\\\\\"</code>.</p> <p>When a FIM or RIM rule is tripped, you will see a <code>FIM_HIT</code> event in the Sensor(s) timeline.</p> <p></p>"},{"location":"5-integrations/extensions/limacharlie/integrity/#example-rule-patterns","title":"Example Rule Patterns","text":""},{"location":"5-integrations/extensions/limacharlie/integrity/#windows-file-monitoring","title":"Windows File Monitoring","text":"Monitor a specific directory on all drives Monitor a specific file on a specific drive ?:\\Windows\\System32\\drivers C:\\Windows\\System32\\specialfile.exe ?:\\inetpub\\wwwroot"},{"location":"5-integrations/extensions/limacharlie/integrity/#windows-registry-monitoring","title":"Windows Registry Monitoring","text":"<p>All registry monitoring patterns MUST begin with \\REGISTRY, followed by the hive and then the path or value to monitor.</p> Monitor for changes to system Run and RunOnce Monitor all users for additions to a user's Run \\REGISTRY\\MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\Run* \\REGISTRY\\USER\\S-*\\Software\\Microsoft\\Windows\\CurrentVersion\\Run* \\REGISTRY\\MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce*"},{"location":"5-integrations/extensions/limacharlie/integrity/#linux","title":"Linux","text":"Monitor for changes to root's authorized_keys Monitor for changes to all user private ssh directories /root/.ssh/authorized_keys /home/*/.ssh/*"},{"location":"5-integrations/extensions/limacharlie/integrity/#macos","title":"macOS","text":"Monitor for changes to user keychains Monitor for changes to system keychains /Users/*/Library/Keychains/* /Library/Keychains"},{"location":"5-integrations/extensions/limacharlie/integrity/#linux-support","title":"Linux Support","text":"<p>FIM is supported on Linux systems, however, support may vary based on Linux distribution and software.</p>"},{"location":"5-integrations/extensions/limacharlie/integrity/#linux-with-ebpf-support","title":"Linux with eBPF Support","text":"<p>Linux hosts capable of running with eBPF have file notification and FIM capabilities on par with Windows and macOS.</p>"},{"location":"5-integrations/extensions/limacharlie/integrity/#legacy-support","title":"Legacy Support","text":"<p>FIM is partially supported on systems without eBPF. Specified file expressions are actively monitored via <code>inotify</code> (as opposed to macOS and Windows, which utilize passive kernel monitoring). Due to inotify limitations, paths with wildcards are less efficient and only support monitoring up to 20 sub-directories covered by the wildcard. In addition to this, the path expressions should specify a final wildcard of when all files under a directory need to be monitored. Omitting the final <code>*</code> will result in only the top-level directory being monitoring.</p>"},{"location":"5-integrations/extensions/limacharlie/integrity/#actions-via-rest-api","title":"Actions via REST API","text":"<p>The following REST API actions can be sent to interact with the Integrity extension:</p> <p>List Rules</p> <pre><code>{\n  \"action\": \"list_rules\"\n}\n</code></pre> <p>Add Rule</p> <pre><code>{\n  \"action\": \"add_rule\",\n  \"name\": \"linux-root-ssh-configs\",\n  \"patterns\": [\n    \"/root/.ssh/*\"\n  ],\n  \"tags\": [\n    \"vip\",\n    \"workstation\"\n  ],\n  \"platforms\": [\n    \"linux\"\n  ]\n}\n</code></pre> <p>Remove Rule</p> <pre><code>{\n  \"action\": \"remove_rule\",\n  \"name\": \"linux-ssh-configs\"\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/integrity/#related-articles","title":"Related Articles","text":"<ul> <li>Reference: Endpoint Agent Commands</li> <li>Detection and Response Examples</li> </ul>"},{"location":"5-integrations/extensions/limacharlie/lookup-manager/","title":"Lookup Manager","text":"<p>The Lookup Manager Extension allows you to create, maintain &amp; automatically refresh lookups in the Organization to then reference them in Detection &amp; Response Rules.</p> <p>The saved Lookup Configurations can be managed across tenants using Infrastructure as Code extension. To manage lookup versions across all of your tenants, update the file under the original Authenticated Resource Locator.</p> <p>Every 24 hours, LimaCharlie will sync all of the lookups in the configuration. Lookups can also be manually synced by clicking the <code>Manual Sync</code> button on the extension page. When a lookup configuration is added, it will not be automatically synced immediately, unless you click on <code>Manual Sync</code>.</p> <p>Lookup sources can be either direct links (URLs) to a given lookup or ARLs.</p> <p>Example JSON lookup: link</p>"},{"location":"5-integrations/extensions/limacharlie/lookup-manager/#usage","title":"Usage","text":""},{"location":"5-integrations/extensions/limacharlie/lookup-manager/#option-1-preconfigured-lookups","title":"Option 1: Preconfigured Lookups","text":"<p>LimaCharlie provides a curated list of several publicly available JSON lookups for use within your organization. These are provided in the lookup manager GUI.</p> <p>More details and the contents of each of these lookups can be found here.</p> <p></p> <p></p>"},{"location":"5-integrations/extensions/limacharlie/lookup-manager/#option-2-publicly-available-lookups","title":"Option 2: Publicly available Lookups","text":"<p>Giving the lookup configuration a name, the URL or ARL, and clicking the Save button will create the new lookup source to sync to your lookups.</p> <p><code>[github,my-org/my-repo-name/path/to/lookup]</code></p>"},{"location":"5-integrations/extensions/limacharlie/lookup-manager/#option-3-private-lookup-repository","title":"Option 3: Private Lookup Repository","text":"<p>To use a lookup from a private Github repository you will need to make use of an Authentication Resource Locator.</p> <p>Step 1: Create a token in GitHub In GitHub go to Settings and click Developer settings in the left hand side bar.</p> <p>Next click Personal access token followed by Generate new token. Select repo permissions and finally Generate token.</p> <p>Step 2: Connect LimaCharlie to your GitHub Repository Inside of LimaCharlie, click on Lookup Manager in the left hand menu. Then click Add New Lookup Configuration.</p> <p>Give your lookup a name and then use the token you generated with the following format linked to your repository.</p> <p><code>[github,my-org/my-repo-name/path/to/lookup,token,bfuihferhf8erh7ubhfey7g3y4bfurbfhrb]</code></p>"},{"location":"5-integrations/extensions/limacharlie/lookup-manager/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>Example:</p> <pre><code>hives:\n    extension_config:\n        ext-lookup-manager:\n            data:\n                lookup_manager_rules:\n                    - arl: \"\"\n                      format: json\n                      name: alienvault\n                      predefined: '[https,storage.googleapis.com/lc-lookups-bucket/alienvault-ip-reputation.json]'\n                      tags:\n                        - alienvault\n                    - arl: \"\"\n                      format: json\n                      name: tor\n                      predefined: '[https,storage.googleapis.com/lc-lookups-bucket/tor-ips.json]'\n                      tags:\n                        - tor\n            usr_mtd:\n                enabled: true\n                expiry: 0\n                tags: []\n                comment: \"\"\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/payload-manager/","title":"Payload Manager","text":"<p>Payloads, such as scripts, pre-built binaries, or other files, can be deployed to LimaCharlie sensors for any reason necessary.</p> <p>One method of adding payloads to an Organization is via the web UI on the payloads screen. This is suitable for ad-hoc payload needs, however does not scale past a handful of payloads, or for multiple organizations requiring access the same payload(s).</p> <p>The payload manager allows you to create, maintain, and automatically create/update payloads within your organization(s). Furthermore, payload configurations can be saved and utilized across multiple organizations using LimaCharlie's Infrastructure as Code capabilities.</p> <p>Payloads added in the payload manager will be synced once every 24 hours per org.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.</p>"},{"location":"5-integrations/extensions/limacharlie/reliable-tasking/","title":"Reliable Tasking","text":"<p>The Reliable Tasking Extension enables you to task a Sensor(s) that are currently offline. The extension will automatically send the task(s) to Sensor(s) once it comes online.</p>"},{"location":"5-integrations/extensions/limacharlie/reliable-tasking/#enabling-the-reliable-tasking-extension","title":"Enabling the Reliable Tasking Extension","text":"<p>To enable the Reliable Tasking extension, navigate to the Reliable Tasking extension page in the marketplace. Select the Organization you wish to enable the extension for, and select Subscribe.</p> <p>After clicking Subscribe, the Reliable Tasking extension should be available almost immediately.</p>"},{"location":"5-integrations/extensions/limacharlie/reliable-tasking/#using-the-reliable-tasking-extension","title":"Using the Reliable Tasking Extension","text":"<p>Once enabled, you will see a Reliable Tasking option under Automation within the LimaCharlie web UI. You can also interact with the extension via REST API.</p> <p>Within the Reliable Tasking module, you can:</p> <ul> <li>Task Sensor(s)</li> <li>Untask Sensor(s)</li> <li>List active task(s)</li> </ul>"},{"location":"5-integrations/extensions/limacharlie/reliable-tasking/#actions-via-rest-api","title":"Actions via REST API","text":"<p>The following REST API actions can be sent to interact with the Reliable Tasking extension:</p>"},{"location":"5-integrations/extensions/limacharlie/reliable-tasking/#create-a-task","title":"Create a Task","text":"<pre><code>curl --location 'https://api.limacharlie.io/v1/extension/request/ext-reliable-tasking' \\\n--header 'Authorization: Bearer $JWT' \\\n--header 'Content-Type: application/x-www-form-urlencoded' \\\n--data 'oid=$YOUR_OID&amp;action=task&amp;data={\"context\":\"version\",\"selector\":\"plat==windows\",\"task\":\"run --shell-command whoami\",\"ttl\":3600}'\n</code></pre> <p>All parameters are provided in the request body as URL-encoded form data. The <code>data</code> parameter should contain a JSON object with the following fields:</p> <p>Required Parameters:</p> <ul> <li><code>task</code>: The command to execute, similar to a command-line <code>task</code> (e.g., <code>\"run --shell-command whoami\"</code>, <code>\"mem_map --pid 4\"</code>)</li> </ul> <p>Optional Parameters:</p> <ul> <li><code>selector</code>: A Sensor Selector Expression to specify which sensors should receive the task. If omitted, the task will be sent to all sensors in the organization.</li> <li>Examples:<ul> <li><code>\"selector\":\"plat==windows\"</code> - All Windows sensors</li> <li><code>\"selector\":\"sid=='abc-123-def'\"</code> - A specific sensor by ID</li> <li><code>\"selector\":\"production in tags\"</code> - All sensors with the \"production\" tag</li> <li><code>\"selector\":\"plat==linux and int_ip matches '^10\\\\.3\\\\..*'\"</code> - Complex expressions using AND/OR logic</li> </ul> </li> <li><code>context</code>: An identifier that will be reflected in the <code>investigation_id</code> of the corresponding <code>RECEIPT</code> or <code>_REP</code> event, allowing you to craft D&amp;R rules based on the response</li> <li><code>ttl</code>: Time-to-live in seconds - how long the extension should try to keep sending the task to sensors that haven't acknowledged it. Defaults to 1 week (604800 seconds)</li> </ul> <p>For more details on sensor selector syntax and available fields (<code>sid</code>, <code>plat</code>, <code>tags</code>, <code>hostname</code>, <code>int_ip</code>, etc.), see the Sensor Selector Expressions reference.</p> <p>Additional Examples:</p> <p>Target a specific sensor: <pre><code>curl --location 'https://api.limacharlie.io/v1/extension/request/ext-reliable-tasking' \\\n--header 'Authorization: Bearer $JWT' \\\n--header 'Content-Type: application/x-www-form-urlencoded' \\\n--data 'oid=$YOUR_OID&amp;action=task&amp;data={\"task\":\"os_version\",\"selector\":\"sid=='\\''sensor-123-abc'\\''\",\"ttl\":86400}'\n</code></pre></p> <p>Target all Linux servers with a specific tag: <pre><code>curl --location 'https://api.limacharlie.io/v1/extension/request/ext-reliable-tasking' \\\n--header 'Authorization: Bearer $JWT' \\\n--header 'Content-Type: application/x-www-form-urlencoded' \\\n--data 'oid=$YOUR_OID&amp;action=task&amp;data={\"task\":\"file_get -f /etc/passwd\",\"selector\":\"plat==linux and production in tags\",\"context\":\"audit-2024\",\"ttl\":172800}'\n</code></pre></p> <p>Target all sensors (no selector): <pre><code>curl --location 'https://api.limacharlie.io/v1/extension/request/ext-reliable-tasking' \\\n--header 'Authorization: Bearer $JWT' \\\n--header 'Content-Type: application/x-www-form-urlencoded' \\\n--data 'oid=$YOUR_OID&amp;action=task&amp;data={\"task\":\"os_version\",\"ttl\":3600}'\n</code></pre></p>"},{"location":"5-integrations/extensions/limacharlie/reliable-tasking/#list-tasks","title":"List Tasks","text":"<pre><code>curl --location 'https://api.limacharlie.io/v1/extension/request/ext-reliable-tasking' \\\n--header 'Authorization: Bearer $JWT' \\\n--header 'Content-Type: application/x-www-form-urlencoded' \\\n--data 'oid=$YOUR_OID&amp;action=list&amp;data={}'\n</code></pre> <p>This returns all pending reliable tasks for the organization. The response includes task details such as the task ID, command, sensor selector expression, and which sensors have acknowledged execution.</p> <p>Note: The current API returns all tasks regardless of selector. If you need to filter tasks by sensor characteristics, retrieve all tasks and filter the results based on the <code>sensor_selector</code> field in each task object.</p>"},{"location":"5-integrations/extensions/limacharlie/reliable-tasking/#capturing-task-responses","title":"Capturing Task Responses","text":"<p>If you're using reliable tasks to issue commands across your sensors, you're probably going to want to view or act on the responses from these commands as well.</p> <p>If you add a value to the <code>context</code> parameter in the extension request, this value will be reflected in the <code>investigation_id</code> of the corresponding <code>RECEIPT</code> or <code>_REP</code> event, allowing you to craft a D&amp;R rule based on the response.</p> <p>The above example cURL command has a <code>context</code> of <code>version</code> so the below D&amp;R rule looks for that value.</p>"},{"location":"5-integrations/extensions/limacharlie/reliable-tasking/#example-detect-block","title":"Example detect block:","text":"<pre><code>op: contains\nevent: RECEIPT\npath: routing/investigation_id\nvalue: version\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/reliable-tasking/#example-respond-block","title":"Example respond block:","text":"<pre><code>- action: output\n  name: tasks-output         # Send responses to the specified output\n- action: report\n  name: \"Reliable task ran\"  # Detect on the task being run\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/reliable-tasking/#migrating-rule-from-legacy-service-to-new-extension","title":"Migrating Rule from legacy Service to new Extension","text":"<p>Note: LimaCharlie has migrated from Services to Extensions. Legacy services are no longer supported.</p> <p>The Python CLI gives you a direct way to assess if any rules reference the legacy reliable tasking service and convert them to use the extension.</p> <p>Command line to preview Reliable Tasking rule conversion:</p> <pre><code>limacharlie extension convert_rules --name ext-reliable-tasking\n</code></pre> <p>A dry-run response (default) will display the rule name being changed, a JSON of the service request rule and a JSON of the incoming extension request change.</p> <p>To execute the change in the rule, explicitly set <code>--dry-run</code> flag to <code>--no-dry-run</code></p> <p>Command line to execute reliable tasking rule conversion:</p> <pre><code>limacharlie extension convert_rules --name ext-reliable-tasking --no-dry-run\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/sensor-cull/","title":"Sensor Cull","text":"<p>The Sensor Cull Extension performs continuous cleaning of \"old\" sensors that have not connected to an Organization within a set period of time. This is useful for environments with cloud deployments or VM/template-based deployments that may enroll sensors repeatedly, and for a short period of time.</p> <p>The extension works by creating rules that describe when specified sensors should be cleaned up.</p>"},{"location":"5-integrations/extensions/limacharlie/sensor-cull/#enabling-the-sensor-cull-extension","title":"Enabling the Sensor Cull Extension","text":"<p>To enable the Sensor Cull extension, navigate to the Sensor Cull extension page in the LimaCharlie marketplace.</p> <p></p> <p>After clicking Subscribe, the Sensor Cull extension should be available almost immediately.</p>"},{"location":"5-integrations/extensions/limacharlie/sensor-cull/#using-the-sensor-cull-extension","title":"Using the Sensor Cull Extension","text":"<p>Once enabled, you will see a Sensor Cull option under Sensors within the LimaCharlie web UI. You can also interact with the extension via REST API.</p> <p></p> <p>Within the Sensor Cull module, you have the ability to create rules. Sensor Cull rules are run automatically once a day, and can be edited as needed.</p> <p></p> <p>Each rule specifies a single sensor <code>tag</code> used as a selector for the sensors the rule applies to. A rule also has a <code>name</code> (simply used for your bookkeeping), and a <code>ttl</code> which is the number of days a sensor can remain unconnected to LimaCharlie before it becomes eligible for cleanup.</p>"},{"location":"5-integrations/extensions/limacharlie/sensor-cull/#actions-via-rest-api","title":"Actions via REST API","text":"<p>The following REST API actions can be sent to interact with the Sensor Cull extension:</p>"},{"location":"5-integrations/extensions/limacharlie/sensor-cull/#get_rules","title":"get_rules","text":"<p>Get the list of existing rules</p> <pre><code>{\n  \"action\": \"get_rules\"\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/sensor-cull/#run","title":"run","text":"<p>Perform an ad-hoc cleanup.</p> <pre><code>{\n  \"action\": \"run\"\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/sensor-cull/#add_rule","title":"add_rule","text":"<p>The following example creates a rule name <code>my new rule</code> that applies to all sensors with the <code>vip</code> Tag, and cleans them up when they have not connected in 30 days.</p> <pre><code>{\n  \"action\": \"add_rule\",\n  \"name\": \"my new rule\",\n  \"tag\": \"vip\",\n  \"ttl\": 30\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/sensor-cull/#del_rule","title":"del_rule","text":"<p>Delete an existing rule by name.</p> <pre><code>{\n  \"action\": \"del_rule\",\n  \"name\": \"my new rule\"\n}\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/usage-alerts/","title":"Usage Alerts","text":"<p>The usage alerts Extension allows you to create, maintain, &amp; automatically refresh usage alert conditions for an Organization.</p> <p>For example, you can create a usage alert rule that will fire a detection when artifact downloads have reached a 1GB threshold in the last 30 days (43200 minutes). This alert will be saved as a managed rule. When the threshold is reached, a detection will be created with the following <code>cat</code>:</p> <p><code>Usage alert - Output data over threshold - 1024 MB in 30.00 days</code></p> <p>These alert rules can be managed across tenants using the Infrastructure as Code extension.</p> <p>Every hour, LimaCharlie will sync all of the usage alert rules in the configuration. They can also be manually synced by clicking the <code>Sync Usage Alert Rules</code> button on the extension page. When a usage alert rule is added, it will not be automatically synced immediately, unless you click on <code>Sync Usage Alert Rules</code>.</p> <p>NOTE: The maximum timeframe is currently 43200 minutes (30 days).</p>"},{"location":"5-integrations/extensions/limacharlie/usage-alerts/#usage-gui","title":"Usage - GUI","text":"<p>To define a new usage alert, simply click on the <code>Add New Usage Alert</code> button in the extension UI. Give it a name, like <code>Output data over threshold</code>, select a SKU (in this case, <code>output_data</code>), a timeframe, a limit, and click <code>Save</code>. </p> <p>If you want it to be added immediately, click on the <code>Sync Usage Alert Rules</code> button. Otherwise, it will get pushed automatically at the next hour interval.</p> <p></p> <p>This will create a managed D&amp;R rule on the backend in the <code>dr-managed</code> hive and will sync automatically every hour.</p> <pre><code>hives:\n    dr-managed:\n        Output data over threshold:\n            data:\n                detect:\n                    event: billing_record\n                    op: and\n                    rules:\n                        - op: is\n                          path: event/record/cat\n                          value: output\n                        - op: is\n                          path: event/record/k\n                          value: bytes_tx\n                    target: billing\n                respond:\n                    - action: report\n                      name: Usage alert - Output data over threshold - 1024 MB in 24.00 hours\n                      suppression:\n                        count_path: event/record/v\n                        keys:\n                            - output\n                            - bytes_tx\n                            - ext-usage-alerts\n                            - Output data over threshold\n                        max_count: 1.073741824e+09\n                        min_count: 1.073741824e+09\n                        period: 43200m\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/usage-alerts/#usage-infrastructure-as-code","title":"Usage - Infrastructure as Code","text":"<p>If you are managing your organizations via infrastructure as code, you can also configure these rules in the <code>extension_config</code> hive.</p> <pre><code>hives:\n    extension_config:\n        ext-usage-alerts:\n            data:\n                usage_alert_rules:\n                    - enabled: true\n                      limit: 1024\n                      name: Output data over threshold\n                      sku: output_data\n                      timeframe: 43200\n            usr_mtd:\n                enabled: true\n                expiry: 0\n                tags: []\n                comment: \"\"\n</code></pre>"},{"location":"5-integrations/extensions/limacharlie/yara-manager/","title":"YARA Manager","text":"<p>The YARA manager Extension allows you to reference external YARA rules (rules maintained in GitHub, for example) to use in your YARA scans within LimaCharlie.</p> <p>YARA rule sources defined in the YARA manager configuration will be synced every 24 hours, and can be manually synced by clicking the <code>Manual Sync</code> button on the extension page.</p> <p>If you add rule sources and want them to become available immediately, you will need to click the <code>Manual Sync</code> button to trigger the initial sync of the rules.</p> <p>Rule sources can be either direct links (URLs) to a given YARA rule or ARLs.</p>"},{"location":"5-integrations/extensions/limacharlie/yara-manager/#option-1-predefined-yara-rules","title":"Option 1: Predefined YARA rules","text":"<p>LimaCharlie provides a list of YARA rule repositories, available in the configuration menu. To leverage these rules select \"Predefined\" and a list of LimaCharlie and Community rules will populate. By selecting one or more of these repositories, the respective rules will be automatically imported and will appear in your YARA rules under Automation \u2192 YARA Rules.</p> <p></p>"},{"location":"5-integrations/extensions/limacharlie/yara-manager/#option-2-publicly-available-yara-rules","title":"Option 2: Publicly available YARA rules","text":"<p>An example of setting up a rule using this repo: Yara-Rules</p> <p>For an <code>Email and General Phishing Exploit</code> rule we could use the following URL, which is a link to a single YARA rule.</p> <p>https://raw.githubusercontent.com/Yara-Rules/rules/master/email/Email_generic_phishing.yar</p> <p>For creating a rule out of multiple YARA rules, we could use the following ARL, which is a link to a directory of YARA rules.</p> <p><code>[github,Yara-Rules/rules/email]</code></p> <p>Giving the rule configuration a name, the URL or ARL, and clicking the Save button will create the new rule source to sync to your YARA rules.</p>"},{"location":"5-integrations/extensions/limacharlie/yara-manager/#option-3-private-yara-repository","title":"Option 3: Private YARA Repository","text":"<p>To use a YARA rule from a private Gihub repository you will need to make use of an Authentication Resource Locator.</p> <p>Step 1: Create a token in GitHub In GitHub go to Settings and click Developer settings in the left hand side bar.</p> <p>Next click Personal access token followed by Generate new token. Select repo permissions and finally Generate token.</p> <p>Step 2: Connect LimaCharlie to your GitHub repository Inside of LimaCharlie, click on Yara Manager in the left hand menu. Then click Add New Yara Configuration.</p> <p>Give your rule a name and then use the token you generated with the following format linked to your repo.</p> <p><code>[github,my-org/my-repo-name/path/to/rule.yar,token,bfuihferhf8erh7ubhfey7g3y4bfurbfhrb]</code></p> <p>or</p> <p><code>[github,my-org/my-repo-name/path/to/rules_directory,token,bfuihferhf8erh7ubhfey7g3y4bfurbfhrb]</code></p> <p>LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.</p>"},{"location":"5-integrations/extensions/third-party/atomic-red-team/","title":"Atomic Red Team","text":"<p>Atomic Red Team is a library of tests mapped to the MITRE ATT&amp;CK framework, provided by Red Canary. With this Extension, LimaCharlie users can use Atomic Red Team to quickly, portably, and reproducibly test their environments.</p> <p>Find more information about it here.</p> <p>New Atomic Red Team Extension</p> <p>Please note that the Atomic Red Team Extension has replaced the Atomic Red Team Service. Ensure that your Organization disabled/removes the Service and subscribes to the Extension. This documentation applies to the Atomic Red Team extension.</p>"},{"location":"5-integrations/extensions/third-party/atomic-red-team/#enabling-the-atomic-red-team-extension","title":"Enabling the Atomic Red Team Extension","text":"<p>Enabling Atomic Red Team can be done within the LimaCharlie Marketplace, or at this link.</p> <p></p> <p>Under the Organization dropdown, select a tenant (organization) you want to subscribe to Atomic Red Team and click subscribe.</p> <p></p> <p>Please note that Extensions are applied on the per-tenant basis. If you have multiple organizations you want to subscribe to Atomic Red Team, you will need to subscribe each organization to the extension separately.</p> <p>You can also manage add-ons from the Subscriptions menu under Billing.</p> <p></p> <p>Tenants that have been subscribed to the extension, will be marked with a green check mark in the Organization dropdown.</p>"},{"location":"5-integrations/extensions/third-party/atomic-red-team/#running-atomic-red-team-tests","title":"Running Atomic Red Team test(s)","text":"<p>After Atomic Red Team has been enabled for your organization, the Atomic Red Team option will be available under the Extensions menu in the web UI. Selecting this Extension will render the Atomic Red Team test selection menu.</p> <p></p> <p>Sensor Eligibility for Atomic Red Team tests</p> <p>Currently, LimaCharlie supports Atomic Red Team tests on Sensors installed on Windows operating systems. Furthermore, sensors must be online in order for tests to run.</p> <p>Within the Atomic Red Team menu, you can select a Sensor to run test(s) against. Furthermore, you can also pre-select a set of tests from the full Atomic Red Team suite.</p> <p>System Changes</p> <p>Running Atomic Red Team tests will likely modify some system configurations. LimaCharlie attempts to revert any configuration changes performed, but the core logic is handled by the Atomic Red Team project. The following actions may occur:</p> <ul> <li>Modify PowerShell scripting permissions</li> <li>Modify PowerShell script execution policies</li> <li>Check/Modify Microsoft Defender status</li> <li>Install dependencies like Nuget</li> <li>Install Atomic Red Team technique-specific dependencies</li> <li>Technique-specific configuration changes</li> </ul> <p>The list of available tests is updated every time the window is open, ensuring that you are getting all available options from the Atomic Red Team repository.</p> <p></p> <p>Select your test(s) of choice, and click 'Run Tests'. You will receive a dialog box with a job id that is associated with this particular run of test(s).</p>"},{"location":"5-integrations/extensions/third-party/atomic-red-team/#checking-atomic-red-team-results","title":"Checking Atomic Red Team Results","text":"<p>When the Atomic Red Team extension is enabled, you will see an Adapter named <code>ext-atomic-red-team</code>.</p> <p></p> <p>This Adapter corresponds to all Atomic Red Team activity, including jobs run and results returned. As a separate adapter, this also means that Atomic Red Team tests are actionable events. For example, you could construct a  rule based on Atomic Red Team test results or feedback from system telemetry.</p> <p>Viewing the Timeline within the <code>ext-atomic-red-team</code> adapter will display the test(s) run and associated results, if available.</p> <p></p> <p>Note that results are easily distinguished via a <code>result &lt;MITRE ATT&amp;CK ID&gt;</code> event name, allowing for easy filtering and analysis.</p> <p>Within the Timeline of the system on which you ran a test, you will also find <code>RECEIPT</code> event(s) that contain more details about executed tests. For example, the following output shows data related to a test for ATT&amp;CK ID T1053.</p> <p></p> <p>Between <code>RECEIPT</code> events and output in the <code>ext-atomic-red-team</code> adapter, you can correlate and identify successful and failed Atomic Red Team tests.</p>"},{"location":"5-integrations/extensions/third-party/govee/","title":"Govee","text":"<p>The Govee Extension allows you to trigger color changes on your supported Govee lights via a rule response action. It requires you to configure a Govee API key in the extension.</p>"},{"location":"5-integrations/extensions/third-party/govee/#setup","title":"Setup","text":"<ol> <li>Request an API key from Govee by following their instructions here</li> <li>Get the Device ID (device) and model (sku) of the device you'd like to target by requesting a list of your supported devices from the Govee API:</li> </ol> <pre><code>curl --location 'https://openapi.api.govee.com/router/api/v1/user/devices' --header 'Govee-API-Key: YOUR_GOVEE_API_KEY'\n</code></pre> <ol> <li>Decide what RGB color(s) you want to use. By default, the extension will alert with red (<code>255,0,0</code>), and revert back to white (<code>255,255,255</code>) when the alert <code>duration</code> has ended.</li> <li>Add your Govee API key to the extension configuration:     </li> </ol>"},{"location":"5-integrations/extensions/third-party/govee/#usage","title":"Usage","text":"<p>When enabled, you may configure the response of a D&amp;R rule to trigger a Govee event. Consider the following example response rule:</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-govee\n  extension request:\n    device_id: '{{ \"YOUR_GOVEE_DEVICE\" }}'\n    device_model: '{{ \"YOUR_GOVEE_DEVICE_SKU\" }}'\n    alert_color: '{{ \"255,0,0\" }}'\n    alert_brightness: '{{ \"100\" }}'\n    revert_color: '{{ \"255,255,255\" }}'\n    revert_brightness: '{{ \"10\" }}'\n    duration: '{{ \"30\" }}'\n  suppression:\n    is_global: true\n    keys:\n      - Govee\n    max_count: 1\n    period: 1m\n</code></pre> <p>Note that the only required fields here are the <code>device_id</code> and <code>device_model</code>. Values supplied in the example are the defaults.</p>"},{"location":"5-integrations/extensions/third-party/govee/#parameters","title":"Parameters","text":"<p>Required parameters:</p> <ul> <li><code>device_id</code>: returned via the Govee API, see example response below</li> <li><code>device_model</code>: returned via the Govee API, see example response below</li> </ul> <p>Optional parameters:</p> <ul> <li><code>alert_color</code>: color of the light when alert fires, in RGB format, default <code>255,0,0</code> (red)</li> <li><code>revert_color</code>: color of the light to return to, after alert fires, in RGB format, default <code>255,255,255</code> (white)</li> <li><code>alert_brightness</code>: brightness of the light, default <code>100</code></li> <li><code>revert_brightness</code>: brightness of the light to return to, after alert fires, default <code>10</code></li> <li><code>duration</code>: duration of the alert in seconds, how long the light will remain at <code>alert_color</code> before returning to <code>revert_color</code>, default <code>30</code></li> </ul> <p>Govee API sample request and response:</p> <pre><code>curl --location 'https://openapi.api.govee.com/router/api/v1/user/devices' --header 'Govee-API-Key: YOUR_GOVEE_API_KEY'\n</code></pre> <pre><code>{\n    \"code\": 200,\n    \"message\": \"success\",\n    \"data\": [\n        {\n            \"sku\": \"H6008\",                           # use in `device_model` parameter\n            \"device\": \"AA:BB:00:11:22:33:44:55\",      # use in `device_id` parameter\n            \"deviceName\": \"DetectionLight\",\n            \"type\": \"devices.types.light\",\n            \"capabilities\": [\n                ...\n            ]\n        }\n    ]\n}\n</code></pre>"},{"location":"5-integrations/extensions/third-party/hayabusa/","title":"Hayabusa","text":"<p>Hayabusa Extension Pricing</p> <p>While it is free to enable the Hayabusa extension, pricing is applied to downloaded and processed artifacts -- $0.02/GB for the original artifact, and $0.5/GB for the generation of the Hayabusa artifact.</p> <p>The Hayabusa extension allows you to run Hayabusa against a specified event log (.evtx) or a collection of event logs (.zip).</p> <p>Hayabusa is a Windows event log fast forensics timeline generator and threat hunting tool created by the Yamato Security group in Japan.</p> <p>LimaCharlie will automatically kick off the analysis based off of the artifact ID provided in a  rule action, or you can run it manually via the extension.</p>"},{"location":"5-integrations/extensions/third-party/hayabusa/#configuration","title":"Configuration","text":"<p>When enabled, you may configure the response of a D&amp;R rule to run a Hayabusa analysis against an artifact event. Consider the following example D&amp;R rule:</p> <p>Detect:</p> <pre><code>event: ingest\nop: exists\npath: /\ntarget: artifact_event\nartifact type: wel\n</code></pre> <p>Respond:</p> <pre><code>- action: extension request\n  extension action: generate\n  extension name: ext-hayabusa\n  extension request:\n       artifact_id: '{{ .routing.log_id }}'\n       send_to_timeline: true\n       profile: '{{ \"timesketch-verbose\" }}'\n       min_rule_level: '{{ \"informational\" }}'\n</code></pre> <p>Note that the only required field here is the <code>artifact_id</code>. The other values supplied in the example are the defaults.</p>"},{"location":"5-integrations/extensions/third-party/hayabusa/#results","title":"Results","text":"<pre><code>hayabusa update-rules\n\nhayabusa csv-timeline -f /path/to/your/artifact --RFC-3339 -p timesketch-$profile --min-level $min_rule_level --no-wizard --quiet -o $artifact_id.csv -U\n</code></pre> <p>Upon running Hayabusa, a CSV file is generated. The CSV file will be uploaded as a LimaCharlie artifact.</p> <p>The resulting CSV is compatible with Timesketch, and can be imported as a timeline.</p> <p>Outputting your data to Google BigQuery is another option, and is outlined here</p> <p>Several events will be pushed to the <code>ext-hayabusa</code> Sensor timeline:</p> <ul> <li><code>hayabusa_results</code>: contains the results summary from the Hayabusa output</li> <li><code>hayabusa_artifact</code>: contains the <code>artifact_id</code> of the CSV file that was uploaded to LimaCharlie</li> <li><code>hayabusa_event</code>: many of these will be sent to the timeline if you check the checkbox or parameter for <code>Send to timeline</code>, and it contains the raw contents of the Hayabusa CSV output in JSON format</li> </ul>"},{"location":"5-integrations/extensions/third-party/hayabusa/#arguments","title":"Arguments","text":"<ul> <li><code>artifact_id</code>: ID of the LimaCharlie artifact to process</li> <li> <p><code>profile</code>: either <code>minimal</code>, <code>standard</code>, <code>verbose</code>, <code>all-field-info</code>, <code>all-field-info-verbose</code>, <code>super-verbose</code>, <code>timesketch-minimal</code>, or <code>timesketch-verbose</code></p> </li> <li> <p>Default: <code>timesketch-verbose</code></p> </li> <li>More details</li> <li> <p><code>min_rule_level</code>: <code>informational</code>, <code>low</code>, <code>medium</code>, <code>high</code>, or <code>critical</code>, more details</p> </li> <li> <p>Default: <code>informational</code></p> </li> <li><code>send_to_timeline</code>: whether or not to ingest the Hayabusa results into the sensor timeline as events, boolean, default <code>true</code></li> </ul>"},{"location":"5-integrations/extensions/third-party/hayabusa/#usage","title":"Usage","text":"<p>If you use the LimaCharlie Velociraptor extension, a good use case of this extension would be to trigger Hayabusa analysis upon ingestion of a Velociraptor KAPE files artifact.</p> <p>Go to Extensions / Velociraptor, and run Collect Artifact request.</p> <p></p> <p>Kick off a <code>Windows.KapeFiles.Targets</code> artifact collection in the LimaCharlie Velociraptor extension</p> <p>Argument options:</p> <ul> <li><code>EventLogs=Y</code> </li> <li><code>KapeTriage=Y</code> - this is an option, however the extension will first take all .evtx files out of the triage collection and send them through Hayabusa, and ignore the rest, so there is more overhead involved, versus just using <code>EventLogs=Y</code>.</li> </ul> <p>Configure a D&amp;R rule to look for these events upon ingestion, and then trigger the Hayabusa extension:</p> <p>Detect:</p> <pre><code>op: and\ntarget: artifact_event\nrules:\n    - op: is\n      path: routing/log_type\n      value: velociraptor\n    - op: is\n      not: true\n      path: routing/event_type\n      value: export_complete\n</code></pre> <p>Respond:</p> <pre><code>- action: extension request\n  extension action: generate\n  extension name: ext-hayabusa\n  extension request:\n      artifact_id: '{{ .routing.log_id }}'\n      send_to_timeline: true    # `false` if you only want the CSV artifact\n</code></pre>"},{"location":"5-integrations/extensions/third-party/hayabusa/#generate-lc-detections-from-hayabusa-output","title":"Generate LC Detections from Hayabusa Output","text":"<p>Note</p> <p>This capability depends on setting the parameter to send Hayabusa output to the sensor timeline with <code>send_to_timeline: true</code></p> <p>Assuming you want Hayabusa detections of a certain <code>Level</code> or severity sent directly to your LimaCharlie detections stream, you can use the following D&amp;R rule to accomplish this:</p> <p>Detect:</p> <pre><code>event: hayabusa_event\nop: and\nrules:\n  - op: is\n    path: routing/hostname\n    value: ext-hayabusa\n  - op: matches\n    path: event/results/Level\n    re: (med|high|crit)\n</code></pre> <p>Respond:</p> <pre><code>- action: report\n  name: &gt;-\n    Hayabusa - {{ .event.results.Level }} - {{ .event.results.message }}\n</code></pre> <p>The resulting detection would look something like this:</p> <pre><code>{\n  \"action\": \"report\",\n  \"data\": {\n    \"cat\": \"Hayabusa - med - Failed Logon From Public IP\",\n    \"detect\": {\n      \"event\": {\n        \"artifact_id\": \"eb39c3b4-6312-41c8-8b6e-e0b46b2f870e\",\n        \"artifact_type\": \"evtx\",\n        \"event\": \"hayabusa_event\",\n        \"job_id\": \"2e904fda-6d3f-4ce1-bf82-ede97f3c0d17\",\n        \"results\": {\n          \"Channel\": \"Sec\",\n          \"Computer\": \"windows-server-2022-01304add-3354-4cca-b574-b0a54d7bb6f4-0\",\n          \"Details\": \"Type: 3 - NETWORK \u00a6 TgtUser: 4cca \u00a6 SrcComp: WIN-S2Q2306JU66 \u00a6 SrcIP: 185.161.248.147 \u00a6 AuthPkg: NTLM \u00a6 Proc: -\",\n          \"EventID\": \"4625\",\n          \"EvtxFile\": \"/tmp/triage_1078055872.evtx\",\n          \"ExtraFieldInfo\": \"FailureReason: BAD USER OR PW \u00a6 IpPort: 0 \u00a6 KeyLength: 0 \u00a6 LogonProcessName: NtLmSsp \u00a6 ProcessId: 0 \u00a6 Status: BAD USER OR PW \u00a6 SubStatus: UNKNOWN USER \u00a6 SubjectLogonId: 0x0 \u00a6 SubjectUserSid: S-1-0-0 \u00a6 TargetDomainName: windows-server-2022-01304add-3354-4cca-b574-b0a54d7bb6f4-0 \u00a6 TargetUserSid: S-1-0-0\",\n          \"Level\": \"med\",\n          \"MitreTactics\": \"InitAccess \u00a6 Persis\",\n          \"MitreTags\": \"T1078 \u00a6 T1190 \u00a6 T1133\",\n          \"OtherTags\": \"\",\n          \"RecordID\": \"681128\",\n          \"RuleFile\": \"win_security_susp_failed_logon_source.yml\",\n          \"datetime\": \"2024-03-20 21:50:55.930385+00:00\",\n          \"message\": \"Failed Logon From Public IP\",\n          \"timestamp_desc\": \"hayabusa\"\n        }\n      },\n      \"routing\": {\n        \"arch\": 9,\n        \"did\": \"\",\n        \"event_id\": \"0a6989a1-af71-4583-a8bc-e766bd2a81d8\",\n        \"event_time\": 1711071722721,\n        \"event_type\": \"hayabusa_event\",\n        \"ext_ip\": \"internal\",\n        \"hostname\": \"ext-hayabusa\",\n        \"iid\": \"bfac2d1f-5d8c-4115-9df2-633a4f1d062b\",\n        \"int_ip\": \"\",\n        \"moduleid\": 6,\n        \"oid\": \"01304add-3354-4cca-b574-b0a54d7bb6f4\",\n        \"plat\": 2415919104,\n        \"sid\": \"3109b3c7-c5ca-4029-b493-4d4e6766c4d3\",\n        \"tags\": [\n          \"ext:ext-hayabusa\",\n          \"lc:system\"\n        ],\n        \"this\": \"76088a58bb99484c82cf9e9065fce1ea\"\n      },\n      \"ts\": \"2024-03-22 01:42:02\"\n    },\n    \"detect_id\": \"90609b8b-c2b8-4537-b17e-5d1665fd8717\",\n    \"gen_time\": 1711114007077,\n    \"link\": \"https://app.limacharlie.io/orgs/01304add-3354-4cca-b574-b0a54d7bb6f4/sensors/3109b3c7-c5ca-4029-b493-4d4e6766c4d3/timeline?time=1711071722&amp;selected=76088a58bb99484c82cf9e9065fce1ea\",\n    \"mtd\": null,\n    \"routing\": {\n      \"arch\": 9,\n      \"did\": \"\",\n      \"event_id\": \"0a6989a1-af71-4583-a8bc-e766bd2a81d8\",\n      \"event_time\": 1711071722721,\n      \"event_type\": \"hayabusa_event\",\n      \"ext_ip\": \"internal\",\n      \"hostname\": \"ext-hayabusa\",\n      \"iid\": \"bfac2d1f-5d8c-4115-9df2-633a4f1d062b\",\n      \"int_ip\": \"\",\n      \"moduleid\": 6,\n      \"oid\": \"01304add-3354-4cca-b574-b0a54d7bb6f4\",\n      \"plat\": 2415919104,\n      \"sid\": \"3109b3c7-c5ca-4029-b493-4d4e6766c4d3\",\n      \"tags\": [\n        \"ext:ext-hayabusa\",\n        \"lc:system\"\n      ],\n      \"this\": \"76088a58bb99484c82cf9e9065fce1ea\"\n    },\n    \"source\": \"01304add-3354-4cca-b574-b0a54d7bb6f4.bfac2d1f-5d8c-4115-9df2-633a4f1d062b.3109b3c7-c5ca-4029-b493-4d4e6766c4d3.90000000.9\",\n    \"source_rule\": \"replay-rule\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/extensions/third-party/nims/","title":"NIMS","text":"<p>Notion Incident Management System (NIMS) helps SOC/IR teams streamline their incident collaboration. While not a replacement for advanced SIEM or SOAR case management systems, it offers a practical alternative for teams that don't have access to these tools.</p> <p>The Notion template uses interconnected relational databases to enable effective incident tracking and case management.</p> <p>The LimaCharlie NIMS extension allows you to send detections from LimaCharlie to NIMS via the Notion API.</p> <p>Once you subscribe an org to the extension, it creates a D&amp;R rule that sends all detections from your org to your NIMS alert database. Because Notion databases do have a limit on the number of records, the extension also has the ability to purge old alerts that are 1) not associated with any incidents, and 2) older than the specified number of days. A D&amp;R rule is also created to perform this cleanup automatically (or not) based on your configuration.</p> <p>More information about NIMS, including the template and corresponding docs, can be found here.</p>"},{"location":"5-integrations/extensions/third-party/nims/#configuration","title":"Configuration","text":"<p>In order to use this extension, you will need 3 pieces of data:</p> <ul> <li>Notion authentication token</li> <li>NIMS Alert database ID</li> <li>NIMS Asset database ID</li> </ul>"},{"location":"5-integrations/extensions/third-party/nims/#find-your-database-ids","title":"Find your database IDs","text":"<ol> <li>Navigate to the Alert database within NIMS under <code>Databases</code></li> <li>Right click on the database and click <code>Copy link</code></li> <li> <p>Locate the database ID in the URL</p> </li> <li> <p>The database ID is the long string of letters and numbers in the URL after the last <code>/</code> and before the <code>?</code> or <code>#</code> if present</p> </li> <li> <p>Example:</p> <ul> <li>Link: <code>https://www.notion.so/184cdc5a1ef3710badc2d2b1271aeb81?v=174cdc3a1ef181719981000cab12bf54&amp;pvs=4</code></li> <li>ID: <code>184cdc5a1ef3710badc2d2b1271aeb81</code></li> <li>Copy the ID</li> <li>Repeat the above for the Asset database</li> </ul> </li> </ol>"},{"location":"5-integrations/extensions/third-party/nims/#generate-an-auth-token","title":"Generate an auth token","text":"<p>This will walk you through creating a Notion integration, getting the auth token, and adding the integration to the proper NIMS databases.</p> <p>While completing the following steps, be sure to add the connection to all 3 databases\u2014Alert, Asset, and Incident. Incident is only necessary in order to perform the alerts cleanup to see whether or not the alert is tied to an incident.</p> <ol> <li>Go to <code>Manage connections</code> in Notion </li> <li>Click <code>Develop or manage integrations</code></li> <li>Click <code>New integration</code></li> <li> <p>Configure the new integration</p> </li> <li> <p>Give it a name, ex: <code>nims_template</code></p> </li> <li>Choose the workspace</li> <li>Type: <code>Internal</code></li> <li>Click <code>Save</code> </li> <li>Click <code>Configure integration settings</code> </li> <li> <p>Copy the <code>Internal Integration Secret</code>-- this is your auth token</p> </li> <li> <p>Click <code>Save</code> </p> </li> <li> <p>Navigate to your <code>Alert Database</code></p> </li> <li> <p>Click the 3-dot menu and find <code>Connections</code></p> </li> <li>Click on your newly created integration </li> <li>Click <code>Confirm</code> </li> <li>Repeat steps 7 and 8 for the <code>Asset Database</code> and the <code>Incident Database</code></li> </ol>"},{"location":"5-integrations/extensions/third-party/nims/#example-dr-rule","title":"Example D&amp;R rule","text":"<p>Detect:</p> <pre><code>op: exists\npath: cat\ntarget: detection\n</code></pre> <p>Respond:</p> <pre><code>- action: extension request\n  extension action: push_detections\n  extension name: ext-nims\n  extension request:\n    cat: '{{ .cat }}'\n    detection: '{{json .detect }}'\n    event_time: '{{ .routing.event_time }}'\n    hostname: '{{ .routing.hostname }}'\n    int_ip: '{{ .routing.int_ip }}'\n    link: '{{ .link }}'\n    metadata: '{{json .detect_mtd }}'\n</code></pre>"},{"location":"5-integrations/extensions/third-party/nims/#related","title":"Related","text":"<ul> <li>OTX</li> </ul>"},{"location":"5-integrations/extensions/third-party/otx/","title":"OTX","text":"<p>AlienVault's Open Threat Exchange (OTX) is the \"neighborhood watch of the global intelligence community.\" It enables private companies, independent security researchers, and government agencies to openly collaborate and share the latest information about emerging threats, attack methods, and malicious actors, promoting greater security across the entire community.</p> <p>More information about OTX can be found here.</p>"},{"location":"5-integrations/extensions/third-party/otx/#enabling-the-otx-extension","title":"Enabling the OTX Extension","text":"<p>Before utilizing the OTX extension, you will need an AlienVault OTX API Key. This can be found in your AlienVault OTX account here.</p> <p>To enable the OTX extension, navigate to the OTX extension page. Select the Organization you wish to enable the extension for, and select Subscribe.</p> <p>Once the extension is enabled, navigate to Extensions &gt; OTX. You will need to provide your OTX API Key, which can be done directly in the form or via LimaCharlie's Secrets Manager.</p> <p>Pulses will be synced to rules and lookups automatically every 3 hours.</p>"},{"location":"5-integrations/extensions/third-party/otx/#using-the-otx-extension","title":"Using the OTX Extension","text":"<p>After providing a valid API key, the Extension will automatically create Detection &amp; Response rules for your organization. The OTX rules make use of the following events:</p> <ul> <li>Process Events</li> <li>CODE_IDENTITY</li> <li>EXISTING_PROCESS</li> <li>MEM_HANDLES_REP (response to the mem_handles Sensor command)</li> <li>NEW_PROCESS</li> <li>Network Events</li> <li>DNS_REQUEST</li> <li>HTTP_REQUEST</li> <li>NETWORK_CONNECTIONS</li> <li>NEW_TCP4_CONNECTION</li> <li>NEW_TCP6_CONNECTION</li> <li>NEW_UDP4_CONNECTION</li> <li>NEW_UDP6_CONNECTION</li> </ul> <p>Please ensure that the events you are interested in using with OTX lookups are enabled in the Sensors &gt; Event Collection menu.</p>"},{"location":"5-integrations/extensions/third-party/pagerduty/","title":"PagerDuty","text":"<p>The PagerDuty Extension allows you to trigger events within PagerDuty. It requires you to setup the PagerDuty access token in the Integrations section of your Organization.</p> <p>Some more detailed information is available here.</p>"},{"location":"5-integrations/extensions/third-party/pagerduty/#rest","title":"REST","text":""},{"location":"5-integrations/extensions/third-party/pagerduty/#trigger-event","title":"Trigger Event","text":"<pre><code>{\n  \"summary\": \"Critical credentials theft alert.\",\n  \"source\": \"limacharlie.io\",\n  \"severity\": \"critical\",\n  \"component\": \"dr-creds-theft\",\n  \"group\": \"lc-alerts\",\n  \"class\": \"dr-rules\"\n}\n</code></pre>"},{"location":"5-integrations/extensions/third-party/pagerduty/#pagerduty-configuration","title":"PagerDuty Configuration","text":"<p>On the PagerDuty side, you need to configure your PagerDuty service to receive the API notifications:</p> <ol> <li>In your Service, go to the \"Integrations\" tab.</li> <li>Click \"Add a new integration\".</li> <li>Give it a name, like \"LimaCharlie\".</li> <li>In the \"Integration Type\" section, select the radio button \"Use our API directly\" and select \"Events API v2\" from the dropdown.</li> <li>Click \"Add integration\".</li> <li>Back in the \"Integrations\" page, you should see your new integration in the list. Copy the \"Integration Key\" to your clipboard and add it in the \"Integrations\" section of LimaCharlie for PagerDuty.</li> </ol> <p>From this point on, you may use a rule to trigger a PagerDuty event. For example the following rule \"response\":</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-pagerduty\n  extension request:\n       class: '{{ \"dr-rules\" }}'\n       group: '{{ \"lc-alerts\" }}'\n       severity: '{{ \"critical\" }}'\n       source: '{{ \"LimaCharlie\" }}'\n       component: '{{ \"dr-creds-theft\" }}'\n       summary: '{{ .routing.hostname }} - {{ .routing.sid }} - {{ .cat }}'\n       details: '{{ .event }}'\n</code></pre>"},{"location":"5-integrations/extensions/third-party/pagerduty/#migrating-dr-rule-from-legacy-service-to-new-extension","title":"Migrating D&amp;R Rule from legacy Service to new Extension","text":"<p>Note: LimaCharlie has migrated from Services to Extensions. Legacy services are no longer supported.</p> <p>The Python CLI gives you a direct way to assess if any rules reference legacy PagerDuty service, preview the change and execute the conversion required in the rule \"response\".</p> <p>Command line to preview PagerDuty rule conversion:</p> <pre><code>limacharlie extension convert_rules --name ext-pagerduty\n</code></pre> <p>A dry-run response (default) will display the rule name being changed, a JSON of the service request rule and a JSON of the incoming extension request change.</p> <p>To execute the change in the rule, explicitly set <code>--dry-run</code> flag to <code>--no-dry-run</code></p> <p>Command line to execute PagerDuty rule conversion:</p> <pre><code>limacharlie extension convert_rules --name ext-pagerduty --no-dry-run\n</code></pre> <p>LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p>"},{"location":"5-integrations/extensions/third-party/plaso/","title":"Plaso","text":"<p>Plaso Extension Pricing</p> <p>While it is free to enable the Plaso extension, pricing is applied to both the original downloaded artifact and the processed (Plaso) artifacts -- $0.02/GB for the original downloaded artifact, and $1.0/GB for the generation of the processed artifacts.</p>"},{"location":"5-integrations/extensions/third-party/plaso/#about","title":"About","text":"<p>Plaso is a Python-based suite of tools used for creation of analysis timelines from forensic artifacts acquired from an endpoint.</p> <p>These timelines are invaluable tools for digital forensic investigators and analysts, enabling them to effectively correlate the vast quantities of information encountered in logs and various forensic artifacts encountered in an intrusion investigation.</p> <p>The primary tools in the Plaso suite used for this process are log2timeline, psort, and psteal.</p> <ul> <li><code>log2timeline</code> - bulk forensic artifact parser</li> <li><code>psort</code> - builds timelines based on output from <code>log2timeline</code></li> <li><code>psteal</code> - Simply a wrapper for <code>log2timeline</code> and <code>psort</code></li> </ul> <p>The <code>ext-plaso</code> extension within LimaCharlie allows you to run <code>log2timeline</code> and <code>psort</code> (using the <code>psteal</code> wrapper) against artifacts obtained from an endpoint, such as event logs, registry hives, and various other forensic artifacts. When executed, Plaso will parse and extract information from all acquired evidence artifacts that it has support for. Supported parsers are found here.</p>"},{"location":"5-integrations/extensions/third-party/plaso/#extension-configuration","title":"Extension Configuration","text":"<p>Long Execution Times</p> <p>Note that it can take several minutes for the plaso generation to complete for larger triage collections, but once it finishes you will see the results in the <code>ext-plaso</code> Sensor timeline, as well as the uploaded artifacts on the Artifacts page.</p> <p>The <code>ext-plaso</code> extension runs <code>psteal</code> (<code>log2timeline</code> + <code>psort</code>) against the acquired evidence using the following commands:</p> <ol> <li><code>bash    psteal.py --source /path/to/artifact -o dynamic --storage-file $artifact_id.plaso -w $artifact_id.csv</code></li> </ol> <p>Upon running <code>psteal.py</code>, a <code>.plaso</code> file and a <code>.csv</code> file are generated. They will be uploaded as LimaCharlie artifacts.</p> <ul> <li>Resulting <code>.plaso</code> file contains the raw output of <code>log2timeline.py</code></li> <li> <p>Resulting <code>.csv</code> file contains the CSV formatted version of the <code>.plaso</code> file contents</p> </li> <li> <p><code>bash    pinfo.py $artifact_id.plaso -w $artifact_id_pinfo.json --output_format json</code></p> </li> </ul> <p>After <code>psteal.py</code> runs, information is gathered from the resulting <code>.plaso</code> file using the <code>pinfo.py</code> utility and pushed into the <code>ext-plaso</code> sensor timeline as a <code>pinfo</code> event. This event provides a detailed summary with metrics of the processing that occurred, as well as any relevant errors you should be aware of.</p> <p>The following events will be pushed to the <code>ext-plaso</code> sensor timeline:</p> <ul> <li><code>job_queued</code>: indicates that <code>ext-plaso</code> has received and queued a request to process data</li> <li><code>job_started</code>: indicates that <code>ext-plaso</code> has started processing the data</li> <li><code>pinfo</code>: contains the <code>pinfo.py</code> output summarizing the results of the plaso file generation</li> <li><code>plaso</code>: contains the <code>artifact_id</code> of the plaso file that was uploaded to LimaCharlie</li> <li><code>csv</code>: contains the <code>artifact_id</code> of the CSV file that was uploaded to LimaCharlie</li> </ul>"},{"location":"5-integrations/extensions/third-party/plaso/#usage-automation","title":"Usage &amp; Automation","text":"<p>LimaCharlie can automatically kick off evidence processing with Plaso based off of the artifact ID provided in a  rule action, or you can run it manually via the extension.</p>"},{"location":"5-integrations/extensions/third-party/plaso/#velociraptor-triage-acquisition-processing","title":"Velociraptor Triage Acquisition Processing","text":"<p>If you use the LimaCharlie Velociraptor extension, a good use case of <code>ext-plaso</code> would be to trigger Plaso evidence processing upon ingestion of a Velociraptor KAPE files artifact collection.</p> <ol> <li>Configure a D&amp;R rule to watch for Velociraptor collection events upon ingestion, and then trigger the Plaso extension:</li> </ol> <p>Detect:</p> <pre><code>op: and\ntarget: artifact_event\nrules:\n    - op: is\n      path: routing/log_type\n      value: velociraptor\n    - op: is\n      not: true\n      path: routing/event_type\n      value: export_complete\n</code></pre> <p>Respond:</p> <p><pre><code>- action: extension request\n  extension action: generate\n  extension name: ext-plaso\n  extension request:\n      artifact_id: '{{ .routing.log_id }}'\n</code></pre> 2. Launch a <code>Windows.KapeFiles.Targets</code> artifact collection in the LimaCharlie Velociraptor extension. This instructs Velociraptor to gather all endpoint artifacts defined in this KAPE Target file.</p> <p>Argument options:</p> <ul> <li><code>EventLogs=Y</code> - EventLogs only, quicker processing time for proof of concept</li> <li><code>KapeTriage=Y</code> - full KapeTriage files collection </li> <li>Once Velociraptor collects, zips, and uploads the evidence, the previously created D&amp;R rule will send the triage <code>.zip</code> to <code>ext-plaso</code> for processing. Watch the <code>ext-plaso</code> sensor timeline for status and the Artifacts page for the resulting <code>.plaso</code> &amp; <code>.csv</code> output files. See Working with the Output.</li> </ul>"},{"location":"5-integrations/extensions/third-party/plaso/#mft-processing","title":"MFT Processing","text":"<p>If you use the LimaCharlie Dumper extension, a good use case of <code>ext-plaso</code> would be to trigger Plaso evidence processing upon ingestion of a MFT CSV artifact.</p> <ol> <li>Configure a D&amp;R rule to watch for MFT collection events upon ingestion, and then trigger the Plaso extension:</li> </ol> <p>Detect:</p> <pre><code>op: and\ntarget: artifact_event\nrules:\n    - op: is\n      path: routing/log_type\n      value: mftcsv\n    - op: is\n      not: true\n      path: routing/event_type\n      value: export_complete\n</code></pre> <p>Respond:</p> <p><pre><code>- action: extension request\n  extension action: generate\n  extension name: ext-plaso\n  extension request:\n      artifact_id: '{{ .routing.log_id }}'\n</code></pre> 2. Launch an MFT dump in the LimaCharlie Dumper extension.     3. Once dumper is complete and uploads the evidence, the previously created D&amp;R rule will send the zipped MFT CSV to <code>ext-plaso</code> for processing. Watch the <code>ext-plaso</code> sensor timeline for status and the Artifacts page for the resulting <code>.plaso</code> &amp; <code>.csv</code> output files. See Working with the Output.</p>"},{"location":"5-integrations/extensions/third-party/plaso/#working-with-the-output","title":"Working with the Output","text":"<p>Running the extension generates the following useful outputs:</p> <p></p> <ul> <li> <p><code>pinfo</code> on <code>ext-plaso</code> sensor timeline    First and foremost, after the completion of a processing job by <code>ext-plaso</code>, it is highly encouraged to analyze the resulting <code>pinfo</code> event on the <code>ext-plaso</code> sensor timeline. This event provides a detailed summary with metrics of the processing that occurred, as well as any relevant errors you should be aware of.</p> </li> <li> <p>Pay close attention to fields such as <code>warnings_by_parser</code> or <code>warnings_by_path_spec</code> which may reveal parser errors that were encountered.</p> </li> <li>Sample output of <code>pinfo</code> showing counts of parsed artifacts nested under <code>storage_counters</code> -- this provides insight as to which, and how many events will be present in your CSV timeline.</li> </ul> <pre><code>\"amcache\": 986,\n\"appcompatcache\": 4096,\n\"bagmru\": 29,\n\"chrome_27_history\": 29,\n\"chrome_66_cookies\": 246,\n\"explorer_mountpoints2\": 2,\n\"explorer_programscache\": 1,\n\"filestat\": 3495,\n\"lnk\": 160,\n\"mft\": 4790977,\n\"mrulist_string\": 2,\n\"mrulistex_shell_item_list\": 3,\n\"mrulistex_string\": 5,\n\"mrulistex_string_and_shell_item\": 5,\n\"mrulistex_string_and_shell_item_list\": 1,\n\"msie_webcache\": 143,\n\"msie_zone\": 60,\n\"networks\": 4,\n\"olecf_automatic_destinations\": 37,\n\"olecf_default\": 5,\n\"recycle_bin\": 3,\n\"shell_items\": 297,\n\"total\": 5840430,\n\"user_access_logging\": 34,\n\"userassist\": 44,\n\"utmp\": 13,\n\"windows_boot_execute\": 8,\n\"windows_run\": 10,\n\"windows_sam_users\": 16,\n\"windows_services\": 2004,\n\"windows_shutdown\": 8,\n\"windows_task_cache\": 835,\n\"windows_timezone\": 4,\n\"windows_typed_urls\": 3,\n\"windows_version\": 6,\n\"winevtx\": 382674,\n\"winlogon\": 8,\n\"winreg_default\": 654177\n</code></pre>"},{"location":"5-integrations/extensions/third-party/plaso/#downloadable-artifacts","title":"Downloadable Artifacts","text":"<ul> <li><code>plaso</code> artifact    The downloadable <code>.plaso</code> file contains the raw output of <code>log2timeline.py</code> and can be imported into Timesketch as a timeline.</li> <li><code>csv</code> artifact    The downloadable <code>.csv</code> file can be easily viewed in any CSV viewer, but a highly recommended tool for this is Timeline Explorer from Eric Zimmerman.</li> </ul>"},{"location":"5-integrations/extensions/third-party/renigma/","title":"REnigma","text":""},{"location":"5-integrations/extensions/third-party/renigma/#about-renigma","title":"About REnigma","text":"<p>REnigma is an advanced malware analysis platform leveraging its unique Record and Replay technology to deliver unparalleled precision and depth. By recording every state change in a virtual machine during live execution, REnigma enables analysts to replay and analyze malware behaviors offline, down to the instruction level. This approach eliminates the risk of evasion and ensures a comprehensive capture of malicious activity. For SOC teams triaging alerts or incident responders conducting deep dives, REnigma offers rapid detonation, precision analysis, and effortless artifact extraction. Its API integrations further enhance workflows, enabling seamless automation and streamlined investigation processes.</p>"},{"location":"5-integrations/extensions/third-party/renigma/#about-the-extension","title":"About the Extension","text":"<p>The LimaCharlie Extension for REnigma seamlessly integrates with the REnigma API, enabling automated analysis of suspicious URLs or files collected using the LimaCharlie BinLib or Artifact Extensions. When a file or URL triggers an alert in LimaCharlie, preconfigured Detection &amp; Response () rules can automatically queue the item for further investigation in REnigma.</p> <p>Through the integration, these D&amp;R rules send the artifact or URL directly to REnigma, where it is recorded and analyzed in a controlled virtual machine environment. Analysts can then access detailed execution data, artifacts, and network patterns captured by REnigma's Record and Replay technology. This workflow not only streamlines the triage process but also provides deep insights into potential threats without requiring manual intervention at every step.</p>"},{"location":"5-integrations/extensions/third-party/renigma/#configuration","title":"Configuration","text":"<p>To use the REnigma extension, you will need your REnigma URL and API key. Contact the REnigma team for access.</p> <p></p>"},{"location":"5-integrations/extensions/third-party/renigma/#using-the-extension","title":"Using the Extension","text":"<p>You can submit a file or URL to the REnigma extension for processing in one of 2 ways:</p> <ol> <li> <p>Via the LimaCharlie web UI:</p> </li> <li> <p>Submit the ID of the artifact you wish to process with REnigma, and it will get uploaded and processed via a series of D&amp;R rules. You will see the output in the <code>ext-renigma</code> sensor timeline.</p> </li> <li>Submit the URL you wish to analyze with REnigma, and it will get sent and processed via a series of D&amp;R rules. You will see the output in the <code>ext-renigma</code> sensor timeline.</li> <li> <p>Via D&amp;R rules:</p> </li> <li> <p>Detect:</p> <p><pre><code>event: ingest\nop: exists\npath: /\ntarget: artifact_event\nartifact type: ext-binlib-bin\n</code></pre>    2. Respond</p> <pre><code>- action: \"extension request\"\n  extension name: \"ext-renigma\"\n  extension action: \"upload_file\"\n  extension request:\n      file_id: '{{ .routing.log_id }}'\n      disable_internet: false\n</code></pre> </li> </ol> <p>LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.</p>"},{"location":"5-integrations/extensions/third-party/renigma/#related-articles","title":"Related Articles","text":"<ul> <li>BinLib</li> <li>Artifacts</li> <li>Using Extensions</li> <li>Secure Annex</li> </ul>"},{"location":"5-integrations/extensions/third-party/secureannex/","title":"Secure Annex","text":"<p>Secure Annex is a browser extension security platform that provides a comprehensive analysis of the Chrome extensions installed across your organization's endpoints.</p> <p>The Secure Annex LimaCharlie Extension allows you to query the Secure Annex API with the IDs of Chrome extensions installed on endpoints within your organization in order to get detailed information about the extensions. You can then perform additional analysis or craft rules based on the results.</p> <p>API endpoints available for querying are:</p> <ul> <li>/manifest</li> <li>/extensions</li> <li>/vulnerabilities</li> <li>/signatures</li> <li>/urls</li> <li>/analysis</li> </ul> <p>This is currently only supported on Windows, macOS, and Chrome sensors.</p>"},{"location":"5-integrations/extensions/third-party/secureannex/#setup","title":"Setup","text":"<ol> <li>Sign up and get an API key at https://app.secureannex.com/settings/api</li> <li>Subscribe to the Secure Annex extension in LimaCharlie - https://app.limacharlie.io/add-ons/extension-detail/ext-secureannex</li> <li>Add the API key to the Secure Annex extension configuration within LimaCharlie</li> </ol>"},{"location":"5-integrations/extensions/third-party/secureannex/#usage","title":"Usage","text":""},{"location":"5-integrations/extensions/third-party/secureannex/#manually-in-the-gui","title":"Manually in the GUI","text":"<p>You can trigger an extension request manually within the web app by clicking the <code>Get extensions from endpoint</code> button. This will allow you to choose a sensor, or sensors via a Sensor Selector, to get extensions from. More examples of sensor selectors can be found here.</p> <p>The extensions are gathered from endpoints via the reliable tasking extension, which appends <code>secureannex_extensions</code> to the investigation ID of the <code>RECEIPT</code> or <code>OS_PACKAGES_REP</code> event in order to trigger an extension request to query Secure Annex. The results will be in the timeline of the <code>ext-secureannex</code> sensor.</p>"},{"location":"5-integrations/extensions/third-party/secureannex/#automatically-via-dr-rules","title":"Automatically via D&amp;R Rules","text":"<p>Upon subscribing to the Secure Annex extension, several D&amp;R rules are added to your organization in a disabled state to help you get more use out of the extension and automate your detections. They are as follows:</p> <ul> <li><code>ext-secureannex-detect-vulnerabilities</code></li> <li>This will look at the vulnerabilities and associated severities in the <code>vulnerability</code> results returned, and create detections on high and critical vulnerabilities found</li> <li><code>ext-secureannex-detect-risk-rating</code></li> <li>This will look at the risks and associated severities in the <code>manifest</code> results returned, and create detections on high and critical severities found</li> <li><code>ext-secureannex-get-extensions-windows</code></li> <li>This schedules a base64 encoded PowerShell script to run every 24 hours to query Windows sensors for installed Chrome extensions, and bring back a list of the extension IDs and versions</li> <li>The results will have a <code>secureannex_extensions</code> investigation ID associated that will allow LimaCharlie to automatically create Secure Annex extension requests with the IDs and versions included to perform a full analysis and bring back the results into the <code>ext-secureannex</code> sensor</li> <li><code>ext-secureannex-get-extensions-mac</code></li> <li>This schedules a base64 encoded bash script to run every 24 hours to query macOS sensors for installed Chrome extensions, and bring back a list of the extension IDs and versions</li> <li>The results will have a <code>secureannex_extensions</code> investigation ID associated that will allow LimaCharlie to automatically create Secure Annex extension requests with the IDs and versions included to perform a full analysis and bring back the results into the <code>ext-secureannex</code> sensor</li> <li><code>ext-secureannex-get-extensions-chrome</code></li> <li>This schedules the <code>OS_PACKAGES</code> command to run every 24 hours to query Chrome sensors for installed Chrome extensions, and bring back a list of the extension IDs and versions</li> <li>The results will have an investigation ID associated that will allow LimaCharlie to automatically create Secure Annex extension requests with the IDs and versions included to perform a full analysis and bring back the results into the <code>ext-secureannex</code> sensor</li> </ul> <p>If you wish to use these, you need to enable them first. You can also copy the contents of these rules and create your own so they are no longer managed by the Secure Annex extension if you wish to modify them.</p>"},{"location":"5-integrations/extensions/third-party/secureannex/#results","title":"Results","text":"<p>Results will show up in the live feed and timeline of the <code>ext-secureannex</code> Sensor.</p>"},{"location":"5-integrations/extensions/third-party/strelka/","title":"Strelka","text":""},{"location":"5-integrations/extensions/third-party/strelka/#strelka-extension-pricing","title":"Strelka Extension Pricing","text":"<p>Note that usage of ext-strelka will incur usage of Artifact Exporting (applied to processed artifacts at a rate of $0.02/GB) as well as webhook data received in LimaCharlie and the related costs on top of the ext-strelka specific pricing.</p> <p>Strelka is a real-time file scanning system used for threat hunting, threat detection, and incident response.</p> <p>The Strelka extension receives files using Artifacts by specifying an <code>artifact_id</code> in the <code>run_on</code> request. The extension will then process the file and return the results to the caller as well as send the results to its related Sensor.</p>"},{"location":"5-integrations/extensions/third-party/strelka/#configuration","title":"Configuration","text":"<p>Example  rule that processes all Artifacts ingested with the type <code>zeek-extract</code>:</p> <p>Detect:</p> <pre><code>event: ingest\nop: is\npath: routing/log_type\ntarget: artifact_event\nvalue: zeek-extract\n</code></pre> <p>Respond:</p> <pre><code>- action: extension request\n  extension action: run_on\n  extension name: ext-strelka\n  extension request:\n    artifact_id: '{{ .routing.log_id }}'\n</code></pre>"},{"location":"5-integrations/extensions/third-party/strelka/#usage","title":"Usage","text":"<p>If you use the LimaCharlie Zeek extension, a good use case would be to trigger a Zeek analysis upon ingestion of a PCAP artifact, which will generate the necessary Zeek artifacts to trigger the Strelka extension in the above example.</p> <p>Detect:</p> <pre><code>op: exists\nevent: ingest\nartifact type: pcap\npath: /\ntarget: artifact_event\n</code></pre> <p>Respond:</p> <pre><code>- action: extension request\n  extension action: run_on\n  extension name: ext-zeek\n  extension request:\n    artifact_id: '{{ .routing.log_id }}'\n    retention: 30\n</code></pre>"},{"location":"5-integrations/extensions/third-party/twilio/","title":"Twilio","text":""},{"location":"5-integrations/extensions/third-party/twilio/#overview","title":"Overview","text":"<p>The Twilio Extension allows you to send messages within Twilio. It requires you to setup the Twilio authentication in the Integrations section of your Organization.</p> <p>Some more detailed information is available here.</p>"},{"location":"5-integrations/extensions/third-party/twilio/#setup","title":"Setup","text":"<p>To start leveraging the Twilio extension, first subscribe to the <code>ext-twilio</code> add-on that can be accessed from the LimaCharlie Marketplace.</p> <p></p> <p>After you have subscribed to the extension, setup the Twilio authentication in the <code>Secrets Manager</code> section of your organization.</p> <p>Authentication in Twilio uses two components--a SID and a token. The LimaCharlie Twilio secret will combine both components in a single field like <code>SID/TOKEN</code>.</p>"},{"location":"5-integrations/extensions/third-party/twilio/#detection-response","title":"Detection &amp; Response","text":"<p>Example Response portion of a  rule that sends a message out via Twilio as the response action:</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: ext-twilio\n  extension request:\n    body: '{{ .event }}'\n    from: '{{ \"+10123456789\" }}'\n    to: '{{ \"+10123456789\" }}'\n</code></pre> <p>Note that the <code>{{ .event }}</code> in the example above is the actual text that would be sent to the number you specify.</p>"},{"location":"5-integrations/extensions/third-party/velociraptor/","title":"Velociraptor","text":""},{"location":"5-integrations/extensions/third-party/velociraptor/#overview","title":"Overview","text":"<p>Velociraptor is an open source endpoint visibility tool that includes power digital forensic, incident response, and incident triage capabilities. LimaCharlie can be used to deploy Velociraptor at scale, allowing for easy artifact collection and incident analysis.</p> <p>The interface defines 2 main actions:</p> <ol> <li>Show Artifact - allows you to inspect the VQL artifacts available for collection</li> <li>Collect Artifact - allows you to run an artifact collection on one or more endpoints</li> </ol>"},{"location":"5-integrations/extensions/third-party/velociraptor/#show-artifact","title":"Show Artifact","text":"<p>Simply choose an artifact from the list to inspect it's contents.</p> <p></p> <p>Result of the action</p> <p></p>"},{"location":"5-integrations/extensions/third-party/velociraptor/#collect-artifact","title":"Collect Artifact","text":"<p>This allows you to collect one or more Velociraptor Artifacts from one or more endpoints via the Endpoint Agent. </p> <p>Velociraptor will generate a ZIP file with all collected data, which is automatically ingested into LimaCharlie's Artifact system for download.</p>"},{"location":"5-integrations/extensions/third-party/velociraptor/#arguments","title":"Arguments","text":"<ul> <li>Artifacts - Select one or more Velociraptor artifacts you wish to collect</li> <li>Sensor Selector - Select either a single sensor by selecting it's Sensor ID from the dropdown or use a Sensor Selector Expression to cast a wider net such as <code>plat==windows</code></li> <li>Arguments (optional) - These are optional arguments (or parameters) passed directly to the Velociraptor Artifact. For instance, if you wanted to run a collection for Windows.KapeFiles.Targets and wanted to specify the KapeTriage targets for collection, you would specify <code>KapeTriage=Y</code> in the Arguments since this is a boolean parameter for the <code>Windows.KapeFiles.Targets</code> artifact.</li> <li>Collection Seconds (optional) - Define how long (in seconds) the Extension will wait for a targeted endpoint to come online and be processed for collection.</li> <li>Retention Days (optional) - Define how long the collected artifact will be retained by the platform.</li> <li>Ignore SSL Errors (optional) - Tells the endpoint to ignore SSL errors while running and collecting. This can be useful if the endpoint is behind a MITM proxy or firewall performing SSL interception.</li> </ul>"},{"location":"5-integrations/extensions/third-party/velociraptor/#monitoring-collections","title":"Monitoring Collections","text":"<p>You are able to track Velociraptor hunts by viewing the Timeline for the <code>ext-velociraptor</code> sensor.</p> <p></p> <p>Once you see <code>artifact_uploaded</code> in the timeline, you can expect to find the artifact on the \"Artifacts\" screen.</p> <p></p>"},{"location":"5-integrations/extensions/third-party/velociraptor/#automating-collection-retrieval","title":"Automating Collection Retrieval","text":"<p>Let's say you wanted to automatically fetch new Velociraptor collections and send somewhere else for storage/processing. This can be accomplished via  rules which watch for the artifact upload and send to a tailored output.</p> <p>Example D&amp;R rule</p> <pre><code># Detection\nop: is\npath: routing/log_type\ntarget: artifact_event\nvalue: velociraptor\n\n# Response\n- action: output\n  name: artifacts-tailored\n  suppression:\n    is_global: false\n    keys:\n        - '{{ .event.original_path }}'\n        - '{{ .routing.log_id }}'\n    max_count: 1\n    period: 1m\n- action: report\n  name: VR artifact ingested\n</code></pre> <p>To see how you could use something like this to automate post-processing of Velociraptor triage collections, check out this open source example which sends KAPE Triage acquisitions to a webhook which then retrieves the collection for processing via Plaso and into Timesketch.</p> <p>To see how you can send Velociraptor data to BigQuery for further analysis, see this tutorial.</p>"},{"location":"5-integrations/extensions/third-party/velociraptor/#using-velociraptor-in-dr-rules","title":"Using Velociraptor in D&amp;R Rules","text":"<p>If you want to trigger a Velociraptor collection as a response to one of your detections, you can configure an extension request in the respond block of a rule.</p> <p>This example will kick off the KAPE files Velociraptor artifact to collect event logs from the system involved in the detection.</p> <pre><code>- action: extension request\n  extension action: collect\n  extension name: ext-velociraptor\n  extension request:\n    artifact_list: ['Windows.KapeFiles.Targets']\n    sid: '{{ .routing.sid }}' # Use a sensor selector OR a sid, **not both**\n    sensor_selector: '' # Use a sensor selector OR a sid, **not both**\n    args: '{{ \"EventLogs=Y\" }}'\n    collection_ttl: 3600 # 1 hour - collection_ttl is specified in seconds\n    retention_ttl: 7 # retention_ttl is specified in days\n    ignore_cert: false\n</code></pre>"},{"location":"5-integrations/extensions/third-party/velociraptor/#migrating-dr-rule-from-legacy-service-to-new-extension","title":"Migrating D&amp;R Rule from legacy Service to new Extension","text":"<p>Note: LimaCharlie has migrated from Services to Extensions. Legacy services are no longer supported.</p> <p>The Python CLI gives you a direct way to assess if any rules reference legacy Velociraptor service, preview the change and execute the conversion required in the rule \"response\".</p> <p>Command line to preview Velociraptor rule conversion:</p> <pre><code>limacharlie extension convert_rules --name ext-velociraptor\n</code></pre> <p>A dry-run response (default) will display the rule name being changed, a JSON of the service request rule and a JSON of the incoming extension request change.</p> <p>To execute the change in the rule, explicitly set <code>--dry-run</code> flag to <code>--no-dry-run</code></p> <p>Command line to execute Velociraptor rule conversion:</p> <pre><code>limacharlie extension convert_rules --name ext-velociraptor --no-dry-run\n</code></pre>"},{"location":"5-integrations/extensions/third-party/yara/","title":"YARA","text":"<p>The YARA Extension is designed to help you with all aspects of YARA scanning. It takes what is normally a manual piecewise process, provides a framework and automates it. Once configured, YARA scans can be run on demand for a particular endpoint or continuously in the background across your entire fleet.</p> <p>Yara configurations are synchronized with sensors every few minutes.</p> <p>There are three main sections to the YARA job:</p> <ul> <li>Sources</li> <li>Rules</li> <li>Scan</li> </ul>"},{"location":"5-integrations/extensions/third-party/yara/#where-does-my-yara-scan","title":"Where Does My YARA Scan?","text":"<p>Automated YARA scanners in LimaCharlie will run on all files loaded in memory (e.g. exe, dll, etc), and on the memory itself.</p> <p>Files on disk can be scanned using a Sensor command. You can trigger a Manual Scan that's run on-demand by:</p> <ul> <li>Clicking the Run YARA scan button on the sensor details page,</li> <li>Clicking the Scan button on the YARA Scanners page</li> <li>Using the console</li> <li>Within the Response section of a rule (sample below)</li> <li>Using the LimaCharlie API</li> </ul>"},{"location":"5-integrations/extensions/third-party/yara/#rules","title":"Rules","text":"<p>This is where you define your YARA rule(s). You can copy and paste your YARA rules into the <code>Rule</code> box, or you can define sources via the ext-yara-manager. Sources can be either direct links (URLs) to a given YARA rule (or directory of rules) or ARLs to a YARA rule.</p> <p></p> <p></p>"},{"location":"5-integrations/extensions/third-party/yara/#scanners","title":"Scanners","text":"<p>Scanners define which sets of sensors should be scanned with which sets of YARA rules.</p> <p>Filter Tags are tags that must ALL be present on a sensor for it to match (AND condition), while the platform of the sensor much match one of the platforms in the filter (OR condition).</p> <p>To apply YARA rules to scan an endpoint (or set of endpoints), you must select the platform or tags, and then add the YARA rules you would like to run.</p>"},{"location":"5-integrations/extensions/third-party/yara/#using-yara-in-dr-rules","title":"Using Yara in D&amp;R Rules","text":"<p>If you want to trigger a Yara scan as a response to one of your detections, you can configure an extension request in the respond block of a rule. A Yara scan request can be executed with a blank selector OR Sensor ID. However, one of them must be specified.</p> <pre><code>- action: extension request\n  extension action: scan\n  extension name: ext-yara\n  extension request:\n    sources: [ ]# Specify Yara Rule sources as strings\n    selector: ''\n        sid: '{{ .routing.sid }}' # Use a sensor selector OR a sid, **not both**\n    yara_scan_ttl: 86400 # \"Default: 1 day (86,400 seconds)\"\n</code></pre>"},{"location":"5-integrations/extensions/third-party/yara/#migrating-dr-rule-from-legacy-service-to-new-extension","title":"Migrating D&amp;R Rule from legacy Service to new Extension","text":"<p>Note: LimaCharlie has migrated from Services to Extensions. Legacy services are no longer supported.</p> <p>The Python CLI gives you a direct way to assess if any rules reference legacy Yara service, preview the change and execute the conversion required in the rule \"response\".</p> <p>Command line to preview Yara rule conversion:</p> <pre><code>limacharlie extension convert_rules --name ext-yara\n</code></pre> <p>A dry-run response (default) will display the rule name being changed, a JSON of the service request rule and a JSON of the incoming extension request change.</p> <p>To execute the change in the rule, explicitly set <code>--dry-run</code> flag to <code>--no-dry-run</code></p> <p>Command line to execute Yara rule conversion:</p> <pre><code>limacharlie extension convert_rules --name ext-yara --no-dry-run\n</code></pre>"},{"location":"5-integrations/extensions/third-party/zeek/","title":"Zeek","text":""},{"location":"5-integrations/extensions/third-party/zeek/#zeek-extension-pricing","title":"Zeek Extension Pricing","text":"<p>While it is Free to enable the Zeek extension, pricing is applied to processed PCAPs at a rate of $0.02/GB.</p> <p>Zeek is a comprehensive platform for network traffic analysis and intrusion detection.</p> <p>Once enabled, this extension allows you to generate Zeek logs from packet capture (PCAP) files collected via Artifacts. The resulting Zeek log files are subsequently parsed and pushed into the <code>ext-zeek</code> Sensor timeline as JSON. You can create detection &amp; response rules to automate based on Zeek log data.</p> <p>LimaCharlie will automatically kick off Zeek based on the artifact ID provided in a rule action.</p>"},{"location":"5-integrations/extensions/third-party/zeek/#configuration","title":"Configuration","text":"<p>To enable the Zeek extension, navigate to the Zeek extension page in the marketplace. Select the Organization you wish to enable the extension for, and select Subscribe.</p> <p>When enabled, you may configure the response of a D&amp;R rule to run Zeek against an artifact event. Here is an example D&amp;R rule:</p> <p>Detect:</p> <pre><code>artifact type: pcap\nevent: ingest\nop: exists\npath: /\ntarget: artifact_event\n</code></pre> <p>Respond:</p> <pre><code>- action: extension request\n  extension action: run_on\n  extension name: ext-zeek\n  extension request:\n    artifact_id: '{{ .routing.log_id }}'\n    retention: 30\n</code></pre>"},{"location":"5-integrations/extensions/third-party/zeek/#results","title":"Results","text":"<pre><code>/opt/zeek/bin/zeek -C LogAscii::use_json=T --no-checksums --readfile /path/to/your.pcap\n</code></pre> <p>Upon running Zeek, several JSON log files are generated. The log files are parsed and pushed into the <code>ext-zeek</code> sensor timeline.</p> <p></p>"},{"location":"5-integrations/extensions/third-party/zeek/#usage","title":"Usage","text":""},{"location":"5-integrations/extensions/third-party/zeek/#via-automatic-pcap-collection","title":"Via Automatic PCAP Collection","text":"<p>Note: This is only available on Linux sensors</p> <p>Enable PCAP collection on your Linux sensors via a PCAP capture rule within the artifact collection extension.</p> <p>For example, if you have an interface <code>ens4</code> and would like to gather PCAPs of network traffic on that interface on TCP port 80, you would craft the following rule.</p> <p></p> <p>Once ~30MB of traffic has been collected, a PCAP will be uploaded as an artifact in LimaCharlie. Subsequent PCAPs will continue to be uploaded as additional PCAPs as they hit the size threshold.</p> <p>All PCAPs uploaded will trigger the D&amp;R rule below.</p>"},{"location":"5-integrations/extensions/third-party/zeek/#via-manual-pcap-upload","title":"Via Manual PCAP Upload","text":"<p>If you have already generated a PCAP on a system or systems, you can manually ingest those as artifacts by running the following in your sensor console:</p> <pre><code>artifact_get --file /path/to/your.pcap --type pcap\n</code></pre> <p>This will trigger the D&amp;R rule below.</p>"},{"location":"5-integrations/extensions/third-party/zeek/#dr-rule","title":"D&amp;R Rule","text":"<p>Detect:</p> <pre><code>artifact type: pcap\nevent: ingest\nop: exists\npath: /\ntarget: artifact_event\n</code></pre> <p>Respond:</p> <pre><code>- action: extension request\n  extension action: run_on\n  extension name: ext-zeek\n  extension request:\n    artifact_id: '{{ .routing.log_id }}'\n    retention: 30\n</code></pre>"},{"location":"5-integrations/extensions/third-party/zeek/#migrating-dr-rule-from-legacy-service-to-new-extension","title":"Migrating D&amp;R Rule from legacy Service to new Extension","text":"<p>Note: LimaCharlie has migrated from Services to Extensions. Legacy services are no longer supported.</p> <p>The Python CLI gives you a direct way to assess if any rules reference legacy zeek service, preview the change and execute the conversion required in the rule \"response\".</p> <p>Command line to preview zeek rule conversion:</p> <pre><code>limacharlie extension convert_rules --name ext-zeek\n</code></pre> <p>A dry-run response (default) will display the rule name being changed, a JSON of the service request rule and a JSON of the incoming extension request change.</p> <p>To execute the change in the rule, explicitly set <code>--dry-run</code> flag to <code>--no-dry-run</code></p> <p>Command line to execute zeek rule conversion:</p> <pre><code>limacharlie extension convert_rules --name ext-zeek --no-dry-run\n</code></pre>"},{"location":"5-integrations/outputs/","title":"Outputs","text":"<p>Stream telemetry to external destinations.</p>"},{"location":"5-integrations/outputs/#documentation","title":"Documentation","text":"<ul> <li>Output Allowlisting - Filtering output data</li> <li>Output Billing - Billing and usage</li> <li>Output Stream Structures - Data format specifications</li> <li>Testing Outputs - Testing output configurations</li> </ul>"},{"location":"5-integrations/outputs/#see-also","title":"See Also","text":"<ul> <li>Stream Structures</li> <li>Output Destinations</li> <li>D&amp;R Response Actions</li> </ul>"},{"location":"5-integrations/outputs/allowlisting/","title":"Adding Outputs to an Allow List","text":"<p>At LimaCharlie, we rely on infrastructure with auto-scalers, and thus do not have static IPs nor a CIDR that you can rely on for an allow list (or \"whitelisting\").</p> <p>Typically, the concern around adding IPs to an allow list for Outputs is based on wanting to limit abuse and ensure that data from webhooks is truly coming from LimaCharlie and not other sources. To address this, we provide a <code>secret_key</code> parameter that can be used as a shared secret between LimaCharlie and your webhook receiver. When we issue a webhook, we include a <code>lc-signature</code> header that is an HMAC of the content of the webhook using the shared <code>secret_key</code>.</p>"},{"location":"5-integrations/outputs/billing/","title":"Output Billing","text":"<p>LimaCharlie aims to bill outputs at cost. This means that as a default outputs are billed accordingly to the published pricing.</p> <p>An exception to this is outputs that use Google Cloud Platform mechanism where the destination region is the same as the one the relevant LimaCharlie datacenter lives in. In those cases, outputs are not billed.</p> <p>Here is a list of the relevant regions for the various LimaCharlie datacenter.</p> <ul> <li>USA: <code>us-central1</code></li> <li>Canada: <code>northamerica-northeast1</code></li> <li>Europe: <code>europe-west4</code></li> <li>UK: <code>europe-west2</code></li> <li>India: <code>asia-south1</code></li> <li>Australia: <code>australia-southeast1</code></li> </ul> <p>The supported GCP mechanism for free output are:</p> <ul> <li><code>gcs</code></li> <li><code>pubsub</code></li> <li><code>bigquery</code></li> </ul> <p>Google Cloud Platform general region list: https://cloud.google.com/about/locations</p> <p>IP ranges of GCP resources per region change over time. Google publishes these ranges as a JSON file here: https://www.gstatic.com/ipranges/cloud.json</p>"},{"location":"5-integrations/outputs/stream-structures/","title":"Output Stream Structures","text":"<p>LimaCharlie routes data through four distinct output streams, each with a different structure and purpose. Understanding these structures is essential for:</p> <ul> <li>Configuring output destinations correctly</li> <li>Building parsers in external systems (SIEM, data lake, etc.)</li> <li>Filtering and transforming data before sending it</li> <li>Integrating with webhooks, APIs, and automation platforms</li> </ul>"},{"location":"5-integrations/outputs/stream-structures/#overview-of-output-streams","title":"Overview of Output Streams","text":"Stream Type Purpose Typical Volume Common Destinations <code>event</code> Real-time telemetry from sensors/adapters High SIEM, data lake, long-term storage <code>detect</code> Alerts from D&amp;R rules Low-Medium SIEM, SOAR, incident response platforms <code>audit</code> Platform management actions Low Compliance logging, audit trails <code>deployment</code> Sensor lifecycle events Very Low Asset management, deployment tracking"},{"location":"5-integrations/outputs/stream-structures/#1-event-stream-structure","title":"1. Event Stream Structure","text":"<p>Purpose: Capture real-time telemetry from endpoints and cloud adapters</p> <p>Stream Name: <code>event</code></p>"},{"location":"5-integrations/outputs/stream-structures/#structure","title":"Structure","text":"<p>All events follow a canonical two-level structure:</p> <pre><code>{\n  \"routing\": {\n    \"oid\": \"8cbe27f4-aaaa-aaaa-aaaa-138cd51389cd\",\n    \"sid\": \"bb4b30af-aaaa-aaaa-aaaa-f014ada33345\",\n    \"event_type\": \"NEW_PROCESS\",\n    \"event_time\": 1656959942437,\n    \"event_id\": \"8cec565d-14bd-4639-a1af-4fc8d5420b0c\",\n    \"hostname\": \"workstation-01\",\n    \"iid\": \"7d23bee6-aaaa-aaaa-aaaa-c8e8cca132a1\",\n    \"did\": \"b97e9d00-aaaa-aaaa-aaaa-27c3468d5901\",\n    \"ext_ip\": \"203.0.113.45\",\n    \"int_ip\": \"10.0.1.25\",\n    \"plat\": 268435456,\n    \"arch\": 2,\n    \"moduleid\": 2,\n    \"this\": \"a443f9c48bef700740ef27e062c333c6\",\n    \"parent\": \"42217cb0326ca254999554a862c3298e\",\n    \"tags\": [\"production\", \"critical-assets\"]\n  },\n  \"event\": {\n    \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\cmd.exe\",\n    \"COMMAND_LINE\": \"cmd.exe /c whoami\",\n    \"PROCESS_ID\": 4812,\n    \"USER_NAME\": \"Administrator\",\n    \"PARENT\": {\n      \"FILE_PATH\": \"C:\\\\Windows\\\\explorer.exe\",\n      \"PROCESS_ID\": 2156\n    }\n  }\n}\n</code></pre>"},{"location":"5-integrations/outputs/stream-structures/#routing-object-fields","title":"Routing Object Fields","text":"Field Type Description <code>oid</code> string (UUID) Organization ID <code>sid</code> string (UUID) Sensor ID - uniquely identifies the endpoint <code>event_type</code> string Type of event (NEW_PROCESS, DNS_REQUEST, etc.) <code>event_time</code> integer Unix timestamp in milliseconds <code>event_id</code> string (UUID) Unique event identifier <code>hostname</code> string Hostname of the sensor <code>iid</code> string (UUID) Installation Key ID <code>did</code> string (UUID) Device ID (hardware identifier) <code>ext_ip</code> string External IP address <code>int_ip</code> string Internal IP address <code>plat</code> integer Platform (Windows=268435456, Linux=...) <code>arch</code> integer Architecture (x86, x64, ARM) <code>moduleid</code> integer Sensor module that generated the event <code>this</code> string (hash) Hash of current process/object <code>parent</code> string (hash) Hash of parent process <code>target</code> string (hash) Hash of target object (optional) <code>tags</code> array[string] Sensor tags at event time"},{"location":"5-integrations/outputs/stream-structures/#event-object-fields","title":"Event Object Fields","text":"<p>The <code>event</code> object varies by <code>event_type</code>. Common event types include:</p> <ul> <li>NEW_PROCESS: <code>FILE_PATH</code>, <code>COMMAND_LINE</code>, <code>PROCESS_ID</code>, <code>USER_NAME</code>, <code>PARENT</code></li> <li>DNS_REQUEST: <code>DOMAIN_NAME</code>, <code>IP_ADDRESS</code>, <code>DNS_TYPE</code>, <code>DNS_FLAGS</code></li> <li>NETWORK_CONNECTIONS: <code>NETWORK_ACTIVITY</code> (array of connections)</li> <li>FILE_MODIFIED: <code>FILE_PATH</code>, <code>ACTION</code>, <code>HASH</code></li> <li>WEL (Windows Event Logs): <code>EVENT</code> (nested Windows event structure)</li> </ul> <p>See complete Event Structure Reference</p>"},{"location":"5-integrations/outputs/stream-structures/#use-cases","title":"Use Cases","text":"<ul> <li>SIEM Integration: Parse <code>routing/event_type</code> to route to different indexes</li> <li>Compliance: Store all events for audit and forensic analysis</li> <li>Threat Hunting: Query historical events for IOCs</li> <li>Analytics: Build behavioral baselines from event patterns</li> </ul>"},{"location":"5-integrations/outputs/stream-structures/#2-detection-stream-structure","title":"2. Detection Stream Structure","text":"<p>Purpose: Alerts generated when D&amp;R rules match events</p> <p>Stream Name: <code>detect</code></p>"},{"location":"5-integrations/outputs/stream-structures/#structure_1","title":"Structure","text":"<p>Detections include the original event's routing, the triggering event data, and detection-specific metadata:</p> <pre><code>{\n  \"cat\": \"Suspicious PowerShell Execution\",\n  \"source\": \"dr-general\",\n  \"routing\": {\n    \"oid\": \"8cbe27f4-aaaa-aaaa-aaaa-138cd51389cd\",\n    \"sid\": \"bb4b30af-aaaa-aaaa-aaaa-f014ada33345\",\n    \"event_type\": \"NEW_PROCESS\",\n    \"event_time\": 1656959942437,\n    \"hostname\": \"workstation-01\",\n    \"this\": \"a443f9c48bef700740ef27e062c333c6\",\n    \"parent\": \"42217cb0326ca254999554a862c333c6\"\n  },\n  \"detect\": {\n    \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\",\n    \"COMMAND_LINE\": \"powershell.exe -enc SGVsbG8gV29ybGQ=\",\n    \"PROCESS_ID\": 5124\n  },\n  \"detect_id\": \"f1e2d3c4-aaaa-aaaa-aaaa-123456789abc\",\n  \"namespace\": \"production\",\n  \"priority\": 7,\n  \"mtd\": {\n    \"custom_field\": \"value\"\n  },\n  \"detect_mtd\": {\n    \"rule_name\": \"detect-encoded-powershell\"\n  },\n  \"detect_data\": {\n    \"suspicious_process\": \"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\",\n    \"encoded_command\": \"SGVsbG8gV29ybGQ=\",\n    \"process_hash\": \"a443f9c48bef700740ef27e062c333c6\"\n  },\n  \"link\": \"https://docs.company.com/playbooks/powershell-investigation\",\n  \"author\": \"security-team\",\n  \"source_rule\": \"detect-encoded-powershell\",\n  \"rule_tags\": [\"windows\", \"powershell\", \"encoded\"],\n  \"gen_time\": 1656959942500\n}\n</code></pre>"},{"location":"5-integrations/outputs/stream-structures/#detection-fields","title":"Detection Fields","text":"Field Type Required Description <code>cat</code> string Yes Detection name/category <code>source</code> string Yes Rule source (<code>dr-general</code>, <code>dr-managed</code>, <code>fp</code>) <code>routing</code> object Yes Inherited from triggering event <code>detect</code> object Yes Copy of event data that triggered detection <code>detect_id</code> string (UUID) Yes Unique detection identifier <code>namespace</code> string No Organizational namespace <code>priority</code> integer No Detection priority (0-10) <code>mtd</code> object No General metadata <code>detect_mtd</code> object No Detection-specific metadata <code>detect_data</code> object No Structured IOCs extracted from event <code>link</code> string No URL to playbook/documentation <code>author</code> string No Rule author <code>source_rule</code> string No Rule name that generated this <code>rule_tags</code> array[string] No Tags from the rule <code>gen_time</code> integer No Unix timestamp (ms) of generation"},{"location":"5-integrations/outputs/stream-structures/#key-field-detect_data","title":"Key Field: detect_data","text":"<p>The <code>detect_data</code> field contains structured IOCs extracted by the D&amp;R rule. This is extremely valuable for:</p> <ul> <li>Automated enrichment (lookup IPs, domains, hashes)</li> <li>SOAR playbook inputs</li> <li>Threat intelligence platform integration</li> <li>Case management system ticketing</li> </ul> <p>Example <code>detect_data</code> for different detection types:</p> <p>Malware Detection: <pre><code>\"detect_data\": {\n  \"file_path\": \"C:\\\\Users\\\\admin\\\\Downloads\\\\malware.exe\",\n  \"file_hash\": \"5d41402abc4b2a76b9719d911017c592\",\n  \"process_id\": 4812,\n  \"parent_process\": \"explorer.exe\"\n}\n</code></pre></p> <p>Network IOC: <pre><code>\"detect_data\": {\n  \"destination_ip\": \"198.51.100.42\",\n  \"destination_port\": 8443,\n  \"domain\": \"malicious.example.com\",\n  \"bytes_sent\": 1048576\n}\n</code></pre></p>"},{"location":"5-integrations/outputs/stream-structures/#use-cases_1","title":"Use Cases","text":"<ul> <li>Incident Response: Feed high-priority detections to SOAR platforms</li> <li>Alerting: Send to Slack, email, or ticketing systems</li> <li>Triage: Filter by <code>priority</code> and <code>cat</code> for analyst review</li> <li>Enrichment: Extract IOCs from <code>detect_data</code> for threat intel lookups</li> </ul>"},{"location":"5-integrations/outputs/stream-structures/#3-audit-stream-structure","title":"3. Audit Stream Structure","text":"<p>Purpose: Platform management and operational events</p> <p>Stream Name: <code>audit</code></p>"},{"location":"5-integrations/outputs/stream-structures/#structure_2","title":"Structure","text":"<p>Audit logs track actions within the LimaCharlie platform:</p> <pre><code>{\n  \"oid\": \"8cbe27f4-aaaa-aaaa-aaaa-138cd51389cd\",\n  \"ts\": \"2024-06-05T14:23:18Z\",\n  \"etype\": \"config_change\",\n  \"msg\": \"D&amp;R rule created\",\n  \"origin\": \"api\",\n  \"time\": 1656959942,\n  \"ident\": \"user@company.com\",\n  \"entity\": {\n    \"type\": \"dr_rule\",\n    \"name\": \"detect-encoded-powershell\",\n    \"hive\": \"dr-general\"\n  },\n  \"mtd\": {\n    \"action\": \"create\",\n    \"source_ip\": \"203.0.113.10\",\n    \"user_agent\": \"limacharlie-cli/2.0.0\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/outputs/stream-structures/#audit-fields","title":"Audit Fields","text":"Field Type Description <code>oid</code> string (UUID) Organization ID <code>ts</code> string ISO 8601 timestamp string <code>etype</code> string Event type (config_change, api_call, user_action, error) <code>msg</code> string Human-readable audit message <code>origin</code> string Origin of action (api, ui, cli, system) <code>time</code> integer Unix timestamp in seconds <code>ident</code> string Identity performing the action (email, API key name) <code>entity</code> object Object the action was performed on <code>mtd</code> object Action characteristics (action type, source IP, etc.) <code>component</code> string Component name (for error messages) <code>error</code> string Error message (if applicable)"},{"location":"5-integrations/outputs/stream-structures/#entity-object-examples","title":"Entity Object Examples","text":"<p>D&amp;R Rule: <pre><code>\"entity\": {\n  \"type\": \"dr_rule\",\n  \"name\": \"detect-lateral-movement\",\n  \"hive\": \"dr-general\"\n}\n</code></pre></p> <p>Sensor: <pre><code>\"entity\": {\n  \"type\": \"sensor\",\n  \"sid\": \"bb4b30af-aaaa-aaaa-aaaa-f014ada33345\",\n  \"hostname\": \"workstation-01\"\n}\n</code></pre></p> <p>Output: <pre><code>\"entity\": {\n  \"type\": \"output\",\n  \"name\": \"splunk-events\",\n  \"stream\": \"event\"\n}\n</code></pre></p>"},{"location":"5-integrations/outputs/stream-structures/#use-cases_2","title":"Use Cases","text":"<ul> <li>Compliance: Track all configuration changes for SOC 2, ISO 27001</li> <li>Security Monitoring: Detect unauthorized platform changes</li> <li>Troubleshooting: Audit trail for configuration issues</li> <li>User Activity: Monitor API usage and user actions</li> </ul>"},{"location":"5-integrations/outputs/stream-structures/#4-deployment-stream-structure","title":"4. Deployment Stream Structure","text":"<p>Purpose: Sensor deployment and lifecycle events</p> <p>Stream Name: <code>deployment</code></p>"},{"location":"5-integrations/outputs/stream-structures/#structure_3","title":"Structure","text":"<p>Deployment events track sensor installations, removals, and updates:</p> <pre><code>{\n  \"routing\": {\n    \"oid\": \"8cbe27f4-aaaa-aaaa-aaaa-138cd51389cd\",\n    \"sid\": \"bb4b30af-aaaa-aaaa-aaaa-f014ada33345\",\n    \"event_type\": \"sensor_installed\",\n    \"event_time\": 1656959942437,\n    \"hostname\": \"workstation-01\",\n    \"iid\": \"7d23bee6-aaaa-aaaa-aaaa-c8e8cca132a1\",\n    \"did\": \"b97e9d00-aaaa-aaaa-aaaa-27c3468d5901\",\n    \"plat\": 268435456,\n    \"arch\": 2\n  },\n  \"event\": {\n    \"action\": \"install\",\n    \"sensor_version\": \"4.25.0\",\n    \"installation_method\": \"msi\",\n    \"tags\": [\"production\", \"finance-dept\"],\n    \"installer_user\": \"Administrator\"\n  }\n}\n</code></pre>"},{"location":"5-integrations/outputs/stream-structures/#deployment-event-types","title":"Deployment Event Types","text":"Event Type Description Example Event Data <code>sensor_installed</code> New sensor deployment <code>action</code>, <code>sensor_version</code>, <code>tags</code> <code>sensor_uninstalled</code> Sensor removal <code>action</code>, <code>reason</code>, <code>uninstall_time</code> <code>sensor_upgraded</code> Sensor version update <code>old_version</code>, <code>new_version</code>, <code>upgrade_method</code> <code>sensor_checkin</code> Periodic sensor heartbeat <code>last_seen</code>, <code>connectivity_status</code>"},{"location":"5-integrations/outputs/stream-structures/#use-cases_3","title":"Use Cases","text":"<ul> <li>Asset Tracking: Monitor endpoint agent deployment status</li> <li>Compliance: Ensure all required endpoints have sensors</li> <li>Lifecycle Management: Track sensor versions and upgrades</li> <li>Alerting: Detect unexpected sensor removals</li> </ul>"},{"location":"5-integrations/outputs/stream-structures/#output-configuration-examples","title":"Output Configuration Examples","text":""},{"location":"5-integrations/outputs/stream-structures/#sending-event-stream-to-splunk","title":"Sending Event Stream to Splunk","text":"<pre><code>name: splunk-events\nmodule: webhook_bulk\ntype: event  # Event stream\ndest_host: https://splunk.company.com:8088/services/collector/raw\nauth_header_name: Authorization\nauth_header_value: Splunk YOUR-HEC-TOKEN\n</code></pre>"},{"location":"5-integrations/outputs/stream-structures/#sending-detections-to-slack","title":"Sending Detections to Slack","text":"<pre><code>name: slack-critical-alerts\nmodule: slack\ntype: detect  # Detection stream\nslack_api_token: xoxb-your-slack-token\nslack_channel: security-alerts\ncat: high-priority  # Category filter for high-priority detections\n</code></pre>"},{"location":"5-integrations/outputs/stream-structures/#audit-logs-to-s3","title":"Audit Logs to S3","text":"<pre><code>name: compliance-audit-logs\nmodule: s3\ntype: audit  # Audit stream\nbucket: company-security-audit-logs\ndir: limacharlie/audit/\nkey_id: YOUR-ACCESS-KEY\nsecret_key: YOUR-SECRET-KEY\n</code></pre>"},{"location":"5-integrations/outputs/stream-structures/#filtering-and-transforming-streams","title":"Filtering and Transforming Streams","text":"<p>IMPORTANT: Filter parameters use newline-separated string format, not YAML arrays. Each item must be on its own line within a multiline string.</p>"},{"location":"5-integrations/outputs/stream-structures/#event-type-filtering","title":"Event Type Filtering","text":"<p>Filter specific event types using whitelist/blacklist:</p> <pre><code># Only send NEW_PROCESS and TERMINATE_PROCESS events\nevent_white_list: |\n  NEW_PROCESS\n  TERMINATE_PROCESS\n\n# Or exclude certain events\nevent_black_list: |\n  DNS_REQUEST\n  CONNECTED\n</code></pre> <p>Format Notes: - Use the pipe (<code>|</code>) operator for multiline strings in YAML - Each event type on its own line - No hyphens or list syntax - Empty lines and whitespace are automatically trimmed</p>"},{"location":"5-integrations/outputs/stream-structures/#category-filtering","title":"Category Filtering","text":"<p>Filter detections by category:</p> <pre><code># Only send specific detection categories\ncat_white_list: |\n  high-priority\n  critical\n\n# Or exclude certain categories\ncat_black_list: |\n  informational\n</code></pre>"},{"location":"5-integrations/outputs/stream-structures/#tag-based-filtering","title":"Tag-Based Filtering","text":"<p>Filter events from sensors with specific tags:</p> <pre><code># Only send events from tagged sensors (single tag)\ntag: production\n\n# Exclude events from multiple tags\ntag_black_list: |\n  dev\n  test\n  staging\n</code></pre> <p>Note: The <code>tag</code> parameter accepts a single tag string. To filter multiple tags, use <code>tag_black_list</code> to exclude unwanted tags.</p>"},{"location":"5-integrations/outputs/stream-structures/#rule-tag-filtering","title":"Rule Tag Filtering","text":"<p>Filter detections by D&amp;R rule tags (detection stream only):</p> <pre><code># Only send detections from specific rule tags\nrule_tag_white_list: |\n  compliance\n  ransomware\n  lateral-movement\n\n# Or exclude certain rule tags\nrule_tag_black_list: |\n  low-confidence\n  experimental\n</code></pre> <p>Use Case: Rule tags help organize detections by threat type, compliance requirement, or confidence level.</p>"},{"location":"5-integrations/outputs/stream-structures/#best-practices","title":"Best Practices","text":""},{"location":"5-integrations/outputs/stream-structures/#1-choose-the-right-stream","title":"1. Choose the Right Stream","text":"<ul> <li>event: Long-term storage, SIEM, threat hunting, compliance</li> <li>detect: Real-time alerting, SOAR, incident response</li> <li>audit: Compliance logging, change tracking, security monitoring</li> <li>deployment: Asset management, sensor lifecycle tracking</li> </ul>"},{"location":"5-integrations/outputs/stream-structures/#2-optimize-event-stream-volume","title":"2. Optimize Event Stream Volume","text":"<p>Event streams can be high-volume. Consider: - Filtering by <code>event_type</code> to send only relevant events - Using separate outputs for different event types - Sampling high-frequency events if full fidelity isn't needed</p>"},{"location":"5-integrations/outputs/stream-structures/#3-parse-detection-iocs","title":"3. Parse Detection IOCs","text":"<p>Always extract and process <code>detect_data</code> - it contains pre-parsed IOCs ready for enrichment and response.</p>"},{"location":"5-integrations/outputs/stream-structures/#4-retain-audit-logs-separately","title":"4. Retain Audit Logs Separately","text":"<p>Audit logs are critical for compliance and should be stored in tamper-proof, long-term storage separate from operational data.</p>"},{"location":"5-integrations/outputs/stream-structures/#5-monitor-deployment-stream","title":"5. Monitor Deployment Stream","text":"<p>Use deployment events to track sensor health and detect: - Unexpected uninstalls (potential evasion) - Sensors stuck on old versions (patch management) - Gaps in coverage (missing sensors)</p>"},{"location":"5-integrations/outputs/stream-structures/#related-documentation","title":"Related Documentation","text":"<ul> <li>Event Structure Reference</li> <li>Detection Structure</li> <li>LimaCharlie Data Structures</li> <li>Output Destinations - Configuration guides for specific destinations</li> <li>Testing Outputs - How to validate output configurations</li> </ul>"},{"location":"5-integrations/outputs/testing/","title":"Testing Outputs","text":"<p>The easiest way to test if the outputs are configured correctly is to set the stream to <code>Audit</code> which will send auditing events about activity around the management of the platform in the cloud. You can then edit the same output or make any other change on the platform, which will trigger an audit event to be sent.</p> <p>After you have confirmed that the output configurations works, you can switch the data stream from <code>Audit</code> to the one you are looking to use.</p> <p>If you are running into an error configuring an output, the error details will be listed in the Platform Logs section under Errors, with the key that looks like <code>outputs/OUTPUT_NAME</code>.</p> <p>If an output fails, it gets disabled temporarily to avoid spam. It will be re-enabled automatically after a while, or you can force it to be re-enabled by updating the configuration.</p>"},{"location":"5-integrations/outputs/destinations/amazon-s3/","title":"Amazon S3","text":"<p>Output events and detections to an Amazon S3 bucket.</p> <p>If you have your own visualization stack, or you just need the data archived, you can output directly to Amazon S3. This way you don't need any infrastructure.</p> <ul> <li><code>bucket</code>: the path to the AWS S3 bucket.</li> <li><code>key_id</code>:  the id of the AWS auth key.</li> <li><code>secret_key</code>: the AWS secret key to auth with.</li> <li><code>sec_per_file</code>: the number of seconds after which a file is cut and uploaded.</li> <li><code>is_compression</code>: if set to \"true\", data will be gzipped before upload.</li> <li><code>is_indexing</code>: DEPRECATED if set to \"true\", data is uploaded in a way that makes it searchable.</li> <li><code>region_name</code>: the region name of the bucket, it is recommended to set it, though not always required.</li> <li><code>endpoint_url</code>: optionally specify a custom endpoint URL, usually used with region_name to output to S3-compatible 3<sup>rd</sup> party services.</li> <li><code>dir</code>: the directory prefix</li> <li><code>is_no_sharding</code>: do not add a shard directory at the root of the files generated.</li> </ul> <p>Example:</p> <pre><code>bucket: my-bucket-name\nkey_id: AKIAABCDEHPUXHHHHSSQ\nsecret_key: fonsjifnidn8anf4fh74y3yr34gf3hrhgh8er\nis_indexing: \"true\"\nis_compression: \"true\"\n</code></pre> <p></p> <p>If the <code>is_indexing</code> option is enabled, data uploaded to S3 will be in a specific format enabling some indexed queries.</p> <p>LC data files begin with a <code>d</code>, while special manifest files (indicating  which data files contain which sensors' data) begin with an <code>m</code>. Otherwise (not <code>is_indexing</code>), data is uploaded as flat files with a UUID name.</p> <p>The <code>is_compression</code> flag, if on, will compress each file as a GZIP when uploaded. It is recommended you enable <code>is_compression</code>.</p>"},{"location":"5-integrations/outputs/destinations/amazon-s3/#aws-iam-configuration","title":"AWS IAM Configuration","text":"<ol> <li>Log in to AWS console and go to the IAM service.</li> <li>Click on <code>Users</code> from the menu.</li> <li>Click <code>Create User</code>, give it a name, and click <code>Next</code>.</li> <li>Click <code>Next</code>, then <code>Create User</code></li> <li>Click on the user you just created and click on the <code>Security Credentials</code> tab</li> <li>Click <code>Create access key</code></li> <li>Select <code>Other</code> and click <code>Next</code></li> <li>Provide a description (optional) and click <code>Create access key</code></li> <li>Take note of the \"Access key\", \"Secret access key\" and ARN name for the user (starts with \"arn:\", shown on the user summary screen).</li> </ol>"},{"location":"5-integrations/outputs/destinations/amazon-s3/#aws-s3-configuration","title":"AWS S3 Configuration","text":"<ol> <li>Go to the S3 service.</li> <li>Click <code>Create bucket</code>, enter a name and select a region.</li> <li>Click <code>Create bucket</code></li> <li>Click on your newly created bucket and click on the <code>Permissions</code> tab</li> <li>Select <code>Bucket policy</code> and click <code>Edit</code></li> <li>Input the policy in sample below where you replace the <code>&lt;&lt;USER_ARN&gt;&gt;</code> with the ARN name of the user you created and the <code>&lt;&lt;BUCKET_NAME&gt;&gt;</code> with the name of the bucket you just created.</li> <li>Click <code>Save Changes</code></li> </ol>"},{"location":"5-integrations/outputs/destinations/amazon-s3/#policy-sample","title":"Policy Sample","text":"<pre><code>{\n   \"Version\": \"2012-10-17\",\n   \"Statement\": [\n      {\n         \"Sid\": \"PermissionForObjectOperations\",\n         \"Effect\": \"Allow\",\n         \"Principal\": {\n            \"AWS\": \"&lt;&lt;USER_ARN&gt;&gt;\"\n         },\n         \"Action\": \"s3:PutObject\",\n         \"Resource\": \"arn:aws:s3:::&lt;&lt;BUCKET_NAME&gt;&gt;/*\"\n      }\n   ]\n}\n</code></pre>"},{"location":"5-integrations/outputs/destinations/amazon-s3/#limacharlie-configuration","title":"LimaCharlie Configuration","text":"<ol> <li>Back in the LimaCharlie GUI, in your organization view, click <code>Outputs</code> and <code>Add Output</code></li> <li>Select the stream you would like to send (events, detections, etc)</li> <li>Select the <code>Amazon S3</code> destination</li> <li>Give it a name, enter the bucket name, key_id, and secret_key you noted from AWS, and any other parameters you wish to configure</li> <li>Click <code>Save Output</code></li> <li>After a minute, the data should start getting written to your bucket</li> </ol>"},{"location":"5-integrations/outputs/destinations/amazon-s3/#related-articles","title":"Related articles","text":"<ul> <li>AWS CloudTrail</li> <li>S3</li> <li>AWS</li> <li>AWS GuardDuty</li> </ul>"},{"location":"5-integrations/outputs/destinations/amazon-s3/#whats-next","title":"What's Next","text":"<ul> <li>Apache Kafka</li> </ul>"},{"location":"5-integrations/outputs/destinations/apache-kafka/","title":"Apache Kafka","text":"<p>Output events and detections to a Kafka target.</p> <ul> <li><code>dest_host</code>: the IP or DNS and port to connect to, format <code>kafka.myorg.com</code>.</li> <li><code>is_tls</code>: if <code>true</code> will output over TCP/TLS.</li> <li><code>is_strict_tls</code>: if <code>true</code> will enforce validation of TLS certs.</li> <li><code>username</code>: if specified along with <code>password</code>, use for Basic authentication.</li> <li><code>password</code>: if specified along with <code>username</code>, use for Basic authentication.</li> <li><code>routing_topic</code>: use the element with this name from the <code>routing</code> of the event as the Kafka topic name.</li> <li><code>literal_topic</code>: use this specific value as a topic.</li> </ul> <p>Note on authentication: if you specify <code>username</code> and <code>password</code>, the authentication mechanism assumed is SASL_SSL + SCRAM-SHA-512, which should be compatible with services like AWS Manages Streaming Kafka. If you require different paramaters around authentication please contact us at support@limacharlie.io.</p> <p>Example:</p> <pre><code>dest_host: kafka.corp.com\nis_tls: \"true\"\nis_strict_tls: \"true\"\nusername: lc\npassword: letmein\nliteral_topic: telemetry\n</code></pre>"},{"location":"5-integrations/outputs/destinations/azure-event-hub/","title":"Azure Event Hub","text":"<p>Output events and detections to an Azure Event Hub (similar to PubSub and Kafka).</p> <ul> <li><code>connection_string</code>: the connection string provided by Azure.</li> </ul> <p>Note that the connection string should end with <code>;EntityPath=your-hub-name</code> which is sometimes missing from the \"Connection String\" provided by Azure.</p> <p>Example:</p> <pre><code>connection_string: Endpoint=sb://lc-test.servicebus.windows.net/;SharedAccessKeyName=lc;SharedAccessKey=jidnfisnjfnsdnfdnfjd=;EntityPath=test-hub\n</code></pre>"},{"location":"5-integrations/outputs/destinations/azure-event-hub/#related-articles","title":"Related articles","text":"<ul> <li>Azure Kubernetes Service (AKS)</li> <li>Azure Monitor</li> <li>Azure Network Security Group</li> <li>Azure SQL Audit Logs</li> <li>Azure Event Hub</li> <li>Microsoft Entra ID</li> <li>Azure</li> </ul>"},{"location":"5-integrations/outputs/destinations/azure-event-hub/#whats-next","title":"What's Next","text":"<ul> <li>Azure Storage Blob</li> </ul>"},{"location":"5-integrations/outputs/destinations/azure-storage-blob/","title":"Azure Storage Blob","text":"<p>Output events and detections to a Blob Container in Azure Storage Blobs.</p> <ul> <li><code>secret_key</code>: the secret access key for the Blob Container.</li> <li><code>blob_container</code>: the name of the Blob Container to upload to.</li> <li><code>account_name</code>: the account name used to authenticate in Azure.</li> </ul> <p>Example:</p> <pre><code>blob_container: testlcdatabucket\naccount_name: lctestdata\nsecret_key: dkndsgnlngfdlgfd\n</code></pre>"},{"location":"5-integrations/outputs/destinations/azure-storage-blob/#related-articles","title":"Related articles","text":"<ul> <li>Azure Kubernetes Service (AKS)</li> <li>Azure Monitor</li> <li>Azure Network Security Group</li> <li>Azure SQL Audit Logs</li> <li>Azure Event Hub</li> <li>Microsoft Entra ID</li> <li>Azure</li> <li>Elastic</li> </ul>"},{"location":"5-integrations/outputs/destinations/bigquery/","title":"Google Cloud BigQuery","text":"<p>Output events and detections to a Google Cloud BigQuery Table.</p> <p>For a practical use case of this output, see this tutorial on pushing Velociraptor data to BigQuery.</p> <ul> <li><code>schema</code>: describes the column names, data types, and other information; should match the text-formatted schema from bigquery</li> <li><code>table</code>: the table name where to send data.</li> <li><code>dataset</code>: the dataset name where to send data.</li> <li><code>project</code>: the project name where to send the data.</li> <li><code>secret_key</code>: the secret json key identifying a service account.</li> <li><code>sec_per_file</code>: the number of seconds after which a batch of data is loaded.</li> <li><code>custom_transform</code>: should align with the schema fields/formats</li> </ul> <p>Example:</p> <pre><code>schema: event_type:STRING, oid:STRING, sid:STRING\ntable: alerts\ndataset: limacharlie_data\nproject: lc-example-analytics\nsecret_key: {\n  \"type\": \"service_account\",\n  \"project_id\": \"my-lc-data\",\n  \"private_key_id\": \"EXAMPLE_KEY_ID_REPLACE_WITH_YOURS\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n...(your actual private key here)...\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"my-service-writer@my-lc-data.iam.gserviceaccount.com\",\n  \"client_id\": \"YOUR_CLIENT_ID\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/my-service-writer%40my-lc-data.iam.gserviceaccount.com\"\n}\ncustom_transform: |-\n  {\n    \"oid\":\"routing.oid\",\n    \"sid\":\"routing.sid\",\n    \"event_type\":\"routing.event_type\"\n  }\n</code></pre>"},{"location":"5-integrations/outputs/destinations/bigquery/#related-articles","title":"Related articles","text":"<ul> <li>Building Reports with BigQuery + Looker Studio</li> <li>Google Cloud Pubsub</li> <li>Google Cloud Storage</li> <li>Google Workspace</li> <li>Google Cloud Storage</li> <li>Tutorial: Ingesting Google Cloud Logs</li> <li>Google Cloud</li> </ul>"},{"location":"5-integrations/outputs/destinations/elastic/","title":"Elastic","text":"<p>Output events and detections to Elastic.</p> <ul> <li><code>addresses</code>: the IPs or DNS where to send the data to.</li> <li><code>index</code>: the index name to send data to.</li> <li><code>username</code>: user name if using username/password auth. (use either username/password -or- API key)</li> <li><code>password</code>: password if using username/password auth.</li> <li><code>cloud_id</code>: Cloud ID from Elastic.</li> <li><code>api_key</code>: API key; if using it for auth. (use either username/password -or- API key)</li> </ul> <p>Example:</p> <pre><code>addresses: 11.10.10.11,11.10.11.11\nusername: some\npassword: pass1234\nindex: limacharlie\n</code></pre>"},{"location":"5-integrations/outputs/destinations/elastic/#related-articles","title":"Related articles","text":"<ul> <li>OpenSearch</li> </ul>"},{"location":"5-integrations/outputs/destinations/elastic/#whats-next","title":"What's Next","text":"<ul> <li>Google Cloud BigQuery</li> </ul>"},{"location":"5-integrations/outputs/destinations/google-cloud-storage/","title":"Google Cloud Storage","text":"<p>Output events and detections to a GCS bucket.</p> <p>Looking for Google Chronicle?</p> <p>If you already use Google Chronicle, we make it easy to send telemetry you've collected in LimaCharlie to Chronicle. You can get that set up by creating an Output in LimaCharlie to a GCS bucket.</p> <ul> <li><code>bucket</code>: the path to the GCS bucket.</li> <li><code>secret_key</code>: the secret json key identifying a service account.</li> <li><code>sec_per_file</code>: the number of seconds after which a file is cut and uploaded.</li> <li><code>is_compression</code>: if set to \"true\", data will be gzipped before upload.</li> <li><code>is_indexing</code>: if set to \"true\", data is uploaded in a way that makes it searchable.</li> <li><code>dir</code>: the directory prefix where to output the files on the remote host.</li> </ul> <p>Example:</p> <pre><code>bucket: my-bucket-name\nsecret_key: {\n  \"type\": \"service_account\",\n  \"project_id\": \"my-lc-data\",\n  \"private_key_id\": \"EXAMPLE_KEY_ID_REPLACE_WITH_YOURS\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n...(your actual private key here)...\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"my-service-writer@my-lc-data.iam.gserviceaccount.com\",\n  \"client_id\": \"YOUR_CLIENT_ID\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/my-service-writer%40my-lc-data.iam.gserviceaccount.com\"\n}\nis_indexing: \"true\"\nis_compression: \"true\"\n</code></pre>"},{"location":"5-integrations/outputs/destinations/google-cloud-storage/#related-articles","title":"Related articles","text":"<ul> <li>Building Reports with BigQuery + Looker Studio</li> <li>Google Cloud Pubsub</li> <li>Google Cloud BigQuery</li> <li>Google Workspace</li> <li>Google Cloud Storage</li> <li>Google Cloud Pubsub</li> <li>Tutorial: Ingesting Google Cloud Logs</li> <li>Google Cloud</li> </ul>"},{"location":"5-integrations/outputs/destinations/google-cloud-storage/#whats-next","title":"What's Next","text":"<ul> <li>Humio</li> </ul>"},{"location":"5-integrations/outputs/destinations/google-pubsub/","title":"Google Cloud Pubsub","text":"<p>Output events and detections to a Pubsub topic.</p> <ul> <li><code>secret_key</code>: the secret json key identifying a service account.</li> <li><code>project</code>: the GCP Project name where the Topic lives.</li> <li><code>topic</code>: use this specific value as a topic.</li> </ul> <p>Example:</p> <pre><code>project: my-project\ntopic: telemetry\nsecret_key: {\n  \"type\": \"service_account\",\n  \"project_id\": \"my-lc-data\",\n  \"private_key_id\": \"EXAMPLE_KEY_ID_REPLACE_WITH_YOURS\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n...(your actual private key here)...\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"my-service-writer@my-lc-data.iam.gserviceaccount.com\",\n  \"client_id\": \"YOUR_CLIENT_ID\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/my-service-writer%40my-lc-data.iam.gserviceaccount.com\"\n}\n</code></pre>"},{"location":"5-integrations/outputs/destinations/humio/","title":"Humio","text":"<p>Output events and detections to the Humio.com service.</p> <ul> <li><code>humio_repo</code>: the name of the humio repo to upload to.</li> <li><code>humio_api_token</code>: the humio ingestion token.</li> <li><code>endpoint_url</code>: optionally specify a custom endpoint URL, if you have Humio deployed on-prem use this to point to it, otherwise it defaults to the Humio cloud.</li> </ul> <p>Example:</p> <pre><code>humio_repo: sandbox\nhumio_api_token: fdkoefj0erigjre8iANUDBFyfjfoerjfi9erge\n</code></pre> <p>Note: You may need to create a new parser in Humio to correctly parse timestamps.  You can use the following JSON parser:</p> <pre><code>parseJson() | parseTimestamp(field=@timestamp,format=\"unixTimeMillis\",timezone=\"Etc/UTC\")\n</code></pre> <p>For the Community Edition of Humio, the <code>endpoint_url</code> is: <code>https://cloud.community.humio.com</code>.</p>"},{"location":"5-integrations/outputs/destinations/opensearch/","title":"OpenSearch","text":"<p>Output events and detections to OpenSearch.</p> <ul> <li><code>addresses</code>: the IPs or DNS where to send the data to</li> <li><code>index</code>: the index name to send data to</li> <li><code>username</code>: user name if using username/password auth</li> <li><code>password</code>: password if using username/password auth</li> </ul> <p>Example:</p> <pre><code>addresses: https://1.2.3.4:9200, https://elastic.mydomain.com:9200\nusername: some\npassword: pass1234\nindex: limacharlie-events\n</code></pre>"},{"location":"5-integrations/outputs/destinations/opensearch/#related-articles","title":"Related articles","text":"<ul> <li>Elastic</li> <li>SCP</li> </ul>"},{"location":"5-integrations/outputs/destinations/scp/","title":"SCP","text":"<p>Output events and detections over SCP (SSH file transfer).</p> <ul> <li><code>dest_host</code>: the ip:port where to send the data to, like <code>1.2.3.4:22</code>.</li> <li><code>dir</code>: the directory where to output the files on the remote host.</li> <li><code>username</code>: the SSH username to log in with.</li> <li><code>password</code>: optional password to use to login with.</li> <li><code>secret_key</code>: the optional SSH private key to authenticate with.</li> </ul> <p>Example:</p> <pre><code>dest_host: storage.corp.com\ndir: /uploads/\nusername: storage_user\npassword: XXXXXXXXXXXX\n</code></pre>"},{"location":"5-integrations/outputs/destinations/sftp/","title":"SFTP","text":"<p>Output events and detections over SFTP.</p> <ul> <li><code>dest_host</code>: the ip:port where to send the data to, like <code>1.2.3.4:22</code>.</li> <li><code>dir</code>: the directory where to output the files on the remote host.</li> <li><code>username</code>: the username to log in with.</li> <li><code>password</code>: optional password to use to login with.</li> <li><code>secret_key</code>: the optional SSH private key to authenticate with.</li> </ul> <p>Example:</p> <pre><code>dest_host: storage.corp.com\ndir: /uploads/\nusername: storage_user\npassword: XXXXXXXXXXXX\n</code></pre>"},{"location":"5-integrations/outputs/destinations/sftp/#whats-next","title":"What's Next","text":"<ul> <li>Slack</li> </ul>"},{"location":"5-integrations/outputs/destinations/slack/","title":"Slack","text":"<p>Output detections and audit (only) to a Slack community and channel.</p> <ul> <li><code>slack_api_token</code>: the Slack provided API token used to authenticate.</li> <li><code>slack_channel</code>: the channel to output to within the community.</li> </ul> <p>Example:</p> <pre><code>slack_api_token: sample_api_token\nslack_channel: #detections\n</code></pre>"},{"location":"5-integrations/outputs/destinations/slack/#provisioning","title":"Provisioning","text":"<p>To use this Output, you need to create a Slack App and Bot. This is very simple:</p> <ol> <li>Head over to https://api.slack.com/apps</li> <li>Click on \"Create App\" and select the workspace where it should go</li> <li>From the sidebar, click on OAuth &amp; Permissions</li> <li>Go to the section \"Bot Token Scope\" and click \"Add an OAuth Scope\"</li> <li>Select the scope <code>chat:write</code></li> <li>From the sidebar, click \"Install App\" and then \"Install to Workspace\"</li> <li>Copy token shown, this is the <code>slack_api_token</code> you need in LimaCharlie</li> <li>In your Slack workspace, go to the channel you want to receive messages in, and type the slash command: <code>/invite @limacharlie</code> (assuming the app name is <code>limacharlie</code>)</li> </ol>"},{"location":"5-integrations/outputs/destinations/smtp/","title":"SMTP","text":"<p>One option to export data from LimaCharlie is via SMTP, allowing you to send emails directly to a ticketing inbox or send high-priority detections to an on-call, shared email.</p> <p>To utilize SMTP output, you will need:</p> <ul> <li>An SMTP server that utilizes SSL</li> <li>Username and password to send through the SMTP server (if applicable)</li> <li>A destination email, to receive output</li> </ul>"},{"location":"5-integrations/outputs/destinations/smtp/#webapp-configuration","title":"Webapp Configuration","text":"<p>Output individually each event, detection, audit, deployment or log through an email.</p> <ul> <li><code>dest_host</code>: the IP or DNS (and optionally port) of the SMTP server to use to send the email.</li> <li><code>dest_email</code>: the email address to send the email to.</li> <li><code>from_email</code>: the email address set in the From field.</li> <li><code>username</code>: the username (if any) used to authenticate to the SMTP server.</li> <li><code>password</code>: the password (if any) used to authenticate to the SMTP server.</li> <li><code>secret_key</code>: an arbitrary shared secret used to compute an HMAC (SHA256) signature of the email to verify authenticity. This is a required field. See \"Webhook Details\" section below.</li> <li><code>is_readable</code>: if 'true' the email format will be HTML and designed to be readable by a human instead of a machine.</li> <li><code>is_starttls</code>: if 'true', use the Start TLS method of securing the connection instead of pure SSL.</li> <li><code>is_authlogin</code>: if 'true', authenticate using <code>AUTH LOGIN</code> instead of <code>AUTH PLAIN</code>.</li> <li><code>subject</code>: is specified, use this as the alternate \"subject\" line.</li> </ul> <p>Example:</p> <pre><code>dest_host: smtp.gmail.com\ndest_email: soc@corp.com\nfrom_email: lc@corp.com\nusername: lc\npassword: password-for-my-lc-email-user\nsecret_key: this-is-my-secret-shared-key\nis_readable: true\nis_starttls: false\nis_authlogin: false\nsubject: LC Detection- &lt;Name&gt;\n</code></pre>"},{"location":"5-integrations/outputs/destinations/smtp/#related-articles","title":"Related articles","text":"<ul> <li>IMAP</li> </ul>"},{"location":"5-integrations/outputs/destinations/smtp/#whats-next","title":"What's Next","text":"<ul> <li>Splunk</li> </ul>"},{"location":"5-integrations/outputs/destinations/splunk/","title":"Splunk","text":"<p>To send data from LimaCharlie to Splunk, you will need to configure an output.</p> <p>Want to reduce Splunk spend?</p> <p>Watch the webinar recording to learn about using LimaCharlie to reduce spending on Splunk and other high-cost security data solutions.</p>"},{"location":"5-integrations/outputs/destinations/splunk/#splunk-setup","title":"Splunk Setup","text":"<p>Follow Splunk's guide to set up an HEC, and as you do, set the source type to <code>_json</code>.</p>"},{"location":"5-integrations/outputs/destinations/splunk/#limacharlie-setup","title":"LimaCharlie Setup","text":"<p>From the Outputs view, click <code>Add Output</code>.</p> <p></p> <p>Choose the type of stream you want to output from LimaCharlie.</p> <p></p> <p>Set <code>Webhook</code> or <code>Webhook Bulk</code> as a destination.</p> <p></p> <p>Enter the output name.</p> <p></p> <p>Enter the correct HEC URI for your Splunk implementation as Destination Host. Use the  /services/collector/event  endpoint. Note if you are using Spunk Cloud, this will be the string from the URL <code>https://&lt;host&gt;.splunkcloud.com/</code>.</p> <p>Here is a sample Splunk HEC configuration:</p> <p>Destination Host = <code>https://host.domain.com:8088/services/collector/raw</code>  Auth Header Name = Authorization  Auth Header value = Splunk xxxxxx-xxxx-xxxx-xxxx-xxxxxx</p> <p>Before saving the output, you can configure any of the advanced Output settings.</p> <p>Tag - Providing a tag name allows you to only send events from sensor with this tag. Tags can be managed at the sensor details view.</p> <p>Sensor - choosing a sensor ID will only send events or detections from this sensor.</p> <p>Flatten will flatted the JSON; no changes are needed for the email configuration.</p> <p>**Wrap JSON event with Event Type **- by default, we do not add prefix in front of every record. Prefix is useful for loading data into relational databases. If you are looking to receive a human-readable email, leave this option unchecked.</p> <p>Delete on Failure - when set to Yes, the system will completely delete the output configuration in case of failure. This is useful when you are configuring a temporary output needed for a short while and you don't want to have to worry about cleaning up later.</p> <p>You can choose to only send a specific list of event types by configuring an allow list in the Detection Category section. Alternatively, if you want to exclude certain event types, you can denote it in a deny list (Disallowed Detection Categories).</p> <p>Do not include routing flag allows users to forward only the original logs to outputs, excluding the routing label. This can be helpful for users wanting to use LimaCharlie for storage optimization since the routing label can add significant overhead.</p> <p></p>"},{"location":"5-integrations/outputs/destinations/syslog/","title":"Syslog","text":""},{"location":"5-integrations/outputs/destinations/syslog/#syslog-tcp","title":"Syslog (TCP)","text":"<p>Output events and detections to a syslog target.</p> <ul> <li><code>dest_host</code>: the IP or DNS and port to connect to, format <code>www.myorg.com:514</code>.</li> <li><code>is_tls</code>: if <code>true</code> will output over TCP/TLS.</li> <li><code>is_strict_tls</code>: if <code>true</code> will enforce validation of TLS certs.</li> <li><code>is_no_header</code>: if <code>true</code> will not emit a Syslog header before every message. This effectively turns it into a TCP output.</li> <li><code>structured_data</code>: arbitrary field to include in syslog \"Structured Data\" headers. Sometimes useful for cloud SIEMs integration.</li> </ul> <p>Example:</p> <pre><code>dest_host: storage.corp.com\nis_tls: \"true\"\nis_strict_tls: \"true\"\nis_no_header: \"false\"\n</code></pre>"},{"location":"5-integrations/outputs/destinations/syslog/#related-articles","title":"Related articles","text":"<ul> <li>Syslog</li> </ul>"},{"location":"5-integrations/outputs/destinations/syslog/#whats-next","title":"What's Next","text":"<ul> <li>Tines</li> </ul>"},{"location":"5-integrations/outputs/destinations/tines/","title":"Tines","text":"<p>Output events and detections to Tines.</p> <ul> <li><code>dest_host</code>: the Tines-provided <code>Webhook URL</code></li> </ul> <p>Example:</p> <pre><code>dest_host: https://something.tines.com/webhook/de2314c5f6246d17e82bf7b5742c9eaf/2d2dbcd2ab3845e9592d33c0526bc123\n</code></pre> <p>Detections or events sent to Tines via an output can be used to subsequently create cases, or take other actions within Tines.</p> <p></p>"},{"location":"5-integrations/outputs/destinations/tines/#whats-next","title":"What's Next","text":"<ul> <li>Webhook</li> </ul>"},{"location":"5-integrations/outputs/destinations/webhook-bulk/","title":"Webhook (Bulk)","text":"<p>Output batches of events, detections, audits, deployments or artifacts through a POST webhook.</p> <ul> <li><code>dest_host</code>: the IP or DNS, port and page to HTTP(S) POST to, format <code>https://www.myorg.com:514/whatever</code>.</li> <li><code>secret_key</code>: an arbitrary shared secret used to compute an HMAC (SHA256) signature of the webhook to verify authenticity. This is a required field. See \"Webhook Details\" section.</li> <li><code>auth_header_name</code> and <code>auth_header_value</code>: set a specific value to a specific HTTP header name in the outgoing webhooks.</li> <li><code>sec_per_file</code>: the number of seconds after which a file is cut and uploaded.</li> <li><code>is_no_sharding</code>: do not add a shard directory at the root of the files generated.</li> </ul> <p>Example:</p> <pre><code>dest_host: https://webhooks.corp.com/new_detection\nsecret_key: this-is-my-secret-shared-key\nauth_header_name: x-my-special-auth\nauth_header_value: 4756345846583498\n</code></pre>"},{"location":"5-integrations/outputs/destinations/webhook-bulk/#related-articles","title":"Related articles","text":"<ul> <li>Tutorial: Creating a Webhook Adapter</li> </ul>"},{"location":"5-integrations/outputs/destinations/webhook-bulk/#whats-next","title":"What's Next","text":"<ul> <li>Testing Outputs</li> </ul>"},{"location":"5-integrations/outputs/destinations/webhook/","title":"Webhook","text":"<p>Output individually each event, detection, audit, deployment or artifact through a POST webhook.</p> <ul> <li><code>dest_host</code>: the IP or DNS, port and page to HTTP(S) POST to, format <code>https://www.myorg.com:514/whatever</code>.</li> <li><code>secret_key</code>: an arbitrary shared secret used to compute an HMAC (SHA256) signature of the webhook to verify authenticity. See \"Webhook Details\" section.</li> <li><code>auth_header_name</code> and <code>auth_header_value</code>: set a specific value to a specific HTTP header name in the outgoing webhooks.</li> </ul> <p>Example:</p> <pre><code>dest_host: https://webhooks.corp.com/new_detection\nsecret_key: this-is-my-secret-shared-key\nauth_header_name: x-my-special-auth\nauth_header_value: 4756345846583498\n</code></pre> <p>Example hook to Google Chat:</p> <pre><code>dest_host: https://chat.googleapis.com/v1/spaces/AAAA4-AAAB/messages?key=afsdfgfdgfE6vySjMm-dfdssss&amp;token=pBh2oZWr7NTSj9jisenfijsnvfisnvijnfsdivndfgyOYQ%3D\nsecret_key: gchat-hook-sig42\ncustom_transform: |\n   {\n      \"text\": \"Detection {{ .cat }} on {{ .routing.hostname }}: {{ .link }}\"\n   }\n</code></pre>"},{"location":"5-integrations/services/dumper/","title":"Dumper","text":"<p>The Dumper Extension provides the ability to do dumping of several forensic artifacts on Windows hosts. It supports a single action, which is to dump.</p> <p>It supports multiple targets -- <code>memory</code> to dump the memory of the host, and <code>mft</code> to dump the MFT of the file system to CSV. The extension then automates the ingestion of the resulting dump (and dump metadata) to LimaCharlie's Artifact Ingestion system where it can be downloaded or analyzed, and where you can create  rules to automate detections of characteristics of those dumps.</p>"},{"location":"5-integrations/services/dumper/#usage","title":"Usage","text":"<p>When enabled, dumper will be added to the Extensions view inside your Organization. It will accept the following parameters:</p> <ul> <li><code>sid</code> - a Sensor ID for the host to perform the memory dump</li> <li><code>target</code> - memory or mft</li> <li><code>retention</code> - the number of days the memory dump should be retained for (default is 30)</li> <li><code>ignore_cert</code> - ignore cert errors for payload and collection purposes (default <code>false</code>)</li> </ul> <p>Upon submission of a request, the extension will perform a full memory dump of a host and upload the resulting dumps to LimaCharlie's artifact ingestion system and delete the local dumps afterwards.</p> <p>Dumper requests can also be made via D&amp;R rules. Here is is example of a D&amp;R rule action that makes a request to Dumper:</p> <pre><code>- action: extension request\n  extension name: ext-dumper\n  extension action: request_dump\n  extension request:\n    target: memory\n    sid: &lt;&lt;routing.sid&gt;&gt;\n    retention: 30 #default 30\n    ignore_cert: true # default false\n</code></pre> <p>Notes:</p> <p>The dumper extension does not currently validate that the host has enough available disc space for the memory dump. Although the dumper extension is free, the resulting memory dumps uploaded to LimaCharlie are subject to external logs pricing. This add-on relies on other paid resources (payloads) billed based on usage.</p>"},{"location":"5-integrations/services/replay/","title":"Replay","text":"<p>Replay allows you to run Detection &amp; Response (D&amp;R) rules against historical traffic.  This can be done in a few combinations of sources:</p> <p>Rule Source:</p> <ul> <li>Existing rule in the organization, by name.</li> <li>Rule in the replay request.</li> </ul> <p>Traffic:</p> <ul> <li>Sensor historical traffic.</li> <li>Local events provided during request.</li> </ul>"},{"location":"5-integrations/services/replay/#using","title":"Using","text":"<p>Using the Replay API requires the API key to have the following permissions:</p> <ul> <li><code>insight.evt.get</code></li> </ul> <p>The returned data from the API contains the following:</p> <ul> <li><code>responses</code>: a list of the actions that would have been taken by the rule (like <code>report</code>, <code>task</code>, etc).</li> <li><code>num_evals</code>: a number of evaluation operations performed by the rule. This is a rough estimate of the performance of the rule.</li> <li><code>num_events</code>: the number of events that were replayed.</li> <li><code>eval_time</code>: the number of seconds it took to replay the data.</li> </ul> <pre><code>{\n  \"error\": \"\",        // if an error occured.\n  \"stats\": {\n    \"n_proc\": 0,      // the number of events processed\n    \"n_shard\": 0,     // the number of chunks the replay job was broken into\n    \"n_eval\": 0,      // the number of operator evaluations performed\n    \"wall_time\": 0    // the number of real-world seconds the job took\n  },\n  \"did_match\": false, // indicates if the rule matched any event at all\n  \"results\": [],      // a list of dictionaries containing the details of actions the engine would have taken\n  \"traces\": []        // a list of trace items to help you troubleshoot where a rule failed\n}\n</code></pre>"},{"location":"5-integrations/services/replay/#query-language","title":"Query Language","text":"<p>To use Replay in LCQL Mode (LimaCharlie Query Language), you can specify your query in the <code>query</code> parameter of the Replay Request (defined below) when using the REST interface, or you can use the LimaCharlie Python SDK/CLI's query interface: <code>limacharlie query --help</code>.</p>"},{"location":"5-integrations/services/replay/#python-cli","title":"Python CLI","text":"<p>The Python CLI gives you a friendly way to replay data, and to do so across larger datasets by automatically splitting up your query into multiple queries that can run in parallel.</p> <p>Sample command line to query one sensor:</p> <pre><code>limacharlie-replay --sid 9cbed57a-6d6a-4af0-b881-803a99b177d9 --start 1556568500 --end 1556568600 --rule-content ./test_rule.txt\n</code></pre> <p>Sample command line to query an entire organization:</p> <pre><code>limacharlie-replay --entire-org --start 1555359000 --end 1556568600 --rule-name my-rule-name\n</code></pre> <p>If specifying a rule as content with the <code>--rule-content</code>, the format should be  in <code>JSON</code> or <code>YAML</code> like:</p> <pre><code>detect:\n  event: DNS_REQUEST\n  op: is\n  path: event/DOMAIN_NAME\n  value: www.dilbert.com\nrespond:\n  - action: report\n    name: dilbert-is-here\n</code></pre> <p>Instead of specifying the <code>--entire-org</code> or <code>--sid</code> flags, you may use events from a local file via the <code>--events</code> flag.</p> <p>We invite you to look at the command line usage itself, as the tool evolves.</p>"},{"location":"5-integrations/services/replay/#rest-api","title":"REST API","text":"<p>The Replay API is available to all DataCenter locations using a per-location URL.  To get the appropriate URL for your organization, use the REST endpoint to retrieve the URLs found here named <code>replay</code>.</p> <p>Having per-location URLs will allow us to guarantee that processing occurs within the geographical area you chose. Currently, some locations are NOT guaranteed to be in the same area due to the fact we are using the Google Cloud Run product which is not available globally. For these cases, processing is currently done in the United States, but as soon as it becomes available in your area, the processing will be moved transparently.</p> <p>Authentication to this API works with the same JWTs as the main limacharlie.io API.</p> <p>For this example, we will use the experimental datacenter's URL:</p> <pre><code>https://0651b4f82df0a29c.replay.limacharlie.io/\n</code></pre> <p>The API mainly works on a per-sensor basis, on a limited amount of time. Replaying for multiple sensors (or entire org), or longer time period is done through multiple parallel API calls. This multiplexing is taken care of by the Python CLI above.</p> <p>To query Replay, do a <code>POST</code> with a <code>Content-Type</code> header of <code>application-json</code> and with a JSON body like:</p> <pre><code>{\n  \"oid\": \"\",             // OID this query relates to\n  \"rule_source\": {       // rule source information (use one of \"rule_name\" or \"rule\")\n    \"rule_name\": \"\",     // pre-existing rule name to run\n    \"namespace\": \"\", // default: general namespace, can also be \"managed\" and \"service\"\n    \"rule\": {            // literal rule to run\n      \"detect\": {},\n      \"respond\": []\n    }\n  },\n  \"event_source\": {      // event source information (use one of \"sensor_events\" or \"events\")\n    \"sensor_events\": {   // use historical events from sensors\n      \"sid\": \"\",         // sensor id to replay from, or entire org if empty\n      \"selector\": \"\", // a sensor selector\n      \"start_time\": 0,   // start second epoch time to replay from\n      \"end_time\": 0      // end second epoch time to replay to\n    },\n    \"events\": [{}],       // literal list of events to replay\n    \"stream\": \"\" // defaults to events, can also be \"audit\" or \"detect\"\n  },\n  \"limit_event\": 0,      // optional approximate number of events to process\n  \"limit_eval\": 0,       // optional approximate number of operator evaluations to perform\n  \"trace\": false,        // optional, if true add trace information to response, VERY VERBOSE\n  \"is_dry_run\": false,   // optional, if true, an estimate of the total cost of the query will be returned\n  \"query\": \"\"            // optional alternative way to describe a replay query as a LimaCharlie Query Language (LCQL) query.\n}\n</code></pre> <p>Like the other endpoints you can also submit a <code>rule_name</code> in the URL query if you want  to use an existing organization rule.</p> <p>You may also specify a <code>limit_event</code> and <code>limit_eval</code> parameter as integers. They will limit the number of events evaluated and the number of rule evaluations performed (approximately). If the limits are reached, the response will contain an item named <code>limit_eval_reached: true</code> and <code>limit_event_reached: true</code>.</p> <p>Finally, you may also set <code>trace</code> to <code>true</code> in the request to receive a detailed trace of the rule evaluation. This is useful in the development of new rules to find where rules are failing.</p>"},{"location":"5-integrations/services/replay/#billing","title":"Billing","text":"<p>The Replay service is billed on a per event evaluated.</p>"},{"location":"5-integrations/tutorials/hayabusa-bigquery/","title":"Hayabusa to BigQuery","text":""},{"location":"5-integrations/tutorials/hayabusa-bigquery/#overview","title":"Overview","text":"<p>Our BigQuery output allows you to send Hayabusa analysis results to a BigQuery table allowing SQL-like queries against the data. This allows you to perform analysis at scale against massive datasets. For guidance on using Hayabusa within LimaCharlie, see Hayabusa Extension.</p> <p>Imagine you wanted to analyze event logs from 10s, 100s, or 1000s of systems using Hayabusa. You have a couple options:</p> <ol> <li>Send the resulting CSV artifact to another platform, like Timesketch, for further analysis, as the CSV generated by Hayabusa in LimaCharlie is compatible with Timesketch</li> <li>Run queries against all of the data returned by Hayabusa in BigQuery</li> </ol> <p>BigQuery dataset containing Hayabusa results: </p>"},{"location":"5-integrations/tutorials/hayabusa-bigquery/#steps-to-accomplish","title":"Steps to Accomplish","text":"<ol> <li>You will need a Google Cloud project</li> <li> <p>You will need to create a service account within your Google Cloud project</p> </li> <li> <p>Navigate to your project</p> </li> <li>Navigate to IAM</li> <li>Navigate to Service Accounts &gt; Create Service Account</li> <li> <p>Click on newly created Service Account and create a new key</p> <ol> <li></li> <li>This will provide you with the JSON format secret key you will later setup in your LimaCharlie output.</li> <li> <p>In BigQuery, create a Dataset, Table, &amp; Schema similar to the screenshot below. Keep in mind, the name of your dataset and table are arbitrary but they need to match what you configure in your output in LimaCharlie.</p> </li> <li> <p>Project - <code>your_project_name</code></p> </li> <li>Dataset - <code>hayabusa</code></li> <li>Table - <code>hayabusa</code></li> <li> <p>Schema - <code>computer:STRING, message:STRING, timestamp:STRING, details:STRING, channel:STRING, event_id:STRING, level:STRING, mitre_tactics:STRING, mitre_tags:STRING, extra:STRING</code></p> <ol> <li>Note that this can be any of the fields from the Hayabusa event that you wish to use. This schema and transform are based on the CSV output using the <code>timesketch-verbose</code> profile.</li> <li>Now we're ready to create our LimaCharlie Events Output</li> </ol> </li> </ol> </li> <li> <p>In the side navigation menu, click \"Outputs\" then add a new ouput</p> <ol> <li>Output stream: Events</li> <li> <p>Destination: Google Cloud BigQuery</p> <ol> <li> <p>Name: <code>hayabusa-bigquery</code></p> <ol> <li> <p>You can change this, but it affects a subsequent step so take note of the output name          2. schema: <code>computer:STRING, message:STRING, timestamp:STRING, details:STRING, channel:STRING, event_id:STRING, level:STRING, mitre_tactics:STRING, mitre_tags:STRING, extra:STRING</code></p> </li> <li> <p>Note that this can be any of the fields from the Hayabusa event that you wish to use. This schema and transform are based on the CSV output using the <code>timesketch-verbose</code> profile.          3. Dataset: whatever you named BQ your dataset above          4. Table: whatever you named your BQ table above          5. Project: your GCP project name          6. Secret Key: provide the JSON secret key for your GCP service account          7. Advanced Options</p> </li> <li> <p>Custom Transform: paste in this JSON</p> </li> <li> <p>Note that this can be any of the fields from the Hayabusa event that you wish to use. This schema and transform are based on the CSV output using the <code>timesketch-verbose</code> profile.</p> </li> </ol> <p><pre><code>{\n\"channel\": \"event.results.Channel\",\n\"computer\": \"event.results.Computer\",\n\"message\": \"event.results.message\",\n\"timestamp\": \"event.results.datetime\",\n\"details\": \"event.results.Details\",\n\"event_id\": \"event.results.EventID\",\n\"level\": \"event.results.Level\",\n\"mitre_tactics\": \"event.results.MitreTactics\",\n\"mitre_tags\": \"event.results.MitreTags\",\n\"extra\": \"event.results.ExtraFieldInfo\",\n}\n</code></pre> 2. Specific Event Types: <code>hayabusa_event</code> 3. Sensor: <code>ext-hayabusa</code> 4. You are now ready to send Hayabusa events to BigQuery!</p> </li> </ol> </li> </ol> </li> </ol>"},{"location":"5-integrations/tutorials/velociraptor-bigquery/","title":"Velociraptor to BigQuery","text":""},{"location":"5-integrations/tutorials/velociraptor-bigquery/#overview","title":"Overview","text":"<p>Our BigQuery output allows you to send Velociraptor hunt results to a BigQuery table allowing SQL-like queries against the hunt data. This is very similar to using Velociraptor notebooks, allowing you to perform hunt analysis at scale against massive datasets. For guidance on using LimaCharlie to execute Velociraptor hunts, see Velociraptor Extension.</p> <p>Imagine you wanted to obtain running processes from 10s, 100s, or 1000s of systems using Velociraptor. You could easily issue a <code>Windows.System.Pslist</code> hunt across these systems, and let LimaCharlie push Velociraptor to the endpoints and collect the results. The issue is, if you want to run queries against all of the data returned by the hunts, you'll need a database-like tool to do that which is where BigQuery comes in.</p> <p>BigQuery dataset containing Velociraptor hunt results: </p>"},{"location":"5-integrations/tutorials/velociraptor-bigquery/#steps-to-accomplish","title":"Steps to Accomplish","text":"<ol> <li>You will need a Google Cloud project</li> <li> <p>You will need to create a service account within your Google Cloud project</p> </li> <li> <p>Navigate to your project</p> </li> <li>Navigate to IAM</li> <li>Navigate to Service Accounts &gt; Create Service Account</li> <li> <p>Click on newly created Service Account and create a new key</p> <ol> <li></li> <li>This will provide you with the JSON format secret key you will later setup in your LimaCharlie output</li> <li> <p>In BigQuery, create a Dataset, Table, &amp; Schema similar to the screenshot below</p> </li> <li> <p></p> </li> <li>Now we're ready to create our LimaCharlie tailored output</li> </ol> </li> <li> <p>In the side navigation menu, click \"Outputs\" then add a new output</p> <ol> <li>Output stream: Tailored</li> <li> <p>Destination: Google Cloud BigQuery</p> <ol> <li> <p>Name: <code>bigquery-tailored</code></p> <ol> <li> <p>You can change this, but it affects a subsequent step so take note of the output name          2. schema: <code>sid:STRING, job_id:STRING, artifact:JSON</code>          3. Dataset: whatever you named BQ your dataset above          4. Table: whatever you named your BQ table above          5. Project: your GCP project name          6. Secret Key: provide the JSON secret key for your GCP service account          7. Advanced Options</p> </li> <li> <p>Custom Transform: paste in this JSON</p> </li> </ol> <p><pre><code>{\n\"sid\": \"event.sid\",\n\"job_id\": \"event.job_id\",\n\"artifact\": \"{{ json .event.collection }}\"\n}\n</code></pre> 2. Specific Event Types: <code>velociraptor_collection</code>       3.  4. We now need a  rule that will watch for Velociraptor collections send send them to the new tailored output</p> </li> </ol> </li> </ol> </li> <li> <p>Create a new D&amp;R rule</p> <ol> <li> <p>Detection</p> <p><pre><code>event: velociraptor_collection\nop: exists\npath: event/collection\n</code></pre>       2. Response</p> <p><pre><code>- action: output\n  name: bigquery-tailored # must match the output name you created earlier\n- action: report\n  name: Velociraptor hunt sent to BigQuery\n</code></pre> 5. You are now ready to send Velociraptor hunts to BigQuery!</p> </li> </ol> </li> </ol>"},{"location":"5-integrations/tutorials/velociraptor-bigquery/#bigquery-tips","title":"BigQuery Tips","text":""},{"location":"5-integrations/tutorials/velociraptor-bigquery/#query-examples","title":"Query Examples","text":"<p>Once the data arrives in BigQuery, it will be in three simple columns: <code>sid</code>, <code>job_id</code>, and <code>artifact</code>. The <code>artifact</code> column contains the raw JSON of the hunt results from each sensor that returned results.</p> <p></p> <p>Let's say we wanted to split out all results of a <code>Windows.System.Pslist</code> hunt so that each process, from each system, is returned in it's own row. Here is an example notebook to accomplish this:</p> <pre><code>SELECT\n  sid,\n  json_extract_scalar(obj, '$.Name') as Name,\n  json_extract_scalar(obj, '$.Exe') as Exe,\n  json_extract_scalar(obj, '$.CommandLine') as CommandLine,\n  json_extract_scalar(obj, '$.Authenticode.Trusted') as Authenticode,\n  json_extract_scalar(obj, '$.Hash.SHA256') as SHA256,\n  json_extract_scalar(obj, '$.Pid') as Pid,\n  json_extract_scalar(obj, '$.Ppid') as Ppid,\n  json_extract_scalar(obj, '$.Username') as Username\nFROM\n  `lc-demo-infra.velociraptor.hunts`,\n  UNNEST(json_extract_array(artifact.Windows_System_Pslist)) as obj\nLIMIT 1000\n</code></pre> <p>Be sure to swap out <code>lc-demo-infra.velociraptor.hunts</code> for your own <code>project.dataset.table</code> names.</p> <p>This results in the following view of our data </p> <p>Suppose we wanted to perform some stacking analysis to identify the rarest combinations of <code>Exe</code> and <code>CommandLine</code>; the following query could help:</p> <pre><code>SELECT\n  json_extract_scalar(obj, '$.Exe') as Exe,\n  json_extract_scalar(obj, '$.CommandLine') as CommandLine,\n  COUNT(*) as Count\nFROM\n  `lc-demo-infra.velociraptor.hunts`,\n  UNNEST(json_extract_array(artifact.Windows_System_Pslist)) as obj\nGROUP BY\n  Exe,\n  CommandLine\nORDER BY\n  Count ASC\n</code></pre> <p>This results in the following view of our data </p> <p>Now let's say you wanted to look for only processes that are <code>Authenticode</code> = <code>untrusted</code>, you would use a query such as this:</p> <pre><code>SELECT\n  sid,\n  json_extract_scalar(obj, '$.Name') as Name,\n  json_extract_scalar(obj, '$.Exe') as Exe,\n  json_extract_scalar(obj, '$.CommandLine') as CommandLine,\n  json_extract_scalar(obj, '$.Authenticode.Trusted') as Authenticode,\n  json_extract_scalar(obj, '$.Hash.SHA256') as SHA256,\n  json_extract_scalar(obj, '$.Pid') as Pid,\n  json_extract_scalar(obj, '$.Ppid') as Ppid,\n  json_extract_scalar(obj, '$.Username') as Username\nFROM\n  `lc-demo-infra.velociraptor.hunts`,\n  UNNEST(json_extract_array(artifact.Windows_System_Pslist)) as obj\nWHERE\n  json_extract_scalar(obj, '$.Authenticode.Trusted') = 'untrusted'\nLIMIT 1000\n</code></pre>"},{"location":"5-integrations/tutorials/velociraptor-bigquery/#where-filters-for-specific-conditions","title":"WHERE Filters for Specific Conditions","text":"<p>Here are some brief examples of <code>WHERE</code> statements to perform specific filtering.</p>"},{"location":"5-integrations/tutorials/velociraptor-bigquery/#string-presence","title":"String presence","text":"<p>This example checks for the presence of a string <code>mimikatz</code> appearing anywhere within <code>CommandLine</code></p> <pre><code>WHERE\n  STRPOS(json_extract_scalar(obj, '$.CommandLine'), 'mimikatz') &gt; 0 AND\n</code></pre>"},{"location":"5-integrations/tutorials/velociraptor-bigquery/#compare-integers","title":"Compare integers","text":"<p>This example checks for the presence of an integer <code>0</code> in a numeric field <code>GroupID</code></p> <pre><code>WHERE\n  CAST(json_extract_scalar(obj, '$.GroupID') AS INT64) = 0\n</code></pre>"},{"location":"5-integrations/tutorials/velociraptor-bigquery/#parsing-nested-json-objects","title":"Parsing Nested JSON Objects","text":"<p>In the <code>Windows.System.Pslist</code> examples above, there are a few columns which contain nested JSON such as <code>Authenticode</code> and <code>Hash</code>. To expand these objects in their entirety in the corresponding column/row, we'd write a query like this:</p> <pre><code>SELECT\n  json_extract(obj, '$.Authenticode') as Authenticode, # json_extract to unpack nested json\n  json_extract_scalar(obj, '$.Authenticode.Trusted') as Trusted,\n  json_extract(obj, '$.Hash') as Hashes, # json_extract to unpack nested json\n  json_extract_scalar(obj, '$.Hash.SHA256') as SHA256, # extract a specific field from the nested json\nFROM\n  `lc-demo-infra.velociraptor.hunts`,\n  UNNEST(json_extract_array(artifact.Windows_System_Pslist)) as obj\nLIMIT 1000\n</code></pre> <p>See the output of this query below: </p>"},{"location":"5-integrations/tutorials/virustotal-integration/","title":"VirusTotal Integration","text":"<p>You can easily integrate LimaCharlie with VirusTotal to enhance your data enrichment and detections. You will need a VirusTotal API key in order to utilize this add-on.</p> <p>VirusTotal Data Caching</p> <p>The free tier of VirusTotal allows four lookups per minute via the API. LimaCharlie employs a global cache of VirusTotal requests which should significantly reduce costs if you are using VirusTotal at scale. VirusTotal requests are cached for 3 days.</p> <p>Once you have your VirusTotal API key, you can add it in the Organization integrations section of the LimaCharlie web app.</p> <p></p> <p>Once you have entered your API key, you can then create a  rule to perform a lookup of a hash. For example, the following rule will let you know if there is a hit from VirusTotal on a hash with at least two different engines.</p> <pre><code>path: event/HASH\nop: lookup\nresource: hive://lookup/vt\nevent: CODE_IDENTITY\nmetadata_rules:\n  path: /\n  value: 2\n  length of: true\n  op: is greater than\n</code></pre>"},{"location":"6-developer-guide/","title":"Developer Guide","text":"<p>Build on the LimaCharlie platform with SDKs, APIs, and extension development.</p>"},{"location":"6-developer-guide/#sdks","title":"SDKs","text":"<p>Programmatic access to LimaCharlie:</p> <ul> <li>Python SDK - Full-featured Python library</li> <li>Go SDK - Native Go implementation</li> <li>SDK Overview - Getting started with SDKs</li> </ul>"},{"location":"6-developer-guide/#mcp-server","title":"MCP Server","text":"<p>AI-native integration for Claude and other AI assistants:</p> <ul> <li>MCP Server Setup</li> </ul>"},{"location":"6-developer-guide/#building-extensions","title":"Building Extensions","text":"<p>Create custom extensions for LimaCharlie:</p> <ul> <li>Getting Started</li> <li>User Interface</li> <li>Schema &amp; Data Types</li> </ul>"},{"location":"6-developer-guide/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>Manage LimaCharlie configuration as code:</p> <ul> <li>Git Sync Extension</li> <li>Pipeline</li> </ul>"},{"location":"6-developer-guide/#developer-program","title":"Developer Program","text":"<ul> <li>Developer Grant Program</li> </ul>"},{"location":"6-developer-guide/#see-also","title":"See Also","text":"<ul> <li>Python SDK</li> <li>Go SDK</li> <li>Building Extensions</li> <li>API Keys</li> </ul>"},{"location":"6-developer-guide/cli/","title":"LimaCharlie CLI","text":"<p>LimaCharlie CLI Extension allows you to issue LimaCharlie CLI commands using extension requests.</p> <p>Repo - https://github.com/refractionPOINT/python-limacharlie</p> <p>You may use a rule to trigger a LimaCharlie CLI event. For example the following rule response actions:</p> <pre><code>- action: extension request\n  extension action: run\n  extension name: limacharlie-cli\n  extension request:\n    command_line: '{{ \"limacharlie configs push --dry-run --oid\" }}'\n    credentials: '{{ \"hive://secret/secret-name\" }}'\n</code></pre>"},{"location":"6-developer-guide/grant-program/","title":"Developer Grant Program","text":"<p>The Developer Grant Program is designed to help fuel the growth of LimaCharlie add-ons and other projects that utilize the LimaCharlie platform. To help developers with their projects, we offer a $1,000 credit that can be applied towards using LimaCharlie to develop any kind of project you want.</p> <p>If you are looking to commercialize an idea we can help you get it into our marketplace and if there is traction there, we can further support you in growing.</p> <p>Interested parties can apply for the grant program here.</p>"},{"location":"6-developer-guide/mcp-server/","title":"MCP Server","text":"<ul> <li>Query and analyze historical telemetry from any sensor</li> <li>Actively investigate endpoints using the LimaCharlie Agent (EDR) in real-time</li> <li>Take remediation actions like isolating endpoints, killing processes, and managing tags</li> <li>Generate content using AI-powered tools for LCQL queries, D&amp;R rules, playbooks, and detection summaries</li> <li>Manage platform configuration including rules, outputs, adapters, secrets, and more</li> <li>Access threat intelligence through IOC searches and MITRE ATT&amp;CK mappings</li> </ul> <p>This opens up the entire LimaCharlie platform to AI agents, regardless of their implementation or location.</p>"},{"location":"6-developer-guide/mcp-server/#transport-modes","title":"Transport Modes","text":"<p>The server supports two transport modes based on the PUBLIC_MODE environment variable:</p>"},{"location":"6-developer-guide/mcp-server/#stdio-mode-public_modefalse-default","title":"STDIO Mode (PUBLIC_MODE=false, default)","text":"<p>Used for local MCP clients like Claude Desktop or Claude Code:</p> <ul> <li>Communication through stdin/stdout using JSON-RPC</li> <li>Uses LimaCharlie SDK's default authentication</li> <li>Reads credentials from environment variables or config files</li> </ul>"},{"location":"6-developer-guide/mcp-server/#http-mode-public_modetrue","title":"HTTP Mode (PUBLIC_MODE=true)","text":"<p>Used when deploying as a public service:</p> <ul> <li>Server runs as a stateless HTTP API with JSON responses</li> <li>Authentication via HTTP headers</li> <li>Supports multiple organizations concurrently</li> <li>Run with: <code>uvicorn server:app</code></li> </ul>"},{"location":"6-developer-guide/mcp-server/#requirements-authentication","title":"Requirements &amp; Authentication","text":""},{"location":"6-developer-guide/mcp-server/#for-http-mode","title":"For HTTP Mode","text":"<p>The server requires authentication headers:</p> <ol> <li> <p>Authorization header in one of these formats:</p> </li> <li> <p><code>Authorization: Bearer &lt;jwt&gt;</code> (OID must be in x-lc-oid header)</p> </li> <li><code>Authorization: Bearer &lt;jwt&gt;:&lt;oid&gt;</code> (combined format)</li> <li> <p><code>Authorization: Bearer &lt;api_key&gt;:&lt;oid&gt;</code> (API key with OID)</p> </li> <li> <p>x-lc-oid header (if not included in Authorization):</p> </li> <li> <p><code>x-lc-oid: &lt;organization_id&gt;</code></p> </li> </ol>"},{"location":"6-developer-guide/mcp-server/#for-stdio-mode","title":"For STDIO Mode","text":"<p>Set environment variables:</p> <ul> <li><code>LC_OID</code>: Your LimaCharlie Organization ID</li> <li><code>LC_API_KEY</code>: Your LimaCharlie API key</li> <li><code>GOOGLE_API_KEY</code>: For AI-powered generation features (optional)</li> </ul>"},{"location":"6-developer-guide/mcp-server/#capabilities","title":"Capabilities","text":"<p>The LimaCharlie MCP server exposes over 100 tools organized by category:</p>"},{"location":"6-developer-guide/mcp-server/#investigation-telemetry","title":"Investigation &amp; Telemetry","text":"<ul> <li>Process inspection: <code>get_processes</code>, <code>get_process_modules</code>, <code>get_process_strings</code>, <code>yara_scan_process</code></li> <li>System information: <code>get_os_version</code>, <code>get_users</code>, <code>get_services</code>, <code>get_drivers</code>, <code>get_autoruns, get_packages</code></li> <li>Network analysis: <code>get_network_connections</code>, <code>is_online</code>, <code>get_online_sensors</code></li> <li>File operations: <code>find_strings</code>, <code>yara_scan_file</code>, <code>yara_scan_directory</code>, <code>yara_scan_memory</code></li> <li>Registry access: <code>get_registry_keys</code></li> <li>Historical data: <code>get_historic_events</code>, <code>get_historic_detections</code>, <code>get_time_when_sensor_has_data</code></li> </ul>"},{"location":"6-developer-guide/mcp-server/#threat-response-remediation","title":"Threat Response &amp; Remediation","text":"<ul> <li>Network isolation: <code>isolate_network</code>, <code>rejoin_network</code>, <code>is_isolated</code></li> <li>Sensor management: <code>add_tag</code>, <code>remove_tag</code>, <code>delete_sensor</code></li> <li>Reliable tasking: <code>reliable_tasking</code>, <code>list_reliable_tasks</code></li> </ul>"},{"location":"6-developer-guide/mcp-server/#ai-powered-generation-requires-google_api_key","title":"AI-Powered Generation (requires GOOGLE_API_KEY)","text":"<ul> <li>Query generation: <code>generate_lcql_query</code> - Create LCQL queries from natural language</li> <li>Rule creation: <code>generate_dr_rule_detection</code>, <code>generate_dr_rule_respond</code> - Generate D&amp;R rules</li> <li>Automation: <code>generate_python_playbook</code> - Create Python playbooks</li> <li>Analysis: <code>generate_detection_summary</code> - Summarize detection data</li> <li>Sensor selection: <code>generate_sensor_selector</code> - Generate sensor selectors</li> </ul>"},{"location":"6-developer-guide/mcp-server/#platform-configuration","title":"Platform Configuration","text":"<ul> <li>Detection &amp; Response: <code>get_detection_rules</code>, <code>set_dr_general_rule</code>, <code>set_dr_managed_rule</code>, <code>delete_dr_general_rule</code></li> <li>False Positive Management: <code>get_fp_rules</code>, <code>set_fp_rule</code>, <code>delete_fp_rule</code></li> <li>YARA Rules: <code>list_yara_rules</code>, <code>set_yara_rule</code>, <code>validate_yara_rule</code>, <code>delete_yara_rule</code></li> <li>Outputs &amp; Adapters: <code>list_outputs</code>, <code>add_output</code>, <code>delete_output</code>, <code>list_external_adapters</code>, <code>set_external_adapter</code></li> <li>Extensions: <code>list_extension_configs</code>, <code>set_extension_config</code>, <code>delete_extension_config</code></li> <li>Playbooks: <code>list_playbooks</code>, <code>set_playbook</code>, <code>delete_playbook</code></li> <li>Secrets Management: <code>list_secrets</code>, <code>set_secret</code>, <code>delete_secret</code></li> <li>Saved Queries: <code>list_saved_queries</code>, <code>set_saved_query</code>, <code>run_saved_query</code></li> <li>Lookups: <code>list_lookups</code>, <code>set_lookup</code>, <code>query_lookup</code>, <code>delete_lookup</code></li> </ul>"},{"location":"6-developer-guide/mcp-server/#threat-intelligence","title":"Threat Intelligence","text":"<ul> <li>IOC Search: <code>search_iocs</code>, <code>batch_search_iocs</code></li> <li>Host Search: <code>search_hosts</code></li> <li>MITRE ATT&amp;CK: <code>get_mitre_report</code></li> </ul>"},{"location":"6-developer-guide/mcp-server/#administrative","title":"Administrative","text":"<ul> <li>API Keys: <code>list_api_keys</code>, <code>create_api_key</code>, <code>delete_api_key</code></li> <li>Installation Keys: <code>list_installation_keys</code>, <code>create_installation_key</code>, <code>delete_installation_key</code></li> <li>Cloud Sensors: <code>list_cloud_sensors</code>, <code>set_cloud_sensor</code>, <code>delete_cloud_sensor</code></li> <li>Organization Info: <code>get_org_info</code>, <code>get_usage_stats</code></li> <li>Artifacts: <code>list_artifacts</code>, <code>get_artifact</code></li> </ul>"},{"location":"6-developer-guide/mcp-server/#schema-documentation","title":"Schema &amp; Documentation","text":"<ul> <li>Event Schemas: <code>get_event_schema</code>, <code>get_event_schemas_batch</code>, <code>get_event_types_with_schemas</code></li> <li>Platform Support: <code>get_platform_names</code>, <code>list_with_platform</code>, <code>get_event_types_with_schemas_for_platform</code></li> </ul>"},{"location":"6-developer-guide/mcp-server/#advanced-features","title":"Advanced Features","text":""},{"location":"6-developer-guide/mcp-server/#large-result-handling","title":"Large Result Handling","text":"<p>The server automatically handles large responses by uploading them to Google Cloud Storage (if configured):</p> <ul> <li>Set <code>GCS_BUCKET_NAME</code> for the storage bucket</li> <li>Configure <code>GCS_TOKEN_THRESHOLD</code> (default: 1000 tokens)</li> <li>Results are returned as signed URLs valid for 24 hours</li> </ul>"},{"location":"6-developer-guide/mcp-server/#lcql-query-execution","title":"LCQL Query Execution","text":"<p>The <code>run_lcql_query</code> tool supports:</p> <ul> <li>Streaming results for real-time monitoring</li> <li>Flexible time windows and limits</li> <li>Output formatting options</li> </ul>"},{"location":"6-developer-guide/mcp-server/#examples","title":"Examples","text":""},{"location":"6-developer-guide/mcp-server/#claude-desktopcode-configuration-stdio","title":"Claude Desktop/Code Configuration (STDIO)","text":"<pre><code>  {\n    \"mcpServers\": {\n      \"limacharlie\": {\n        \"command\": \"python3\",\n        \"args\": [\"/path/to/server.py\"],\n        \"env\": {\n          \"LC_OID\": \"your-org-id\",\n          \"LC_API_KEY\": \"your-api-key\",\n          \"GOOGLE_API_KEY\": \"your-google-api-key\"\n        }\n      }\n    }\n  }\n</code></pre>"},{"location":"6-developer-guide/mcp-server/#http-service-usage","title":"HTTP Service Usage","text":"<pre><code>claude mcp add --transport http limacharlie https://mcp.limacharlie.io/mcp \\\n--header \"Authorization: Bearer API_KEY:OID\" \\\n--header \"x-lc-oid: OID\"\n</code></pre>"},{"location":"6-developer-guide/mcp-server/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>PUBLIC_MODE</code>: Set to true for HTTP mode, false for STDIO (default: false)</li> <li><code>GOOGLE_API_KEY</code>: API key for AI-powered features</li> <li><code>GCS_BUCKET_NAME</code>: Google Cloud Storage bucket for large results</li> <li><code>GCS_SIGNER_SERVICE_ACCOUNT</code>: Service account for GCS URL signing</li> <li><code>GCS_TOKEN_THRESHOLD</code>: Token count threshold for GCS upload (default: 1000)</li> <li><code>GCS_URL_EXPIRY_HOURS</code>: Hours until GCS URLs expire (default: 24)</li> <li><code>LC_OID</code>: Organization ID (STDIO mode only)</li> <li><code>LC_API_KEY</code>: API key (STDIO mode only)</li> </ul>"},{"location":"6-developer-guide/mcp-server/#notes","title":"Notes","text":"<ul> <li>The server is stateless when running in HTTP mode</li> <li>HTTP mode uses JSON responses (not Server-Sent Events)</li> <li>No OAuth flow is used - authentication is via bearer tokens only</li> <li>If you encounter missing capabilities, contact https://community.limacharlie.com for quick additions</li> </ul>"},{"location":"6-developer-guide/pipeline/","title":"LimaCharlie Documentation Pipeline","text":"<p>This directory contains scripts to fetch and process the LimaCharlie documentation from https://docs.limacharlie.io/docs.</p>"},{"location":"6-developer-guide/pipeline/#scripts","title":"Scripts","text":""},{"location":"6-developer-guide/pipeline/#fetch_docspy","title":"fetch_docs.py","text":"<p>Main script to fetch all documentation articles from the LimaCharlie documentation site via the Algolia API.</p> <p>Features: - Automatically extracts API credentials from the documentation page - Fetches all public, non-deleted, non-draft articles (~612 articles) - Creates directory structure based on article breadcrumbs - Saves articles as markdown with metadata headers - Supports resume capability (skips already downloaded files)</p> <p>Dependencies: <pre><code>pip3 install requests beautifulsoup4 html2text\n</code></pre></p> <p>Usage: <pre><code># Fetch all documentation\npython3 limacharlie/pipeline/fetch_docs.py\n\n# Or make it executable and run directly\nchmod +x limacharlie/pipeline/fetch_docs.py\n./limacharlie/pipeline/fetch_docs.py\n</code></pre></p> <p>Output: - Articles are saved to <code>./limacharlie/raw_markdown/</code> - Directory structure mirrors the breadcrumb hierarchy (e.g., <code>Add-Ons/API Integrations/</code>) - Each file includes a YAML metadata header with title, slug, breadcrumb, source URL, and article ID</p>"},{"location":"6-developer-guide/pipeline/#test_fetchpy","title":"test_fetch.py","text":"<p>Test script that fetches only the first 3 articles to verify the setup works correctly.</p> <p>Usage: <pre><code>python3 limacharlie/pipeline/test_fetch.py\n</code></pre></p>"},{"location":"6-developer-guide/pipeline/#how-it-works","title":"How It Works","text":"<ol> <li> <p>API Credential Extraction: The script fetches the documentation home page and extracts the Algolia API credentials (app ID, search key, index name) from the page source.</p> </li> <li> <p>Article Metadata Fetch: Using the Algolia API, it fetches all article metadata including title, slug, breadcrumb, and full text content in a single query.</p> </li> <li> <p>Filtering: The Algolia API key has built-in filters that automatically exclude:</p> </li> <li>Deleted articles (isDeleted: true)</li> <li>Hidden articles (isHidden: true)</li> <li>Draft articles (isDraft: true)</li> <li>Excluded articles (exclude: true)</li> <li>Category entries (isCategory: true)</li> <li> <p>Unpublished articles (isUnpublished: true)</p> </li> <li> <p>Processing: For each article:</p> </li> <li>Creates the directory structure based on breadcrumb</li> <li>Generates a markdown file with metadata header</li> <li> <p>Saves the plain text content from Algolia</p> </li> <li> <p>Error Handling:</p> </li> <li>Skips articles without content</li> <li>Supports resume capability (skips existing files)</li> <li>Comprehensive error logging</li> </ol>"},{"location":"6-developer-guide/pipeline/#output-format","title":"Output Format","text":"<p>Each markdown file contains:</p> <pre><code>---\ntitle: Article Title\nslug: article-slug\nbreadcrumb: Category &gt; Subcategory\nsource: https://docs.limacharlie.io/docs/article-slug\narticleId: uuid-here\n---\n\nArticle content in plain text format...\n</code></pre>"},{"location":"6-developer-guide/pipeline/#statistics","title":"Statistics","text":"<p>As of the last run: - Total entries in Algolia: 680 - Articles (filtered): 612 - Categories (excluded): 68 - Output directory: <code>./limacharlie/raw_markdown/</code></p>"},{"location":"6-developer-guide/sdk-overview/","title":"SDK Overview","text":""},{"location":"6-developer-guide/sdk-overview/#authentication","title":"Authentication","text":"<p>You can use Client Options to declare your client/org, or you can use environment variables.</p> <p>Using Environment Variables:</p> <ul> <li><code>LC_OID</code>: Organization ID</li> <li><code>LC_API_KEY</code>: your LC API KEY</li> <li><code>LC_UID</code>: optional, your user ID</li> </ul> <pre><code>package main\n\nimport (\n    \"fmt\"\n\n    \"github.com/refractionPOINT/go-limacharlie/limacharlie\"\n)\n\nfunc main() {\n    client, err := limacharlie.NewClientFromLoader(limacharlie.ClientOptions{}, nil, &amp;limacharlie.EnvironmentClientOptionLoader{})\n    if err != nil {\n        fmt.Println(err)\n    }\n\n    org, _ := limacharlie.NewOrganization(client)\n    fmt.Printf(\"Hello, this is %s\", org.GetOID())\n}\n</code></pre> <p>Using Client Options:</p> <pre><code>package main\n\nimport (\n    \"fmt\"\n\n    \"github.com/refractionPOINT/go-limacharlie/limacharlie\"\n)\n\nfunc main() {\n    clientOptions = limacharlie.ClientOptions{\n        OID: \"MY_OID\",\n        APIKey: \"MY_API_KEY\",\n        UID: \"MY_UID\",\n    }\n    org, _ := limacharlie.NewOrganizationFromClientOptions(clientOptions, nil)\n    fmt.Printf(\"Hello, this is %s\", org.GetOID())\n}\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#sdk","title":"SDK","text":""},{"location":"6-developer-guide/sdk-overview/#examples","title":"Examples","text":"<pre><code>package main\n\nimport (\n    \"fmt\"\n\n    \"github.com/refractionPOINT/go-limacharlie/limacharlie\"\n)\n\nfunc main() {\n    client, err := limacharlie.NewClientFromLoader(limacharlie.ClientOptions{}, nil, &amp;limacharlie.EnvironmentClientOptionLoader{})\n    if err != nil {\n        fmt.Println(err)\n    }\n\n    org, _ := limacharlie.NewOrganization(client)\n\n    // List all sensors\n    sensors, err := org.ListSensors()\n    if err != nil {\n        fmt.Println(err)\n    }\n    for sid, sensor := range sensors {\n        fmt.Printf(\"%s - %s\", sid, sensor.Hostname)\n    }\n\n    // List D&amp;R rules from Hive\n    hiveClient := limacharlie.NewHiveClient(org)\n    rules, _ := hiveClient.List(limacharlie.HiveArgs{\n        HiveName:     \"dr-general\",\n        PartitionKey:  org.GetOID(),\n    })\n    for rule_name, _ := range rules {\n        fmt.Println(rule_name)\n    }\n\n    // Add D&amp;R rule to Hive\n    enabled := true\n    case_sensitive := false\n    if _, err := hiveClient.Add(limacharlie.HiveArgs{\n        HiveName:     \"dr-general\",\n        PartitionKey: org.GetOID(),\n        Key:          \"test_rule_name\",\n        Enabled:      &amp;enabled,\n        Data: limacharlie.Dict{\n            \"detect\": limacharlie.Dict{\n                \"event\":            \"NEW_PROCESS\",\n                \"op\":               \"is\",\n                \"path\":             \"event/COMMAND_LINE\",\n                \"value\":            \"whoami\",\n                \"case sensitive\":   &amp;case_sensitive,\n            },\n            \"respond\": []limacharlie.Dict{{\n                \"action\": \"report\",\n                \"name\":   \"whoami detection\",\n            }},\n        },\n    }); err != nil {\n        fmt.Println(err)\n    }\n\n    // List extensions\n    extensions, _ := org.Extensions()\n    for _, extension_name := range extensions {\n        fmt.Println(extension_name)\n    }\n\n    // Subscribe to extension\n    subscription_request := org.SubscribeToExtension(\"binlib\")\n    if subscription_request != nil {\n        fmt.Println(subscription_request)\n    }\n\n    // List payloads\n    payloads, _ := org.Payloads()\n    for payload, _ := range payloads {\n        fmt.Println(payload)\n    }\n\n    // List installation keys\n    installation_keys, _ := org.InstallationKeys()\n    for _, key := range installation_keys {\n        fmt.Println(key.Description)\n    }\n\n    // Create installation key\n    key_request, _ := org.AddInstallationKey(InstallationKey{\n        Description: \"my-test-key\",\n        Tags:        []string{\"tag\", \"another-tag\"},\n    })\n\n}\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#python","title":"Python","text":"<p>The Python library is a simple abstraction to the LimaCharlie.io REST API. The REST API currently supports many more functions. If it's missing a function available in the REST API that you would like to use, let us know at support@limacharlie.io.</p> <ul> <li>Repo - https://github.com/refractionpoint/python-limacharlie</li> </ul>"},{"location":"6-developer-guide/sdk-overview/#getting-started","title":"Getting Started","text":""},{"location":"6-developer-guide/sdk-overview/#installing","title":"Installing","text":""},{"location":"6-developer-guide/sdk-overview/#pypi-pip","title":"PyPi (pip)","text":"<p>The library and the CLI is available as a Python package on PyPi (https://pypi.org/project/limacharlie/). It can be installed using pip as shown below.</p> <pre><code>pip install limacharlie\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#docker-image","title":"Docker Image","text":"<p>In addition to the PyPi distribution we also offer a pre-built Docker image on DockerHub (https://hub.docker.com/r/refractionpoint/limacharlie).</p> <pre><code>docker run refractionpoint/limacharlie:latest whoami\n\n# Using a specific version (Docker image tag matches the library version)\ndocker run refractionpoint/limacharlie:4.9.13 whoami\n\n# If you already have a credential file locally, you can mount it inside the Docker container\ndocker run -v ${HOME}/.limacharlie:/root/.limacharlie:ro refractionpoint/limacharlie:latest whoami\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#credentials","title":"Credentials","text":"<p>Authenticating to use the SDK / CLI can be done in a few ways.</p> <p>Option 1 - Logging In  The simplest is to login to an Organization using an API key.</p> <p>Use <code>limacharlie login</code> to store credentials locally. You will need an <code>OID</code> (Organization ID) and an API key, and (optionally) a <code>UID</code> (User ID), all of which you can get from the Access Management \u2192 REST API section of the web interface.</p> <p>The login interface supports named environments, or a default one used when no environment is selected.</p> <p>To list available environments:</p> <pre><code>limacharlie use\n</code></pre> <p>Setting a given environment in the current shell session can be done like this:</p> <pre><code>limacharlie use my-dev-org\n</code></pre> <p>You can also specify a <code>UID</code> (User ID) during login to use a user API key representing  the total set of permissions that user has (see User Profile in the web interface).</p> <p>Option 2 - Environment Variables  You can use the <code>LC_OID</code> and <code>LC_API_KEY</code> and <code>LC_UID</code> environment variables to replace the values used logging in. The environment variables will be used if no other credentials are specified.</p>"},{"location":"6-developer-guide/sdk-overview/#sdk_1","title":"SDK","text":"<p>The root of the functionality in the SDK is from the <code>Manager</code> object. It holds the credentials and is tied to a specific LimaCharlie Organization.</p> <p>You can authenticate the <code>Manager</code> using an <code>oid</code> (and optionally a <code>uid</code>), along with either a <code>secret_api_key</code> or <code>jwt</code> directly. Alternatively you can just use an environment name (as specified in <code>limacharlie login</code>). If no creds are provided, the <code>Manager</code> will try to use the default environment and credentials.</p>"},{"location":"6-developer-guide/sdk-overview/#importing","title":"Importing","text":"<pre><code>import limacharlie\n\nYARA_SIG = 'https://raw.githubusercontent.com/Yara-Rules/rules/master/Malicious_Documents/Maldoc_PDF.yar'\n\n# Create an instance of the SDK.\nmgr = limacharlie.Manager()\n\n# Get a list of all the sensors in the current Organization.\nall_sensors = mgr.sensors()\n\n# Select the first sensor in the list.\nsensor = all_sensors[0]\n\n# Tag this sensor with a tag for 10 minutes.\nsensor.tag( 'suspicious', ttl = 60 * 10 )\n\n# Send a task to the sensor (unidirectionally, not expecting a response).\nsensor.task( 'os_processes' )\n\n# Send a yara scan to that sensor for processes \"evil.exe\".\nsensor.task( 'yara_scan -e *evil.exe ' + YARA_SIG )\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#use-of-gevent","title":"Use of gevent","text":"<p>Note that the SDK uses the <code>gevent</code> package which sometimes has issues with other  packages that operate at a low level in python. For example, Jupyter notebooks  may see freezing on importing <code>limacharlie</code> and require a tweak to load:</p> <pre><code>{\n \"display_name\": \"IPython 2 w/gevent\",\n \"language\": \"python\",\n \"argv\": [\n  \"python\",\n  \"-c\", \"from gevent.monkey import patch_all; patch_all(thread=False); from ipykernel.kernelapp import main; main()\",\n  \"-f\",\n  \"{connection_file}\"\n ]\n}\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#components","title":"Components","text":""},{"location":"6-developer-guide/sdk-overview/#manager","title":"Manager","text":"<p>This is a the general component that provides access to the managing functions of the API like querying sensors online, creating and removing Outputs etc.</p>"},{"location":"6-developer-guide/sdk-overview/#firehose","title":"Firehose","text":"<p>The <code>Firehose</code> is a simple object that listens on a port for LimaCharlie.io data. Under the hood it creates a Syslog Output on limacharlie.io pointing to itself and removes it on shutdown. Data from limacharlie.io is added to <code>firehose.queue</code> (a <code>gevent Queue</code>) as it is received.</p> <p>It is a basic building block of automation for limacharlie.io.</p>"},{"location":"6-developer-guide/sdk-overview/#spout","title":"Spout","text":"<p>Much like the <code>Firehose</code>, the Spout receives data from LimaCharlie.io, the difference  is that the <code>Spout</code> does not require opening a local port to listen actively on. Instead  it leverages <code>stream.limacharlie.io</code> to receive the data stream over HTTPS.</p> <p>A <code>Spout</code> is automatically created when you instantiate a <code>Manager</code> with the <code>is_interactive = True</code> and <code>inv_id = XXXX</code> arguments in order to provide real-time  feedback from tasking sensors.</p>"},{"location":"6-developer-guide/sdk-overview/#sensor","title":"Sensor","text":"<p>This is the object returned by <code>manager.sensor( sensor_id )</code>.</p> <p>It supports a <code>task</code>, <code>hostname</code>, <code>tag</code>, <code>untag</code>, <code>getTags</code> and more functions. This  is the main way to interact with a specific sensor.</p> <p>The <code>task</code> function sends a task to the sensor unidirectionally, meaning it does not  receive the response from the sensor (if any). If you want to interact with a sensor  in real-time, use the interactive mode (as mentioned in the <code>Spout</code>) and use either  the <code>request</code> function to receive replies through a <code>FutureResults</code> object or the <code>simpleRequest</code> to wait for the response and receive it as a return value.</p>"},{"location":"6-developer-guide/sdk-overview/#artifacts","title":"Artifacts","text":"<p>The <code>Artifacts</code> is a helpful class to upload artifacts to LimaCharlie without going through a sensor.</p>"},{"location":"6-developer-guide/sdk-overview/#extensions","title":"Extensions","text":"<p>The <code>Extensions</code> can be used to subscribe to and manage extensions within your org.</p> <pre><code>import limacharlie\nfrom limacharlie import Extension\n\nmgr = limacharlie.Manager()\next = Extension(mgr)\next.subscribe('binlib')\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#payloads","title":"Payloads","text":"<p>The <code>Payloads</code> can be used to manage various executable payloads accessible to sensors.</p>"},{"location":"6-developer-guide/sdk-overview/#replay","title":"Replay","text":"<p>The <code>Replay</code> object allows you to interact with Replay jobs managed by LimaCharlie. These allow you to re-run D&amp;R Rules on historical data.</p> <p>Sample command line to query one sensor:</p> <pre><code>limacharlie-replay --sid 9cbed57a-6d6a-4af0-b881-803a99b177d9 --start 1556568500 --end 1556568600 --rule-content ./test_rule.txt\n</code></pre> <p>Sample command line to query an entire organization:</p> <pre><code>limacharlie-replay --entire-org --start 1555359000 --end 1556568600 --rule-name my-rule-name\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#search","title":"Search","text":"<p>The <code>Search</code> object allows you to perform an IOC search across multiple organizations.</p>"},{"location":"6-developer-guide/sdk-overview/#spotcheck","title":"SpotCheck","text":"<p>The <code>SpotCheck</code> object (sometimes called Fleet Check) allows you to manage an active (query sensors directly as opposed to searching on indexed historical data) search for various IOCs on an organization's sensors.</p>"},{"location":"6-developer-guide/sdk-overview/#configs","title":"Configs","text":"<p>The <code>Configs</code> is used to retrieve an organization's configuration as a config file, or apply  an existing config file to an organization. This is the concept of Infrastructure as Code.</p>"},{"location":"6-developer-guide/sdk-overview/#webhook","title":"Webhook","text":"<p>The <code>Webhook</code> object demonstrates handling webhooks emitted by the LimaCharlie cloud, including verifying the shared-secret signing of the webhooks.</p>"},{"location":"6-developer-guide/sdk-overview/#examples_1","title":"Examples:","text":"<ul> <li>Basic Manager Operations</li> <li>Basic Firehose Operations</li> <li>Basic Spout Operations</li> <li>Basic Integrated Operations</li> <li>Sample Configs</li> </ul>"},{"location":"6-developer-guide/sdk-overview/#command-line-interface","title":"Command Line Interface","text":"<p>Many of the objects available as part of the LimaCharlie Python SDK also support various command line interfaces.</p>"},{"location":"6-developer-guide/sdk-overview/#query","title":"Query","text":"<p>LimaCharlie Query Language (LCQL) provides a flexible, intuitive and interactive way to explore your data in LimaCharlie.</p> <pre><code>limacharlie query --help\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#arls","title":"ARLs","text":"<p>Authenticated Resource Locators (ARLs) describe a way to specify access to a remote resource, supporting many methods, including authentication data, and all that within a single string.</p> <p>ARLs can be used in the YARA manager to import rules from GitHub repositories and other locations.</p> <p>Testing an ARL before applying it somewhere can be helpful to shake out access or authentication errors beforehand. You can test an ARL and see what files are fetched, and their contents, by running the following command:</p> <pre><code>limacharlie get-arl -a [github,Yara-Rules/rules/email]\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#firehose_1","title":"Firehose","text":"<p>Listens on interface <code>1.2.3.4</code>, port <code>9424</code> for incoming connections from LimaCharlie.io.  Receives only events from hosts tagged with <code>fh_test</code>.</p> <pre><code>python -m limacharlie.Firehose 1.2.3.4:9424 event -n firehose_test -t fh_test --oid c82e5c17-d519-4ef5-a4ac-caa4a95d31ca\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#spout_1","title":"Spout","text":"<p>Behaves similarly to the Firehose, but instead of listening from an internet accessible port, it connects to the <code>stream.limacharlie.io</code> service to stream the output over HTTPS. This means the Spout allows you to get ad-hoc output like the Firehose, but it also works through NATs and proxies.</p> <p>It is MUCH more convenient for short term ad-hoc outputs, but it is less reliable than a Firehose for very large amounts of data.</p> <pre><code>python -m limacharlie.Spout event --oid c82e5c17-d519-4ef5-a4ac-caa4a95d31ca\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#configs_1","title":"Configs","text":"<p>The <code>fetch</code> command will get a list of the Detection &amp; Response rules in your  organization and will write them to the config file specified or the default  config file <code>lc_conf.yaml</code> in YAML format.</p> <pre><code>limacharlie configs fetch --oid c82e5c17-d519-4ef5-a4ac-c454a95d31ca`\n</code></pre> <p>Then <code>push</code> can upload the rules specified in the config file (or the default one)  to your organization. The optional <code>--force</code> argument will remove active rules not  found in the config file. The <code>--dry-run</code> simulates the sync and displays the changes  that would occur.</p> <p>The <code>--config</code> allows you to specify an alternate config file and the <code>--api-key</code> allows  you to specify a file on disk where the API should be read from (otherwise, of if <code>-</code> is  specified as a file, the API Key is read from STDIN).</p> <pre><code>limacharlie configs push --dry-run --oid c82e5c17-d519-4ef5-a4ac-c454a95d31ca --config /path/to/template.yaml --all --ignore-inaccessible\n</code></pre> <p>All these capabilities are also supported directly by the <code>limacharlie.Configs</code> object.</p> <p>The Sync functionality currently supports all common useful configurations. The <code>--no-rules</code> and <code>--no-outputs</code> flags can be used to ignore one or the other in config files and sync. Additional flags are also supported, see <code>limacharlie configs --help</code>.</p> <p>To understand better the config format, do a <code>fetch</code> from your organization. Notice the use of the <code>include</code>  statement. Using this statement you can combine multiple config files together, making  it ideal for the management of complex rule sets and their versioning.</p>"},{"location":"6-developer-guide/sdk-overview/#spot-checks","title":"Spot Checks","text":"<p>Used to perform Organization-wide checks for specific indicators of compromise. Available as a custom API <code>SpotCheck</code> object or as a module from the command line. Supports many types of IoCs like file names, directories, registry keys, file hashes and YARA signatures.</p> <pre><code>python -m limacharlie.SpotCheck --no-macos --no-linux --tags vip --file c:\\\\evil.exe`\n</code></pre> <p>For detailed usage:</p> <pre><code>python -m limacharlie.SpotCheck --help\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#search_1","title":"Search","text":"<p>Shortcut utility to perform IOC searches across all locally configured organizations.</p> <pre><code>limacharlie search --help\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#extensions_1","title":"Extensions","text":"<p>Shortcut utility to manage extensions.</p> <pre><code>limacharlie extension --help\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#artifact-upload","title":"Artifact Upload","text":"<p>Shortcut utility to upload and retrieve Artifacts within LimaCharlie with just the CLI (no agent).</p> <pre><code>limacharlie artifacts --help\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#artifact-download","title":"Artifact Download","text":"<p>Shortcut utility to download Artifact Collection in LimaCharlie locally.</p> <pre><code>limacharlie artifacts get_original --help\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#replay_1","title":"Replay","text":"<p>Shortcut utility to perform Replay jobs from the CLI.</p> <pre><code>limacharlie replay --help\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#detection-response","title":"Detection &amp; Response","text":"<p>Shortcut utility to manage Detection and Response rules over the CLI.</p> <pre><code>limacharlie dr --help\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#events-detections","title":"Events &amp; Detections","text":"<p>Print out to STDOUT events or detections matching the parameter.</p> <pre><code>limacharlie events --help\nlimacharlie detections --help\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#list-sensors","title":"List Sensors","text":"<p>Print out all basic sensor information for all sensors matching the selector.</p> <pre><code>limacharlie sensors --selector 'plat == windows'\n</code></pre>"},{"location":"6-developer-guide/sdk-overview/#invite-users","title":"Invite Users","text":"<p>Invite single or multiple users to LimaCharlie. Invited users will be sent an email to confirm their address, enable the account and create a new password.</p> <p>Keep in mind that this actions operates in the user context which means you need to use user scoped API key. For more information on how to obtain one, see https://api.limacharlie.io/static/swagger/#getting-a-jwt</p> <p>Invite a single user:</p> <pre><code>limacharlie users invite --email=user1@example.com\n</code></pre> <p>Invite multiple users:</p> <pre><code>limacharlie users invite --email=user1@example.com,user2@example.com,user3@example.com\n</code></pre> <p>Invite multiple users from new line delimited entries in a text file:</p> <pre><code>cat users_to_invite.txt\nuser1@example.com\nuser2@example.com\nuser3@example.com\n</code></pre> <pre><code>limacharlie users invite --file=users_to_invite.txt\n</code></pre>"},{"location":"6-developer-guide/extensions/building-extensions/","title":"Building Extensions","text":"<p>This section is a work in progress</p> <p>Feel free to reach out to us on our Community Slack if you'd like to learn more</p>"},{"location":"6-developer-guide/extensions/building-extensions/#why-extensions","title":"Why Extensions?","text":"<p>Building functionality as a LimaCharlie Extension provides you specific convenience:</p> <ul> <li>Multi-tenancy: LC organizations can subscribe to your extension and you can replicate the features you're building across tenants.</li> <li>Credentials handling: you don't need to store any credentials from LC organizations. Every callback you receive will include an authenticated LimaCharlie SDK for the Organization relevant to the callback, with the permissions you requesed for the extension.</li> <li>Configuration: you're always welcome to store some configuration wherever the extension lives, but as a convenience LC will provide you with a configuration JSON object for your extension (stored in Hive) and with a callback for you to validate the content of the configuration when a user makes a modification.</li> <li>GUI: each extension defines its own Schema, a structure indicating to LimaCharlie what actions the extension exposes, how to call it and what to expect as a return value from actions. This information is then automatically interpreted by LimaCharlie to generate a custom user interface for your extension, making it extremely easy to expose new functionality in LimaCharlie without having to build any kind of UI (though you're always free to build one if you'd like).</li> </ul>"},{"location":"6-developer-guide/extensions/building-extensions/#publicprivate-limitations","title":"Public/Private Limitations","text":"<p>Anyone can build Extensions for LimaCharlie. The only limit is put on making an Extension public. Private extensions require the owner of the extension to have the <code>billing.ctrl</code> and <code>user.ctrl</code> permission on an organization in order to subscribe the organization to the private extension.</p>"},{"location":"6-developer-guide/extensions/building-extensions/#want-to-take-your-extension-public","title":"Want to take your Extension public?","text":"<p>If you'd like to make your extension public (and/or monetize it), reach out to <code>answers@limacharlie.io</code> and we'll help you out. Once public, an extension is visible by everyone and can subscribed by everyone.</p>"},{"location":"6-developer-guide/extensions/building-extensions/#high-level-structure","title":"High Level Structure","text":"<p>Extensions are small services that receive webhooks from LimaCharlie. This means building an extension requires exposing a small HTTPS service to the internet. We recommend using something like Google Cloud Run, but ultimately you could also use AWS Lambdas or even host on your own hardware.</p> <p>This https server will communicate with the LimaCharlie cloud according to a simple protocol using JSON.</p> <p>That being said, don't worry, you don't need to know the underlying way the extension protocol works as long as you're comfortable with our public implementations.</p>"},{"location":"6-developer-guide/extensions/building-extensions/#getting-started","title":"Getting Started","text":"<p>Want to get your hands on an example? We recommend using one of the following frameworks to get started.</p> <ul> <li>Golang: https://github.com/refractionPOINT/lc-extension</li> <li>Python: https://github.com/refractionPOINT/lc-extension/tree/master/python</li> </ul> <p>For a more step-by-step overview, let's dig into some of the core concepts of building an extension. We will reference Golang since it provides stricter typing, but conceptually it's the same across implementations.</p>"},{"location":"6-developer-guide/extensions/building-extensions/#extension-definition","title":"Extension Definition","text":"<p>To create an extension, start by creating a definition - accessible through the web interface for your personal add-ons.</p> <p>The required aspects of your definition are as follows:</p> <ul> <li>Destination URL: this is the HTTPS URL where your extension will be reachable at.</li> <li>Required Extensions: this is the list of other extensions your extension assumes it will have access to. When an org subscribes and is missing one of those, the user will be prompted to subscribe to these.</li> <li>Shared Secret: this is an arbitrary string that will be used by LimaCharlie and your extension to sign webhooks to your extension, allowing it to very the authenticity of the hook. Make it something at least 32 characters and random.</li> <li>Extension Flairs: these are modifiers that will be applied to your extension. Namely the <code>segment</code> flair will isolate the resources the extension can access so that it can only see and modify things (like  rules) that it has created, making it great for extensions that need a narrow scope, you should enable it unless you know you need it off. The <code>bulk</code> flair tells LimaCharlie that it expects to make a lot of API calls to the LC cloud, which will increase the API quota for the extension.</li> <li>Permissions: the list of permissions this extension requires on each organization subscribed to it. Use the least amount of permissions possible.</li> </ul>"},{"location":"6-developer-guide/extensions/building-extensions/#schema","title":"Schema","text":"<p>The Extension Schema is the next important piece of building your extension. It describes what your extension can do and helps define the GUI.</p> <p>Here's an example high-level structure of a schema.</p> <pre><code>{\n  \"config_schema\": {\n    \"fields\": { ... }\n    \"requirements\": null\n  },\n  \"request_schema\": {\n    // defines two custom requests, 'dir_list' and 'refresh'\n    \"dir_list\": {\n      \"is_impersonated\": false,\n      \"is_user_facing\": false,\n      \"long_description\": \"directory listing\",\n      \"parameters\": {\n        \"fields\": { ... },\n        \"requirements\": null\n      },\n      \"short_description\": \"directory listing\"\n    },\n    \"refresh\": {\n      \"is_impersonated\": false,\n      \"is_user_facing\": true,\n      \"long_description\": \"refresh data\",\n      \"parameters\": {\n        \"fields\": { ... },\n        \"requirements\": null\n      },\n      \"short_description\": \"refresh data\"\n    },\n  },\n  \"required_events\": [\n    \"subscribe\",\n    \"unsubscribe\"\n  ]\n}\n</code></pre> <p>The Field Configuration  Notice that for both the <code>config_schema</code> and the <code>request_schema</code> there is a recurring object structure that looks like the following:</p> <pre><code>\"fields\": { .. }, // key-value pair\n\"requirements\": [[]],\n</code></pre> <p>While hidden in the example above, each <code>field</code> key-value pair shares the same structure and has a minimal implementation as such:</p> <pre><code>field_name: {\n  data_type: \"string\",\n  description: \"\",\n},\n</code></pre> <p>The <code>requirements</code> field references the field keys to define whether or not certain fields individually or as a set are required. You can think of the first array to join elements with an AND, while the nested array serves as an OR.  For example:</p> <ul> <li><code>[['denominator'], ['numerator']]</code> means:    (denominator AND numerator),</li> <li><code>[['denominator'], ['numerator', 'default']]</code> means:    (denominator AND ( one of numerator OR default)).</li> </ul> <p>When getting started, we recommend utilizing the simplest data type applicable. This will enable you to get a grasp of the whole extensions framework and allow you to quickly test our your service. Such as <code>string</code>, <code>boolean</code>, <code>json</code>, etc.</p> <p>Afterwards, we recommend you define the data_type and other optional fields further, so that the UI may adapt to your defined data types. For more details, please see the page on data types or review the code definitions here.</p>"},{"location":"6-developer-guide/extensions/building-extensions/#config-schema-optional","title":"Config Schema (optional)","text":"<p>The config schema is a description of what the extension's config should look like, when stored as a Hive record in the <code>extension_configuration</code> Hive for convenience.</p> <p>Not all extensions will have a configuration, feel free to reach out on the community slack if you need help determining whether or not your extension needs a configuration.</p> <p>At the core, the config schema is simply a list of fields.</p>"},{"location":"6-developer-guide/extensions/building-extensions/#request-schema","title":"Request Schema","text":"<p>Every Request Schema exists as a key value pair of the request name, and a corresponding schema contents. The critical contents include the following fields:</p> <ul> <li>is_impersonated: Whether or not the request impersonates the user through it's authentication</li> <li>is_user_facing: Whether or not this request should be visisble to the user in the UI. It does not prevent this request from bieng used through the API or as a <code>supported_action</code> (more on that later).</li> <li>parameters: This contains the data_type and other fields (recall the same fields format as the config schema)</li> </ul> <p>Other optional fields exist to facilitate the user experience, such as:</p> <ul> <li>short_description</li> <li>long_description</li> <li>messages: Includes 3 nested fields, <code>in_progress</code>, <code>success</code>, <code>error</code> to provide additional context for each case.</li> </ul>"},{"location":"6-developer-guide/extensions/building-extensions/#response-schema-optional","title":"Response Schema (optional)","text":"<p>Each request schema may optionally contain a response schema in the same fields format as a config schema and the request parameters.</p> <p>When getting started, we recommend that you skip this until you are ready to refine the extension's GUI, or you wish to clarify that kind of response a user should expect.</p>"},{"location":"6-developer-guide/extensions/building-extensions/#callbacks","title":"Callbacks","text":"<p>Callbacks are functionality that an extension can specify whenever some type of event occurs.</p>"},{"location":"6-developer-guide/extensions/building-extensions/#configuration-validation-callback","title":"Configuration Validation Callback","text":"<p>This callback is used by LimaCharlie to check the validity of a change in configuration done in Hive. If the configuration is valid, return success, otherwise you can return an error.</p>"},{"location":"6-developer-guide/extensions/building-extensions/#event-callback","title":"Event Callback","text":"<p>Events are events generated by the LimaCharlie platform outside your control. Currently, these 3 events are supported:</p> <ul> <li>subscribe: called when an organization subscribes to an extension.</li> <li>unsubscribe: called when an organization unsubscribes from an extension.</li> <li>update: called once a day per organization subscribed to the extension. It is a convenient way to perform updates to an organization like when needing to update D&amp;R rules used by the extension.</li> </ul> <p>Your extension will only receive these events if they were specified as of-interest in the extension's Schema.</p>"},{"location":"6-developer-guide/extensions/building-extensions/#request-callback","title":"Request Callback","text":"<p>The requests are the core way users, D&amp;R rules or other extensions can interact with your extension. You can define one callback per <code>action</code>. It is common for an extension to have multiple actions, some public (for user-generated requests) and some private (to be used internally by the extension in the course of doing whatever it does).</p>"},{"location":"6-developer-guide/extensions/building-extensions/#simplified-frameworks","title":"Simplified Frameworks","text":"<p>The Golang implementation of Extensions provides 3 different simplified frameworks to make the job of producing a new extension more straight forward in specific cases: https://github.com/refractionPOINT/lc-extension/tree/master/simplified</p>"},{"location":"6-developer-guide/extensions/building-extensions/#dr","title":"D&amp;R","text":"<p>This simplified framework, found in <code>dr.go</code> allows you to package D&amp;R rules as an extension making it easy for you to distribute and update D&amp;R rules to many orgs. Its core mechanism is based on defining the <code>GetRules()</code> function and returning a structure like <code>map[DR-Namespace]map[RuleName]RuleContent</code>. The simplified framework takes care of the recurring updates and everything else.</p>"},{"location":"6-developer-guide/extensions/building-extensions/#lookup","title":"Lookup","text":"<p>Similarl to the D&amp;R simplified framework, but is used to package Lookups. Example: https://github.com/refractionPOINT/lc-extension/blob/master/examples/lookup/main.go</p>"},{"location":"6-developer-guide/extensions/building-extensions/#cli","title":"CLI","text":"<p>This simplified framework serves to streamline the integration of 3<sup>rd</sup> party Command Line Interface tools so that they can be automated using LimaCharlie, often bringing bi-directionality to the platform.</p> <p>LimaCharlie Extensions allow users to expand and customize their security environments by integrating third-party tools, automating workflows, and adding new capabilities. Organizations subscribe to Extensions, which are granted specific permissions to interact with their infrastructure. Extensions can be private or public, enabling tailored use or broader community sharing. This framework supports scalability, flexibility, and secure, repeatable deployments.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p>"},{"location":"6-developer-guide/extensions/building-ui/","title":"Building the User Interface","text":""},{"location":"6-developer-guide/extensions/building-ui/#auto-generated-ui","title":"Auto Generated UI","text":"<p>The Extensions UI uses the information provided in the schema to auto-determine it's UI elements, and for most simple extensions, the UI will be able to auto conform based on the bare minimum schema definition alone. However, further customization may be made in the schema for more complex or specific use cases by adjusting the layout, or adjusting the details for a specific field.</p>"},{"location":"6-developer-guide/extensions/building-ui/#deconstructing-the-page","title":"Deconstructing the Page","text":"<p>Generally the top of the extension page will show the extension label and it's short description. If it exists, it will also show a button for quick access to this extension's \"associated sensor\".</p> <p></p> <p>In the top right, any actions (as defined in your request schema) will be displayed as a dropdown and button. </p> <p>Note that there are small changes to this structure depending on the layout selected, however all variations should be intuitive as they do not deviate much from this general page structure.  Beyond this, main content of the page is determined by the layout.</p>"},{"location":"6-developer-guide/extensions/building-ui/#picking-your-layout-type","title":"Picking Your Layout Type","text":"<ul> <li><code>auto</code> (default layout, it will pick one of the below)</li> <li><code>config</code> (use this if you have a configuration)</li> <li><code>editor</code> (very specific use-case for editing large code blocks like yaml)</li> <li><code>action</code> (use this to prioritize certain actions in the UI)</li> <li><code>description</code></li> <li><code>key</code> (just a variation of description)</li> </ul> <p>For the action, and editor layouts, make sure you define one (or more) default actions as well. The editor UI for the action layout will show all the actions in-page, as opposed to a button on the top right. When set to the editor layout, the UI will automatically run the default action and display the results and a supported action.</p>"},{"location":"6-developer-guide/extensions/building-ui/#form-data-types","title":"Form Data Types","text":"<p>Every field has the following optional details to further adjust the UI.</p> <ul> <li>label: Add a label if you want a more 'human-legible' label on this field</li> <li>placeholder: Placeholder text on the input can serve as an example for the user</li> <li>description: A description for this field can be added that will be available as a tooltip on the UI next to the field label</li> <li>display_index: The display index starts at 1 (not 0) and guides the GUI on the order to show the fields. A display index of 1, will display before a display index of 2.</li> <li>default_value: A default value for the field, will auto-populate the field with this value</li> </ul> <p>Some other configurations that conditionally apply to specific data_types:</p> <ul> <li>filter: Available on select primitive data_types.</li> <li>enum_values: Details on the available enums, to support the enum data type.</li> <li>complex_enum_values: Details to support the complex enum data type. Supports reference links, and categories.</li> <li>object: An object that contains nested key-value pairs for more fields, and serves to detail the nested fields.</li> </ul> <p>For the complete list of all data types, please see the page on data types.</p>"},{"location":"6-developer-guide/extensions/building-ui/#nuanced-usage","title":"Nuanced Usage","text":"<p>If your extension requires it, there are more opportunities to adjust the UI in order to better guide or facilitate a user on using your extension.</p>"},{"location":"6-developer-guide/extensions/building-ui/#multiple-layouts-as-tabs","title":"Multiple Layouts as Tabs","text":"<p>In the schema, it is possible to define several views to utilize a combination of layout types. This may be useful in order to guide a user on how you want them to use your extension. </p>"},{"location":"6-developer-guide/extensions/building-ui/#setting-supported-actions","title":"Setting Supported Actions","text":"<p>Functionality for this field is set to be expanded in the future</p> <p>Please feel free to reach out to us on our community slack if you'd like to stay up to date on</p> <p>Supported actions are tied to a request's (also called \"actions\") response. It allows the response data to be modified and passed along to a follow-up action. This may be useful when operating a dry run, or triggering a workflow.</p>"},{"location":"6-developer-guide/extensions/schema-data-types/","title":"Schema Data Types","text":""},{"location":"6-developer-guide/extensions/schema-data-types/#all-data-types","title":"All Data Types","text":"<p>The data types in your schema can be further subdivided into three categories. Primitives, Code Blocks, and Objects (including tables). These data types allow for a cleaner UI and a more intuitive schema.</p> <p>For a direct code reference, check out the type definition here.</p>"},{"location":"6-developer-guide/extensions/schema-data-types/#before-you-start","title":"Before you Start","text":"<p>When getting started, we recommend utilizing the simplest data type applicable for each field in your schema as to enable quick and reliable testing of your service.</p>"},{"location":"6-developer-guide/extensions/schema-data-types/#primitives","title":"Primitives","text":"<p>The following is the list of primitive values. Note that the following fields are also affected by filters:</p> <ul> <li>number, time and date types are affected by <code>min</code> and <code>max</code></li> <li>events and string types are affected by <code>whitelist</code> and <code>blacklist</code></li> <li>only string types are affected by <code>valid_re</code> and <code>invalid_re</code> (regex)</li> <li>SID types (and maybe platforms) are affected by <code>platforms</code> filters</li> </ul> <p>Oops, some fields may be missing support for filters</p> <p>Please reach out if any of the above use-cases don't work as you might expect.</p> name description string integer bool enum Requires the field <code>enum_values</code> complex_enum a complex enum allows for a more detailed enum selection, including categories and description. Requires the field <code>complex_enum_values</code> sid your Organization's sensor ids oid your Organization's ID platform architecture sensor_selector tag duration time url domain yara_rule_name Will show your Organization's list of yara rules available, if the user has permission event_name secret Will show your Organization's list of secrets as per the secrets manager"},{"location":"6-developer-guide/extensions/schema-data-types/#code-blocks","title":"Code Blocks","text":"<p>There are currently 3 code types available:</p> <ol> <li>JSON</li> <li>YAML</li> <li>Yara_rule</li> </ol> <p>Yara Rule UI Support is limited</p> <p>Code blocks do not support the field <code>is_list</code>. If your extensions require a set of code blocks, we reocmmend wrapping it into key-value pair using the 'record' data type (see 'objects' section below).</p>"},{"location":"6-developer-guide/extensions/schema-data-types/#objects-and-tables","title":"Objects (and tables)","text":"<p>While objects generally reflect a nested layer of abstraction, it's utility grows when using the field <code>is_list</code> to utilize the tables UI, or when defining a set of key-value pairs in the 'record' data type.</p> <p>Note: there is a functional difference between an 'object' and 'record' data type.</p> <p>Single Objects  Plain objects allow for nested fields, and are visually indifferent from if the nested fields were flattened to begin with. They also allow for extra context to be wrapped in the parent object's description.</p> <pre><code>table: {\n  is_list: false,\n  data_type: \"object\",\n  object: {\n    fields: { ... }, // key-value pairs\n    requirements: null\n  }\n}\n</code></pre> <p>Lists of Objects  Lists of objects display as tables and allow for a more complex and scalable data structure. Simply enable <code>is_list</code> on a base object.</p> <pre><code>table: {\n  is_list: true,\n  data_type: \"object\",\n  object: {\n    fields: { ... }, // key-value pairs\n    requirements: null\n  }\n}\n</code></pre> <p>Record Type  Records are inherently lists of a key-value pair, where the value is the defined object, and the key may vary. Record types require a key to be defined in the nested object details, and also supports additional fields for the nested element's name and description.</p> <pre><code>table: {\n  is_list: true,\n  data_type: \"object\",\n  object: {\n    key: {\n      name: \"key\",\n      data_type: \"string\"\n    },\n    element_name: \"single row\", // optional\n    element_desc: \"a single row that represents a key-value pair on a record type\", // optional\n\n    fields: { ... }, // key-value pairs\n    requirements: null\n  }\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/","title":"SDK Documentation","text":"<p>Programmatic access to LimaCharlie via official SDKs.</p>"},{"location":"6-developer-guide/sdks/#overview","title":"Overview","text":"<p>LimaCharlie provides official SDKs for Go and Python, enabling complete programmatic control of the platform:</p> <ul> <li>Sensor management and tasking</li> <li>Detection rule deployment</li> <li>Artifact collection and export</li> <li>Organization administration</li> <li>Real-time event streaming</li> </ul>"},{"location":"6-developer-guide/sdks/#available-sdks","title":"Available SDKs","text":""},{"location":"6-developer-guide/sdks/#go-sdk","title":"Go SDK","text":"<p>The Go SDK provides a comprehensive client library for building security automation, integrations, and custom tools.</p> <p>Installation: <pre><code>go get github.com/refractionPOINT/go-limacharlie/limacharlie\n</code></pre></p> <p>Key Features: - Type-safe API client - Sensor management - Detection &amp; Response rule management - Artifact collection - Real-time event streaming (Firehose) - Organization administration</p>"},{"location":"6-developer-guide/sdks/#python-sdk","title":"Python SDK","text":"<p>The Python SDK offers a full-featured interface perfect for security automation, data analysis, and rapid prototyping.</p> <p>Installation: <pre><code>pip install limacharlie\n</code></pre></p> <p>Key Features: - Manager class for all platform operations - Sensor tasking and management - Real-time streaming (Firehose/Spout) - Detection rule management via Hive - LCQL query support - Artifact and payload management</p>"},{"location":"6-developer-guide/sdks/#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"6-developer-guide/sdks/#python","title":"Python","text":"<pre><code>import limacharlie\n\n# Initialize the manager\nmanager = limacharlie.Manager(\n    oid='your-org-id',\n    secret_api_key='your-api-key'\n)\n\n# List all online sensors\nsensors = manager.sensors()\nfor sensor in sensors:\n    if sensor.isOnline():\n        print(f\"Online: {sensor.sid}\")\n</code></pre>"},{"location":"6-developer-guide/sdks/#go","title":"Go","text":"<pre><code>import \"github.com/refractionPOINT/go-limacharlie/limacharlie\"\n\n// Initialize client\nclient := limacharlie.NewClientFromLoader(\n    limacharlie.ClientOptions{\n        OID:    \"your-org-id\",\n        APIKey: \"your-api-key\",\n    },\n)\n\n// List sensors\nsensors, err := client.GetSensors()\nif err != nil {\n    log.Fatal(err)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/#resources","title":"Resources","text":"<ul> <li>API Documentation</li> <li>GitHub - Go SDK</li> <li>GitHub - Python SDK</li> <li>Community Slack</li> </ul>"},{"location":"6-developer-guide/sdks/#authentication","title":"Authentication","text":"<p>Both SDKs support multiple authentication methods:</p> <ol> <li>API Key: Organization-level API key</li> <li>JWT: User-specific JWT tokens</li> <li>Environment Variables: Auto-load from <code>LC_OID</code> and <code>LC_API_KEY</code></li> </ol>"},{"location":"6-developer-guide/sdks/#support","title":"Support","text":"<p>For SDK-specific questions:</p> <ul> <li>File issues on the respective GitHub repositories</li> <li>Join the Community Slack</li> <li>Email support@limacharlie.io</li> </ul>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/","title":"Documentation Regeneration Recipe for LimaCharlie Go SDK","text":""},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#purpose","title":"Purpose","text":"<p>This recipe provides step-by-step instructions for an AI assistant (Claude Code or similar LLM) to regenerate the LimaCharlie Go SDK documentation when the SDK code changes.</p>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#prerequisites","title":"Prerequisites","text":"<ul> <li>Access to the LimaCharlie Go SDK repository: https://github.com/refractionPOINT/go-limacharlie/</li> <li>Access to the LimaCharlie API OpenAPI specification: https://api.limacharlie.io/openapi</li> <li>Access to existing LimaCharlie documentation (if available) in <code>limacharlie-docs-markdown</code> directory</li> </ul>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#regeneration-steps","title":"Regeneration Steps","text":""},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#step-1-analyze-current-sdk-structure","title":"Step 1: Analyze Current SDK Structure","text":"<pre><code>Task: Fetch and analyze the Go SDK repository at https://github.com/refractionPOINT/go-limacharlie/\n\nExtract:\n- Repository structure and organization\n- Main modules (limacharlie, firehose)\n- Package dependencies\n- Build and test configuration\n- README content for context\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#step-2-deep-dive-into-sdk-code","title":"Step 2: Deep Dive into SDK Code","text":"<pre><code>Task: Analyze the main SDK code in the limacharlie directory\n\nFocus on:\n1. Client struct and initialization methods\n   - Look for: NewClient*, ClientOptions, configuration loading\n\n2. Authentication mechanisms\n   - API key, JWT, UID support\n   - Configuration file formats (YAML)\n   - Environment variable usage\n\n3. Core functionality modules:\n   - Sensor management (sensor.go or similar)\n   - Detection rules (rules.go, dr_rules.go)\n   - Artifacts (artifacts.go)\n   - Organization management (org.go)\n   - Event streaming (webhook.go, events.go)\n\n4. Data structures and types\n   - All exported structs\n   - Enums and constants\n   - Error types\n\n5. Helper utilities\n   - HTTP client wrappers\n   - Retry logic\n   - Validation functions\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#step-3-analyze-api-integration","title":"Step 3: Analyze API Integration","text":"<pre><code>Task: Fetch the OpenAPI spec from https://api.limacharlie.io/openapi\n\nMap SDK methods to API endpoints:\n- Which endpoints does each SDK method call?\n- What are the request/response formats?\n- Authentication headers required\n- Rate limiting information\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#step-4-identify-code-patterns","title":"Step 4: Identify Code Patterns","text":"<pre><code>Task: Analyze the SDK for patterns and conventions\n\nLook for:\n- Error handling patterns\n- Logging approach (zerolog usage)\n- Concurrency patterns\n- Testing patterns\n- Configuration management\n- Resource cleanup patterns\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#step-5-generate-documentation-structure","title":"Step 5: Generate Documentation Structure","text":"<p>Create a comprehensive README.md with the following sections:</p> <pre><code># LimaCharlie Go SDK Documentation\n\n## Overview\n[Brief description of the SDK and its purpose]\n\n## Table of Contents\n- Installation\n- Authentication\n- Client Initialization\n- Core Components\n  - Sensor Management\n  - Detection Rules\n  - Artifacts\n  - Events and Data Streaming\n  - Organization Management\n- Data Structures\n- Error Handling\n- Advanced Features\n- Examples\n- Best Practices\n- Troubleshooting\n- API Endpoints Reference\n- SDK Versioning\n- Additional Resources\n\n## Installation\n[Current installation commands from go.mod]\n\n## Authentication\n[All authentication methods with code examples]\n- API Key Authentication\n- JWT Authentication\n- Configuration File\n- Environment Variables\n\n## Client Initialization\n[How to create and configure clients]\n\n## Core Components\n\n### Sensor Management\n[Complete coverage of sensor operations]\n- List, Get, Delete sensors\n- Isolation/Network control\n- Tagging\n- Tasking with examples\n\n### Detection Rules\n[Rule structure and management]\n- Rule format (YAML/JSON)\n- CRUD operations\n- Namespaces\n- TTL support\n\n### Artifacts\n[File and data artifact handling]\n- Upload methods\n- Export methods\n- GCS integration\n- Size limitations\n\n### Events and Data Streaming\n[Real-time and historical data]\n- Webhook configuration\n- Event types\n- Firehose module usage\n\n### Organization Management\n[Administrative operations]\n- Organization info\n- Quota management\n- User management\n- API key management\n\n## Data Structures\n[All exported types with field descriptions]\n\n## Error Handling\n[Common errors and handling patterns]\n\n## Advanced Features\n[Special capabilities like investigation context, concurrent operations]\n\n## Examples\n[Complete, runnable code examples for common use cases]\n- Basic sensor monitoring\n- Detection rule creation\n- Artifact collection\n- Batch operations\n- Error handling examples\n\n## Best Practices\n[Security, performance, and maintainability guidelines]\n\n## Troubleshooting\n[Common issues and solutions]\n\n## API Endpoints Reference\n[Table of endpoints used by SDK]\n\n## SDK Versioning\n[How to check and update versions]\n\n## Additional Resources\n[Links to repo, docs, support]\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#step-6-code-examples-requirements","title":"Step 6: Code Examples Requirements","text":"<p>For EACH major function/method in the SDK, provide:</p> <ol> <li> <p>Basic Usage Example <pre><code>// Clear, simple example showing the most common use case\n</code></pre></p> </li> <li> <p>Complete Example with Error Handling <pre><code>// Production-ready example with proper error handling\n</code></pre></p> </li> <li> <p>Advanced Usage (if applicable)    <pre><code>// Examples showing optional parameters, configuration options\n</code></pre></p> </li> </ol>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#step-7-llm-optimized-documentation","title":"Step 7: LLM-Optimized Documentation","text":"<p>Ensure the documentation is optimized for LLM consumption:</p> <ol> <li>Precise Type Information</li> <li>Include all struct fields with their types</li> <li>Show JSON tags for API serialization</li> <li> <p>Document optional vs required fields</p> </li> <li> <p>Method Signatures</p> </li> <li>Full function signatures with parameter and return types</li> <li>Document all parameters including optional ones</li> <li> <p>Explain return values and possible errors</p> </li> <li> <p>Import Statements</p> </li> <li>Always show complete import statements in examples</li> <li> <p>Include version specifications where relevant</p> </li> <li> <p>Context and Dependencies</p> </li> <li>Explain when to use each method</li> <li>Note any prerequisites or dependencies</li> <li> <p>Clarify relationships between different components</p> </li> <li> <p>Common Patterns</p> </li> <li>Show idiomatic Go patterns used in the SDK</li> <li>Include error checking patterns</li> <li>Demonstrate proper resource cleanup</li> </ol>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#step-8-validation-checklist","title":"Step 8: Validation Checklist","text":"<p>Before finalizing, ensure:</p> <ul> <li> All exported functions are documented</li> <li> All data structures have field descriptions</li> <li> Authentication methods are clearly explained</li> <li> Error types and handling are covered</li> <li> Examples compile and are realistic</li> <li> Configuration options are enumerated</li> <li> API endpoint mappings are accurate</li> <li> Versioning information is current</li> <li> Security best practices are included</li> <li> Performance considerations are noted</li> </ul>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#step-9-special-considerations","title":"Step 9: Special Considerations","text":"<ol> <li>Breaking Changes</li> <li>Note any breaking changes from previous versions</li> <li> <p>Provide migration guides if applicable</p> </li> <li> <p>Platform-Specific Features</p> </li> <li>Document any OS-specific functionality</li> <li> <p>Note platform limitations</p> </li> <li> <p>Dependencies</p> </li> <li>List all external dependencies</li> <li> <p>Note minimum Go version required</p> </li> <li> <p>Testing</p> </li> <li>Document how to run tests</li> <li>Include test environment setup</li> </ol>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#step-10-output-format","title":"Step 10: Output Format","text":"<p>Generate the documentation as: - Primary file: <code>README.md</code> in the <code>go-sdk</code> directory - Format: Markdown with Go syntax highlighting - Style: Concise, technical, example-heavy - Target audience: Developers and AI assistants generating code</p>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#execution-instructions-for-ai-assistant","title":"Execution Instructions for AI Assistant","text":"<p>When asked to regenerate this documentation:</p> <ol> <li>Start by creating a task list using TodoWrite tool</li> <li>Fetch the latest SDK code from GitHub</li> <li>Analyze all <code>.go</code> files in the repository</li> <li>Fetch the current OpenAPI specification</li> <li>Follow steps 1-10 above systematically</li> <li>Generate comprehensive documentation</li> <li>Save to <code>go-sdk/README.md</code></li> </ol>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#example-prompt-to-trigger-regeneration","title":"Example Prompt to Trigger Regeneration","text":"<p>\"Please regenerate the LimaCharlie Go SDK documentation following the recipe in go-sdk/REGENERATION_RECIPE.md. The SDK repository is at https://github.com/refractionPOINT/go-limacharlie/\"</p>"},{"location":"6-developer-guide/sdks/go-sdk-regeneration/#important-notes","title":"Important Notes","text":"<ul> <li>Focus on precision and completeness over brevity</li> <li>Include ALL public methods and types</li> <li>Provide working code examples for every major feature</li> <li>Ensure examples are self-contained and runnable</li> <li>Document both common and edge cases</li> <li>Keep security considerations prominent</li> <li>Make the documentation LLM-friendly with clear patterns and complete information</li> </ul>"},{"location":"6-developer-guide/sdks/go-sdk/","title":"LimaCharlie Go SDK Documentation","text":""},{"location":"6-developer-guide/sdks/go-sdk/#overview","title":"Overview","text":"<p>The LimaCharlie Go SDK provides a comprehensive client library for interacting with the LimaCharlie security platform API. This SDK enables developers to programmatically manage sensors, detection rules, artifacts, organizational configurations, real-time event streaming, and more within the LimaCharlie ecosystem.</p> <p>Repository: github.com/refractionPOINT/go-limacharlie</p>"},{"location":"6-developer-guide/sdks/go-sdk/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Authentication</li> <li>Client Initialization</li> <li>Core Components</li> <li>Sensor Management</li> <li>Detection &amp; Response Rules</li> <li>Artifacts</li> <li>Events and Data Streaming</li> <li>Organization Management</li> <li>Installation Keys</li> <li>Outputs</li> <li>Billing</li> <li>LCQL Queries</li> <li>Hive Configuration Management</li> <li>Data Structures</li> <li>Error Handling</li> <li>Advanced Features</li> <li>Examples</li> <li>Best Practices</li> <li>Troubleshooting</li> <li>Firehose CLI Tool</li> </ul>"},{"location":"6-developer-guide/sdks/go-sdk/#installation","title":"Installation","text":""},{"location":"6-developer-guide/sdks/go-sdk/#main-sdk-package","title":"Main SDK Package","text":"<pre><code>go get github.com/refractionPOINT/go-limacharlie/limacharlie\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#firehose-cli-tool","title":"Firehose CLI Tool","text":"<pre><code>go get github.com/refractionPOINT/go-limacharlie/firehose\n</code></pre> <p>Minimum Go Version: 1.18 or higher</p>"},{"location":"6-developer-guide/sdks/go-sdk/#authentication","title":"Authentication","text":"<p>The SDK supports multiple authentication methods for flexible integration.</p>"},{"location":"6-developer-guide/sdks/go-sdk/#environment-variables","title":"Environment Variables","text":"<p>The SDK automatically loads credentials from environment variables:</p> <pre><code>export LC_OID=\"your-organization-id\"\nexport LC_API_KEY=\"your-api-key\"\nexport LC_ENVIRONMENT=\"production\"  # Optional: environment name from config file\n</code></pre> <pre><code>import \"github.com/refractionPOINT/go-limacharlie/limacharlie\"\n\n// Automatically loads from environment variables\nclient, err := limacharlie.NewClient(limacharlie.ClientOptions{}, nil)\nif err != nil {\n    log.Fatal(err)\n}\norg, err := limacharlie.NewOrganization(client)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#direct-api-key-authentication","title":"Direct API Key Authentication","text":"<pre><code>client, err := limacharlie.NewClient(limacharlie.ClientOptions{\n    OID:    \"your-organization-id\",\n    APIKey: \"your-api-key\",\n}, nil)\nif err != nil {\n    log.Fatal(err)\n}\n\norg, err := limacharlie.NewOrganization(client)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#jwt-authentication","title":"JWT Authentication","text":"<p>For user-based authentication or limited-scope permissions:</p> <pre><code>client, err := limacharlie.NewClient(limacharlie.ClientOptions{\n    OID:         \"your-organization-id\",\n    JWT:         \"your-jwt-token\",\n    Permissions: []string{\"sensor.get\", \"sensor.task\"}, // Optional: specific permissions\n}, nil)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#configuration-file","title":"Configuration File","text":"<p>Create a YAML configuration file at <code>~/.limacharlie</code> or specify with <code>LC_CREDS_FILE</code>:</p> <pre><code>environments:\n  production:\n    oid: \"your-production-oid\"\n    api_key: \"your-production-api-key\"\n\n  development:\n    oid: \"your-dev-oid\"\n    api_key: \"your-dev-api-key\"\n    uid: \"your-user-id\"  # Optional\n</code></pre> <p>Load configuration:</p> <pre><code>// Set environment to use (defaults to first in file)\nos.Setenv(\"LC_ENVIRONMENT\", \"production\")\n\nclient, err := limacharlie.NewClient(limacharlie.ClientOptions{}, nil)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#jwt-refresh","title":"JWT Refresh","text":"<p>The SDK automatically refreshes JWT tokens when they expire:</p> <pre><code>// Manual JWT refresh\nnewJWT, err := client.RefreshJWT(24 * time.Hour) // 24-hour expiry\nif err != nil {\n    log.Fatal(err)\n}\n\n// Get current JWT\ncurrentJWT := client.GetCurrentJWT()\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#client-initialization","title":"Client Initialization","text":""},{"location":"6-developer-guide/sdks/go-sdk/#basic-client-creation","title":"Basic Client Creation","text":"<pre><code>package main\n\nimport (\n    \"log\"\n    \"github.com/refractionPOINT/go-limacharlie/limacharlie\"\n)\n\nfunc main() {\n    // Initialize client (loads from environment or config file)\n    client, err := limacharlie.NewClient(limacharlie.ClientOptions{}, nil)\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // Get organization handle\n    org, err := limacharlie.NewOrganization(client)\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer org.Close()\n\n    // Verify authentication\n    whoami, err := org.WhoAmI()\n    if err != nil {\n        log.Fatal(err)\n    }\n    log.Printf(\"Authenticated as: %v\", whoami.Identity)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#with-custom-logger","title":"With Custom Logger","text":"<pre><code>import \"github.com/rs/zerolog\"\n\nlogger := &amp;limacharlie.LCLoggerZerolog{}\n\nclient, err := limacharlie.NewClient(\n    limacharlie.ClientOptions{\n        OID:    \"your-oid\",\n        APIKey: \"your-api-key\",\n    },\n    logger,\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#organization-from-direct-options","title":"Organization from Direct Options","text":"<pre><code>// Create organization directly\norg, err := limacharlie.NewOrganizationFromClientOptions(\n    limacharlie.ClientOptions{\n        OID:    \"your-oid\",\n        APIKey: \"your-api-key\",\n    },\n    nil, // logger\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#core-components","title":"Core Components","text":""},{"location":"6-developer-guide/sdks/go-sdk/#sensor-management","title":"Sensor Management","text":""},{"location":"6-developer-guide/sdks/go-sdk/#listing-sensors","title":"Listing Sensors","text":"<pre><code>// Get all sensors\nsensors, err := org.ListSensors()\nif err != nil {\n    log.Fatal(err)\n}\n\nfor sid, sensor := range sensors {\n    fmt.Printf(\"Sensor: %s\\n\", sid)\n    fmt.Printf(\"  Hostname: %s\\n\", sensor.Hostname)\n    fmt.Printf(\"  Platform: %d\\n\", sensor.Platform)\n    fmt.Printf(\"  Internal IP: %s\\n\", sensor.InternalIP)\n    fmt.Printf(\"  Is Isolated: %v\\n\", sensor.IsIsolated)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#list-sensors-with-selector","title":"List Sensors with Selector","text":"<pre><code>// List sensors matching a selector\nsensors, err := org.ListSensorsFromSelector(\"platform: windows AND tag: production\")\nif err != nil {\n    log.Fatal(err)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#list-sensors-with-options","title":"List Sensors with Options","text":"<pre><code>// List with limit and selector\nsensors, err := org.ListSensors(limacharlie.ListSensorsOptions{\n    Selector: \"platform: linux\",\n    Limit:    100,\n})\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#iterative-listing-pagination","title":"Iterative Listing (Pagination)","text":"<pre><code>// For very large organizations, use iterative listing\ncontinuationToken := \"\"\nallSensors := make(map[string]*limacharlie.Sensor)\n\nfor {\n    sensors, nextToken, err := org.ListSensorsFromSelectorIteratively(\n        \"tag: critical\",\n        continuationToken,\n    )\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // Merge results\n    for sid, sensor := range sensors {\n        allSensors[sid] = sensor\n    }\n\n    // Check if more results\n    if nextToken == \"\" {\n        break\n    }\n    continuationToken = nextToken\n}\n\nfmt.Printf(\"Total sensors: %d\\n\", len(allSensors))\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#getting-specific-sensor","title":"Getting Specific Sensor","text":"<pre><code>// Get sensor by SID\nsensor := org.GetSensor(\"sensor-id-here\")\nif sensor.LastError != nil {\n    log.Fatal(sensor.LastError)\n}\n\nfmt.Printf(\"Sensor %s:\\n\", sensor.SID)\nfmt.Printf(\"  Hostname: %s\\n\", sensor.Hostname)\nfmt.Printf(\"  Enrollment: %s\\n\", sensor.EnrollTS)\nfmt.Printf(\"  Last Alive: %s\\n\", sensor.AliveTS)\nfmt.Printf(\"  Kernel Available: %v\\n\", sensor.IsKernelAvailable)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#get-multiple-sensors","title":"Get Multiple Sensors","text":"<pre><code>sids := []string{\"sid1\", \"sid2\", \"sid3\"}\nsensors := org.GetSensors(sids)\n\nfor sid, sensor := range sensors {\n    if sensor.LastError != nil {\n        log.Printf(\"Error getting %s: %v\", sid, sensor.LastError)\n        continue\n    }\n    fmt.Printf(\"Sensor: %s - %s\\n\", sid, sensor.Hostname)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#check-sensor-online-status","title":"Check Sensor Online Status","text":"<pre><code>// Check single sensor\nisOnline, err := sensor.IsOnline()\nif err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(\"Sensor is online: %v\\n\", isOnline)\n\n// Check multiple sensors\nsids := []string{\"sid1\", \"sid2\", \"sid3\"}\nstatuses, err := org.ActiveSensors(sids)\nif err != nil {\n    log.Fatal(err)\n}\n\nfor sid, isOnline := range statuses {\n    fmt.Printf(\"Sensor %s online: %v\\n\", sid, isOnline)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#sensor-actions","title":"Sensor Actions","text":"<pre><code>// Isolate sensor from network\nerr := sensor.IsolateFromNetwork()\nif err != nil {\n    log.Fatal(err)\n}\n\n// Rejoin network\nerr = sensor.RejoinNetwork()\nif err != nil {\n    log.Fatal(err)\n}\n\n// Delete sensor\nerr = sensor.Delete()\nif err != nil {\n    log.Fatal(err)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#sensor-tagging","title":"Sensor Tagging","text":"<pre><code>// Get current tags\ntags, err := sensor.GetTags()\nif err != nil {\n    log.Fatal(err)\n}\n\nfor _, tag := range tags {\n    fmt.Printf(\"Tag: %s (by %s at %s)\\n\", tag.Tag, tag.By, tag.AddedTS)\n}\n\n// Add a tag (with 1-hour TTL)\nerr = sensor.AddTag(\"incident-response\", 1*time.Hour)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Add permanent tag (0 TTL)\nerr = sensor.AddTag(\"production\", 0)\n\n// Remove a tag\nerr = sensor.RemoveTag(\"old-tag\")\nif err != nil {\n    log.Fatal(err)\n}\n\n// Get all tags in organization\nallTags, err := org.GetAllTags()\n\n// Get sensors with specific tag\nsensorMap, err := org.GetSensorsWithTag(\"production\")\n// Returns map[string][]string - map of SID to list of tags\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#tasking-sensors","title":"Tasking Sensors","text":""},{"location":"6-developer-guide/sdks/go-sdk/#simple-task-execution","title":"Simple Task Execution","text":"<pre><code>// Basic task\nerr := sensor.Task(`{\"action\": \"os_processes\"}`)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Task with investigation ID\nerr = sensor.Task(\n    `{\"action\": \"file_get\", \"path\": \"C:\\\\Windows\\\\System32\\\\calc.exe\"}`,\n    limacharlie.TaskingOptions{\n        InvestigationID: \"investigation-123\",\n    },\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#task-with-idempotent-key","title":"Task with Idempotent Key","text":"<pre><code>// Prevent duplicate task execution\nerr := sensor.Task(\n    `{\"action\": \"os_version\"}`,\n    limacharlie.TaskingOptions{\n        InvestigationID: \"inv-001\",\n        IdempotentKey:   \"unique-task-key-12345\",\n    },\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#simplerequest-task-with-synchronous-response","title":"SimpleRequest - Task with Synchronous Response","text":"<pre><code>// Enable interactive mode (creates Spout for receiving responses)\norg = org.WithInvestigationID(\"my-investigation-id\")\n\n// Send task and wait for response\nresponse, err := sensor.SimpleRequest(\n    `{\"action\": \"os_version\"}`,\n    limacharlie.SimpleRequestOptions{\n        Timeout:         30 * time.Second,\n        UntilCompletion: false, // Return after first response\n    },\n)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Response is map[string]interface{}\nif respMap, ok := response.(map[string]interface{}); ok {\n    fmt.Printf(\"OS Version: %v\\n\", respMap)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#simplerequest-multiple-tasks","title":"SimpleRequest - Multiple Tasks","text":"<pre><code>// Send multiple tasks\ntasks := []string{\n    `{\"action\": \"os_version\"}`,\n    `{\"action\": \"os_processes\"}`,\n}\n\nresponses, err := sensor.SimpleRequest(\n    tasks,\n    limacharlie.SimpleRequestOptions{\n        Timeout:         60 * time.Second,\n        UntilCompletion: false,\n    },\n)\n\n// responses is []interface{} containing all responses\nif respList, ok := responses.([]interface{}); ok {\n    for i, resp := range respList {\n        fmt.Printf(\"Response %d: %v\\n\", i, resp)\n    }\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#request-async-response-handling","title":"Request - Async Response Handling","text":"<pre><code>// For more control, use Request() to get FutureResults\nfuture, err := sensor.Request(`{\"action\": \"os_processes\"}`)\nif err != nil {\n    log.Fatal(err)\n}\ndefer future.Close()\n\n// Wait for response with timeout\nresponse, err := future.GetWithTimeout(30 * time.Second)\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Response: %v\\n\", response)\n\n// Or get multiple responses as they arrive\nfor i := 0; i &lt; 3; i++ {\n    resp, ok := future.Get()\n    if !ok {\n        break\n    }\n    fmt.Printf(\"Got response %d: %v\\n\", i, resp)\n}\n\n// Batch retrieval with timeout\nnewResponses := future.GetNewResponses(5 * time.Second)\nfor _, resp := range newResponses {\n    fmt.Printf(\"Response: %v\\n\", resp)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#device-association","title":"Device Association","text":"<p>Sensors may be associated with logical devices (when multiple sensors represent the same device):</p> <pre><code>sensor := org.GetSensor(\"sensor-id\")\nif sensor.Device != nil {\n    fmt.Printf(\"Device ID: %s\\n\", sensor.Device.DID)\n    // Device operations can be performed through sensor.Device\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#detection-response-rules","title":"Detection &amp; Response Rules","text":""},{"location":"6-developer-guide/sdks/go-sdk/#rule-structure","title":"Rule Structure","text":"<pre><code>type CoreDRRule struct {\n    Name      string                 `json:\"name,omitempty\"`\n    Namespace string                 `json:\"namespace,omitempty\"` // Default: \"general\"\n    Detect    map[string]interface{} `json:\"detect\"`\n    Response  []map[string]interface{} `json:\"respond\"`\n    IsEnabled *bool                  `json:\"is_enabled,omitempty\"`\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#adding-detection-rules","title":"Adding Detection Rules","text":"<pre><code>// Simple detection rule\ndetection := map[string]interface{}{\n    \"event\": \"NEW_PROCESS\",\n    \"op\":    \"and\",\n    \"rules\": []map[string]interface{}{\n        {\n            \"op\":    \"contains\",\n            \"path\":  \"event/FILE_PATH\",\n            \"value\": \"\\\\Windows\\\\Temp\\\\\",\n        },\n    },\n}\n\nresponse := []map[string]interface{}{\n    {\n        \"action\": \"report\",\n        \"name\":   \"suspicious-temp-execution\",\n    },\n}\n\nenabled := true\nerr := org.DRRuleAdd(\n    \"suspicious-temp-execution\",\n    detection,\n    response,\n    limacharlie.NewDRRuleOptions{\n        IsEnabled: true,\n        Namespace: \"custom\",\n        IsReplace: true, // Replace if exists\n        TTL:       86400, // 24 hours in seconds\n    },\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#advanced-detection-rule-with-response-actions","title":"Advanced Detection Rule with Response Actions","text":"<pre><code>// Ransomware detection with automated response\ndetection := map[string]interface{}{\n    \"event\": \"FILE_CREATE\",\n    \"op\":    \"and\",\n    \"rules\": []map[string]interface{}{\n        {\n            \"op\":   \"matches\",\n            \"path\": \"event/FILE_PATH\",\n            \"re\":   \".*\\\\.(locked|encrypted|enc|cry)$\",\n        },\n        {\n            \"op\":    \"greater than\",\n            \"path\":  \"event/SIZE\",\n            \"value\": 100,\n        },\n    },\n}\n\nresponse := []map[string]interface{}{\n    {\n        \"action\":   \"report\",\n        \"name\":     \"potential-ransomware\",\n        \"priority\": 10,\n    },\n    {\n        \"action\": \"task\",\n        \"command\": map[string]interface{}{\n            \"action\": \"os_kill_process\",\n            \"pid\":    \"&lt;&lt;event/PROCESS_ID&gt;&gt;\",\n        },\n    },\n    {\n        \"action\": \"task\",\n        \"command\": map[string]interface{}{\n            \"action\": \"isolate_network\",\n        },\n    },\n}\n\nenabled := true\nerr := org.DRRuleAdd(\n    \"ransomware-file-encryption\",\n    detection,\n    response,\n    limacharlie.NewDRRuleOptions{\n        IsEnabled: true,\n        Namespace: \"threats\",\n        IsReplace: true,\n    },\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#listing-detection-rules","title":"Listing Detection Rules","text":"<pre><code>// Get all rules\nrules, err := org.DRRules()\nif err != nil {\n    log.Fatal(err)\n}\n\nfor name, rule := range rules {\n    fmt.Printf(\"Rule: %s\\n\", name)\n    fmt.Printf(\"  Detect: %v\\n\", rule[\"detect\"])\n    fmt.Printf(\"  Respond: %v\\n\", rule[\"respond\"])\n}\n\n// Get rules in specific namespace\nrules, err = org.DRRules(limacharlie.WithNamespace(\"custom\"))\nif err != nil {\n    log.Fatal(err)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#deleting-detection-rules","title":"Deleting Detection Rules","text":"<pre><code>// Delete rule from default namespace\nerr := org.DRRuleDelete(\"rule-name\")\nif err != nil {\n    log.Fatal(err)\n}\n\n// Delete rule from specific namespace\nerr = org.DRRuleDelete(\"rule-name\", limacharlie.WithNamespace(\"custom\"))\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#artifacts","title":"Artifacts","text":"<p>Artifacts are files or data collected from sensors for analysis.</p>"},{"location":"6-developer-guide/sdks/go-sdk/#creating-artifacts-from-bytes","title":"Creating Artifacts from Bytes","text":"<pre><code>artifactData := []byte(\"Suspicious file content...\")\n\nerr := org.CreateArtifactFromBytes(\n    \"suspicious-file.txt\",         // name\n    artifactData,                  // data\n    \"text/plain\",                  // content type\n    \"artifact-12345\",              // artifact ID (or \"\" for auto-generate)\n    7,                             // retention days\n    \"your-ingestion-key\",          // ingestion key\n)\nif err != nil {\n    log.Fatal(err)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#creating-artifacts-from-file","title":"Creating Artifacts from File","text":"<pre><code>err := org.CreateArtifactFromFile(\n    \"collected-malware\",           // artifact name\n    \"/path/to/local/file.exe\",     // local file path\n    \"application/octet-stream\",    // content type\n    \"\",                            // auto-generate artifact ID\n    30,                            // 30 days retention\n    \"your-ingestion-key\",\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#uploading-large-artifacts","title":"Uploading Large Artifacts","text":"<p>For large files, the SDK automatically handles chunked uploads:</p> <pre><code>file, err := os.Open(\"/path/to/large/file.bin\")\nif err != nil {\n    log.Fatal(err)\n}\ndefer file.Close()\n\nfileInfo, _ := file.Stat()\n\nerr = org.UploadArtifact(\n    file,                          // io.Reader\n    fileInfo.Size(),               // size\n    \"application/octet-stream\",    // hint (content type)\n    \"large-memory-dump\",           // source name\n    \"artifact-uuid\",               // artifact ID\n    \"/path/to/large/file.bin\",     // original path\n    7,                             // retention days\n    \"your-ingestion-key\",\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#exporting-artifacts","title":"Exporting Artifacts","text":"<pre><code>deadline := time.Now().Add(5 * time.Minute)\n\n// Export artifact\nreader, err := org.ExportArtifact(\"artifact-id\", deadline)\nif err != nil {\n    log.Fatal(err)\n}\ndefer reader.Close()\n\n// Save to file\noutFile, _ := os.Create(\"exported-artifact.bin\")\ndefer outFile.Close()\n\nio.Copy(outFile, reader)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#exporting-through-google-cloud-storage","title":"Exporting Through Google Cloud Storage","text":"<pre><code>import (\n    \"context\"\n    \"cloud.google.com/go/storage\"\n)\n\nctx := context.Background()\ndeadline := time.Now().Add(10 * time.Minute)\n\n// Setup GCS client\ngcsClient, err := storage.NewClient(ctx)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Export artifact through GCS\nreader, err := org.ExportArtifactThroughGCS(\n    ctx,\n    \"artifact-id\",\n    deadline,\n    \"your-gcs-bucket\",\n    \"gcs-service-account-credentials-json\",\n    gcsClient,\n)\nif err != nil {\n    log.Fatal(err)\n}\ndefer reader.Close()\n\n// Process the data\ndata, _ := io.ReadAll(reader)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#artifact-collection-rules","title":"Artifact Collection Rules","text":"<p>Define rules for automatic artifact collection:</p> <pre><code>// Add artifact collection rule\nrule := limacharlie.ArtifactRule{\n    Patterns: []string{\n        \"C:\\\\Windows\\\\Temp\\\\*.exe\",\n        \"C:\\\\Users\\\\*\\\\AppData\\\\Local\\\\Temp\\\\*.dll\",\n    },\n    Filters: limacharlie.ArtifactRuleFilter{\n        Tags:      []string{\"production\"},\n        Platforms: []string{\"windows\"},\n    },\n    DaysRetentions: 30,\n    IsDeleteAfter:  false,\n    IsIgnoreCert:   false,\n}\n\nerr := org.ArtifactRuleAdd(\"collect-temp-executables\", rule)\nif err != nil {\n    log.Fatal(err)\n}\n\n// List artifact rules\nrules, err := org.ArtifactsRules()\nif err != nil {\n    log.Fatal(err)\n}\n\nfor name, rule := range rules {\n    fmt.Printf(\"Rule: %s\\n\", name)\n    fmt.Printf(\"  Patterns: %v\\n\", rule.Patterns)\n    fmt.Printf(\"  Retention: %d days\\n\", rule.DaysRetentions)\n}\n\n// Delete artifact rule\nerr = org.ArtifactRuleDelete(\"collect-temp-executables\")\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#events-and-data-streaming","title":"Events and Data Streaming","text":"<p>The SDK provides powerful real-time event streaming through the Spout system.</p>"},{"location":"6-developer-guide/sdks/go-sdk/#spout-real-time-event-streaming","title":"Spout - Real-Time Event Streaming","text":"<p>Spout provides WebSocket-based streaming of events, detections, audit logs, and more:</p> <pre><code>import \"github.com/refractionPOINT/go-limacharlie/limacharlie\"\n\n// Create a Spout for events\nspout, err := limacharlie.NewSpout(\n    org,\n    \"event\", // Type: \"event\", \"detect\", \"audit\", \"deployment\", \"billing\"\n    limacharlie.WithInvestigationID(\"my-investigation\"),\n)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Start receiving data\nif err := spout.Start(); err != nil {\n    log.Fatal(err)\n}\ndefer spout.Shutdown()\n\n// Process events\nfor {\n    event, ok := &lt;-spout.GetDataChannel()\n    if !ok {\n        break // Spout closed\n    }\n\n    if eventMap, ok := event.(map[string]interface{}); ok {\n        fmt.Printf(\"Event: %v\\n\", eventMap)\n    }\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#spout-options","title":"Spout Options","text":"<pre><code>// Filter by tag\nspout, err := limacharlie.NewSpout(\n    org,\n    \"event\",\n    limacharlie.WithTag(\"production\"),\n)\n\n// Filter by category (for detections)\nspout, err := limacharlie.NewSpout(\n    org,\n    \"detect\",\n    limacharlie.WithCategory(\"malware\"),\n)\n\n// Filter by sensor ID\nspout, err := limacharlie.NewSpout(\n    org,\n    \"event\",\n    limacharlie.WithSensorID(\"sensor-id\"),\n)\n\n// Combine multiple options\nspout, err := limacharlie.NewSpout(\n    org,\n    \"detect\",\n    limacharlie.WithTag(\"critical\"),\n    limacharlie.WithCategory(\"ransomware\"),\n    limacharlie.WithInvestigationID(\"incident-2024-001\"),\n)\n\n// Disable auto-reconnect\nspout, err := limacharlie.NewSpout(\n    org,\n    \"event\",\n    limacharlie.WithoutReconnect(),\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#using-spout-with-futureresults","title":"Using Spout with FutureResults","text":"<p>The Spout system integrates with sensor tasking for request/response workflows:</p> <pre><code>// Organization with investigation ID enables interactive mode\norg = org.WithInvestigationID(\"investigation-123\")\n\n// The organization will create a shared Spout automatically\nsensor := org.GetSensor(\"sensor-id\")\n\n// SimpleRequest uses the shared Spout internally\nresponse, err := sensor.SimpleRequest(`{\"action\": \"os_version\"}`)\n\n// Or use Request() for manual handling\nfuture, err := sensor.Request(`{\"action\": \"os_processes\"}`)\nif err != nil {\n    log.Fatal(err)\n}\ndefer future.Close()\n\nresponse, err := future.GetWithTimeout(30 * time.Second)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#manual-spout-management-for-interactive-mode","title":"Manual Spout Management for Interactive Mode","text":"<pre><code>org := org.WithInvestigationID(\"my-investigation\")\n\n// Manually enable interactive mode (creates shared Spout)\nif err := org.MakeInteractive(); err != nil {\n    log.Fatal(err)\n}\n\n// Now you can use SimpleRequest/Request on sensors\nsensor := org.GetSensor(\"sensor-id\")\nresponse, err := sensor.SimpleRequest(`{\"action\": \"os_version\"}`)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#monitoring-dropped-events","title":"Monitoring Dropped Events","text":"<pre><code>spout, err := limacharlie.NewSpout(org, \"event\")\nspout.Start()\n\n// Check dropped count\ndroppedCount := spout.GetDropped()\nfmt.Printf(\"Dropped events: %d\\n\", droppedCount)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#organization-management","title":"Organization Management","text":""},{"location":"6-developer-guide/sdks/go-sdk/#organization-information","title":"Organization Information","text":"<pre><code>// Get organization info\ninfo, err := org.GetInfo()\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Organization: %s\\n\", info.Name)\nfmt.Printf(\"OID: %s\\n\", info.OID)\nfmt.Printf(\"Sensor Version: %s\\n\", info.SensorVersion)\nfmt.Printf(\"Number of Rules: %d\\n\", info.NumberRules)\nfmt.Printf(\"Number of Outputs: %d\\n\", info.NumberOutputs)\nfmt.Printf(\"Sensor Quota: %d\\n\", info.SensorQuota)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#online-sensor-count","title":"Online Sensor Count","text":"<pre><code>count, err := org.GetOnlineCount()\nif err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(\"Online sensors: %d\\n\", count.Count)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#site-connectivity-information","title":"Site Connectivity Information","text":"<pre><code>// Get URLs for different services\nurls, err := org.GetURLs()\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Artifacts URL: %s\\n\", urls[\"artifacts\"])\nfmt.Printf(\"Replay URL: %s\\n\", urls[\"replay\"])\nfmt.Printf(\"Ingestion URL: %s\\n\", urls[\"ingestion\"])\n\n// Get full site connectivity info (URLs + certificates)\ninfo, err := org.GetSiteConnectivityInfo()\nif err != nil {\n    log.Fatal(err)\n}\n\nfor service, url := range info.URLs {\n    fmt.Printf(\"%s: %s\\n\", service, url)\n}\n\nfor service, cert := range info.Certs {\n    fmt.Printf(\"%s cert: %s...\\n\", service, cert[:50])\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#quota-management","title":"Quota Management","text":"<pre><code>// Set organization quota\nsuccess, err := org.SetQuota(1000) // Max 1000 sensors\nif err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(\"Quota set: %v\\n\", success)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#creating-organizations","title":"Creating Organizations","text":"<pre><code>// Create a new organization\nnewOrg, err := org.CreateOrganization(\n    \"us\",                    // location\n    \"New Organization Name\", // name\n)\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Created organization: %s\\n\", newOrg.Data.Oid)\n\n// Create with template\ntemplateYAML := `\ndetection:\n  - name: \"default-rule\"\n    namespace: \"general\"\n    detect: ...\n    respond: ...\n`\n\nnewOrg, err = org.CreateOrganization(\n    \"us\",\n    \"Templated Org\",\n    templateYAML,\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#organization-deletion","title":"Organization Deletion","text":"<pre><code>// Get confirmation token\ntoken, err := org.GetDeleteConfirmationToken()\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Confirmation token: %s\\n\", token)\n\n// Delete organization (DANGEROUS!)\nsuccess, err := org.DeleteOrganization(token)\nif err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(\"Deletion successful: %v\\n\", success)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#group-management","title":"Group Management","text":"<pre><code>// Add organization to a group\nsuccess, err := org.AddToGroup(\"group-id\")\nif err != nil {\n    log.Fatal(err)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#authorization-and-permissions","title":"Authorization and Permissions","text":"<pre><code>// Check who you are\nwhoami, err := org.WhoAmI()\nif err != nil {\n    log.Fatal(err)\n}\n\nif whoami.Identity != nil {\n    fmt.Printf(\"Identity: %s\\n\", *whoami.Identity)\n}\nif whoami.Organizations != nil {\n    fmt.Printf(\"Organizations: %v\\n\", *whoami.Organizations)\n}\nif whoami.Permissions != nil {\n    fmt.Printf(\"Permissions: %v\\n\", *whoami.Permissions)\n}\n\n// Check specific permission\nhasPermission := whoami.HasPermissionForOrg(\"org-id\", \"sensor.task\")\nfmt.Printf(\"Has sensor.task permission: %v\\n\", hasPermission)\n\n// Check access to org\nhasAccess := whoami.HasAccessToOrg(\"org-id\")\nfmt.Printf(\"Has access to org: %v\\n\", hasAccess)\n\n// Authorize with required permissions\nidentity, perms, err := org.Authorize([]string{\"sensor.get\", \"sensor.task\"})\nif err != nil {\n    log.Fatal(\"Missing required permissions:\", err)\n}\nfmt.Printf(\"Authorized as %s with %d permissions\\n\", identity, len(perms))\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#service-and-extension-requests","title":"Service and Extension Requests","text":"<pre><code>// Generic service request\nvar response map[string]interface{}\nerr := org.ServiceRequest(\n    &amp;response,\n    \"logging\", // service name\n    limacharlie.Dict{\n        \"action\": \"list_rules\",\n    },\n    false, // is_async\n)\n\n// Extension request\nvar extResponse map[string]interface{}\nerr = org.ExtensionRequest(\n    &amp;extResponse,\n    \"extension-name\",\n    \"action-name\",\n    limacharlie.Dict{\n        \"param1\": \"value1\",\n    },\n    false, // is_impersonate\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#installation-keys","title":"Installation Keys","text":"<p>Installation keys are used for enrolling new sensors.</p>"},{"location":"6-developer-guide/sdks/go-sdk/#list-installation-keys","title":"List Installation Keys","text":"<pre><code>keys, err := org.InstallationKeys()\nif err != nil {\n    log.Fatal(err)\n}\n\nfor _, key := range keys {\n    fmt.Printf(\"Key ID: %s\\n\", key.ID)\n    fmt.Printf(\"  Description: %s\\n\", key.Description)\n    fmt.Printf(\"  Tags: %v\\n\", key.Tags)\n    fmt.Printf(\"  Created: %d\\n\", key.CreatedAt)\n    fmt.Printf(\"  Use Public CA: %v\\n\", key.UsePublicCA)\n    fmt.Printf(\"  Key: %s\\n\", key.Key)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#get-specific-installation-key","title":"Get Specific Installation Key","text":"<pre><code>key, err := org.InstallationKey(\"installation-key-id\")\nif err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(\"Key: %s\\n\", key.Key)\nfmt.Printf(\"JSON Key: %s\\n\", key.JsonKey)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#add-installation-key","title":"Add Installation Key","text":"<pre><code>key := limacharlie.InstallationKey{\n    Description: \"Production Servers\",\n    Tags:        []string{\"production\", \"linux\"},\n    UsePublicCA: false, // Use LimaCharlie's certificate\n}\n\niid, err := org.AddInstallationKey(key)\nif err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(\"Created installation key: %s\\n\", iid)\n\n// With custom ID\nkey.ID = \"custom-key-id\"\niid, err = org.AddInstallationKey(key)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#delete-installation-key","title":"Delete Installation Key","text":"<pre><code>err := org.DelInstallationKey(\"installation-key-id\")\nif err != nil {\n    log.Fatal(err)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#outputs","title":"Outputs","text":"<p>Outputs define where LimaCharlie sends events, detections, and other data. The SDK provides comprehensive output management through the <code>output.go</code> module.</p>"},{"location":"6-developer-guide/sdks/go-sdk/#supported-output-modules","title":"Supported Output Modules","text":"<p>The SDK supports numerous output types via the <code>OutputTypes</code> struct:</p> <ul> <li>Cloud Storage: <code>s3</code>, <code>gcs</code>, <code>azure_storage_blob</code></li> <li>Messaging: <code>pubsub</code>, <code>kafka</code>, <code>azure_event_hub</code></li> <li>Databases: <code>bigquery</code>, <code>elastic</code>, <code>opensearch</code></li> <li>File Transfer: <code>scp</code>, <code>sftp</code></li> <li>Webhooks: <code>webhook</code>, <code>webhook_bulk</code>, <code>websocket</code></li> <li>Monitoring/SIEM: <code>syslog</code>, <code>humio</code>, <code>datadog</code></li> <li>Orchestration: <code>slack</code>, <code>smtp</code>, <code>tines</code>, <code>torq</code></li> </ul>"},{"location":"6-developer-guide/sdks/go-sdk/#billing","title":"Billing","text":"<p>The SDK provides access to billing information and invoices through the billing service.</p>"},{"location":"6-developer-guide/sdks/go-sdk/#get-billing-status","title":"Get Billing Status","text":"<pre><code>status, err := org.GetBillingOrgStatus()\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Past due: %v\\n\", status.IsPastDue)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#get-billing-details","title":"Get Billing Details","text":"<pre><code>details, err := org.GetBillingOrgDetails()\nif err != nil {\n    log.Fatal(err)\n}\n\n// Customer info (Stripe Customer object)\nif customer, ok := details.Customer[\"email\"].(string); ok {\n    fmt.Printf(\"Customer email: %s\\n\", customer)\n}\n\n// Status\nif status, ok := details.Status[\"is_past_due\"].(bool); ok {\n    fmt.Printf(\"Is past due: %v\\n\", status)\n}\n\n// Upcoming invoice\nif invoice := details.UpcomingInvoice; invoice != nil {\n    if amount, ok := invoice[\"amount_due\"].(float64); ok {\n        fmt.Printf(\"Amount due: $%.2f\\n\", amount/100)\n    }\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#get-invoice","title":"Get Invoice","text":"<pre><code>// Get invoice URL for download\ninvoice, err := org.GetBillingInvoiceURL(2024, 1, \"\") // January 2024\nif err != nil {\n    log.Fatal(err)\n}\n\nif url, ok := invoice[\"url\"].(string); ok {\n    fmt.Printf(\"Invoice URL: %s\\n\", url)\n}\n\n// Get invoice as JSON\ninvoice, err = org.GetBillingInvoiceURL(2024, 1, \"json\")\nif invoiceObj, ok := invoice[\"invoice\"].(map[string]interface{}); ok {\n    fmt.Printf(\"Invoice: %v\\n\", invoiceObj)\n}\n\n// Get simple JSON format\ninvoice, err = org.GetBillingInvoiceURL(2024, 1, \"simple_json\")\nif lines, ok := invoice[\"lines\"].([]interface{}); ok {\n    fmt.Printf(\"Invoice has %d lines\\n\", len(lines))\n}\n\n// Get CSV format\ninvoice, err = org.GetBillingInvoiceURL(2024, 1, \"simple_csv\")\nif csv, ok := invoice[\"csv\"].(string); ok {\n    fmt.Printf(\"CSV: %s\\n\", csv)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#get-available-plans","title":"Get Available Plans","text":"<pre><code>plans, err := org.GetBillingAvailablePlans()\nif err != nil {\n    log.Fatal(err)\n}\n\nfor _, plan := range plans {\n    fmt.Printf(\"Plan: %s\\n\", plan.Name)\n    fmt.Printf(\"  ID: %s\\n\", plan.ID)\n    fmt.Printf(\"  Price: $%.2f %s\\n\", plan.Price, plan.Currency)\n    fmt.Printf(\"  Description: %s\\n\", plan.Description)\n    fmt.Printf(\"  Features: %v\\n\", plan.Features)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#get-user-auth-requirements","title":"Get User Auth Requirements","text":"<pre><code>authReqs, err := org.GetBillingUserAuthRequirements()\nif err != nil {\n    log.Fatal(err)\n}\n\nif reqs, ok := authReqs.Requirements[\"methods\"].([]interface{}); ok {\n    fmt.Printf(\"Auth methods: %v\\n\", reqs)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#lcql-queries","title":"LCQL Queries","text":"<p>LCQL (LimaCharlie Query Language) allows querying historical events and detections.</p>"},{"location":"6-developer-guide/sdks/go-sdk/#basic-query","title":"Basic Query","text":"<pre><code>// Query last hour of process creation events\nresponse, err := org.Query(limacharlie.QueryRequest{\n    Query:      `-1h | * | * | event.FILE_PATH ends with \".exe\"`,\n    Stream:     \"event\",    // \"event\", \"detect\", or \"audit\"\n    LimitEvent: 1000,\n})\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Results: %d\\n\", len(response.Results))\nfor i, result := range response.Results {\n    fmt.Printf(\"Result %d: %v\\n\", i, result)\n}\n\n// Print stats\nif response.Stats != nil {\n    fmt.Printf(\"Stats: %v\\n\", response.Stats)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#query-with-context","title":"Query with Context","text":"<pre><code>import \"context\"\n\nctx, cancel := context.WithTimeout(context.Background(), 2*time.Minute)\ndefer cancel()\n\nresponse, err := org.QueryWithContext(ctx, limacharlie.QueryRequest{\n    Query:  `-24h | platform: windows | event | event.COMMAND_LINE contains \"powershell\"`,\n    Stream: \"event\",\n})\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#paginated-query","title":"Paginated Query","text":"<pre><code>// For large result sets, use pagination\nresponse, err := org.Query(limacharlie.QueryRequest{\n    Query:      `-7d | * | detect | *`,\n    Stream:     \"detect\",\n    Cursor:     \"-\",  // Start pagination\n    LimitEvent: 500,\n})\n\nfor response.Cursor != \"\" {\n    // Process current page\n    for _, result := range response.Results {\n        fmt.Printf(\"Detection: %v\\n\", result)\n    }\n\n    // Get next page\n    response, err = org.Query(limacharlie.QueryRequest{\n        Query:  `-7d | * | detect | *`,\n        Stream: \"detect\",\n        Cursor: response.Cursor,\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#query-iterator","title":"Query Iterator","text":"<pre><code>// Use iterator for automatic pagination\niter, err := org.QueryAll(limacharlie.QueryRequest{\n    Query:      `-30d | tag: production | event | event.EVENT_TYPE = \"NEW_PROCESS\"`,\n    Stream:     \"event\",\n    LimitEvent: 1000,\n})\nif err != nil {\n    log.Fatal(err)\n}\n\ntotalResults := 0\nfor iter.HasMore() {\n    response, err := iter.Next()\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    if response == nil {\n        break\n    }\n\n    totalResults += len(response.Results)\n    fmt.Printf(\"Page results: %d\\n\", len(response.Results))\n\n    // Process results...\n}\n\nfmt.Printf(\"Total results: %d\\n\", totalResults)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#complex-lcql-queries","title":"Complex LCQL Queries","text":"<pre><code>// Multi-condition query\nresponse, err := org.Query(limacharlie.QueryRequest{\n    Query: `-1h | platform: windows AND tag: critical | event | ` +\n           `(event.FILE_PATH ends with \".exe\" OR event.FILE_PATH ends with \".dll\") ` +\n           `AND event.FILE_PATH contains \"\\\\Temp\\\\\"`,\n    Stream:     \"event\",\n    LimitEvent: 5000,\n    LimitEval:  10000,\n})\n\n// Detection query with category filter\nresponse, err = org.Query(limacharlie.QueryRequest{\n    Query:  `-24h | * | detect | detect.cat = \"malware\" OR detect.cat = \"ransomware\"`,\n    Stream: \"detect\",\n})\n\n// Audit log query\nresponse, err = org.Query(limacharlie.QueryRequest{\n    Query:  `-7d | * | audit | audit.action = \"sensor.task\"`,\n    Stream: \"audit\",\n})\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#hive-configuration-management","title":"Hive Configuration Management","text":"<p>Hive is LimaCharlie's configuration management system for storing structured data.</p>"},{"location":"6-developer-guide/sdks/go-sdk/#initialize-hive-client","title":"Initialize Hive Client","text":"<pre><code>hive := limacharlie.NewHiveClient(org)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#list-hive-records","title":"List Hive Records","text":"<pre><code>// List all records in a hive partition\nrecords, err := hive.List(limacharlie.HiveArgs{\n    HiveName:     \"dr-general\",\n    PartitionKey: org.GetOID(),\n})\nif err != nil {\n    log.Fatal(err)\n}\n\nfor key, record := range records {\n    fmt.Printf(\"Record: %s\\n\", key)\n    fmt.Printf(\"  Data: %v\\n\", record.Data)\n    fmt.Printf(\"  Enabled: %v\\n\", record.UsrMtd.Enabled)\n    fmt.Printf(\"  Tags: %v\\n\", record.UsrMtd.Tags)\n    fmt.Printf(\"  Last Modified: %d\\n\", record.SysMtd.LastMod)\n    fmt.Printf(\"  Last Author: %s\\n\", record.SysMtd.LastAuthor)\n    fmt.Printf(\"  ETag: %s\\n\", record.SysMtd.Etag)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#get-specific-hive-record","title":"Get Specific Hive Record","text":"<pre><code>record, err := hive.Get(limacharlie.HiveArgs{\n    HiveName:     \"dr-general\",\n    PartitionKey: org.GetOID(),\n    Key:          \"my-config-key\",\n})\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Data: %v\\n\", record.Data)\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#addupdate-hive-record","title":"Add/Update Hive Record","text":"<pre><code>enabled := true\nerr := hive.Add(limacharlie.HiveArgs{\n    HiveName:     \"dr-general\",\n    PartitionKey: org.GetOID(),\n    Key:          \"my-rule\",\n    Data: limacharlie.Dict{\n        \"detect\": map[string]interface{}{\n            \"event\": \"NEW_PROCESS\",\n            \"op\":    \"is\",\n            \"path\":  \"event/FILE_PATH\",\n            \"value\": \"C:\\\\malware.exe\",\n        },\n        \"respond\": []map[string]interface{}{\n            {\n                \"action\": \"report\",\n                \"name\":   \"malware-detected\",\n            },\n        },\n    },\n    Enabled: &amp;enabled,\n    Tags:    []string{\"malware\", \"test\"},\n})\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#delete-hive-record","title":"Delete Hive Record","text":"<pre><code>err := hive.Remove(limacharlie.HiveArgs{\n    HiveName:     \"dr-general\",\n    PartitionKey: org.GetOID(),\n    Key:          \"my-rule\",\n})\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#batch-hive-operations","title":"Batch Hive Operations","text":"<pre><code>// Create a batch\nbatch := hive.NewBatch()\n\n// Add multiple operations\nenabled := true\nbatch.Add(limacharlie.HiveArgs{\n    HiveName:     \"dr-general\",\n    PartitionKey: org.GetOID(),\n    Key:          \"rule-1\",\n    Data:         limacharlie.Dict{/* ... */},\n    Enabled:      &amp;enabled,\n})\n\nbatch.Add(limacharlie.HiveArgs{\n    HiveName:     \"dr-general\",\n    PartitionKey: org.GetOID(),\n    Key:          \"rule-2\",\n    Data:         limacharlie.Dict{/* ... */},\n    Enabled:      &amp;enabled,\n})\n\n// Execute batch\nresponses, err := batch.Execute()\nif err != nil {\n    log.Fatal(err)\n}\n\nfor i, resp := range responses {\n    if resp.Error != \"\" {\n        fmt.Printf(\"Operation %d failed: %s\\n\", i, resp.Error)\n    } else {\n        fmt.Printf(\"Operation %d succeeded: %v\\n\", i, resp.Data)\n    }\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#data-structures","title":"Data Structures","text":""},{"location":"6-developer-guide/sdks/go-sdk/#sensor-structure","title":"Sensor Structure","text":"<pre><code>type Sensor struct {\n    OID          string // Organization ID\n    IID          string // Installation key ID\n    SID          string // Sensor ID\n    DID          string // Device ID (if associated with device)\n    Platform     uint32 // OS platform code\n    Architecture uint32 // CPU architecture code\n\n    EnrollTS string // Enrollment timestamp\n    AliveTS  string // Last alive timestamp\n\n    InternalIP string // Internal IP address\n    ExternalIP string // External IP address\n    Hostname   string // Sensor hostname\n\n    IsIsolated        bool // Currently isolated from network\n    ShouldIsolate     bool // Should be isolated\n    IsKernelAvailable bool // Kernel component available\n\n    Organization    *Organization // Parent organization\n    Device          *Device       // Associated device (if any)\n    InvestigationID string        // Investigation context\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#detection-rule-structure","title":"Detection Rule Structure","text":"<pre><code>type CoreDRRule struct {\n    Name      string                   `json:\"name,omitempty\"`\n    Namespace string                   `json:\"namespace,omitempty\"`\n    Detect    map[string]interface{}   `json:\"detect\"`\n    Response  []map[string]interface{} `json:\"respond\"`\n    IsEnabled *bool                    `json:\"is_enabled,omitempty\"`\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#installation-key-structure","title":"Installation Key Structure","text":"<pre><code>type InstallationKey struct {\n    CreatedAt   uint64   // Unix timestamp\n    Description string   // Human-readable description\n    ID          string   // Installation key ID (IID)\n    Key         string   // The actual installation key\n    JsonKey     string   // JSON-formatted key\n    Tags        []string // Tags to auto-apply to sensors\n    UsePublicCA bool     // Use public CA vs LimaCharlie CA\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#query-structures","title":"Query Structures","text":"<pre><code>type QueryRequest struct {\n    Query      string // LCQL query string\n    Stream     string // \"event\", \"detect\", or \"audit\"\n    LimitEvent int    // Max events to process\n    LimitEval  int    // Max rule evaluations\n    Cursor     string // Pagination cursor\n}\n\ntype QueryResponse struct {\n    Results []map[string]interface{} // Query results\n    Cursor  string                   // Next page cursor\n    Stats   map[string]interface{}   // Query statistics\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#error-handling","title":"Error Handling","text":""},{"location":"6-developer-guide/sdks/go-sdk/#error-types","title":"Error Types","text":"<pre><code>// REST API errors\nif err != nil {\n    if strings.Contains(err.Error(), \"404\") {\n        fmt.Println(\"Resource not found\")\n    } else if strings.Contains(err.Error(), \"401\") {\n        fmt.Println(\"Authentication failed - check credentials\")\n    } else if strings.Contains(err.Error(), \"403\") {\n        fmt.Println(\"Permission denied\")\n    } else if strings.Contains(err.Error(), \"429\") {\n        fmt.Println(\"Rate limited - too many requests\")\n    } else if strings.Contains(err.Error(), \"500\") {\n        fmt.Println(\"Server error\")\n    }\n}\n\n// Sensor-specific errors\nsensor := org.GetSensor(\"invalid-sid\")\nif sensor.LastError != nil {\n    log.Printf(\"Error getting sensor: %v\", sensor.LastError)\n}\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#retry-logic","title":"Retry Logic","text":"<p>The SDK includes automatic retry for transient failures (401, 429, 504).</p>"},{"location":"6-developer-guide/sdks/go-sdk/#best-practices","title":"Best Practices","text":""},{"location":"6-developer-guide/sdks/go-sdk/#1-authentication-security","title":"1. Authentication Security","text":"<ul> <li>Store API keys in environment variables or secure vaults, never in code</li> <li>Use JWT tokens with minimal required permissions</li> <li>Rotate API keys regularly</li> <li>Never commit credentials to version control</li> </ul>"},{"location":"6-developer-guide/sdks/go-sdk/#2-resource-management","title":"2. Resource Management","text":"<ul> <li>Always call <code>org.Close()</code> when done</li> <li>Use <code>defer spout.Shutdown()</code> to ensure cleanup</li> <li>Close FutureResults when done: <code>defer future.Close()</code></li> </ul>"},{"location":"6-developer-guide/sdks/go-sdk/#3-performance-optimization","title":"3. Performance Optimization","text":"<ul> <li>Use concurrent operations for batch processing</li> <li>Use pagination for large result sets</li> <li>Set appropriate timeouts for long-running operations</li> <li>Use selectors to filter sensors server-side</li> </ul>"},{"location":"6-developer-guide/sdks/go-sdk/#firehose-cli-tool_1","title":"Firehose CLI Tool","text":"<p>The <code>firehose</code> module provides a standalone CLI tool for streaming LimaCharlie data to local applications via TCP.</p>"},{"location":"6-developer-guide/sdks/go-sdk/#installation_1","title":"Installation","text":"<pre><code>go install github.com/refractionPOINT/go-limacharlie/firehose@latest\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#usage","title":"Usage","text":"<pre><code># Basic usage (will prompt for API key)\nfirehose --listen_interface 0.0.0.0:4444 --data_type event --oid your-org-id\n\n# Use environment variables for credentials\nexport LC_OID=your-org-id\nexport LC_API_KEY=your-api-key\nfirehose --listen_interface 0.0.0.0:4444 --data_type event --use-env\n\n# Filter by investigation ID\nfirehose --listen_interface 0.0.0.0:4444 --data_type event -i investigation-id --use-env\n\n# Filter by sensor tag\nfirehose --listen_interface 0.0.0.0:4444 --data_type event -t production --use-env\n\n# Filter detections by category\nfirehose --listen_interface 0.0.0.0:4444 --data_type detect -c malware --use-env\n\n# Named firehose (auto-creates Output configuration)\nfirehose --listen_interface 0.0.0.0:4444 --data_type event -n my-firehose --use-env\n</code></pre>"},{"location":"6-developer-guide/sdks/go-sdk/#parameters","title":"Parameters","text":"<ul> <li><code>--listen_interface</code>: IP:port to listen on (required, e.g., <code>0.0.0.0:4444</code>)</li> <li><code>--data_type</code>: Type of data to stream (required: <code>event</code>, <code>detect</code>, <code>audit</code>, <code>deployment</code>, <code>artifact</code>)</li> <li><code>--oid</code>: Organization ID (optional, uses environment if not specified)</li> <li><code>-n, --name</code>: Unique firehose name (optional, auto-creates Output if specified)</li> <li><code>-i, --investigation-id</code>: Filter by investigation ID</li> <li><code>-t, --tag</code>: Filter by sensor tag</li> <li><code>-c, --category</code>: Filter by detection category</li> <li><code>--use-env</code>: Use environment variables for API key instead of prompting</li> </ul>"},{"location":"6-developer-guide/sdks/go-sdk/#additional-resources","title":"Additional Resources","text":"<ul> <li>GitHub Repository: github.com/refractionPOINT/go-limacharlie</li> <li>API Documentation: api.limacharlie.io/openapi</li> <li>LimaCharlie Documentation: docs.limacharlie.io</li> <li>LCQL Query Language: docs.limacharlie.io/docs/query-language</li> <li>Detection &amp; Response Rules: docs.limacharlie.io/docs/detection-and-response</li> <li>Community Support: community.limacharlie.io</li> <li>Commercial Support: support@limacharlie.io</li> </ul>"},{"location":"6-developer-guide/sdks/go-sdk/#see-also","title":"See Also","text":"<ul> <li>SDK Overview</li> <li>Python SDK</li> <li>API Keys</li> </ul>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/","title":"Documentation Regeneration Recipe for LimaCharlie Python SDK","text":""},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#purpose","title":"Purpose","text":"<p>This recipe enables future Claude Code instances to regenerate comprehensive documentation for the LimaCharlie Python SDK when the SDK code changes.</p>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#prerequisites","title":"Prerequisites","text":"<ul> <li>Access to the LimaCharlie Python SDK repository: https://github.com/refractionPOINT/python-limacharlie/</li> <li>Access to LimaCharlie documentation (if available in markdown format)</li> <li>Access to the LimaCharlie OpenAPI spec: https://api.limacharlie.io/openapi</li> </ul>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#step-by-step-instructions","title":"Step-by-Step Instructions","text":""},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#1-repository-analysis","title":"1. Repository Analysis","text":"<pre><code># Clone the latest SDK\ngit clone https://github.com/refractionPOINT/python-limacharlie.git /tmp/python-limacharlie\n</code></pre> <p>Then analyze these key files in order: - <code>/limacharlie/__init__.py</code> - Version, imports, and global configuration - <code>/limacharlie/Manager.py</code> - Main entry point class (read first 500+ lines) - <code>/limacharlie/Sensor.py</code> - Individual sensor management - <code>/limacharlie/Firehose.py</code> - Push-based streaming - <code>/limacharlie/Spout.py</code> - Pull-based streaming - <code>/limacharlie/DRCli.py</code> - Detection &amp; Response CLI interface - <code>/limacharlie/Sync.py</code> - Configuration synchronization - <code>/limacharlie/Payloads.py</code> - Artifact management - <code>/limacharlie/Hive.py</code> - Key-value storage - <code>/limacharlie/Query.py</code> - Query builder - <code>/limacharlie/Replay.py</code> - Event replay - <code>/limacharlie/Jobs.py</code> - Background jobs - <code>/limacharlie/Extensions.py</code> - Add-on management - <code>/limacharlie/Billing.py</code> - Billing operations - <code>/limacharlie/User.py</code> and <code>/limacharlie/UserPreferences.py</code> - User management - <code>/limacharlie/Webhook.py</code> and <code>/limacharlie/WebhookSender.py</code> - Webhook operations - <code>/limacharlie/utils.py</code> - Utility functions and exceptions - <code>/limacharlie/constants.py</code> - Constants and configuration paths</p>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#2-examine-sample-code","title":"2. Examine Sample Code","text":"<p>Review the <code>/samples/</code> directory for real-world usage patterns: - <code>demo_manager.py</code> - Basic manager operations - <code>demo_firehose.py</code> - Streaming implementation - <code>demo_interactive_sensor.py</code> - Interactive sensor control - <code>demo_spout.py</code> - Spout usage - <code>demo_delete_duplicate_sensors.py</code> - Practical automation</p>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#3-api-documentation-analysis","title":"3. API Documentation Analysis","text":"<p>Fetch and analyze the OpenAPI spec: <pre><code>URL: https://api.limacharlie.io/openapi\n```yaml\nExtract:\n- Available endpoints and their purposes\n- Required parameters for each endpoint\n- Authentication methods\n- Response formats\n- Error codes\n\n### 4. Documentation Structure\n\nCreate a comprehensive README.md with these sections:\n\n#### Required Sections (in order):\n1. **Overview** \n   - Brief platform description\n   - Key features list\n   - Current SDK version (from `__version__`)\n\n2. **Installation**\n   - pip install command\n   - Requirements from `requirements.txt`\n   - Python version compatibility\n   - Dependencies\n\n3. **Authentication**\n   - API Key authentication (most common)\n   - OAuth authentication (from oauth_*.py files)\n   - JWT token usage\n   - Environment-based auth (LC_OID, LC_API_KEY)\n   - Configuration file format (~/.limacharlie)\n   - Multiple environment support\n\n4. **Core Classes**\n   - Class hierarchy diagram\n   - Brief description of each class's purpose\n\n5. **Manager Class** (Most important - be thorough!)\n   - Initialization parameters (ALL of them with descriptions)\n   - Organization management methods\n   - Sensor listing and search\n   - Installation key management\n   - Detection &amp; Response rule management\n   - Output management\n   - Artifact operations\n   - Service management\n   - Include return types for each method\n\n6. **Sensor Management**\n   - Creating sensor objects\n   - Getting sensor information\n   - Sending tasks (single and multiple)\n   - Interactive task execution with futures\n   - Sensor isolation/rejoin\n   - Tag management\n   - Common sensor tasks list (os_info, file_get, etc.)\n\n7. **Detection and Response Rules**\n   - D&amp;RL structure explanation\n   - Detection operators (is, contains, matches, and, or, etc.)\n   - Response actions (report, task, isolate, add_tag)\n   - Complete rule examples\n   - FalsePositive rules\n\n8. **Real-time Data Streaming**\n   - Firehose (push) - full initialization parameters\n   - Spout (pull) - full initialization parameters\n   - Event filtering options\n   - Processing patterns\n\n9. **Artifacts and Payloads**\n   - Artifact listing and retrieval\n   - Payload creation and management\n   - Using payloads in tasks\n\n10. **Event Ingestion**\n    - Custom event ingestion\n    - Third-party log integration examples\n\n11. **Advanced Features**\n    - Hive operations (key-value storage)\n    - LCQL query language\n    - Replay functionality\n    - Jobs management\n    - Extensions\n    - Sync operations\n\n12. **Error Handling**\n    - LcApiException usage\n    - Retry logic\n    - Quota error handling\n    - Common error scenarios\n\n13. **Complete Examples** (3 comprehensive examples)\n    - Automated Threat Hunting\n    - Incident Response Automation\n    - Compliance and Audit Automation\n\n14. **Best Practices**\n    - Performance optimization\n    - Security practices\n    - Error handling patterns\n\n15. **Troubleshooting**\n    - Common issues and solutions\n\n### 5. Code Analysis Guidelines\n\nWhen analyzing code:\n\n#### Method Documentation Pattern:\n```python\n# For each public method, document:\nmethod_name(param1, param2, ...)\n  Parameters:\n    - param1 (type): description\n    - param2 (type): description\n  Returns:\n    type: description\n  Example:\n    code example\n</code></pre></p>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#focus-areas","title":"Focus Areas:","text":"<ol> <li>Manager class methods - Document ALL public methods</li> <li>Required vs optional parameters - Be explicit</li> <li>Return value structures - Show example responses</li> <li>Error conditions - What exceptions are raised</li> <li>Deprecation notices - Flag any deprecated methods</li> </ol>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#6-example-generation-rules","title":"6. Example Generation Rules","text":"<p>For each major feature, create: 1. Basic usage example - Minimal working code 2. Advanced usage example - With error handling and options 3. Real-world scenario - Practical implementation</p> <p>Include these patterns: - Authentication setup - Error handling with try/except - Resource cleanup (shutdown() calls) - Timeout specifications - Batch operations vs individual calls</p>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#7-special-attention-areas","title":"7. Special Attention Areas","text":"<p>Pay extra attention to: 1. Authentication methods - Multiple ways to authenticate 2. Streaming differences - Firehose vs Spout use cases 3. Task command syntax - Exact format for sensor tasks 4. Detection rule syntax - D&amp;RL operators and structure 5. Investigation IDs - How they propagate through operations 6. Platform-specific features - Windows vs Linux vs macOS</p>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#8-documentation-style","title":"8. Documentation Style","text":"<ul> <li>Purpose: Optimize for LLM consumption</li> <li>Code blocks: Use ```python for all code</li> <li>Comments: Explain complex operations inline</li> <li>Return values: Always show example returns</li> <li>Parameters: Include type hints and whether optional</li> <li>Links: Reference classes with proper paths (e.g., <code>/limacharlie/Manager.py:line_number</code>)</li> </ul>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#9-validation-checklist","title":"9. Validation Checklist","text":"<p>Before finalizing, ensure: - [ ] All public methods are documented - [ ] Authentication section covers all methods - [ ] At least 3 complete, runnable examples - [ ] Error handling is demonstrated - [ ] Common sensor tasks are listed - [ ] D&amp;R rule structure is explained with examples - [ ] Streaming (Firehose/Spout) differences are clear - [ ] Best practices section includes security guidance - [ ] Troubleshooting covers common issues</p>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#10-output-format","title":"10. Output Format","text":"<p>Generate a single comprehensive README.md file that: - Uses clear markdown formatting - Has a detailed table of contents - Includes extensive code examples - Shows both correct and incorrect usage (Good/Bad patterns) - Provides complete, copy-paste ready examples</p>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#execution-command","title":"Execution Command","text":"<p>To regenerate the documentation, provide this instruction to Claude Code:</p> <pre><code>Please regenerate the LimaCharlie Python SDK documentation following the recipe in REGENERATION_RECIPE.md. \n1. Clone the latest SDK from https://github.com/refractionPOINT/python-limacharlie/\n2. Analyze all core classes and methods\n3. Fetch the OpenAPI spec from https://api.limacharlie.io/openapi\n4. Generate comprehensive documentation optimized for LLM consumption\n5. Include at least 3 complete real-world examples\n6. Save as README.md in the python-sdk directory\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#notes-for-future-claude","title":"Notes for Future Claude","text":"<ul> <li>The SDK uses both Python 2 and 3 compatibility code, but focus on Python 3 patterns</li> <li>The Manager class is the most important - be extremely thorough with it</li> <li>Real-time streaming has two modes (push/pull) - explain when to use each</li> <li>Authentication can be complex - cover all methods clearly</li> <li>Include practical examples that combine multiple features</li> <li>Error handling is critical for production use - emphasize it</li> <li>The documentation should enable an LLM to write functional code without accessing the source</li> </ul>"},{"location":"6-developer-guide/sdks/python-sdk-regeneration/#version-tracking","title":"Version Tracking","text":"<p>When regenerating, note: - Current SDK version from <code>__version__</code> in <code>__init__.py</code> - Date of regeneration - Any major API changes discovered - New features or deprecated methods</p> <p>This recipe should enable consistent, high-quality documentation generation across SDK updates.</p>"},{"location":"6-developer-guide/sdks/python-sdk/","title":"LimaCharlie Python SDK Documentation","text":""},{"location":"6-developer-guide/sdks/python-sdk/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Installation</li> <li>Authentication</li> <li>Core Classes</li> <li>Manager Class</li> <li>Sensor Management</li> <li>Detection and Response Rules</li> <li>Real-time Data Streaming</li> <li>Artifacts and Payloads</li> <li>Event Ingestion</li> <li>Advanced Features</li> <li>Error Handling</li> <li>Complete Examples</li> </ol>"},{"location":"6-developer-guide/sdks/python-sdk/#overview","title":"Overview","text":"<p>The LimaCharlie Python SDK provides a comprehensive interface for interacting with the LimaCharlie SecOps Cloud Platform. This SDK enables programmatic access to all platform features including sensor management, detection and response rules, real-time event streaming, and artifact collection.</p>"},{"location":"6-developer-guide/sdks/python-sdk/#key-features","title":"Key Features","text":"<ul> <li>Organization Management: Create, configure, and manage LimaCharlie organizations</li> <li>Sensor Operations: Deploy, monitor, and control endpoint sensors</li> <li>Detection &amp; Response: Create and manage detection rules with automated response actions</li> <li>Real-time Streaming: Receive events, detections, and audit logs in real-time</li> <li>Artifact Management: Collect and manage forensic artifacts</li> <li>Event Processing: Ingest and query historical events</li> <li>API Integration: Full access to LimaCharlie REST API endpoints</li> </ul>"},{"location":"6-developer-guide/sdks/python-sdk/#sdk-version","title":"SDK Version","text":"<p>Current version: 4.9.24</p>"},{"location":"6-developer-guide/sdks/python-sdk/#installation","title":"Installation","text":""},{"location":"6-developer-guide/sdks/python-sdk/#requirements","title":"Requirements","text":"<ul> <li>Python 3.6 or higher</li> <li>pip package manager</li> </ul>"},{"location":"6-developer-guide/sdks/python-sdk/#install-via-pip","title":"Install via pip","text":"<pre><code>pip install limacharlie\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#install-from-source","title":"Install from source","text":"<pre><code>git clone https://github.com/refractionPOINT/python-limacharlie.git\ncd python-limacharlie\npip install -r requirements.txt\npython setup.py install\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#dependencies","title":"Dependencies","text":"<pre><code># Core dependencies\npyyaml&gt;=5.1\nrequests&gt;=2.20.0\npython-dateutil&gt;=2.8.0\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#authentication","title":"Authentication","text":""},{"location":"6-developer-guide/sdks/python-sdk/#authentication-methods","title":"Authentication Methods","text":"<p>The LimaCharlie SDK supports multiple authentication methods:</p> <ol> <li>API Key Authentication (Recommended for automation)</li> <li>OAuth Authentication (For user-based access)</li> <li>JWT Token Authentication (For temporary access)</li> <li>Environment-based Authentication (Using configuration files)</li> </ol>"},{"location":"6-developer-guide/sdks/python-sdk/#api-key-authentication","title":"API Key Authentication","text":"<pre><code>import limacharlie\n\n# Direct API key authentication\nmanager = limacharlie.Manager(\n    oid='YOUR_ORGANIZATION_ID',  # UUID format\n    secret_api_key='YOUR_API_KEY'  # UUID format\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#environment-based-authentication","title":"Environment-based Authentication","text":"<p>The SDK can read credentials from environment variables or configuration files:</p> <pre><code># Using environment variables\n# Set: LC_OID=\"your-org-id\"\n# Set: LC_API_KEY=\"your-api-key\"\nmanager = limacharlie.Manager()\n\n# Using a specific environment from config file\nmanager = limacharlie.Manager(environment='production')\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#configuration-file-format","title":"Configuration File Format","text":"<p>Create a file at <code>~/.limacharlie</code> or specify with <code>LC_CREDS_FILE</code> environment variable:</p> <pre><code># Default credentials\noid: \"12345678-1234-1234-1234-123456789012\"\napi_key: \"87654321-4321-4321-4321-210987654321\"\n\n# Named environments\nenv:\n  production:\n    oid: \"12345678-1234-1234-1234-123456789012\"\n    api_key: \"87654321-4321-4321-4321-210987654321\"\n\n  staging:\n    oid: \"87654321-4321-4321-4321-210987654321\"\n    api_key: \"12345678-1234-1234-1234-123456789012\"\n\n  dev:\n    oid: \"11111111-1111-1111-1111-111111111111\"\n    api_key: \"22222222-2222-2222-2222-222222222222\"\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#oauth-authentication","title":"OAuth Authentication","text":"<pre><code># OAuth configuration in ~/.limacharlie\noauth:\n  client_id: \"your-client-id\"\n  client_secret: \"your-client-secret\"\n  refresh_token: \"your-refresh-token\"\n  id_token: \"your-id-token\"\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#user-based-authentication","title":"User-based Authentication","text":"<pre><code># Authenticate as a user instead of organization\nmanager = limacharlie.Manager(\n    uid='USER_ID',\n    secret_api_key='USER_API_KEY'\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#core-classes","title":"Core Classes","text":""},{"location":"6-developer-guide/sdks/python-sdk/#class-hierarchy","title":"Class Hierarchy","text":"<pre><code>limacharlie\n\u251c\u2500\u2500 Manager           # Main entry point for API operations\n\u251c\u2500\u2500 Sensor           # Individual sensor management\n\u251c\u2500\u2500 Firehose         # Real-time data streaming (push)\n\u251c\u2500\u2500 Spout            # Real-time data streaming (pull)\n\u251c\u2500\u2500 Configs          # Configuration management\n\u251c\u2500\u2500 Payloads         # Artifact and payload management\n\u251c\u2500\u2500 Logs/Artifacts   # Log and artifact retrieval\n\u251c\u2500\u2500 Hive             # Hive data storage\n\u251c\u2500\u2500 Extensions       # Add-on extensions\n\u251c\u2500\u2500 Billing          # Billing and usage information\n\u251c\u2500\u2500 User             # User management\n\u251c\u2500\u2500 UserPreferences  # User preferences\n\u251c\u2500\u2500 Webhook          # Webhook management\n\u251c\u2500\u2500 WebhookSender    # Send data to webhooks\n\u251c\u2500\u2500 Jobs             # Background job management\n\u251c\u2500\u2500 Query            # Query builder for LCQL\n\u251c\u2500\u2500 Replay           # Event replay functionality\n\u251c\u2500\u2500 Search           # Search operations\n\u251c\u2500\u2500 SpotCheck        # Spot check operations\n\u2514\u2500\u2500 Replicants       # Service replicants (external services)\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#manager-class","title":"Manager Class","text":"<p>The <code>Manager</code> class is the primary entry point for interacting with LimaCharlie.</p>"},{"location":"6-developer-guide/sdks/python-sdk/#initialization","title":"Initialization","text":"<pre><code>import limacharlie\n\n# Basic initialization\nmanager = limacharlie.Manager(\n    oid='ORG_ID',\n    secret_api_key='API_KEY'\n)\n\n# Advanced initialization with all parameters\nmanager = limacharlie.Manager(\n    oid='ORG_ID',                    # Organization ID (UUID)\n    secret_api_key='API_KEY',        # API Key (UUID)\n    environment='production',        # Named environment from config\n    inv_id='investigation-123',      # Investigation ID for tracking\n    print_debug_fn=print,            # Debug output function\n    is_interactive=True,             # Enable interactive mode\n    extra_params={'key': 'value'},   # Additional parameters\n    jwt='existing-jwt-token',        # Use existing JWT\n    uid='USER_ID',                   # User ID for user-based auth\n    onRefreshAuth=callback_func,     # Callback on auth refresh\n    isRetryQuotaErrors=True         # Auto-retry on quota errors\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#core-manager-methods","title":"Core Manager Methods","text":""},{"location":"6-developer-guide/sdks/python-sdk/#organization-management","title":"Organization Management","text":"<pre><code># Get organization information\norg_info = manager.getOrgInfo()\n# Returns: {'oid': '...', 'name': '...', 'tier': '...', ...}\n\n# Get organization URLs\nurls = manager.getOrgURLs()\n# Returns: {'webapp': 'https://...', 'api': 'https://...', ...}\n\n# Get organization configuration\nconfig = manager.getOrgConfig()\n# Returns: {'sensor_quota': 100, 'retention': 30, ...}\n\n# Update organization configuration\nmanager.setOrgConfig({\n    'sensor_quota': 200,\n    'retention': 60\n})\n\n# Get billing information\nbilling = limacharlie.Billing(manager)\nbilling_info = billing.getInfo()\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#sensor-listing-and-search","title":"Sensor Listing and Search","text":"<pre><code># List all sensors\nsensors = manager.sensors()\n# Returns: {'sensor-id-1': {...}, 'sensor-id-2': {...}, ...}\n\n# List sensors with details\ndetailed_sensors = manager.sensors(with_details=True)\n\n# Get sensor count\nonline_count = manager.getOnlineHosts()\n# Returns: 42\n\n# Search sensors by hostname\nmatching_sensors = manager.getHostnames(['web-server-*', 'db-*'])\n# Returns: {'web-server-01': 'sensor-id-1', ...}\n\n# Get sensors by tag\ntagged_sensors = manager.getSensorsWithTag('production')\n# Returns: ['sensor-id-1', 'sensor-id-2', ...]\n\n# Get sensor information\nsensor_info = manager.getSensorInfo('SENSOR_ID')\n# Returns: {'hostname': '...', 'platform': '...', 'architecture': '...', ...}\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#installation-keys","title":"Installation Keys","text":"<pre><code># List installation keys\nkeys = manager.getInstallationKeys()\n# Returns: [{'key': '...', 'tags': [...], 'desc': '...', ...}, ...]\n\n# Create new installation key\nnew_key = manager.setInstallationKey(\n    key_name='prod-servers',\n    tags=['production', 'server'],\n    desc='Production server deployment key'\n)\n# Returns: 'INSTALLATION_KEY_STRING'\n\n# Delete installation key\nmanager.delInstallationKey('INSTALLATION_KEY_ID')\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#outputs-management","title":"Outputs Management","text":"<pre><code># List all outputs\noutputs = manager.outputs()\n# Returns: {'output1': {...}, 'output2': {...}, ...}\n\n# Add new output\nmanager.add_output(\n    name='siem_output',\n    module='syslog',\n    type='detect',\n    config={\n        'dest_host': 'siem.example.com',\n        'dest_port': 514,\n        'protocol': 'tcp'\n    }\n)\n\n# Delete output\nmanager.del_output('siem_output')\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#artifact-collection","title":"Artifact Collection","text":"<pre><code># List available artifacts\nartifacts = manager.getArtifacts(\n    start_time=1234567890,  # Unix timestamp\n    end_time=1234567999\n)\n\n# Get specific artifact\nartifact_data = manager.getArtifact('ARTIFACT_ID')\n\n# Get artifact as JSON\nartifact_json = manager.getArtifactAsJson('ARTIFACT_ID')\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#service-management","title":"Service Management","text":"<pre><code># List services\nservices = manager.getServices()\n\n# Subscribe to a service\nmanager.subscribeToService('virustotal')\n\n# Unsubscribe from service\nmanager.unsubscribeFromService('virustotal')\n\n# Get service configuration\nservice_config = manager.getServiceConfig('virustotal')\n\n# Update service configuration\nmanager.setServiceConfig('virustotal', {\n    'api_key': 'YOUR_VT_API_KEY'\n})\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#sensor-management","title":"Sensor Management","text":"<p>The <code>Sensor</code> class provides detailed control over individual sensors.</p>"},{"location":"6-developer-guide/sdks/python-sdk/#creating-a-sensor-object","title":"Creating a Sensor Object","text":"<pre><code># Create from Manager\nsensor = manager.sensor('SENSOR_ID')\n\n# Direct instantiation\nfrom limacharlie import Sensor\nsensor = Sensor(manager, 'SENSOR_ID')\n\n# With detailed info pre-loaded\nsensor = Sensor(manager, 'SENSOR_ID', detailedInfo={...})\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#sensor-properties-and-methods","title":"Sensor Properties and Methods","text":""},{"location":"6-developer-guide/sdks/python-sdk/#getting-sensor-information","title":"Getting Sensor Information","text":"<pre><code># Check if sensor is online\nis_online = sensor.isOnline()\n# Returns: True/False\n\n# Get sensor hostname\nhostname = sensor.getHostname()\n# Returns: 'web-server-01'\n\n# Get platform information\nplatform = sensor.getPlatform()\n# Returns: 'windows', 'linux', 'macos', etc.\n\n# Get architecture\narchitecture = sensor.getArchitecture()\n# Returns: 'x64', 'x86', 'arm64', etc.\n\n# Get full sensor information\ninfo = sensor.getInfo()\n# Returns: {'hostname': '...', 'platform': '...', 'last_seen': ..., ...}\n\n# Get sensor tags\ntags = sensor.getTags()\n# Returns: ['production', 'web-server', ...]\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#sending-tasks-to-sensors","title":"Sending Tasks to Sensors","text":"<pre><code># Send a single task\nresponse = sensor.task('os_info')\n\n# Send multiple tasks\nresponses = sensor.task([\n    'os_info',\n    'os_packages',\n    'os_services'\n])\n\n# Task with investigation ID\nsensor.setInvId('investigation-123')\nresponse = sensor.task('os_processes')\n\n# Direct task with inv_id\nresponse = sensor.task('os_processes', inv_id='investigation-456')\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#interactive-task-execution","title":"Interactive Task Execution","text":"<pre><code># Manager must be in interactive mode\nmanager = limacharlie.Manager(\n    oid='ORG_ID',\n    secret_api_key='API_KEY',\n    is_interactive=True,\n    inv_id='investigation-123'\n)\n\nsensor = manager.sensor('SENSOR_ID')\n\n# Request with future results\nfuture = sensor.request('os_info')\n\n# Wait for results\nresult = future.getNewResponses(timeout=30)\n\n# Simple request (blocking)\nresult = sensor.simpleRequest('os_info', timeout=30)\n\n# Request with completion tracking\nresults = sensor.simpleRequest(\n    ['os_info', 'os_processes'],\n    timeout=60,\n    until_completion=True  # Wait for all tasks to complete\n)\n\n# Request with callback\ndef process_response(event):\n    print(f\"Received: {event}\")\n\nsensor.simpleRequest(\n    'os_processes',\n    timeout=30,\n    until_completion=process_response  # Called for each response\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#sensor-isolation","title":"Sensor Isolation","text":"<pre><code># Isolate sensor from network\nsensor.isolate()\n\n# Re-join sensor to network\nsensor.rejoin()\n\n# Check isolation status\nis_isolated = sensor.isIsolated()\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#sensor-management_1","title":"Sensor Management","text":"<pre><code># Tag management\nsensor.addTag('critical')\nsensor.removeTag('test')\n\n# Wait for sensor to come online\ncame_online = sensor.waitToComeOnline(timeout=300)  # 5 minutes\n# Returns: True if online, False if timeout\n\n# Delete sensor\nsensor.delete()\n\n# Drain sensor (mark for deletion after offline)\nsensor.drain()\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#available-sensor-tasks","title":"Available Sensor Tasks","text":"<p>Common tasks that can be sent to sensors:</p> <pre><code># System Information\n'os_info'           # Get OS information\n'os_packages'       # List installed packages\n'os_services'       # List running services\n'os_processes'      # List running processes\n'os_autoruns'       # List autorun entries\n'os_drivers'        # List loaded drivers\n\n# File Operations\n'file_info &lt;path&gt;'  # Get file information\n'file_get &lt;path&gt;'   # Retrieve file content\n'file_del &lt;path&gt;'   # Delete file\n'file_mov &lt;src&gt; &lt;dst&gt;'  # Move file\n'file_hash &lt;path&gt;'  # Get file hash\n\n# Process Operations\n'mem_map &lt;pid&gt;'     # Get process memory map\n'mem_read &lt;pid&gt; &lt;address&gt; &lt;size&gt;'  # Read process memory\n'mem_strings &lt;pid&gt;' # Get process strings\n'kill &lt;pid&gt;'        # Kill process\n\n# Network Operations\n'netstat'           # Get network connections\n'dns_resolve &lt;domain&gt;'  # Resolve DNS\n\n# Registry Operations (Windows)\n'reg_list &lt;path&gt;'   # List registry keys\n'reg_get &lt;path&gt;'    # Get registry value\n\n# History and Forensics\n'history_dump'      # Dump sensor history\n'hidden_module_scan'  # Scan for hidden modules\n'exec_oob_scan'     # Out-of-band executable scan\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#detection-and-response-rules","title":"Detection and Response Rules","text":"<p>Note: The direct D&amp;R rule methods (<code>rules()</code>, <code>add_rule()</code>, <code>del_rule()</code>, <code>add_fp()</code>, <code>del_fp()</code>) are deprecated. Please use the Hive accessors instead for managing Detection &amp; Response rules. See the Hive Operations section for details on using the key-value storage system for rule management.</p>"},{"location":"6-developer-guide/sdks/python-sdk/#real-time-data-streaming","title":"Real-time Data Streaming","text":""},{"location":"6-developer-guide/sdks/python-sdk/#firehose-push-based-streaming","title":"Firehose (Push-based Streaming)","text":"<p>The Firehose class receives data pushed from LimaCharlie:</p> <pre><code>import limacharlie\n\nmanager = limacharlie.Manager('ORG_ID', 'API_KEY')\n\n# Create a Firehose for events\nfirehose = limacharlie.Firehose(\n    manager,\n    listen_on='0.0.0.0:4443',  # Listen interface and port\n    data_type='event',          # event, detect, or audit\n    name='my_firehose',         # Output name in LC\n    public_dest='1.2.3.4:4443', # Public IP:port for LC to connect\n    ssl_cert='/path/to/cert.pem',  # Optional SSL cert\n    ssl_key='/path/to/key.pem',    # Optional SSL key\n    is_parse=True,              # Parse JSON automatically\n    max_buffer=1024,            # Max messages to buffer\n    inv_id='investigation-123', # Filter by investigation ID\n    tag='production',           # Filter by sensor tag\n    sid='SENSOR_ID'            # Filter by sensor ID\n)\n\n# Start receiving data\nfirehose.start()\n\n# Process events\nwhile True:\n    event = firehose.queue.get()\n    print(f\"Received event: {event}\")\n\n    # Process event\n    if event.get('event_type') == 'PROCESS_START':\n        process_path = event.get('event', {}).get('FILE_PATH')\n        print(f\"Process started: {process_path}\")\n\n# Shutdown\nfirehose.shutdown()\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#spout-pull-based-streaming","title":"Spout (Pull-based Streaming)","text":"<p>The Spout class pulls data from LimaCharlie:</p> <pre><code># Create a Spout for detections\nspout = limacharlie.Spout(\n    manager,\n    data_type='detect',      # event, detect, audit, or tailored\n    is_parse=True,           # Parse JSON\n    inv_id='investigation-123',\n    tag='critical',\n    cat='malware',           # Detection category filter\n    sid='SENSOR_ID',\n    is_compressed=True,      # Use compression\n    rel_parent_events=True,  # Include parent events\n    rel_child_events=True    # Include child events\n)\n\n# Process detections\nfor detection in spout:\n    print(f\"Detection: {detection['detect_name']}\")\n    print(f\"Sensor: {detection['sid']}\")\n    print(f\"Event: {detection['event']}\")\n\n    # Take action based on detection\n    if detection['detect_name'] == 'ransomware_behavior':\n        sensor = manager.sensor(detection['sid'])\n        sensor.isolate()\n\n# Shutdown\nspout.shutdown()\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#tailored-event-streaming","title":"Tailored Event Streaming","text":"<pre><code># Stream specific event types\nspout = limacharlie.Spout(\n    manager,\n    data_type='tailored',\n    event_type=['PROCESS_START', 'NETWORK_CONNECT'],\n    is_parse=True\n)\n\nfor event in spout:\n    if event['event_type'] == 'PROCESS_START':\n        print(f\"Process: {event['event']['FILE_PATH']}\")\n    elif event['event_type'] == 'NETWORK_CONNECT':\n        print(f\"Connection: {event['event']['DESTINATION']}\")\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#artifacts-and-payloads","title":"Artifacts and Payloads","text":""},{"location":"6-developer-guide/sdks/python-sdk/#managing-artifacts","title":"Managing Artifacts","text":"<pre><code># Initialize Artifacts/Logs manager\nartifacts = limacharlie.Artifacts(manager)\n\n# List artifacts in time range\nartifact_list = artifacts.listArtifacts(\n    start_time=1234567890,\n    end_time=1234567999,\n    sid='SENSOR_ID',  # Optional: filter by sensor\n    type='log'        # Optional: filter by type\n)\n\n# Get specific artifact\nartifact_data = artifacts.getArtifact('ARTIFACT_ID')\n\n# Get artifact metadata\nmetadata = artifacts.getArtifactMetadata('ARTIFACT_ID')\n\n# Delete artifact\nartifacts.deleteArtifact('ARTIFACT_ID')\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#payloads-management","title":"Payloads Management","text":"<pre><code># Initialize Payloads manager\npayloads = limacharlie.Payloads(manager)\n\n# List available payloads\npayload_list = payloads.list()\n\n# Create a new payload\npayload_id = payloads.create(\n    name='custom_script',\n    data=b'#!/bin/bash\\necho \"Hello World\"',\n    description='Custom bash script'\n)\n\n# Get payload\npayload_data = payloads.get('PAYLOAD_ID')\n\n# Delete payload\npayloads.delete('PAYLOAD_ID')\n\n# Use payload in a task\nsensor.task(f'run_payload {payload_id}')\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#event-ingestion","title":"Event Ingestion","text":""},{"location":"6-developer-guide/sdks/python-sdk/#ingesting-custom-events","title":"Ingesting Custom Events","text":"<pre><code># Ingest a single event\nmanager.ingestEvent({\n    'event_type': 'CUSTOM_EVENT',\n    'timestamp': 1234567890,\n    'data': {\n        'key': 'value',\n        'severity': 'high'\n    }\n})\n\n# Batch ingestion\nevents = [\n    {\n        'event_type': 'CUSTOM_LOGIN',\n        'timestamp': 1234567890,\n        'user': 'admin',\n        'source_ip': '192.168.1.100'\n    },\n    {\n        'event_type': 'CUSTOM_FILE_ACCESS',\n        'timestamp': 1234567891,\n        'file': '/etc/passwd',\n        'user': 'admin'\n    }\n]\n\nfor event in events:\n    manager.ingestEvent(event)\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#ingesting-third-party-logs","title":"Ingesting Third-party Logs","text":"<pre><code># Ingest syslog events\ndef ingest_syslog(syslog_line):\n    # Parse syslog format\n    parsed = parse_syslog(syslog_line)\n\n    manager.ingestEvent({\n        'event_type': 'SYSLOG',\n        'timestamp': parsed['timestamp'],\n        'hostname': parsed['hostname'],\n        'facility': parsed['facility'],\n        'severity': parsed['severity'],\n        'message': parsed['message']\n    })\n\n# Ingest Windows Event Logs\ndef ingest_windows_event(event_xml):\n    # Parse Windows Event XML\n    parsed = parse_windows_event(event_xml)\n\n    manager.ingestEvent({\n        'event_type': 'WINDOWS_EVENT',\n        'timestamp': parsed['TimeCreated'],\n        'event_id': parsed['EventID'],\n        'provider': parsed['Provider'],\n        'level': parsed['Level'],\n        'data': parsed['EventData']\n    })\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#advanced-features","title":"Advanced Features","text":""},{"location":"6-developer-guide/sdks/python-sdk/#hive-operations","title":"Hive Operations","text":"<p>The Hive is LimaCharlie's key-value storage system:</p> <pre><code># Initialize Hive\nhive = limacharlie.Hive(manager)\n\n# Store data\nhive_record = limacharlie.HiveRecord(\n    hive_name='threat_intel',\n    key='malware_hash_123',\n    data={\n        'hash': 'abc123...',\n        'type': 'ransomware',\n        'first_seen': 1234567890\n    },\n    ttl=86400  # TTL in seconds\n)\nhive.set(hive_record)\n\n# Get data\nrecord = hive.get('threat_intel', 'malware_hash_123')\nprint(record.data)\n\n# List keys\nkeys = hive.list('threat_intel')\n\n# Delete data\nhive.delete('threat_intel', 'malware_hash_123')\n\n# Bulk operations\nrecords = [\n    limacharlie.HiveRecord('intel', f'hash_{i}', {'value': i})\n    for i in range(100)\n]\nhive.setBulk(records)\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#query-language-lcql","title":"Query Language (LCQL)","text":"<pre><code>from limacharlie import Query\n\n# Build queries programmatically\nquery = Query()\n\n# Simple query\nresults = manager.query(\n    query='event_type == \"PROCESS_START\" AND event.FILE_PATH contains \"powershell\"',\n    limit=100\n)\n\n# Complex query with time range\nresults = manager.query(\n    query='''\n        event_type == \"NETWORK_CONNECT\" \n        AND event.DESTINATION contains \"suspicious.com\"\n        AND timestamp &gt; now() - 86400\n    ''',\n    start_time=time.time() - 86400,\n    end_time=time.time(),\n    limit=1000\n)\n\n# Query with aggregation\nresults = manager.query(\n    query='event_type == \"PROCESS_START\"',\n    select=['event.FILE_PATH', 'count()'],\n    group_by=['event.FILE_PATH'],\n    order_by='count() DESC'\n)\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#replay-functionality","title":"Replay Functionality","text":"<pre><code># Initialize Replay\nreplay = limacharlie.Replay(manager)\n\n# Start replay of historical events\nreplay.start(\n    start_time=time.time() - 3600,  # 1 hour ago\n    end_time=time.time(),\n    filters={\n        'event_type': ['PROCESS_START', 'FILE_CREATE'],\n        'sid': 'SENSOR_ID'\n    },\n    rules=['suspicious_process', 'ransomware_behavior']  # Test specific rules\n)\n\n# Get replay results\nresults = replay.getResults()\nfor result in results:\n    print(f\"Rule triggered: {result['rule_name']}\")\n    print(f\"Event: {result['event']}\")\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#jobs-management","title":"Jobs Management","text":"<pre><code># Create a job\njob = limacharlie.Job(manager)\n\njob_id = job.create(\n    name='daily_scan',\n    schedule='0 2 * * *',  # Cron format\n    task='full_scan',\n    sensors=['SENSOR_ID_1', 'SENSOR_ID_2']\n)\n\n# List jobs\njobs = job.list()\n\n# Get job status\nstatus = job.getStatus('JOB_ID')\n\n# Cancel job\njob.cancel('JOB_ID')\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#extensions-management","title":"Extensions Management","text":"<pre><code># Initialize Extensions\nextensions = limacharlie.Extension(manager)\n\n# List available extensions\navailable = extensions.list()\n\n# Install extension\nextensions.install('velociraptor')\n\n# Configure extension\nextensions.configure('velociraptor', {\n    'api_key': 'YOUR_API_KEY',\n    'server_url': 'https://velociraptor.example.com'\n})\n\n# Uninstall extension\nextensions.uninstall('velociraptor')\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#error-handling","title":"Error Handling","text":""},{"location":"6-developer-guide/sdks/python-sdk/#exception-types","title":"Exception Types","text":"<pre><code>from limacharlie.utils import LcApiException\n\ntry:\n    manager = limacharlie.Manager('INVALID_OID', 'INVALID_KEY')\nexcept LcApiException as e:\n    print(f\"API Error: {e}\")\n    # Handle authentication error\n\ntry:\n    sensor = manager.sensor('INVALID_SENSOR_ID')\n    sensor.task('os_info')\nexcept LcApiException as e:\n    if 'not found' in str(e):\n        print(\"Sensor not found\")\n    elif 'offline' in str(e):\n        print(\"Sensor is offline\")\n    else:\n        print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#retry-logic","title":"Retry Logic","text":"<pre><code>import time\nfrom limacharlie.utils import LcApiException\n\ndef retry_operation(func, max_retries=3, delay=1):\n    \"\"\"Retry an operation with exponential backoff\"\"\"\n    for attempt in range(max_retries):\n        try:\n            return func()\n        except LcApiException as e:\n            if 'rate limit' in str(e).lower():\n                wait_time = delay * (2 ** attempt)\n                print(f\"Rate limited, waiting {wait_time}s...\")\n                time.sleep(wait_time)\n            else:\n                raise\n    raise Exception(f\"Failed after {max_retries} attempts\")\n\n# Usage\nresult = retry_operation(lambda: manager.sensors())\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#handling-quota-errors","title":"Handling Quota Errors","text":"<pre><code># Enable automatic retry on quota errors\nmanager = limacharlie.Manager(\n    oid='ORG_ID',\n    secret_api_key='API_KEY',\n    isRetryQuotaErrors=True  # Auto-retry on HTTP 429\n)\n\n# Manual handling\ntry:\n    sensors = manager.sensors()\nexcept LcApiException as e:\n    if e.http_code == 429:  # Too Many Requests\n        retry_after = e.headers.get('Retry-After', 60)\n        print(f\"Quota exceeded, retry after {retry_after}s\")\n        time.sleep(int(retry_after))\n        sensors = manager.sensors()  # Retry\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#complete-examples","title":"Complete Examples","text":""},{"location":"6-developer-guide/sdks/python-sdk/#example-1-automated-threat-hunting","title":"Example 1: Automated Threat Hunting","text":"<pre><code>import limacharlie\nimport time\nfrom datetime import datetime, timedelta\n\nclass ThreatHunter:\n    def __init__(self, org_id, api_key):\n        self.manager = limacharlie.Manager(org_id, api_key)\n        self.suspicious_processes = [\n            'mimikatz.exe',\n            'lazagne.exe',\n            'pwdump.exe',\n            'procdump.exe'\n        ]\n\n    def hunt_suspicious_processes(self):\n        \"\"\"Hunt for suspicious processes across all sensors\"\"\"\n        print(\"Starting threat hunt...\")\n\n        # Get all online sensors\n        sensors = self.manager.sensors()\n        online_sensors = [\n            sid for sid, info in sensors.items()\n            if info.get('online', False)\n        ]\n\n        print(f\"Found {len(online_sensors)} online sensors\")\n\n        findings = []\n\n        for sid in online_sensors:\n            sensor = self.manager.sensor(sid)\n            hostname = sensor.getHostname()\n\n            print(f\"Scanning {hostname}...\")\n\n            # Get running processes\n            try:\n                result = sensor.simpleRequest('os_processes', timeout=30)\n                if result and 'processes' in result:\n                    for process in result['processes']:\n                        process_name = process.get('name', '').lower()\n                        for suspicious in self.suspicious_processes:\n                            if suspicious.lower() in process_name:\n                                findings.append({\n                                    'sensor': sid,\n                                    'hostname': hostname,\n                                    'process': process_name,\n                                    'pid': process.get('pid'),\n                                    'path': process.get('path')\n                                })\n                                print(f\"  [!] Found suspicious process: {process_name}\")\n            except Exception as e:\n                print(f\"  Error scanning {hostname}: {e}\")\n\n        return findings\n\n    def monitor_detections(self, duration=3600):\n        \"\"\"Monitor for detections in real-time\"\"\"\n        print(f\"Monitoring detections for {duration} seconds...\")\n\n        spout = limacharlie.Spout(\n            self.manager,\n            data_type='detect',\n            is_parse=True\n        )\n\n        start_time = time.time()\n\n        try:\n            for detection in spout:\n                if time.time() - start_time &gt; duration:\n                    break\n\n                print(f\"\\n[DETECTION] {detection['detect_name']}\")\n                print(f\"  Sensor: {detection['hostname']} ({detection['sid']})\")\n                print(f\"  Time: {datetime.fromtimestamp(detection['ts'])}\")\n\n                # Auto-respond to critical detections\n                if detection.get('priority', 0) &gt;= 4:\n                    sensor = self.manager.sensor(detection['sid'])\n                    print(f\"  [!] High priority detection - isolating sensor\")\n                    sensor.isolate()\n\n                    # Collect forensics\n                    sensor.task([\n                        'history_dump',\n                        'os_processes',\n                        'netstat'\n                    ])\n        finally:\n            spout.shutdown()\n\n    def generate_hunt_report(self, findings):\n        \"\"\"Generate a hunting report\"\"\"\n        report = {\n            'timestamp': datetime.now().isoformat(),\n            'total_sensors': len(self.manager.sensors()),\n            'findings_count': len(findings),\n            'findings': findings,\n            'recommendations': []\n        }\n\n        if findings:\n            report['recommendations'].append(\n                \"Suspicious processes detected - investigate immediately\"\n            )\n            report['recommendations'].append(\n                \"Consider isolating affected systems\"\n            )\n            report['recommendations'].append(\n                \"Review process execution history on affected systems\"\n            )\n\n        return report\n\n# Usage\nif __name__ == \"__main__\":\n    hunter = ThreatHunter('ORG_ID', 'API_KEY')\n\n    # Hunt for suspicious processes\n    findings = hunter.hunt_suspicious_processes()\n\n    # Generate report\n    report = hunter.generate_hunt_report(findings)\n    print(f\"\\nHunt Report: {report}\")\n\n    # Monitor for new detections\n    hunter.monitor_detections(duration=3600)\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#example-2-incident-response-automation","title":"Example 2: Incident Response Automation","text":"<pre><code>import limacharlie\nimport json\nfrom datetime import datetime\nimport hashlib\n\nclass IncidentResponder:\n    def __init__(self, org_id, api_key):\n        self.manager = limacharlie.Manager(\n            org_id, \n            api_key,\n            is_interactive=True,\n            inv_id=f\"incident_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n        )\n        self.artifacts = limacharlie.Artifacts(self.manager)\n        self.hive = limacharlie.Hive(self.manager)\n\n    def respond_to_incident(self, sensor_id, incident_type):\n        \"\"\"Orchestrate incident response\"\"\"\n        print(f\"Responding to {incident_type} on sensor {sensor_id}\")\n\n        sensor = self.manager.sensor(sensor_id)\n        hostname = sensor.getHostname()\n\n        # Create incident record\n        incident = {\n            'id': hashlib.md5(f\"{sensor_id}{datetime.now()}\".encode()).hexdigest(),\n            'type': incident_type,\n            'sensor': sensor_id,\n            'hostname': hostname,\n            'timestamp': datetime.now().isoformat(),\n            'status': 'investigating',\n            'artifacts': [],\n            'actions': []\n        }\n\n        # Step 1: Isolate if critical\n        if incident_type in ['ransomware', 'data_theft', 'backdoor']:\n            print(f\"  Isolating {hostname}...\")\n            sensor.isolate()\n            incident['actions'].append({\n                'action': 'isolate',\n                'timestamp': datetime.now().isoformat()\n            })\n\n        # Step 2: Collect forensics\n        print(\"  Collecting forensic data...\")\n        forensics_tasks = [\n            'os_processes',\n            'netstat',\n            'os_autoruns',\n            'history_dump'\n        ]\n\n        for task in forensics_tasks:\n            try:\n                result = sensor.simpleRequest(task, timeout=60)\n                if result:\n                    # Store in Hive for analysis\n                    self.hive.set(limacharlie.HiveRecord(\n                        hive_name='incidents',\n                        key=f\"{incident['id']}_{task}\",\n                        data=result,\n                        ttl=2592000  # 30 days\n                    ))\n                    incident['artifacts'].append(task)\n            except Exception as e:\n                print(f\"    Failed to collect {task}: {e}\")\n\n        # Step 3: Collect memory dump for critical incidents\n        if incident_type in ['ransomware', 'backdoor']:\n            print(\"  Collecting memory dump...\")\n            try:\n                sensor.task('os_memory_dump')\n                incident['actions'].append({\n                    'action': 'memory_dump',\n                    'timestamp': datetime.now().isoformat()\n                })\n            except Exception as e:\n                print(f\"    Memory dump failed: {e}\")\n\n        # Step 4: Kill malicious processes\n        if incident_type == 'malware':\n            self.kill_malicious_processes(sensor)\n            incident['actions'].append({\n                'action': 'kill_processes',\n                'timestamp': datetime.now().isoformat()\n            })\n\n        # Step 5: Update incident status\n        incident['status'] = 'contained'\n        self.hive.set(limacharlie.HiveRecord(\n            hive_name='incidents',\n            key=incident['id'],\n            data=incident,\n            ttl=7776000  # 90 days\n        ))\n\n        return incident\n\n    def kill_malicious_processes(self, sensor):\n        \"\"\"Kill known malicious processes\"\"\"\n        malicious_patterns = [\n            'mimikatz',\n            'cobalt',\n            'empire',\n            'meterpreter'\n        ]\n\n        try:\n            result = sensor.simpleRequest('os_processes', timeout=30)\n            if result and 'processes' in result:\n                for process in result['processes']:\n                    process_name = process.get('name', '').lower()\n                    for pattern in malicious_patterns:\n                        if pattern in process_name:\n                            print(f\"    Killing {process_name} (PID: {process['pid']})\")\n                            sensor.task(f\"kill {process['pid']}\")\n        except Exception as e:\n            print(f\"    Error killing processes: {e}\")\n\n    def analyze_network_connections(self, sensor_id):\n        \"\"\"Analyze network connections for IOCs\"\"\"\n        sensor = self.manager.sensor(sensor_id)\n\n        try:\n            result = sensor.simpleRequest('netstat', timeout=30)\n            suspicious_connections = []\n\n            if result and 'connections' in result:\n                for conn in result['connections']:\n                    # Check for suspicious ports\n                    if conn.get('dst_port') in [4444, 5555, 31337, 1337]:\n                        suspicious_connections.append(conn)\n\n                    # Check for known C2 IPs (would come from threat intel)\n                    # This is a placeholder - real implementation would check against threat intel\n                    if conn.get('dst_ip') in ['1.2.3.4', '5.6.7.8']:\n                        suspicious_connections.append(conn)\n\n            return suspicious_connections\n        except Exception as e:\n            print(f\"Error analyzing network: {e}\")\n            return []\n\n    def generate_incident_timeline(self, incident_id):\n        \"\"\"Generate timeline of incident events\"\"\"\n        timeline = []\n\n        # Get incident data from Hive\n        incident = self.hive.get('incidents', incident_id)\n\n        if incident:\n            # Query events around incident time\n            results = self.manager.query(\n                query=f\"sid == '{incident.data['sensor']}'\",\n                start_time=datetime.fromisoformat(incident.data['timestamp']).timestamp() - 3600,\n                end_time=datetime.fromisoformat(incident.data['timestamp']).timestamp() + 3600,\n                limit=1000\n            )\n\n            for event in results:\n                timeline.append({\n                    'timestamp': event['ts'],\n                    'event_type': event['event_type'],\n                    'summary': self.summarize_event(event)\n                })\n\n        return sorted(timeline, key=lambda x: x['timestamp'])\n\n    def summarize_event(self, event):\n        \"\"\"Create human-readable event summary\"\"\"\n        event_type = event.get('event_type')\n\n        if event_type == 'PROCESS_START':\n            return f\"Process started: {event.get('event', {}).get('FILE_PATH', 'unknown')}\"\n        elif event_type == 'NETWORK_CONNECT':\n            return f\"Network connection to {event.get('event', {}).get('DESTINATION', 'unknown')}\"\n        elif event_type == 'FILE_CREATE':\n            return f\"File created: {event.get('event', {}).get('FILE_PATH', 'unknown')}\"\n        else:\n            return f\"Event: {event_type}\"\n\n# Usage\nif __name__ == \"__main__\":\n    responder = IncidentResponder('ORG_ID', 'API_KEY')\n\n    # Respond to a ransomware incident\n    incident = responder.respond_to_incident(\n        sensor_id='SENSOR_ID',\n        incident_type='ransomware'\n    )\n\n    print(f\"\\nIncident Response Complete:\")\n    print(json.dumps(incident, indent=2))\n\n    # Generate timeline\n    timeline = responder.generate_incident_timeline(incident['id'])\n    print(f\"\\nIncident Timeline: {len(timeline)} events\")\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#example-3-compliance-and-audit-automation","title":"Example 3: Compliance and Audit Automation","text":"<pre><code>import limacharlie\nimport csv\nfrom datetime import datetime, timedelta\nimport json\n\nclass ComplianceAuditor:\n    def __init__(self, org_id, api_key):\n        self.manager = limacharlie.Manager(org_id, api_key)\n        self.required_software = {\n            'windows': ['Windows Defender', 'BitLocker'],\n            'linux': ['auditd', 'aide'],\n            'macos': ['XProtect', 'Gatekeeper']\n        }\n\n    def audit_sensor_compliance(self, sensor_id):\n        \"\"\"Audit individual sensor for compliance\"\"\"\n        sensor = self.manager.sensor(sensor_id)\n\n        compliance_report = {\n            'sensor_id': sensor_id,\n            'hostname': sensor.getHostname(),\n            'platform': sensor.getPlatform(),\n            'timestamp': datetime.now().isoformat(),\n            'checks': {},\n            'compliant': True\n        }\n\n        # Check 1: Sensor online status\n        compliance_report['checks']['sensor_online'] = {\n            'status': sensor.isOnline(),\n            'required': True\n        }\n        if not sensor.isOnline():\n            compliance_report['compliant'] = False\n\n        # Check 2: Required software installed\n        if sensor.isOnline():\n            platform = sensor.getPlatform()\n            required = self.required_software.get(platform, [])\n\n            try:\n                result = sensor.simpleRequest('os_packages', timeout=60)\n                installed_packages = []\n\n                if result and 'packages' in result:\n                    installed_packages = [p.get('name', '') for p in result['packages']]\n\n                for software in required:\n                    found = any(software.lower() in pkg.lower() for pkg in installed_packages)\n                    compliance_report['checks'][f'software_{software}'] = {\n                        'status': found,\n                        'required': True\n                    }\n                    if not found:\n                        compliance_report['compliant'] = False\n            except Exception as e:\n                compliance_report['checks']['software_audit'] = {\n                    'status': False,\n                    'error': str(e)\n                }\n                compliance_report['compliant'] = False\n\n        # Check 3: Security patches\n        if sensor.isOnline():\n            try:\n                # Check for critical patches (platform-specific)\n                if platform == 'windows':\n                    result = sensor.simpleRequest('os_patches', timeout=60)\n                    if result:\n                        missing_critical = [\n                            p for p in result.get('missing', [])\n                            if p.get('severity') == 'Critical'\n                        ]\n                        compliance_report['checks']['critical_patches'] = {\n                            'status': len(missing_critical) == 0,\n                            'missing_count': len(missing_critical),\n                            'required': True\n                        }\n                        if missing_critical:\n                            compliance_report['compliant'] = False\n            except Exception as e:\n                pass  # Not all platforms support patch checking\n\n        return compliance_report\n\n    def audit_organization_compliance(self):\n        \"\"\"Audit entire organization for compliance\"\"\"\n        print(\"Starting organization-wide compliance audit...\")\n\n        sensors = self.manager.sensors()\n        audit_results = []\n\n        for sid in sensors:\n            print(f\"Auditing sensor {sid}...\")\n            report = self.audit_sensor_compliance(sid)\n            audit_results.append(report)\n\n        # Generate summary\n        summary = {\n            'timestamp': datetime.now().isoformat(),\n            'total_sensors': len(sensors),\n            'compliant_sensors': sum(1 for r in audit_results if r['compliant']),\n            'non_compliant_sensors': sum(1 for r in audit_results if not r['compliant']),\n            'compliance_rate': 0,\n            'details': audit_results\n        }\n\n        if summary['total_sensors'] &gt; 0:\n            summary['compliance_rate'] = (\n                summary['compliant_sensors'] / summary['total_sensors'] * 100\n            )\n\n        return summary\n\n    def generate_audit_log(self, days=30):\n        \"\"\"Generate audit log for compliance reporting\"\"\"\n\n        end_time = datetime.now()\n        start_time = end_time - timedelta(days=days)\n\n        # Query audit events\n        audit_events = self.manager.query(\n            query='event_type == \"AUDIT\"',\n            start_time=start_time.timestamp(),\n            end_time=end_time.timestamp(),\n            limit=10000\n        )\n\n        # Process and categorize audit events\n        audit_log = {\n            'period': {\n                'start': start_time.isoformat(),\n                'end': end_time.isoformat()\n            },\n            'events': {\n                'authentication': [],\n                'authorization': [],\n                'configuration_changes': [],\n                'data_access': []\n            },\n            'summary': {}\n        }\n\n        for event in audit_events:\n            event_data = event.get('event', {})\n            audit_type = event_data.get('type', 'unknown')\n\n            if 'auth' in audit_type.lower():\n                audit_log['events']['authentication'].append(event)\n            elif 'config' in audit_type.lower():\n                audit_log['events']['configuration_changes'].append(event)\n            elif 'access' in audit_type.lower():\n                audit_log['events']['data_access'].append(event)\n            else:\n                audit_log['events']['authorization'].append(event)\n\n        # Generate summary statistics\n        audit_log['summary'] = {\n            'total_events': len(audit_events),\n            'authentication_events': len(audit_log['events']['authentication']),\n            'configuration_changes': len(audit_log['events']['configuration_changes']),\n            'data_access_events': len(audit_log['events']['data_access'])\n        }\n\n        return audit_log\n\n    def export_compliance_report(self, audit_results, filename='compliance_report.csv'):\n        \"\"\"Export compliance audit results to CSV\"\"\"\n\n        with open(filename, 'w', newline='') as csvfile:\n            fieldnames = [\n                'sensor_id', 'hostname', 'platform', \n                'compliant', 'timestamp', 'issues'\n            ]\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n            writer.writeheader()\n            for result in audit_results['details']:\n                issues = []\n                for check, status in result['checks'].items():\n                    if not status.get('status', False):\n                        issues.append(check)\n\n                writer.writerow({\n                    'sensor_id': result['sensor_id'],\n                    'hostname': result['hostname'],\n                    'platform': result['platform'],\n                    'compliant': result['compliant'],\n                    'timestamp': result['timestamp'],\n                    'issues': ', '.join(issues)\n                })\n\n        print(f\"Compliance report exported to {filename}\")\n\n# Usage\nif __name__ == \"__main__\":\n    auditor = ComplianceAuditor('ORG_ID', 'API_KEY')\n\n    # Perform organization-wide audit\n    audit_results = auditor.audit_organization_compliance()\n\n    print(f\"\\nCompliance Audit Summary:\")\n    print(f\"  Total Sensors: {audit_results['total_sensors']}\")\n    print(f\"  Compliant: {audit_results['compliant_sensors']}\")\n    print(f\"  Non-Compliant: {audit_results['non_compliant_sensors']}\")\n    print(f\"  Compliance Rate: {audit_results['compliance_rate']:.1f}%\")\n\n    # Export results\n    auditor.export_compliance_report(audit_results)\n\n    # Generate audit log\n    audit_log = auditor.generate_audit_log(days=30)\n    print(f\"\\nAudit Log Summary (Last 30 days):\")\n    print(json.dumps(audit_log['summary'], indent=2))\n</code></pre>"},{"location":"6-developer-guide/sdks/python-sdk/#best-practices","title":"Best Practices","text":""},{"location":"6-developer-guide/sdks/python-sdk/#performance-optimization","title":"Performance Optimization","text":"<ol> <li> <p>Batch Operations <pre><code># Good: Batch sensor queries\nsensors = manager.sensors(with_details=True)\n\n# Bad: Individual queries for each sensor\nfor sid in sensor_ids:\n    sensor = manager.sensor(sid)\n    info = sensor.getInfo()\n</code></pre></p> </li> <li> <p>Use Streaming for Large Datasets <pre><code># Good: Stream events\nspout = limacharlie.Spout(manager, 'event')\nfor event in spout:\n    process_event(event)\n\n# Bad: Query all events at once\nevents = manager.query('*', limit=1000000)\n</code></pre></p> </li> <li> <p>Connection Pooling <pre><code># Reuse Manager instance\nmanager = limacharlie.Manager('ORG_ID', 'API_KEY')\n# Use this manager instance throughout your application\n</code></pre></p> </li> </ol>"},{"location":"6-developer-guide/sdks/python-sdk/#security-best-practices","title":"Security Best Practices","text":"<ol> <li> <p>Credential Management <pre><code># Good: Use environment variables or secure vaults\nimport os\napi_key = os.environ.get('LC_API_KEY')\n\n# Bad: Hardcode credentials\napi_key = 'hardcoded-api-key'\n</code></pre></p> </li> <li> <p>Least Privilege <pre><code># Create API keys with minimal required permissions\n# Use read-only keys when write access isn't needed\n</code></pre></p> </li> <li> <p>Audit Logging <pre><code># Enable audit logging for all operations\nmanager = limacharlie.Manager(\n    oid='ORG_ID',\n    secret_api_key='API_KEY',\n    print_debug_fn=audit_logger.log\n)\n</code></pre></p> </li> </ol>"},{"location":"6-developer-guide/sdks/python-sdk/#error-handling-best-practices","title":"Error Handling Best Practices","text":"<ol> <li> <p>Graceful Degradation <pre><code>def get_sensor_info_safe(sensor_id):\n    try:\n        sensor = manager.sensor(sensor_id)\n        return sensor.getInfo()\n    except LcApiException:\n        return {'error': 'Unable to retrieve sensor info'}\n</code></pre></p> </li> <li> <p>Retry with Backoff <pre><code>@retry(max_attempts=3, backoff_factor=2)\ndef reliable_task(sensor, command):\n    return sensor.task(command)\n</code></pre></p> </li> <li> <p>Timeout Handling <pre><code># Always set reasonable timeouts\nresult = sensor.simpleRequest('os_processes', timeout=60)\n</code></pre></p> </li> </ol>"},{"location":"6-developer-guide/sdks/python-sdk/#troubleshooting","title":"Troubleshooting","text":""},{"location":"6-developer-guide/sdks/python-sdk/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<ol> <li> <p>Authentication Failures <pre><code># Check API key format\nassert len(api_key) == 36  # UUID format\nassert api_key.count('-') == 4\n\n# Verify organization ID\nassert len(oid) == 36  # UUID format\n</code></pre></p> </li> <li> <p>Sensor Offline <pre><code># Wait for sensor to come online\nif not sensor.isOnline():\n    came_online = sensor.waitToComeOnline(timeout=300)\n    if not came_online:\n        print(\"Sensor did not come online\")\n</code></pre></p> </li> <li> <p>Rate Limiting <pre><code># Handle rate limits\nmanager = limacharlie.Manager(\n    oid='ORG_ID',\n    secret_api_key='API_KEY',\n    isRetryQuotaErrors=True\n)\n</code></pre></p> </li> <li> <p>Network Issues <pre><code># Check connectivity\nimport requests\ntry:\n    response = requests.get('https://api.limacharlie.io/health')\n    assert response.status_code == 200\nexcept:\n    print(\"Cannot reach LimaCharlie API\")\n</code></pre></p> </li> </ol>"},{"location":"6-developer-guide/sdks/python-sdk/#api-reference-links","title":"API Reference Links","text":"<ul> <li>LimaCharlie REST API Documentation</li> <li>LimaCharlie Python SDK GitHub</li> <li>LimaCharlie Documentation</li> <li>LimaCharlie Web Console</li> </ul>"},{"location":"6-developer-guide/sdks/python-sdk/#support","title":"Support","text":"<p>For SDK issues or questions: - GitHub Issues: https://github.com/refractionPOINT/python-limacharlie/issues - LimaCharlie Support: support@limacharlie.io - Community Slack: https://slack.limacharlie.io</p>"},{"location":"6-developer-guide/sdks/python-sdk/#see-also","title":"See Also","text":"<ul> <li>SDK Overview</li> <li>Go SDK</li> <li>API Keys</li> </ul>"},{"location":"7-administration/","title":"Platform Management","text":"<p>Organization configuration and management.</p>"},{"location":"7-administration/#documentation","title":"Documentation","text":"<ul> <li>LimaCharlie SDK - SDK and CLI tools</li> </ul>"},{"location":"7-administration/#see-also","title":"See Also","text":"<ul> <li>User Access</li> <li>API Keys</li> <li>Billing</li> </ul>"},{"location":"7-administration/access/api-keys/","title":"API Keys","text":"<p>LimaCharlie Cloud has a concept of API keys. Those are secret keys that can be created and named, and then in turn be used to retrieve a JWT that can be associated with the LC REST API at https://api.limacharlie.io.</p> <p>This allows construction of headless applications able to securely acquire time-restricted REST authentication tokens it can then use.</p> <p>The list of available permissions can be programmatically retrieved from this URL: https://app.limacharlie.io/owner_permissions</p>"},{"location":"7-administration/access/api-keys/#managing","title":"Managing","text":"<p>The API Keys are managed through the Organization view of the https://limacharlie.io web interface.</p>"},{"location":"7-administration/access/api-keys/#getting-a-jwt","title":"Getting a JWT","text":"<p>Simply issue an HTTP POST such as:</p> <p><code>curl -X POST \"https://jwt.limacharlie.io\" -H \"Content-Type: application/x-www-form-urlencoded\" -d \"oid=&lt;YOUR_OID&gt;&amp;secret=&lt;YOUR_API_KEY&gt;\"</code></p> <p>where the <code>oid</code> parameter is the Organization ID as found through the web interface and the <code>secret</code> parameter is the API key.</p> <p>The return value is a simple JSON response with a <code>jwt</code> component which is the JSON web token. This token is only valid for one hour to limit the possible damage of a leak, and make the deletion of the API keys easier.</p> <p>Response:</p> <p><code>{ \"jwt\": \"&lt;JWT_VALUE_HERE&gt;\" }</code></p>"},{"location":"7-administration/access/api-keys/#user-api-keys","title":"User API Keys","text":"<p>User API keys are to generate JSON web tokens (JWTs) for the REST API. In contrast to Organization API keys, the User API keys are associated with a specific user and provide the exact same access across all organizations.</p> <p>This makes User API Keys very powerful but also riskier to manage. Therefore we recommend using Organization API keys whenever possible.</p> <p>The User API keys can be used through all the same interfaces as the Organization API keys. The only difference is how you get the JWT. Instead of giving an <code>oid</code> parameter to <code>https://jwt.limacharlie.io/</code>, provide it with a <code>uid</code> parameter available through the LimaCharlie web interface.</p> <p><code>curl -X POST \"https://jwt.limacharlie.io\" -H \"Content-Type: application/x-www-form-urlencoded\" -d \"uid=&lt;YOUR_USER_ID&gt;&amp;secret=&lt;YOUR_API_KEY&gt;\"</code></p> <p>In some instances, the JWT resulting from a User API key may be to large for normal API use, in which case you will get an <code>HTTP 413 Payload too large</code> from the API gateway. In those instances, also provide an <code>oid</code> (on top of the <code>uid</code>) to the <code>jwt.limacharlie.io</code> REST endpoint to get a JWT valid only for that organization.</p> <p><code>curl -X POST \"https://jwt.limacharlie.io\" -H \"Content-Type: application/x-www-form-urlencoded\" -d \"oid=&lt;YOUR_OID&gt;&amp;uid=&lt;YOUR_USER_ID&gt;&amp;secret=&lt;YOUR_API_KEY&gt;\"</code></p> <p>You may also use a User API Key to get the list of organizations available to it by querying the following REST endpoint:</p> <p><code>https://app.limacharlie.io/user_key_info?secret=&lt;YOUR_USER_API_KEY&gt;&amp;uid=&lt;YOUR_USER_ID&gt;&amp;with_names=true</code></p>"},{"location":"7-administration/access/api-keys/#ingestion-keys","title":"Ingestion Keys","text":"<p>The artifact collection in LC requires Ingestion Keys, which can be managed through the REST API section of the LC web interface. Access to manage these Ingestion Keys requires the <code>ingestkey.ctrl</code> permission.</p>"},{"location":"7-administration/access/api-keys/#python","title":"Python","text":"<p>A simple Python API is also provided that simplifies usage of the REST API by taking care of the API Key -&gt; JWT exchange as necessary and wraps the functionality into nicer objects.</p>"},{"location":"7-administration/access/api-keys/#privileges","title":"Privileges","text":"<p>API Keys have several on-off privileges available.</p> <p>To see a full list, see the \"REST API\" section of your organization.</p> <p>Making a REST call will fail with a <code>401</code> if your API Key / token is missing some privileges and the missing privilege will be specified in the error.</p>"},{"location":"7-administration/access/api-keys/#required-privileges","title":"Required Privileges","text":"<p>Below is a list of privileges required for some common tasks.</p>"},{"location":"7-administration/access/api-keys/#go-live","title":"Go Live","text":"<p>When \"going Live\" through the web UI, the following is required by the user:</p> <ul> <li><code>output.*</code>: for the creation of the real-time output via HTTP to the browser.</li> <li><code>sensor.task</code>: to send the commands (both manually for the console and to populate the various tabs) to the Sensor.</li> </ul>"},{"location":"7-administration/access/api-keys/#flair","title":"Flair","text":"<p>API Keys may have \"flair\" as part of the key name. A flair is like a tag surrounded by <code>[]</code>. Although it is not required, we advise to put the flair at the end of the API key name for readability.</p> <p>For example: <code>orchestration-key[bulk]</code> is a key with a <code>bulk</code> flair.</p> <p>Flairs are used to modify the behavior of an API key or provide some usage hints to various systems in LimaCharlie.</p> <p>The following flairs are currently supported:</p> <ul> <li><code>bulk</code>: indicates to the REST API that this key is meant to do a large amount of calls, the API gateway tweaks the API call limits accordingly.</li> <li><code>segment</code>: indicates that only resources created by this key will be visible by this key. This is useful to provide access to a 3<sup>rd</sup> party in a limited fashion.</li> </ul>"},{"location":"7-administration/access/api-keys/#allowed-ip-range","title":"Allowed IP Range","text":"<p>When creating an API key, you can optionally include an <code>allowed_ip_range</code>, which should be a CIDR notation IP range from which the API key can be used. Any use of the API key from a different IP address will fail. This is currently only configurable when creating an API key via the API and not in the UI.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p>"},{"location":"7-administration/access/api-keys/#see-also","title":"See Also","text":"<ul> <li>SDKs</li> </ul>"},{"location":"7-administration/access/sso/","title":"Single Sign-On","text":"<p>Single sign-on (SSO) is available at no extra cost for customers that leverage LimaCharlie's custom branded offering. If this applies to your Organization, and if you are interested in using the SSO, please submit a Custom Branding / SSO Request.</p> <p>If your organization does not currently have a custom branded site with LimaCharlie, you can learn about the requirements, costs &amp; get started here.</p>"},{"location":"7-administration/access/sso/#strict-sso-enforcement","title":"Strict SSO Enforcement","text":"<p>LimaCharlie offers the ability to implement strict SSO enforcement. This means that SSO can be configured as the only authentication option.</p> <p>With this capability, you may say that any user with your email domain @example.com must authenticate via Google. This way you can disable the login + password, GitHub, and Microsoft login options for users with your email domain (@example.com) - regardless if they are logging in via your custom branded site, or via app.limacharlie.io</p>"},{"location":"7-administration/access/sso/#how-it-works","title":"How It Works","text":"<p>LimaCharlie's single sign-on functionality lets companies add their own SSO option that goes through their authentication server instead of through Google or something else. Identity Platform acts as the coordinator here. After configuring new Providers in Identity Platform, the app only needs to specify a provider ID, and then Identity Platform will handle talking to the company's auth server.</p>"},{"location":"7-administration/access/sso/#user-experience","title":"User Experience","text":"<p>The high-level user experience is as follows:</p> <ul> <li>For organizations that choose to use SSO, the SSO will be enforced. Users going to custom branded versions of the LimaCharlie site will be presented with only the option to login through SSO, if their domain has the SSO configuration.</li> </ul> <p></p> <ul> <li>The same user going to the non-branded site would still be presented with all other authentication options. However, a user would only be able to use the authentification option approved for their domain.</li> </ul> <p></p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p>"},{"location":"7-administration/access/sso/#related-articles","title":"Related Articles","text":"<ul> <li>User Access</li> </ul>"},{"location":"7-administration/access/sso/#whats-next","title":"What's Next","text":"<ul> <li>Reference: Permissions</li> </ul>"},{"location":"7-administration/access/user-access/","title":"User Access","text":"<p>To control who has access to an Organization, and what they have access to, go to the \"Users\" section of the web application.</p> <p>Adding users is done by email address and requires the user to already have a limacharlie.io account.</p> <p>The first user of an organization is added with Owner permissions at creation time. Owner permissions give full access to everything.</p> <p>New users added after the creation of an organization are added with Unset privileges, which means the user is only able to get the most basic information on the organization.</p> <p>Therefore, the first step after adding a new user should always be to change their permissions by clicking the Edit icon beside their name.</p> <p>Permissions can be controlled individually, or you can apply pre-set permission schemes by selecting it at the top of the dialog box, clicking Apply, and then clicking the Save button at the bottom.</p> <p>User Permissions</p> <p>We offer granular user permissions, allowing you to customize what roles and how much access users should have. For a full list of permissions, see Reference: Permissions.</p>"},{"location":"7-administration/access/user-access/#access-on-a-per-organization-basis","title":"Access on a per-organization basis","text":"<p>To add a user to an Organization, the new user needs to first create their own LimaCharlie account.</p> <p>After the new user has created their LimaCharlie account, you can add them by inputting their email account to your Organization.</p> <p>After adding the user, you have the ability to control what permissions they get in this tenant. To do so, click on their email and adjust their permissions in the modal that opens. (See information about user permissions above).</p> <p></p>"},{"location":"7-administration/access/user-access/#access-via-organization-groups","title":"Access via Organization Groups","text":"<p>Groups allow you to grant permissions to a set of users on a group of organizations. To get started, navigate to the upper right section of the web app and select groups.</p> <p></p> <p>From there, create a new group or click to edit an existing one.</p> <p></p> <p>The user who creates a group becomes a group owner. Group owners manage the group but do not have permissions themselves.</p> <p>You can add multiple group owners.</p> <p></p> <p>In the Users section (left panel), you can add all existing users who should receive access to the organizations included in this group. Note that if you are a Group Owner and you want the permissions of this group to apply to yourself, you will need to add your email here as well.</p> <p>Adding Accounts</p> <p>Note that all accounts will need to be existing LimaCharlie users.</p> <p></p> <p>Group owners are allowed to manage the group, but are not affected by the permissions. Members are affected by the permissions but cannot modify the group.</p> <p>Under Organizations (left panel), select a list of organizations you have access to. Note that in order to add an organization to the group, you need to have the user.ctrl permission enabled for that organization.</p> <p></p> <p>Last, select the permissions you want members of the group to have in the organizations included in this group.</p> <p>Permissions granted through the group are applied on top of permissions granted at the organization level. The permissions are additive, and a group cannot be used to subtract permissions granted at the organization level.</p> <p></p> <p>To finish, click <code>Update Permissions</code> at the top right corner.</p> <p>To review activity that has occurred in this group, click on Activity Logs (left panel).</p> <p></p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p>"},{"location":"7-administration/billing/custom-plans/","title":"Using Custom Billing Plans","text":"<p>Applicability</p> <p>This page only applies to Organizations with a contracted custom billing plan.</p> <p>If your organization has a custom pricing plan, follow these steps to ensure it's correctly applied when creating your organization. You will need to know the exact plan ID that's been allocated for your organization. If you're unsure about your plan details or need assistance, please reach out.</p> <p>How to apply your custom billing plan to newly created organizations:</p> <ul> <li>Web UI: When creating your organization, select your assigned plan from the drop-down menu.</li> <li>API Users: If using the API, specify your plan using the appropriate <code>loc</code> parameter.</li> <li>REST API: Use the <code>loc</code> parameter (general location). If you need to specify a custom plan, provide the exact plan ID. API Documentation</li> <li>Python SDK: Use the <code>location</code> parameter for the same purpose. Python SDK Reference</li> </ul> <p>Note: If you do not specify your custom plan at the time your organization is created, you will be put on standard pricing and will not receive discounted pricing.</p>"},{"location":"7-administration/billing/options/","title":"Billing Options","text":"<p>LimaCharlie users have multiple billing options available to them, depending on their unique needs. We'll walk through these two options, Default Billing and Unified Billing, below.</p>"},{"location":"7-administration/billing/options/#default-billing","title":"Default Billing","text":"<p>By default, every Organization is billed using a credit card set at the individual organization level. The billing cycle for each organization starts at the time the organization goes from the free tier into a paid tier. The invoices go to the email address of the user who initially created the organization.</p>"},{"location":"7-administration/billing/options/#unified-billing","title":"Unified Billing","text":"<p>For customers that require flexibility managing multiple organizations, LimaCharlie offers unified billing - the ability to customize billing to satisfy their needs.</p> <p>All the options described below apply based on the \"billing domain\", which is the domain name of the email address of a user. For example, the users <code>ceo@mycorp.com</code> and <code>sales@mycorp.com</code> both belong to the <code>mycorp.com</code> billing domain.</p> <p>All organizations under the same billing domain will have their billing cycles on the same day, regardless of the creation time or the time the organization first exits free tier. Instead of receiving one invoice per organization, all invoices for a billing domain will be aggregated together under a single invoice sent manually monthly.</p> <p>The following are the options you can customize as a part of the Unified Billing:</p> <ul> <li>Override the email where each individual organization's invoice goes to. Instead of the email of the creator, a central email address (like billing@mycorp.com) is used. Billing domains with unified billing enabled will receive a monthly report summarizing all organizations under the domain and their respective billing.</li> <li>Choose to be invoiced manually. Organizations in a billing domain can have their invoices sent manually by email without the use of a credit card. This will then allow the recipient to pay invoices using ACH or credit card, but this will have to be done manually each month.</li> </ul>"},{"location":"7-administration/billing/options/#default-billing-setup-vs-unified-billing","title":"Default Billing Setup vs Unified Billing","text":"Default Billing Setup Unified Billing Can be used by Anyone Customers that have their users share a custom domain name of the email address (for example, the users <code>ceo@mycorp.com</code> and <code>sales@mycorp.com</code> both belong to the <code>mycorp.com</code> domain). Best suited for * Customers that have one or a few (1-3) tenants to manage * Enterprise clients that want to manage billing at the department level (billed to different cards) * Service providers (MSP, MSSP, DFIR) who manage multiple tenants * Enterprise clients that want to manage billing at the company level (billed to one card) Payment method used Billed using a credit card set at the individual organization level. One payment method will be used for all organizations under the same billing domain. Manual invoicing Not available Available  Organizations in a billing domain can have their invoices sent manually by email without the use of a credit card. This will then allow the recipient to pay invoices using ACH or credit card, but this will have to be done manually each month. Billing cycle Starts at the time the organization goes from the free tier into a paying tier (different billing cycle for each tenant). All organizations under the same billing domain will have their billing cycles on the same day. Invoicing Users will receive one invoice per organization. All invoices for a billing domain will be aggregated together under a single invoice sent manually monthly. Email invoices go to Email address of the user who initially created the organization. Instead of the email of the creator, a central email address (like <code>billing@mycorp.com</code>) is used. Billing domains with unified billing enabled will receive a monthly report summarizing all organizations under the domain and their respective billing. <p>To learn more or to get setup with Unified Billing, contact us.</p>"},{"location":"7-administration/config-hive/","title":"Config Hive","text":"<p>The Config Hive is LimaCharlie's hierarchical configuration store. It provides a centralized way to manage configurations that can be referenced across the platform.</p>"},{"location":"7-administration/config-hive/#hive-types","title":"Hive Types","text":"<ul> <li>D&amp;R Rules - Detection and response rule storage</li> <li>Lookups - Key-value lookup tables for enrichment</li> <li>Secrets - Secure credential management</li> <li>YARA - YARA rule storage and management</li> <li>Cloud Sensors - Cloud sensor configurations</li> <li>Investigation - Investigation data storage</li> </ul>"},{"location":"7-administration/config-hive/#usage","title":"Usage","text":"<p>Hive records can be:</p> <ul> <li>Referenced in D&amp;R rules using the <code>hive://</code> prefix</li> <li>Managed via the web interface, CLI, or API</li> <li>Version controlled using the Git Sync extension</li> </ul>"},{"location":"7-administration/config-hive/#see-also","title":"See Also","text":"<ul> <li>D&amp;R Rules</li> <li>Secrets Manager</li> <li>Lookups</li> </ul>"},{"location":"7-administration/config-hive/cloud-sensors/","title":"Config Hive: Cloud Sensors","text":""},{"location":"7-administration/config-hive/cloud-sensors/#format","title":"Format","text":""},{"location":"7-administration/config-hive/cloud-sensors/#permissions","title":"Permissions","text":"<ul> <li><code>cloudsensor.get</code></li> <li><code>cloudsensor.set</code></li> <li><code>cloudsensor.del</code></li> <li><code>cloudsensor.get.mtd</code></li> <li><code>cloudsensor.set.mtd</code></li> </ul>"},{"location":"7-administration/config-hive/cloud-sensors/#command-line-usage","title":"Command-Line Usage","text":"<p>Hive secrets can be managed from the command-line, via the <code>limacharlie hive</code> command. Positional and optional arguments for command-line usage are below:</p> <pre><code>usage: limacharlie hive [-h] [-k KEY] [-d DATA] [-pk PARTITIONKEY] [--etag ETAG] [--expiry EXPIRY] [--enabled ENABLED] [--tags TAGS] action hive_name\n\npositional arguments:\n  action                the action to take, one of: list, list_mtd, get, get_mtd, set, update, remove\n  hive_name             the hive name\n\noptions:\n  -h, --help            show this help message and exit\n  -k KEY, --key KEY     the name of the key.\n  -d DATA, --data DATA  file containing the JSON data for the record, or \"-\" for stdin.\n  -pk PARTITIONKEY, --partition-key PARTITIONKEY\n                        the partition key to use instead of the default OID.\n  --etag ETAG           the optional previous etag expected for transactions.\n  --expiry EXPIRY       a millisecond epoch timestamp when the record should expire.\n  --enabled ENABLED     whether the record is enabled or disabled.\n  --tags TAGS           comma separated list of tags.\n</code></pre>"},{"location":"7-administration/config-hive/cloud-sensors/#usage","title":"Usage","text":""},{"location":"7-administration/config-hive/cloud-sensors/#example","title":"Example","text":"<pre><code>{\n    \"sensor_type\": \"webhook\",\n    \"webhook\": {\n        \"client_options\": {\n            \"hostname\": \"test-webhook\",\n            \"identity\": {\n                \"installation_key\": \"3bc13b74-0d27-4633-9773-62293bf940a7\",\n                \"oid\": \"aecec56a-046c-4078-bc08-8ebdc84dcad5\"\n            },\n            \"platform\": \"json\",\n            \"sensor_seed_key\": \"test-webhook\"\n        },\n        \"secret\": \"super-secret-hook\"\n    }\n}\n</code></pre>"},{"location":"7-administration/config-hive/dr-rules/","title":"Config Hive: Detection &amp; Response Rules","text":""},{"location":"7-administration/config-hive/dr-rules/#format","title":"Format","text":""},{"location":"7-administration/config-hive/dr-rules/#permissions","title":"Permissions","text":"<p>There are three \"sub-categories\" within detection and response rules contained in Hive.</p> <ul> <li><code>dr-general</code> pertains to rules that your Organization has created and/or controls.</li> <li><code>dr-managed</code> pertains to rules that you can use for detection, however are managed or curated by another party (i.e. Soteria rules).</li> <li><code>dr-service</code> is a protected namespace, and users will only ever have metadata permissions.</li> </ul>"},{"location":"7-administration/config-hive/dr-rules/#dr-general","title":"dr-general","text":"<ul> <li><code>dr.list</code></li> <li><code>dr.set</code></li> <li><code>dr.del</code></li> </ul>"},{"location":"7-administration/config-hive/dr-rules/#dr-managed","title":"dr-managed","text":"<ul> <li><code>dr.list.managed</code></li> <li><code>dr.set.managed</code></li> <li><code>dr.del.managed</code></li> </ul>"},{"location":"7-administration/config-hive/dr-rules/#dr-service","title":"dr-service","text":"<ul> <li><code>dr.list</code> or <code>dr.list.managed</code> (metadata only)</li> <li><code>dr.set</code> or <code>dr.set.managed</code> (metadata only)</li> </ul>"},{"location":"7-administration/config-hive/dr-rules/#command-line-usage","title":"Command-Line Usage","text":"<pre><code>usage: limacharlie hive [-h] [-k KEY] [-d DATA] [-pk PARTITIONKEY] [--etag ETAG] [--expiry EXPIRY] [--enabled ENABLED] [--tags TAGS] action hive_name\n\npositional arguments:\n  action                the action to take, one of: list, list_mtd, get, get_mtd, set, update, remove\n  hive_name             the hive name\n\noptions:\n  -h, --help            show this help message and exit\n  -k KEY, --key KEY     the name of the key.\n  -d DATA, --data DATA  file containing the JSON data for the record, or \"-\" for stdin.\n  -pk PARTITIONKEY, --partition-key PARTITIONKEY\n                        the partition key to use instead of the default OID.\n  --etag ETAG           the optional previous etag expected for transactions.\n  --expiry EXPIRY       a millisecond epoch timestamp when the record should expire.\n  --enabled ENABLED     whether the record is enabled or disabled.\n  --tags TAGS           comma separated list of tags.\n</code></pre>"},{"location":"7-administration/config-hive/dr-rules/#usage","title":"Usage","text":""},{"location":"7-administration/config-hive/dr-rules/#example","title":"Example","text":"<pre><code>{\n  \"detect\": {\n    \"event\": \"WEL\",\n    \"op\": \"and\",\n    \"rules\": [\n      {\n        \"op\": \"is\",\n        \"path\": \"event/EVENT/System/Channel\",\n        \"value\": \"Microsoft-Windows-Windows Defender/Operational\"\n      },\n      {\n        \"op\": \"is\",\n        \"path\": \"event/EVENT/System/EventID\",\n        \"value\": \"1006\"\n      }\n    ]\n  },\n  \"respond\": [\n    {\n      \"action\": \"report\",\n      \"name\": \"windows-defender-malware-detected\"\n    }\n  ]\n}\n</code></pre> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p>"},{"location":"7-administration/config-hive/investigation/","title":"Config Hive: Investigation","text":"<p>Investigations are records used during cybersecurity incident response to organize events, detections, and entities of interest. They enable analysts to track investigation progress, add annotations, and document findings throughout an incident.</p>"},{"location":"7-administration/config-hive/investigation/#format","title":"Format","text":"<p>Investigation records store references to events and detections (by ID), along with entities, notes, and investigation metadata. The maximum record size is 5MB.</p>"},{"location":"7-administration/config-hive/investigation/#root-fields","title":"Root Fields","text":"Field Type Required Max Length Description <code>name</code> string Yes 256 Human-readable investigation name <code>description</code> string No 4096 Detailed description of the investigation <code>status</code> string No - Investigation status (see enum below) <code>priority</code> string No - Priority level (see enum below) <code>events</code> array No - Event references with annotations <code>detections</code> array No - Detection references with annotations <code>entities</code> array No - Entities of interest (IOCs) <code>notes</code> array No - Investigation notes and findings <code>summary</code> string No 16384 Executive summary <code>conclusion</code> string No 16384 Final investigation conclusion"},{"location":"7-administration/config-hive/investigation/#event-structure","title":"Event Structure","text":"<p>Events reference telemetry by atom and sensor ID.</p> Field Type Required Max Length Description <code>atom</code> string Yes - LimaCharlie event atom identifier <code>sid</code> string Yes - Sensor ID the event originated from <code>tags</code> array No - Tags for categorizing the event <code>comments</code> array No - Analyst comments (see Comment structure) <code>relevance</code> string No 1024 Why this event matters to the investigation <code>verdict</code> string No - Analyst verdict (see Verdict enum)"},{"location":"7-administration/config-hive/investigation/#detection-structure","title":"Detection Structure","text":"<p>Detections reference D&amp;R detection records by ID.</p> Field Type Required Description <code>detection_id</code> string Yes Detection identifier <code>tags</code> array No Tags for categorizing the detection <code>comments</code> array No Analyst comments (see Comment structure) <code>false_positive</code> object No False positive determination (see below) <p>False Positive Object:</p> Field Type Description <code>is_fp</code> boolean Whether marked as false positive <code>reason</code> string Reason for FP determination (max 1024) <code>determined_by</code> string User who made determination (max 256) <code>determined_at</code> int64 Timestamp when determined (Unix epoch ms)"},{"location":"7-administration/config-hive/investigation/#entity-structure","title":"Entity Structure","text":"<p>Entities represent IOCs and other items of interest.</p> Field Type Required Max Length Description <code>type</code> string Yes - Entity type (see enum below) <code>value</code> string Yes 2048 Entity value <code>name</code> string No 256 Human-readable name/alias <code>first_seen</code> int64 No - First observation timestamp (Unix epoch ms) <code>last_seen</code> int64 No - Last observation timestamp (Unix epoch ms) <code>context</code> string No 2048 Why this entity is of interest <code>verdict</code> string No - Analyst verdict (see Verdict enum) <code>related_events</code> array No - Event atoms this entity relates to <code>related_detections</code> array No - Detection IDs this entity relates to <code>comments</code> array No - Analyst comments (see Comment structure)"},{"location":"7-administration/config-hive/investigation/#note-structure","title":"Note Structure","text":"<p>Notes document observations, findings, and action items.</p> Field Type Required Max Length Description <code>id</code> string No 64 Unique identifier for the note <code>type</code> string No - Note type (see enum below) <code>content</code> string Yes 16384 Note content <code>author</code> string No 256 User who created the note <code>timestamp</code> int64 No - Creation timestamp (Unix epoch ms) <code>related_events</code> array No - Event atoms this note refers to <code>related_detections</code> array No - Detection IDs this note refers to <code>resolved</code> boolean No - For action_items/questions: whether resolved"},{"location":"7-administration/config-hive/investigation/#comment-structure","title":"Comment Structure","text":"<p>Comments can be added to events, detections, and entities.</p> Field Type Required Max Length Description <code>content</code> string Yes 4096 Comment text <code>author</code> string No 256 User who wrote the comment <code>timestamp</code> int64 No - When written (Unix epoch ms)"},{"location":"7-administration/config-hive/investigation/#enum-values","title":"Enum Values","text":"<p>Status: <code>new</code>, <code>in_progress</code>, <code>pending_review</code>, <code>escalated</code>, <code>closed_false_positive</code>, <code>closed_true_positive</code></p> <p>Priority: <code>critical</code>, <code>high</code>, <code>medium</code>, <code>low</code>, <code>informational</code></p> <p>Verdict: <code>unknown</code>, <code>benign</code>, <code>suspicious</code>, <code>malicious</code></p> <p>Entity Type: <code>ip</code>, <code>domain</code>, <code>hash</code>, <code>user</code>, <code>host</code>, <code>email</code>, <code>file_path</code>, <code>process</code>, <code>url</code>, <code>other</code></p> <p>Note Type: <code>observation</code>, <code>hypothesis</code>, <code>finding</code>, <code>conclusion</code>, <code>action_item</code>, <code>question</code></p>"},{"location":"7-administration/config-hive/investigation/#permissions","title":"Permissions","text":"<p>The investigation hive requires the following permissions:</p> <ul> <li><code>investigation.get</code> - Read investigation records</li> <li><code>investigation.set</code> - Create/update investigation records</li> <li><code>investigation.del</code> - Delete investigation records</li> <li><code>investigation.get.mtd</code> - Read investigation metadata</li> <li><code>investigation.set.mtd</code> - Modify investigation metadata</li> </ul>"},{"location":"7-administration/config-hive/investigation/#command-line-usage","title":"Command-Line Usage","text":"<pre><code># Create an investigation from a JSON file\nlimacharlie hive set investigation --key investigation-2024-001 --data investigation.json\n\n# Get an investigation\nlimacharlie hive get investigation --key investigation-2024-001\n\n# Delete an investigation\nlimacharlie hive del investigation --key investigation-2024-001\n\n# List all investigations\nlimacharlie hive list investigation\n</code></pre>"},{"location":"7-administration/config-hive/investigation/#usage","title":"Usage","text":""},{"location":"7-administration/config-hive/investigation/#infrastructure-as-code","title":"Infrastructure as Code","text":"<pre><code>hives:\n  investigation:\n    ransomware-investigation:\n      data:\n        name: \"Ransomware Investigation 2024-001\"\n        description: \"Investigating ransomware activity on DESKTOP-001\"\n        status: \"in_progress\"\n        priority: \"critical\"\n        events:\n          - atom: \"abc123def456\"\n            sid: \"sensor-001-uuid\"\n            tags:\n              - initial_access\n            relevance: \"First suspicious process execution\"\n            verdict: \"malicious\"\n        entities:\n          - type: \"ip\"\n            value: \"203.0.113.50\"\n            context: \"C2 infrastructure\"\n            verdict: \"malicious\"\n        notes:\n          - type: \"finding\"\n            content: \"Initial compromise via phishing email\"\n            author: \"analyst@example.com\"\n      usr_mtd:\n        enabled: true\n        expiry: 0\n        tags:\n          - ransomware\n          - critical\n</code></pre>"},{"location":"7-administration/config-hive/investigation/#example","title":"Example","text":"<pre><code>{\n  \"name\": \"Ransomware Investigation 2024-001\",\n  \"description\": \"Investigating potential ransomware activity on endpoint DESKTOP-001\",\n  \"status\": \"in_progress\",\n  \"priority\": \"critical\",\n  \"events\": [\n    {\n      \"atom\": \"abc123def456\",\n      \"sid\": \"550e8400-e29b-41d4-a716-446655440000\",\n      \"tags\": [\"initial_access\", \"suspicious\"],\n      \"relevance\": \"First suspicious process execution\",\n      \"verdict\": \"malicious\",\n      \"comments\": [\n        {\n          \"content\": \"This is the initial payload dropper\",\n          \"author\": \"analyst@example.com\",\n          \"timestamp\": 1700000000000\n        }\n      ]\n    }\n  ],\n  \"detections\": [\n    {\n      \"detection_id\": \"det-456-uuid\",\n      \"tags\": [\"ransomware\", \"critical\"],\n      \"false_positive\": {\n        \"is_fp\": false\n      }\n    }\n  ],\n  \"entities\": [\n    {\n      \"type\": \"ip\",\n      \"value\": \"203.0.113.50\",\n      \"name\": \"C2 Server\",\n      \"first_seen\": 1700000000000,\n      \"last_seen\": 1700100000000,\n      \"context\": \"Command and control infrastructure\",\n      \"verdict\": \"malicious\",\n      \"related_events\": [\"abc123def456\"]\n    },\n    {\n      \"type\": \"hash\",\n      \"value\": \"d41d8cd98f00b204e9800998ecf8427e\",\n      \"context\": \"Malware payload hash\",\n      \"verdict\": \"malicious\"\n    }\n  ],\n  \"notes\": [\n    {\n      \"id\": \"note-1\",\n      \"type\": \"finding\",\n      \"content\": \"Initial compromise occurred via phishing email with malicious attachment\",\n      \"author\": \"analyst@example.com\",\n      \"timestamp\": 1700000000000\n    },\n    {\n      \"type\": \"action_item\",\n      \"content\": \"Isolate affected endpoint and collect forensic image\",\n      \"resolved\": true\n    }\n  ],\n  \"summary\": \"Ransomware attack detected on DESKTOP-001. Initial access via phishing.\",\n  \"conclusion\": \"Attack contained. No data exfiltration observed.\"\n}\n</code></pre>"},{"location":"7-administration/config-hive/investigation/#best-practices","title":"Best Practices","text":"<p>For opinionated guidance on tagging events and detections for SOC investigations, including MITRE ATT&amp;CK mapping and attack chain visualization, see the Investigation Guide.</p>"},{"location":"7-administration/config-hive/investigation/#related","title":"Related","text":"<ul> <li>Investigation Guide - Best practices for tagging and documenting investigations</li> </ul>"},{"location":"7-administration/config-hive/lookups/","title":"Config Hive: Lookups","text":""},{"location":"7-administration/config-hive/lookups/#format","title":"Format","text":"<p>Lookups are dictionaries/maps/key-value-pairs where the key is a string. The lookup can then be queried by various parts of LimaCharlie (like rules). The value component of a lookup must be a dictionary and represents metadata associated with the given key, which will be returned to the rule using the lookup.</p> <p>Lookup data can be ingested by specifying one of the following root keys indicating the format of the lookupd data:</p> <ul> <li><code>lookup_data</code>: represented direct as parsed JSON.</li> <li><code>newline_content</code>: a string where each key is separated by a newline, LimaCharlie will assume the metadata is empty.</li> <li><code>yaml_content</code>: a string in YAML format that contains a dictionary with the string keys and dictionary metadata like the <code>lookup_data</code>.</li> </ul>"},{"location":"7-administration/config-hive/lookups/#permissions","title":"Permissions","text":"<ul> <li><code>lookup.get</code></li> <li><code>lookup.set</code></li> <li><code>lookup.del</code></li> <li><code>lookup.get.mtd</code></li> <li><code>lookup.set.mtd</code></li> </ul>"},{"location":"7-administration/config-hive/lookups/#usage","title":"Usage","text":""},{"location":"7-administration/config-hive/lookups/#infrastructure-as-code","title":"Infrastructure as Code","text":"<pre><code>hives:\n    lookup:                             # Example lookup in the lookup hive\n        example-lookup:\n            data:\n                lookup_data:\n                    8.8.8.8: {}\n                    8.8.4.4: {}\n                    1.1.1.1: {}\n                optimized_lookup_data:\n                    _LC_INDICATORS: null\n                    _LC_METADATA: null\n            usr_mtd:\n                enabled: true\n                expiry: 0\n                tags:\n                    - example-lookup\n                comment: \"\"\n    extension_config:                   # Example lookup manager extension config\n        ext-lookup-manager:\n            data:\n                lookup_manager_rules:\n                    - arl: \"\"\n                      format: json\n                      name: tor\n                      predefined: '[https,storage.googleapis.com/lc-lookups-bucket/tor-ips.json]'\n                      tags:\n                        - tor\n                    - arl: \"\"\n                      format: json\n                      name: talos\n                      predefined: '[https,storage.googleapis.com/lc-lookups-bucket/talos-ip-blacklist.json]'\n                      tags:\n                        - talos\n            usr_mtd:\n                enabled: true\n                expiry: 0\n                tags: []\n                comment: \"\"\n</code></pre>"},{"location":"7-administration/config-hive/lookups/#manually-in-the-gui","title":"Manually in the GUI","text":"<p>Lookups can be added in the web interface by navigating to Automation \u2192 Lookups. Name your lookup, choose the format, and copy paste the contents of your lookup in the <code>JSON data</code> field.</p> <p>LimaCharlie also provides several publicly available lookups for use in your Organization. More information and the contents of these can be found on GitHub. The contents of these lookups can be used here as well.</p> <p></p>"},{"location":"7-administration/config-hive/lookups/#automatically-via-the-lookup-manager","title":"Automatically via the Lookup Manager","text":"<p>If your lookups change frequently and you wish to keep them up to date, LimaCharlie offers the lookup manager extension as a mechanism to automatically update your lookups every 24 hours. Documentation on the lookup manager can be found here.</p>"},{"location":"7-administration/config-hive/lookups/#example-lookup","title":"Example Lookup","text":"<pre><code>{\n  \"lookup_data\": {\n    \"c:\\\\windows\\\\system32\\\\ping.exe\": {\n      \"mtd1\": \"known_bin\",\n      \"mtd2\": 4\n    },\n    \"c:\\\\windows\\\\system32\\\\sysmon.exe\": {\n      \"mtd1\": \"good_val\",\n      \"mtd2\": 10\n    }\n  }\n}\n</code></pre> <p>or</p> <pre><code>{\n  \"newline_content\": \"lvalue1\\nlvalue2\\nlvalue3\"\n}\n</code></pre>"},{"location":"7-administration/config-hive/secrets/","title":"Config Hive: Secrets","text":"<p>With its multitude of data ingestion and output options, LimaCharlie users can end up with a myriad of credentials and secret keys to faciliate unique data operations. However, not all users should be privy to these secret keys. Within the Config Hive, the <code>secrets</code> hive component allows you to decouple secrets from their usage or configuration across LimaCharlie. Furthermore, you can also grant permissions to users that allows them to see the configuration of an output, but not have access to the associated credentials.</p> <p>The most common usage is for storing secret keys used by various Adapters or Outputs. By referencing <code>secrets</code> within the Config Hive, we can configure these services without needing to reveal secret keys to all users.</p> <p>Watch the video below to learn more about hive secrets, or continue reading below.</p>"},{"location":"7-administration/config-hive/secrets/#format","title":"Format","text":"<p>A secret record in <code>hive</code> has a very basic format:</p> <pre><code>{\n    \"secret\": \"data\"\n}\n</code></pre> <p>The <code>data</code> portion of the records in this hive must have a single key called <code>secret</code> who's value will be used by various LimaCharlie components.</p>"},{"location":"7-administration/config-hive/secrets/#permissions","title":"Permissions","text":"<p>The <code>secret</code> hive requires the following permissions for the various operations:</p> <ul> <li><code>secret.get</code></li> <li><code>secret.set</code></li> <li><code>secret.del</code></li> <li><code>secret.get.mtd</code></li> <li><code>secret.set.mtd</code></li> </ul>"},{"location":"7-administration/config-hive/secrets/#secret-management","title":"Secret Management","text":"<p>Over time, and with enough integrations, you may need to create and/or update secrets on demand. We provide quick options for both via either the LimaCharlie CLI or web app.</p>"},{"location":"7-administration/config-hive/secrets/#creating-secrets","title":"Creating Secrets","text":"<p>With the appropriate permissions, users can create secrets in the following ways:</p> <ol> <li>Using the LimaCharlie CLI, secrets can be created using the <code>limacharlie hive set secret</code> command (example below).</li> <li>Via the web app, under Organization Settings &gt; Secrets Manager.</li> </ol>"},{"location":"7-administration/config-hive/secrets/#updating-secrets","title":"Updating Secrets","text":"<p>Once they are set, secrets can be updated via the following methods:</p> <ol> <li>Using the LimaCharlie CLI, secrets can be updated using the <code>limacharlie hive update secret</code> command.</li> <li>Via the web app, Organization Settings &gt; Secrets Manager. Select the secret you wish to update, and update in the dialog box. Click Save Secret to save changes in the platform.</li> </ol>"},{"location":"7-administration/config-hive/secrets/#usage","title":"Usage","text":"<p>Using a secret in combination with an output has very few steps:</p> <ol> <li>Create a secret in the <code>secret</code> hive</li> <li>Create an Output and use the format <code>hive://secret/my-secret-name</code> as the value for a credentials field.</li> </ol>"},{"location":"7-administration/config-hive/secrets/#example","title":"Example","text":"<p>Let's create a simple secret using the LimaCharlie CLI in a terminal. First, create a small file with the secret record in it:</p> <pre><code>$ echo \"my-secret-value\" &gt; my-secret\n</code></pre> <p>Next, set this secret in Hive via the LimaCharlie CLI:</p> <pre><code>$ limacharlie hive set secret --key my-secret --data my-secret --data-key secret\n</code></pre> <p>You should get a confirmation that the secret was created, including metadata of the secret and associated OID:</p> <pre><code>{\n    \"guid\": \"3a7a2865-a439-4d1a-8f50-b9a6d833075c\",\n    \"hive\": {\n        \"name\": \"secret\",\n        \"partition\": \"8cbe27f4-aaaa-bbbb-cccc-138cd51389cd\"\n        },\n    \"name\": \"my-secret\"\n}\n</code></pre> <p>Next, create an output in the web app, using the value <code>hive://secret/my-secret</code> as the Secret Key value.</p> <p></p> <p>And that's it! The output should start as expected, however when viewing the output's configuration, the secret should refer to the <code>hive</code> ARN, rather than the actual credentials.</p>"},{"location":"7-administration/config-hive/yara/","title":"Config Hive: Yara","text":""},{"location":"7-administration/config-hive/yara/#format","title":"Format","text":"<p>A yara record in <code>hive</code> has a very basic format:</p> <pre><code>{\n    \"rule\": \"data\"\n}\n</code></pre> <p>The <code>data</code> portion of the records in this hive must have a single key called <code>rule</code> who's value will be the yara rule content used by various LimaCharlie components.</p> <p>A single rule record can contain a series of actual Yara rule, like this: https://github.com/Yara-Rules/rules/blob/master/malware/APT_APT1.yar</p>"},{"location":"7-administration/config-hive/yara/#permissions","title":"Permissions","text":"<p>The <code>yara</code> hive requires the following permissions for the various operations:</p> <ul> <li><code>yara.get</code></li> <li><code>yara.set</code></li> <li><code>yara.del</code></li> <li><code>yara.get.mtd</code></li> <li><code>yara.set.mtd</code></li> </ul>"},{"location":"7-administration/config-hive/yara/#usage","title":"Usage","text":"<p>Yara rules can be create in the <code>yara</code> Hive. Those rules will then be available, either through the <code>ext-yara</code> Extension, or directly using the <code>yara_scan</code> command directly using the reference <code>hive://yara/your-rule-name</code>.</p>"},{"location":"7-administration/config-hive/yara/#example","title":"Example","text":"<p>Let's create a new Yara rule using the LimaCharlie CLI in a terminal. Assuming you have a Yara rule in the <code>rule.yara</code> file.</p> <p>Load the rule in the LimaCharlie Hive via the CLI:</p> <pre><code>$ limacharlie hive set yara --key my-rule --data rule.yara --data-key rule\n</code></pre> <p>You should get a confirmation that the rule was created, including metadata of the rule associated OID:</p> <pre><code>{\n  \"guid\": \"d88826b7-d583-4bcc-b7d3-4f450a12e1be\",\n  \"hive\": {\n    \"name\": \"yara\",\n    \"partition\": \"8cbe27f4-aaaa-bbbb-cccc-138cd51389cd\"\n  },\n  \"name\": \"my-rule\"\n}\n</code></pre> <p>Next, assuming you want to issue a scan command directly to a Sensor (via the Console or a rule):</p> <pre><code>yara_scan hive://yara/my-rule\n</code></pre>"},{"location":"8-reference/","title":"Reference","text":"<p>Technical reference documentation for LimaCharlie operators, commands, and schemas.</p>"},{"location":"8-reference/#detection-response","title":"Detection &amp; Response","text":"<ul> <li>Detection Operators - All available detection logic operators</li> <li>Response Actions - Available response action types</li> <li>Error Codes - D&amp;R error code reference</li> </ul>"},{"location":"8-reference/#sensors","title":"Sensors","text":"<ul> <li>Endpoint Commands - Sensor command reference</li> <li>Sensor Selectors - Selector expression syntax</li> <li>ID Schema - Understanding LimaCharlie IDs</li> </ul>"},{"location":"8-reference/#events","title":"Events","text":"<ul> <li>EDR Events - Endpoint agent event types</li> <li>Platform Events - Platform-level events</li> <li>Event Schemas - Event structure reference</li> </ul>"},{"location":"8-reference/#other","title":"Other","text":"<ul> <li>Template Strings - Template syntax and transforms</li> <li>Authentication - Auth resource locator reference</li> <li>Log Collection Guide</li> </ul>"},{"location":"8-reference/#faq","title":"FAQ","text":"<p>Frequently asked questions:</p> <ul> <li>General</li> <li>Account Management</li> <li>Billing</li> <li>D&amp;R Rules</li> <li>Sensor Installation</li> <li>Troubleshooting</li> </ul>"},{"location":"8-reference/#see-also","title":"See Also","text":"<ul> <li>Detection Operators</li> <li>Response Actions</li> <li>EDR Events</li> <li>FAQ</li> </ul>"},{"location":"8-reference/authentication-resource-locator/","title":"Reference: Authenticated Resource Locator","text":""},{"location":"8-reference/authentication-resource-locator/#overview","title":"Overview","text":"<p>Many features in LimaCharlie require access to external resources, sometimes authenticated, provided by users.</p> <p>Authenticated Resource Locators (ARLs) describe a way to specify access to a remote resource, supporting many methods, including authentication data, and all that within a single string.</p>"},{"location":"8-reference/authentication-resource-locator/#format","title":"Format","text":""},{"location":"8-reference/authentication-resource-locator/#with-authentication","title":"With authentication","text":"<pre><code>[methodName,methodDest,authType,authData]\n</code></pre>"},{"location":"8-reference/authentication-resource-locator/#without-authentication","title":"Without authentication","text":"<pre><code>[methodName,methodDest]\n</code></pre> <ul> <li><code>methodName</code>: the transport to use, one of <code>http</code>, <code>https</code>, <code>gcs</code> and <code>github</code>.</li> <li><code>methodDest</code>: the actual destination of the transport. A domain and path for HTTP(S) and a bucket name and path for GCS.</li> <li><code>authType</code>: how to authenticate, one of <code>basic</code>, <code>bearer</code>, <code>token</code>, <code>gaia</code> or <code>otx</code>.</li> <li><code>authData</code>: the auth data, like <code>username:password</code> for <code>basic</code>, or access token values. If the value is a complex structure, like a <code>gaia</code> JSON service key, it must be base64-encoded.</li> </ul>"},{"location":"8-reference/authentication-resource-locator/#examples","title":"Examples","text":""},{"location":"8-reference/authentication-resource-locator/#http-get-with-no-auth","title":"HTTP GET with no auth","text":"<p><code>[https,my.corpwebsite.com/resourdata]</code></p>"},{"location":"8-reference/authentication-resource-locator/#http-get-with-basic-auth","title":"HTTP GET with basic auth","text":"<p><code>[https,my.corpwebsite.com/resourdata,basic,myusername:mypassword]</code></p>"},{"location":"8-reference/authentication-resource-locator/#http-get-with-bearer-auth","title":"HTTP GET with bearer auth","text":"<p><code>[https,my.corpwebsite.com/resourdata,bearer,bfuihferhf8erh7ubhfey7g3y4bfurbfhrb]</code></p>"},{"location":"8-reference/authentication-resource-locator/#http-get-with-token-auth","title":"HTTP GET with token auth","text":"<p><code>[https,my.corpwebsite.com/resourdata,token,bfuihferhf8erh7ubhfey7g3y4bfurbfhrb]</code></p>"},{"location":"8-reference/authentication-resource-locator/#retrieve-from-google-cloud-storage","title":"Retrieve from Google Cloud Storage","text":"<p><code>[gcs,my-bucket-name/some-blob-prefix,gaia,base64(GCP_SERVICE_KEY)]</code></p>"},{"location":"8-reference/authentication-resource-locator/#retrieve-otx-pulse-via-rest-api","title":"Retrieve OTX Pulse via REST API","text":"<p><code>[https,otx.alienvault.com/api/v1/pulses/5dc56c60a9edbde72dd5d013,otx,9uhr438uhf4h4u9fj7f6the8h383v8jv4ccc1e263d37f29d034d]</code></p>"},{"location":"8-reference/authentication-resource-locator/#retrieve-from-public-github-repo-main-branch","title":"Retrieve from public GitHub repo main branch","text":"<p><code>[github,myGithubUserOrOrg/repoName/path/to/file]</code></p> <p>Note: The path to the repo is NOT the same as the URL. Utilize the UI breadcrumbs for the correct path. For example, in the following screenshot:</p> <p></p> <p>The GitHub user is: romainmarcoux The repo name is: malicious-domains The path is: sources/alienvault-phishing-scam So the ARL would be:  <code>[github,romainmarcoux/malicious-domains/sources/alienvault-phishing-scam]</code></p>"},{"location":"8-reference/authentication-resource-locator/#retrieve-from-github-repo-with-github-personal-access-token","title":"Retrieve from GitHub repo with Github Personal Access Token","text":"<p><code>[github,myGithubUserOrOrg/repoName/optional/subpath/to,token,f1eb898f20a0db07e88878aadfsdfdfsffdsdfadwq8f767a72218f2]</code></p>"},{"location":"8-reference/authentication-resource-locator/#retrieve-from-public-github-repo-at-a-specific-branch","title":"Retrieve from public GitHub repo at a specific branch","text":"<p><code>[github,refractionPOINT/sigma/some-sub-dir?ref=my-branch]</code></p>"},{"location":"8-reference/detection-logic-operators/","title":"Detection Logic Operators","text":"<p>Operators are used in the Detection part of a Detection &amp; Response rule. Operators may also be accompanied by other available parameters, such as transforms, times, and others, referenced later in this page.</p> <p>For more information on how to use operators, read Detection &amp; Response Rules.</p>"},{"location":"8-reference/detection-logic-operators/#operators","title":"Operators","text":""},{"location":"8-reference/detection-logic-operators/#and-or","title":"and, or","text":"<p>The standard logical boolean operations to combine other logical operations. Takes a single <code>rules:</code> parameter that contains a list of other operators to \"AND\" or \"OR\" together.</p> <p>Example:</p> <pre><code>op: or\nrules:\n  - ...rule1...\n  - ...rule2...\n  - ...\n</code></pre>"},{"location":"8-reference/detection-logic-operators/#is","title":"is","text":"<p>Tests for equality between the value of the <code>\"value\": &lt;&gt;</code> parameter and the value found in the event at the <code>\"path\": &lt;&gt;</code> parameter.</p> <p>Supports the file name and sub domain transforms.</p> <p>Example rule:</p> <pre><code>event: NEW_PROCESS\nop: is\npath: event/PARENT/PROCESS_ID\nvalue: 9999\n</code></pre>"},{"location":"8-reference/detection-logic-operators/#exists","title":"exists","text":"<p>Tests if any elements exist at the given path (regardless of its value).</p> <p>Example rule:</p> <pre><code>event: NEW_PROCESS\nop: exists\npath: event/PARENT\n</code></pre> <p>The <code>exists</code> operator also supports an optional <code>truthy</code> parameter. When <code>true</code>, this parameter indicates the <code>exists</code> should treat <code>null</code> and <code>\"\"</code> (empty string) values as if they were non-existent like:</p> <p>The rule:</p> <pre><code>op: exists\npath: some/path\ntruthy: true\n</code></pre> <p>applied to:</p> <pre><code>{\n  \"some\": {\n    \"path\": \"\"\n  }\n}\n</code></pre> <p>would NOT match.</p>"},{"location":"8-reference/detection-logic-operators/#contains","title":"contains","text":"<p>The <code>contains</code> checks if a substring can be found in the value at the path.</p> <p>An optional parameter <code>count: 3</code> can be specified to only match if the given  substring is found at least 3 times in path.</p> <p>Supports the file name and sub domain transforms.</p> <p>Example rule:</p> <pre><code>event: NEW_PROCESS\nop: contains\npath: event/COMMAND_LINE\nvalue: reg\ncount: 2\n</code></pre>"},{"location":"8-reference/detection-logic-operators/#ends-with-starts-with","title":"ends with, starts with","text":"<p>The <code>starts with</code> checks for a prefix match and <code>ends with</code> checks for a suffix match.</p> <p>They both check if the value found at <code>path</code> matches the given <code>value</code>, based on the operator.</p> <p>Supports the file name and sub domain transforms.</p>"},{"location":"8-reference/detection-logic-operators/#is-greater-than-is-lower-than","title":"is greater than, is lower than","text":"<p>Check to see if a value is greater or lower (numerically) than a value in the event.</p> <p>They both use the <code>path</code> and <code>value</code> parameters. They also both support the <code>length of</code> parameter as a boolean (true or false). If set to true, instead of comparing  the value at the specified path, it compares the length of the value at that path.</p>"},{"location":"8-reference/detection-logic-operators/#matches","title":"matches","text":"<p>The <code>matches</code> op compares the value at <code>path</code> with a regular expression supplied in the <code>re</code> parameter. Under the hood, this uses the Golang's <code>regexp</code> package, which also enables you to apply the regexp to log files.</p> <p>Supports the file name and sub domain transforms.</p> <p>Example:</p> <pre><code>event: FILE_TYPE_ACCESSED\nop: matches\npath: event/FILE_PATH\nre: .*\\\\system32\\\\.*\\.scr\ncase sensitive: false\n</code></pre>"},{"location":"8-reference/detection-logic-operators/#not","title":"not","text":"<p>The <code>not</code> operator inverts the result of its rule. For example, when applied to an <code>is</code> operator, it changes the logic from \"equals\" to \"does not equal\". When applied to an or operator, it changes the logic from \"any of these conditions are true\" to \"none of these conditions are true\"</p> <p>Example:</p> <pre><code>event: NEW_PROCESS\nop: is\nnot: true\npath: event/PARENT/PROCESS_ID\nvalue: 9999\n</code></pre>"},{"location":"8-reference/detection-logic-operators/#string-distance","title":"string distance","text":"<p>The <code>string distance</code> op looks up the Levenshtein Distance between two strings. In other words it generates the minimum number of character changes required for one string to become equal to another.</p> <p>For example, the Levenshtein Distance between <code>google.com</code> and <code>googlr.com</code> (<code>r</code> instead of <code>e</code>) is 1.</p> <p>This can be used to find variations of file names or domain names that could be used for phishing, for example.</p> <p>Suppose your company is <code>onephoton.com</code>. Looking for the Levenshtein Distance between all <code>DOMAIN_NAME</code> in <code>DNS_REQUEST</code> events, compared to <code>onephoton.com</code> it could detect an attacker using <code>onephot0n.com</code> in a phishing email domain.</p> <p>The operator takes a <code>path</code> parameter indicating which field to compare, a <code>max</code> parameter indicating the maximum Levenshtein Distance to match and a <code>value</code> parameter that is either a string or a list of strings that represent the value(s) to compare to. Note that although <code>string distance</code> supports the <code>value</code> to be a list, most other operators do not.</p> <p>Supports the file name and sub domain transforms.</p> <p>Example:</p> <pre><code>event: DNS_REQUEST\nop: string distance\npath: event/DOMAIN_NAME\nvalue:\n  - onephoton.com\n  - www.onephoton.com\nmax: 2\n</code></pre> <p>This would match <code>onephotom.com</code> and <code>0nephotom.com</code> but NOT <code>0neph0tom.com</code>.</p> <p>Using the file name transform to apply to a file name in a path:</p> <pre><code>event: NEW_PROCESS\nop: string distance\npath: event/FILE_PATH\nfile name: true\nvalue:\n  - svchost.exe\n  - csrss.exe\nmax: 2\n</code></pre> <p>This would match <code>svhost.exe</code> and <code>csrss32.exe</code> but NOT <code>csrsswin32.exe</code>.</p>"},{"location":"8-reference/detection-logic-operators/#is-32-bit-is-64-bit-is-arm","title":"is 32 bit, is 64 bit, is arm","text":"<p>All of these operators take no additional arguments, they simply match if the relevant Sensor characteristic is correct.</p> <p>Example:</p> <pre><code>op: is 64 bit\n</code></pre>"},{"location":"8-reference/detection-logic-operators/#is-platform","title":"is platform","text":"<p>Checks if the event under evaluation is from a sensor of the given platform.</p> <p>Takes a <code>name</code> parameter for the platform name. The current platforms are:</p> <p>Endpoint Platforms: * <code>windows</code> * <code>linux</code> * <code>macos</code> * <code>ios</code> * <code>android</code> * <code>chrome</code></p> <p>Cloud &amp; Service Platforms: * <code>gcp</code> (Google Cloud Platform) * <code>aws</code> (Amazon Web Services) * <code>azure_ad</code> (Azure Active Directory) * <code>azure_event_hub_namespace</code> * <code>azure_key_vault</code> * <code>azure_kubernetes_service</code> * <code>azure_monitor</code> * <code>azure_network_security_group</code> * <code>azure_sql_audit</code> * <code>guard_duty</code> (AWS GuardDuty) * <code>k8s_pods</code> (Kubernetes)</p> <p>Identity &amp; Access Management: * <code>1password</code> * <code>duo</code> * <code>entraid</code> (Microsoft Entra ID) * <code>okta</code> * <code>sublime</code></p> <p>Security Products: * <code>carbon_black</code> * <code>crowdstrike</code> * <code>cylance</code> * <code>falconcloud</code> * <code>msdefender</code> (Microsoft Defender) * <code>sentinel_one</code> * <code>sophos</code> * <code>trend_worryfree</code> * <code>wiz</code></p> <p>Communication &amp; Collaboration: * <code>box</code> * <code>github</code> * <code>office365</code> * <code>slack</code> * <code>email</code></p> <p>IT &amp; Business Services: * <code>hubspot</code> * <code>itglue</code> * <code>mimecast</code> * <code>pandadoc</code> * <code>proofpoint</code> * <code>zendesk</code></p> <p>Network &amp; Infrastructure: * <code>canary_token</code> * <code>fortigate</code> * <code>iis</code> (Internet Information Services) * <code>netscaler</code> * <code>paloalto_fw</code> (Palo Alto Firewall) * <code>zeek</code></p> <p>Data Formats: * <code>vpn</code> * <code>text</code> * <code>json</code> * <code>xml</code> * <code>cef</code> (Common Event Format) * <code>wel</code> (Windows Event Log) * <code>mac_unified_logging</code></p> <p>Other: * <code>lc_event</code> (LimaCharlie internal events)</p> <p>Example:</p> <pre><code>op: is platform\nname: 1password\n</code></pre> <p>Note: Platform names are case-sensitive and should be lowercase.</p>"},{"location":"8-reference/detection-logic-operators/#is-tagged","title":"is tagged","text":"<p>Determines if the Tag supplied in the <code>tag</code> parameter is already associated with the sensor that the event under evaluation is from.</p>"},{"location":"8-reference/detection-logic-operators/#lookup","title":"lookup","text":"<p>Looks up a value against a lookup add-on (a.k.a. resource) such as a threat feed.</p> <pre><code>event: DNS_REQUEST\nop: lookup\npath: event/DOMAIN_NAME\nresource: hive://lookup/malwaredomains\ncase sensitive: false\n</code></pre> <p>This rule will get the <code>event/DOMAIN_NAME</code> of a <code>DNS_REQUEST</code> event and check if it's a member of the <code>lookup</code> named <code>malwaredomains</code>. If it is, then the rule is a match.</p> <p>The value is supplied via the <code>path</code> parameter and the lookup is defined in the <code>resource</code> parameter. Resources are of the form <code>hive://lookup/RESOURCE_NAME</code>. In order to access a lookup, your Organization must be subscribed to it.</p> <p>Supports the file name and sub domain transforms.</p> <p>API-based lookups, like VirusTotal and IP Geolocation, work a little bit differently. For more information, see Using API-based lookups.</p> <p>You can create your own lookups and optionally publish them in the add-on marketplace. To learn more, see Lookups and Lookup Manager.</p>"},{"location":"8-reference/detection-logic-operators/#scope","title":"scope","text":"<p>In some cases, you may want to limit the scope of the matching and the <code>path</code> you use to be within a specific part of the event. The <code>scope</code> operator allows you to do just that, reset the root of the <code>event/</code> in paths to be a sub-path of the event.</p> <p>This comes in as very useful for example when you want to test multiple values of a connection in a <code>NETWORK_CONNECTIONS</code> event but always on a per-connection. If you  were to do a rule like:</p> <pre><code>event: NETWORK_CONNECTIONS\nop: and\nrules:\n  - op: starts with\n    path: event/NETWORK_ACTIVITY/?/SOURCE/IP_ADDRESS\n    value: '10.'\n  - op: is\n    path: event/NETWORK_ACTIVITY/?/DESTINATION/PORT\n    value: 445\n</code></pre> <p>you would hit on events where any connection has a source IP prefix of <code>10.</code> and any connection has a destination port of <code>445</code>. Obviously this is not what we had in mind, we wanted to know if a single connection has those two characteristics.</p> <p>The solution is to use the <code>scope</code> operator. The <code>path</code> in the operator will become the new <code>event/</code> root path in all operators found under the <code>rule</code>. So the above would become</p> <p>Example:</p> <pre><code>event: NETWORK_CONNECTIONS\nop: scope\npath: event/NETWORK_ACTIVITY/\nrule:\n  op: and\n  rules:\n    - op: starts with\n      path: event/SOURCE/IP_ADDRESS\n      value: '10.'\n    - op: is\n      path: event/DESTINATION/PORT\n      value: 445\n</code></pre>"},{"location":"8-reference/detection-logic-operators/#cidr","title":"cidr","text":"<p>The <code>cidr</code> checks if an IP address at the path is contained within a given CIDR network mask.</p> <p>Example rule:</p> <pre><code>event: NETWORK_CONNECTIONS\nop: cidr\npath: event/NETWORK_ACTIVITY/SOURCE/IP_ADDRESS\ncidr: 10.16.1.0/24\n</code></pre>"},{"location":"8-reference/detection-logic-operators/#is-private-address","title":"is private address","text":"<p>The <code>is private address</code> checks if an IP address at the path is a private address  as defined by RFC 1918.</p> <p>Example rule:</p> <pre><code>event: NETWORK_CONNECTIONS\nop: is private address\npath: event/NETWORK_ACTIVITY/SOURCE/IP_ADDRESS\n</code></pre>"},{"location":"8-reference/detection-logic-operators/#is-public-address","title":"is public address","text":"<p>The <code>is public address</code> checks if an IP address at the path is a public address  as defined by RFC 1918.</p> <p>Example rule:</p> <pre><code>event: NETWORK_CONNECTIONS\nop: is public address\npath: event/NETWORK_ACTIVITY/SOURCE/IP_ADDRESS\n</code></pre>"},{"location":"8-reference/detection-logic-operators/#transforms","title":"Transforms","text":"<p>Transforms are transformations applied to the value being evaluated in an event, prior to the evaluation.</p>"},{"location":"8-reference/detection-logic-operators/#file-name","title":"file name","text":"<p>Sample: <code>file name: true</code></p> <p>The <code>file name</code> transform takes a <code>path</code> and replaces it with the file name component of the <code>path</code>. This means that a <code>path</code> of <code>c:\\windows\\system32\\wininet.dll</code> will become <code>wininet.dll</code>.</p>"},{"location":"8-reference/detection-logic-operators/#sub-domain","title":"sub domain","text":"<p>Sample: <code>sub domain: \"-2:\"</code></p> <p>The <code>sub domain</code> extracts specific components from a domain name. The value of <code>sub domain</code> is in slice notation. It looks like <code>startIndex:endIndex</code>, where the index is 0-based and indicates which parts of the domain to keep.</p> <p>Some examples:</p> <ul> <li><code>0:2</code> means the first 2 components of the domain: <code>aa.bb</code> for <code>aa.bb.cc.dd</code>.</li> <li><code>-1</code> means the last component of the domain: <code>cc</code> for <code>aa.bb.cc</code>.</li> <li><code>1:</code> means all components starting at 1: <code>bb.cc</code> for <code>aa.bb.cc</code>.</li> <li><code>:</code> means to test the operator to every component individually.</li> </ul>"},{"location":"8-reference/detection-logic-operators/#is-older-than","title":"is older than","text":"<p>Test if a value in event at the <code>\"path\": &lt;&gt;</code> parameter, assumed to be either a second-based epoch or a millisecond-based epoch is older than a number of seconds as specified by the <code>seconds</code> parameter, centered in time at \"now\" during evaluation.</p> <p>Example rule:</p> <pre><code>event: login-attempt\nop: is older than\npath: routing/event_time\nseconds: 3600\n</code></pre> <p>where the example above would match on a <code>login-attempt</code> event that occurred more than 1h ago.</p>"},{"location":"8-reference/detection-logic-operators/#times","title":"Times","text":"<p>All operators support an optional parameter named <code>times</code>. When specified, it must contain a list of Time Descriptors when the accompanying operator is valid. Your rule can mix-and-match multiple Time Descriptors as part of a single rule on per-operator basis.</p> <p>Here's an example rule that matches a Chrome process starting between 11PM and 5AM, Monday through Friday, Pacific Time:</p> <pre><code>event: NEW_PROCESS\nop: ends with\npath: event/FILE_PATH\nvalue: chrome.exe\ncase sensitive: false\ntimes:\n  - day_of_week_start: 2     # 1 - 7\n    day_of_week_end: 6       # 1 - 7\n    time_of_day_start: 2200  # 0 - 2359\n    time_of_day_end: 2359    # 0 - 2359\n    tz: America/Los_Angeles  # time zone\n  - day_of_week_start: 2\n    day_of_week_end: 6\n    time_of_day_start: 0\n    time_of_day_end: 500\n    tz: America/Los_Angeles\n</code></pre>"},{"location":"8-reference/detection-logic-operators/#time-zone","title":"Time Zone","text":"<p>The <code>tz</code> should match a TZ database name from the Time Zones Database.</p>"},{"location":"8-reference/detection-logic-operators/#see-also","title":"See Also","text":"<ul> <li>D&amp;R Rules Overview</li> <li>Response Actions</li> <li>Writing Rules</li> </ul>"},{"location":"8-reference/edr-events/","title":"Reference: EDR Events","text":""},{"location":"8-reference/edr-events/#overview","title":"Overview","text":"<p>This page provides a detailed overview of all events generated by the LimaCharlie Endpoint Agent. Each event type represents a specific system activity, from process creation to network connections and file modifications. Events serve as key components in detection, response, and monitoring, enabling security teams to track, analyze, and take action on endpoint behavior. Use this guide to understand the purpose and structure of each event for effective threat detection and investigation.</p> <p>Generally, event types ending with <code>*_REP</code> are emitted in response to a command being issued to the endpoint agent.</p>"},{"location":"8-reference/edr-events/#edr-events-by-supported-os","title":"EDR Events by Supported OS","text":"<p>These are the events emitted by the endpoint agent for each supported operating system. Below the table, you can find descriptions of each event type.</p> EDR Event Type macOS Windows Linux Chrome Edge AUTORUN_CHANGE \u2611\ufe0f CLOUD_NOTIFICATION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f CODE_IDENTITY \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f CONNECTED \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f DATA_DROPPED \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f DEBUG_DATA_REP \u2611\ufe0f DELETED_SENSOR \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f DIR_FINDHASH_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f DIR_LIST_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f DNS_REQUEST \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f DRIVER_CHANGE \u2611\ufe0f EXEC_OOB \u2611\ufe0f \u2611\ufe0f EXISTING_PROCESS \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f EXPORT_COMPLETE \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f FIM_ADD \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f FIM_REMOVE \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f FIM_HIT \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f FILE_CREATE \u2611\ufe0f \u2611\ufe0f FILE_DEL_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f FILE_DELETE \u2611\ufe0f \u2611\ufe0f FILE_GET_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f FILE_HASH_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f FILE_INFO_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f FILE_MODIFIED \u2611\ufe0f \u2611\ufe0f FILE_MOV_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f FILE_TYPE_ACCESSED \u2611\ufe0f \u2611\ufe0f GET_DOCUMENT_REP \u2611\ufe0f \u2611\ufe0f GET_EXFIL_EVENT_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f HIDDEN_MODULE_DETECTED \u2611\ufe0f HISTORY_DUMP_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f HTTP_REQUEST \u2611\ufe0f \u2611\ufe0f HTTP_REQUEST_HEADERS \u2611\ufe0f HTTP_RESPONSE_HEADERS \u2611\ufe0f INGEST \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f LOG_GET_REP LOG_LIST_REP MEM_FIND_HANDLES_REP \u2611\ufe0f MEM_FIND_STRING_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f MEM_HANDLES_REP \u2611\ufe0f MEM_MAP_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f MEM_READ_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f MEM_STRINGS_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f MODULE_LOAD \u2611\ufe0f \u2611\ufe0f MODULE_MEM_DISK_MISMATCH \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f NETSTAT_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f NETWORK_CONNECTIONS \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f NETWORK_SUMMARY \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f NEW_DOCUMENT \u2611\ufe0f \u2611\ufe0f NEW_NAMED_PIPE \u2611\ufe0f NEW_PROCESS \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f NEW_REMOTE_THREAD \u2611\ufe0f NEW_TCP4_CONNECTION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f NEW_TCP6_CONNECTION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f NEW_UDP4_CONNECTION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f NEW_UDP6_CONNECTION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f OPEN_NAMED_PIPE \u2611\ufe0f OS_AUTORUNS_REP \u2611\ufe0f \u2611\ufe0f OS_DRIVERS_REP \u2611\ufe0f OS_KILL_PROCESS_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f OS_PACKAGES_REP \u2611\ufe0f OS_PROCESSES_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f OS_RESUME_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f OS_SERVICES_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f OS_SUSPEND_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f OS_USERS_REP \u2611\ufe0f OS_VERSION_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f PCAP_LIST_INTERFACES_REP \u2611\ufe0f PROCESS_ENVIRONMENT \u2611\ufe0f \u2611\ufe0f RECEIPT \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f REGISTRY_CREATE \u2611\ufe0f REGISTRY_DELETE \u2611\ufe0f REGISTRY_LIST_REP \u2611\ufe0f REGISTRY_WRITE \u2611\ufe0f REJOIN_NETWORK \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f REMOTE_PROCESS_HANDLE \u2611\ufe0f SEGREGATE_NETWORK \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f SENSITIVE_PROCESS_ACCESS \u2611\ufe0f SERVICE_CHANGE \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f SHUTTING_DOWN \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f SSH_LOGIN \u2611\ufe0f SSH_LOGOUT \u2611\ufe0f STARTING_UP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f TERMINATE_PROCESS \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f TERMINATE_TCP4_CONNECTION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f TERMINATE_TCP6_CONNECTION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f TERMINATE_UDP4_CONNECTION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f TERMINATE_UDP6_CONNECTION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f THREAD_INJECTION \u2611\ufe0f USER_LOGIN \u2611\ufe0f USER_LOGOUT \u2611\ufe0f USER_OBSERVED \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f VOLUME_MOUNT \u2611\ufe0f \u2611\ufe0f VOLUME_UNMOUNT \u2611\ufe0f \u2611\ufe0f WEL \u2611\ufe0f YARA_DETECTION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f"},{"location":"8-reference/edr-events/#event-descriptions","title":"Event Descriptions","text":""},{"location":"8-reference/edr-events/#autorun_change","title":"AUTORUN_CHANGE","text":"<p>Generated when an Autorun is changed.</p> <p>Platforms:</p> <pre><code>{\n  \"REGISTRY_KEY\": \"HKEY_LOCAL_MACHINE\\\\Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\",\n  \"TIMESTAMP\": 1627497894000\n}\n</code></pre>"},{"location":"8-reference/edr-events/#cloud_notification","title":"CLOUD_NOTIFICATION","text":"<p>This event is a receipt from the agent that it has received the task sent to it, and includes high-level errors (if any).</p> <p>Platforms:</p> <pre><code>{\n  \"NOTIFICATION_ID\": \"ADD_EXFIL_EVENT_REQ\",\n  \"NOTIFICATION\": {\n    \"INVESTIGATION_ID\": \"digger-4afdeb2b-a0d8-4a37-83b5-48996117998e\"\n  },\n  \"HCP_IDENT\": {\n    \"HCP_ORG_ID\": \"c82e5c17d5194ef5a4acc454a95d31db\",\n    \"HCP_SENSOR_ID\": \"8fc370e6699a49858e75c1316b725570\",\n    \"HCP_INSTALLER_ID\": \"00000000000000000000000000000000\",\n    \"HCP_ARCHITECTURE\": 0,\n    \"HCP_PLATFORM\": 0\n  },\n  \"EXPIRY\": 0\n}\n</code></pre>"},{"location":"8-reference/edr-events/#code_identity","title":"CODE_IDENTITY","text":"<p>Unique combinations of file hash and file path. This event is emitted the first time the combination is seen, typically when the binary is executed or loaded. Therefore it's a great event to look for hashes without being overwhelmed by process execution or module loads.</p> <p>ONGOING_IDENTITY</p> <p>The <code>ONGOING_IDENTITY</code> event emits code signature information even if not newly seen, however this data can become duplicative and verbose.</p> <p>Platforms:</p> <pre><code>{\n  \"MEMORY_SIZE\": 0,\n  \"FILE_PATH\": \"C:\\\\Users\\\\dev\\\\AppData\\\\Local\\\\Temp\\\\B1B207E5-300E-434F-B4FE-A4816E6551BE\\\\dismhost.exe\",\n  \"TIMESTAMP\": 1456285265,\n  \"SIGNATURE\": {\n    \"CERT_ISSUER\": \"C=US, S=Washington, L=Redmond, O=Microsoft Corporation, CN=Microsoft Code Signing PCA\",\n    \"CERT_CHAIN_STATUS\": 124,\n    \"FILE_PATH\": \"C:\\\\Users\\\\dev\\\\AppData\\\\Local\\\\Temp\\\\B1B207E5-300E-434F-B4FE-A4816E6551BE\\\\dismhost.exe\",\n    \"CERT_SUBJECT\": \"C=US, S=Washington, L=Redmond, O=Microsoft Corporation, OU=MOPR, CN=Microsoft Corporation\"\n  },\n  \"HASH\": \"4ab4024eb555b2e4c54d378a846a847bd02f66ac54849bbce5a1c8b787f1d26c\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#connected","title":"CONNECTED","text":"<p>This event is generated when a Sensor connects to the cloud.</p> <p>Platforms:</p> <pre><code>{\n    \"HOST_NAME\" : \"demo-win-2016\",\n    \"IS_SEGREGATED\" : 0,\n    \"KERNEL_ACQ_AVAILABLE\" : 1,\n    \"MAC_ADDRESS\" : \"42-01-0A-80-00-02\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#debug_data_rep","title":"DEBUG_DATA_REP","text":"<p>Response from a <code>get_debug_data</code> request.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#dir_findhash_rep","title":"DIR_FINDHASH_REP","text":"<p>Response event for the <code>dir_find_hash</code> sensor command.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n    \"DIRECTORY_LIST\": [\n        {\n            \"HASH\": \"f11dda931637a1a1bc614fc2f320326b24336c5155679aa062acae7c79f33d67\",\n            \"ACCESS_TIME\": 1535994794247,\n            \"FILE_SIZE\": 113664,\n            \"CREATION_TIME\": 1467173189067,\n            \"MODIFICATION_TIME\": 1467173190171,\n            \"FILE_NAME\": \"MALWARE_DEMO_WINDOWS_1.exe\",\n            \"ATTRIBUTES\": 32,\n            \"FILE_PATH\": \"c:\\\\users\\\\dev\\\\desktop\\\\MALWARE_DEMO_WINDOWS_1.exe\"\n        },\n        {\n            \"HASH\": \"e37726feee8e72f3ab006e023cb9d6fa1a4087274b47217d2462325fa8008515\",\n            \"ACCESS_TIME\": 1535989041078,\n            \"FILE_SIZE\": 1016320,\n            \"CREATION_TIME\": 1522507344821,\n            \"MODIFICATION_TIME\": 1522507355732,\n            \"FILE_NAME\": \"lc_win_64.exe\",\n            \"ATTRIBUTES\": 32,\n            \"FILE_PATH\": \"c:\\\\users\\\\dev\\\\desktop\\\\lc_win_64.exe\"\n        }\n    ],\n    \"HASH\": [\n        \"f11dda931637a1a1bc614fc2f320326b24336c5155679aa062acae7c79f33d67\",\n        \"e37726feee8e72f3ab006e023cb9d6fa1a4087274b47217d2462325fa8008515\"\n    ],\n    \"FILE_PATH\": \"*.exe\",\n    \"DIRECTORY_LIST_DEPTH\": 0,\n    \"DIRECTORY_PATH\": \"c:\\\\users\\\\dev\\\\desktop\\\\\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#dir_list_rep","title":"DIR_LIST_REP","text":"<p>Response event for the <code>dir_list</code> sensor command. Includes Alternate Data Streams on Windows.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n    \"DIRECTORY_LIST\": [\n        {\n            \"FILE_NAME\": \"vssdk_full.exe\",\n            \"CREATION_TIME\": 1553437930012,\n            \"MODIFICATION_TIME\": 1553437937000,\n            \"STREAMS\": [\n                {\n                    \"FILE_NAME\": \"::$DATA\",\n                    \"SIZE\": 13782032\n                }\n            ],\n            \"ACCESS_TIME\": 1567868284440,\n            \"FILE_SIZE\": 13782032,\n            \"ATTRIBUTES\": 32,\n            \"FILE_PATH\": \"c:\\\\users\\\\dev\\\\desktop\\\\vssdk_full.exe\"\n        },\n        {\n            \"FILE_NAME\": \"UniversalLog.txt\",\n            \"CREATION_TIME\": 1553028205525,\n            \"MODIFICATION_TIME\": 1553028206289,\n            \"STREAMS\": [\n                {\n                    \"FILE_NAME\": \"::$DATA\",\n                    \"SIZE\": 125\n                },\n                {\n                    \"FILE_NAME\": \":Zone.Identifier:$DATA\",\n                    \"SIZE\": 377\n                }\n            ],\n            \"ACCESS_TIME\": 1567868284158,\n            \"FILE_SIZE\": 125,\n            \"ATTRIBUTES\": 32,\n            \"FILE_PATH\": \"c:\\\\users\\\\dev\\\\desktop\\\\UniversalLog.txt\"\n        }\n    ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#dns_request","title":"DNS_REQUEST","text":"<p>Generated from DNS responses and therefore includes both the requested domain and the response from the server. If the server responds with multiple responses (as allowed by the DNS protocol) the N answers will become N DNS_REQUEST events, so you can always assume one DNS_REQUEST event means one answer.</p> <p>Platforms:</p> <pre><code>{\n  \"DNS_TYPE\": 1,\n  \"TIMESTAMP\": 1456285240,\n  \"DNS_FLAGS\": 0,\n  \"DOMAIN_NAME\": \"time.windows.com\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#driver_change","title":"DRIVER_CHANGE","text":"<p>Generated when a driver is changed.</p> <p>Platforms:</p> <pre><code>{\n  \"PROCESS_ID\": 0,\n  \"SVC_DISPLAY_NAME\": \"HbsAcq\",\n  \"SVC_NAME\": \"HbsAcq\",\n  \"SVC_STATE\": 1,\n  \"SVC_TYPE\": 1,\n  \"TIMESTAMP\": 1517377895873\n}\n</code></pre>"},{"location":"8-reference/edr-events/#existing_process","title":"EXISTING_PROCESS","text":"<p>This event is similar to the NEW_PROCESS event.  It gets emitted when a process existed prior to the LimaCharlie sensor loading.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#file_create","title":"FILE_CREATE","text":"<p>Generated when a file is created.</p> <p>Platforms:</p> <pre><code>{\n  \"FILE_PATH\": \"C:\\\\Users\\\\dev\\\\AppData\\\\Local\\\\Microsoft\\\\Windows\\\\WebCache\\\\V01tmp.log\",\n  \"TIMESTAMP\": 1468335271948\n}\n</code></pre>"},{"location":"8-reference/edr-events/#file_del_rep","title":"FILE_DEL_REP","text":"<p>Response event for the <code>file_del</code> sensor command.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"FILE_PATH\": \"C:\\\\test\\\\test.txt\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#file_delete","title":"FILE_DELETE","text":"<p>Generated when a file is deleted.</p> <p>Be Aware:</p> <p>When adding this event to an event collection rule, you will be monitoring system-wide. This could result in a large number of events.</p> <p>Best Practices:</p> <ul> <li>Utilize this selectively (ex. deploy on only suspect systems)</li> <li>Use Exfil watch rules to specify paths that are of high interest</li> <li>Consider using File Integrity Monitoring (FIM)</li> <li>Look for this on an ad-hoc basis from the Sensor Console. ex.</li> </ul> <pre><code>history_dump -e FILE_DELETE\n</code></pre> <p>Platforms:</p> <pre><code>{\n  \"FILE_PATH\": \"C:\\\\Users\\\\dev\\\\AppData\\\\Local\\\\Temp\\\\EBA4E4F0-3020-459E-9E34-D5336E244F05\\\\api-ms-win-core-processthreads-l1-1-2.dll\",\n  \"TIMESTAMP\": 1468335611906\n}\n</code></pre>"},{"location":"8-reference/edr-events/#file_get_rep","title":"FILE_GET_REP","text":"<p>Response event for the <code>file_get</code> sensor command.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"FILE_CONTENT\": \"$BASE64_ENCODED_FILE_CONTENTS\",\n  \"FILE_PATH\": \"C:\\\\windows\\\\system32\\\\svchost.exe\",\n  \"FILE_SIZE\": 78880\n}\n</code></pre>"},{"location":"8-reference/edr-events/#file_hash_rep","title":"FILE_HASH_REP","text":"<p>Response event for the <code>file_hash</code> sensor command.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"FILE_IS_SIGNED\": 1,\n  \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\svchost.exe\",\n  \"HASH\": \"31780ff2aaf7bc71f755ba0e4fef1d61b060d1d2741eafb33cbab44d889595a0\",\n  \"SIGNATURE\": {\n    \"CERT_ISSUER\": \"C=US, S=Washington, L=Redmond, O=Microsoft Corporation, CN=Microsoft Windows Production PCA 2011\",\n    \"CERT_SUBJECT\": \"C=US, S=Washington, L=Redmond, O=Microsoft Corporation, CN=Microsoft Windows Publisher\",\n    \"FILE_CERT_IS_VERIFIED_LOCAL\": 1,\n    \"FILE_IS_SIGNED\": 1,\n    \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\svchost.exe\"\n  }\n}\n</code></pre>"},{"location":"8-reference/edr-events/#file_info_rep","title":"FILE_INFO_REP","text":"<p>Response event for the <code>file_info</code> sensor command.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"ACCESS_TIME\": 1686685723546,\n  \"ATTRIBUTES\": 0,\n  \"CREATION_TIME\": 1686685723546,\n  \"FILE_IS_SIGNED\": 1,\n  \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\svchost.exe\",\n  \"FILE_SIZE\": 78880,\n  \"MODIFICATION_TIME\": 1686685723546\n}\n</code></pre>"},{"location":"8-reference/edr-events/#file_modified","title":"FILE_MODIFIED","text":"<p>Generated when a file is modified.</p> <p>Be Aware:</p> <p>When adding this event to an event collection rule, you will be monitoring system-wide. This could result in a large number of events.</p> <p>Best Practices:</p> <ul> <li>Utilize this selectively (ex. deploy on only suspect systems)</li> <li>Use Exfil watch rules to specify paths that are of high interest</li> <li>Consider using File Integrity Monitoring (FIM)</li> <li>Look for this on an ad-hoc basis from the Sensor Console. ex.</li> </ul> <pre><code>history_dump -e FILE_MODIFIED\n</code></pre> <p>Platforms:</p> <pre><code>{\n  \"FILE_PATH\": \"C:\\\\Users\\\\dev\\\\AppData\\\\Local\\\\Microsoft\\\\Windows\\\\WebCache\\\\V01.log\",\n  \"TIMESTAMP\": 1468335272949\n}\n</code></pre>"},{"location":"8-reference/edr-events/#file_mov_rep","title":"FILE_MOV_REP","text":"<p>Response event for the <code>file_mov</code> sensor command.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"DESTINATION\": \"C:\\\\test\\\\test.txt.bak\",\n  \"SOURCE\": \"C:\\\\test\\\\test.txt\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#file_type_accessed","title":"FILE_TYPE_ACCESSED","text":"<p>Generated when a new process is observed interacting with certain file types.</p> <p>The <code>RULE_NAME</code> component is the class of file extension involved:</p> <ul> <li>Rule 1: <code>.doc</code>, <code>.docm</code>, <code>.docx</code></li> <li>Rule 2: <code>.xlt</code>, <code>.xlsm</code>, <code>.xlsx</code></li> <li>Rule 3: <code>.ppt</code>, <code>.pptm</code>, <code>.pptx</code>, <code>.ppts</code></li> <li>Rule 4: <code>.pdf</code></li> <li>Rule 5: <code>.rtf</code></li> <li>Rule 50: <code>.zip</code></li> <li>Rule 51: <code>.rar</code></li> <li>Rule 64: <code>.locky</code>, <code>.aesir</code></li> </ul> <p>Platforms:</p> <pre><code>{\n  \"PROCESS_ID\": 2048,\n  \"RULE_NAME\": 50,\n  \"FILE_PATH\": \"C:\\\\Program Files\\\\7-Zip\\\\7zG.exe\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#fim_add","title":"FIM_ADD","text":"<p>Response event for the <code>fim_add</code> sensor command. An <code>ERROR: 0</code> implies the path was successfully added.</p> <p>Platforms:</p> <p>Output:</p> <pre><code>\"event\": {\n  \"ERROR\":0\n}\n</code></pre>"},{"location":"8-reference/edr-events/#fim_remove","title":"FIM_REMOVE","text":"<p>Response event for the <code>fim_del</code> sensor command. An <code>ERROR: 0</code> implies the path was successfully removed.</p> <p>An <code>ERROR: 3</code> response implies the provided path was not found in the list of FIM patterns.</p> <p>Platforms:</p> <p>Output:</p> <pre><code>\"event\": {\n  \"ERROR\":0\n}\n</code></pre>"},{"location":"8-reference/edr-events/#fim_hit","title":"FIM_HIT","text":"<p>A file, directory, or registry key being monitored by File &amp; Registry Integrity Monitoring has been modified.</p> <p>Platforms:</p> <pre><code>{\n  \"PROCESS\": {\n    \"MEMORY_USAGE\": 25808896,\n    \"TIMESTAMP\": 1541348299886,\n    \"COMMAND_LINE\": \"\\\"C:\\\\WINDOWS\\\\regedit.exe\\\" \",\n    \"PROCESS_ID\": 4340,\n    \"THREADS\": 3,\n    \"USER_NAME\": \"BUILTIN\\\\Administrators\",\n    \"FILE_PATH\": \"C:\\\\WINDOWS\\\\regedit.exe\",\n    \"PARENT_PROCESS_ID\": 6260\n  },\n  \"REGISTRY_KEY\": \"\\\\REGISTRY\\\\MACHINE\\\\SOFTWARE\\\\ActiveState\\\\New Value #1\",\n  \"PROCESS_ID\": 4340\n}\n</code></pre>"},{"location":"8-reference/edr-events/#fim_list_rep","title":"FIM_LIST_REP","text":"<p>Response event for the <code>fim_get</code> sensor command. The response will be a JSON list of FIM patterns.</p> <p>Platforms:</p> <p>Output:</p> <pre><code>{\n  \"PATTERNS\": [\n    0: \"/home/*\",\n    1: \"/home/*/.ssh/*\",\n    2: \"/root/.ssh/authorized_keys\"\n  ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#get_document_rep","title":"GET_DOCUMENT_REP","text":"<p>Generated when a <code>doc_cache_get</code> task requests a cached document.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#get_exfil_event_rep","title":"GET_EXFIL_EVENT_REP","text":"<p>Response from an <code>exfil_get</code> sensor command.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#hidden_module_detected","title":"HIDDEN_MODULE_DETECTED","text":"<p>Generated when a <code>hidden_module_scan</code> command is issued.</p> <p>Note that the name of the event does not confirm the presence of a hidden module. Please check the output to</p> <p>confirm whether a hidden module was detected.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"ERROR\": 0,\n  \"ERROR_MESSAGE\": \"done\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#history_dump_rep","title":"HISTORY_DUMP_REP","text":"<p>Response from <code>history_dump</code> sensor command. Does not itself contain the historic events but will be generated along them.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#http_request","title":"HTTP_REQUEST","text":"<p>This event is emitted whenever an HTTP request is made.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"URL\": \"https://play.google.com/log?authuser=0\",\n  \"IP_ADDRESS\": \"172.217.2.142\",\n  \"RESULT\": 200,\n  \"PARENT\": {\n    \"URL\": \"https://console.cloud.google.com\"\n  }\n}\n</code></pre>"},{"location":"8-reference/edr-events/#http_request_headers","title":"HTTP_REQUEST_HEADERS","text":"<p>Provides HTTP Request headers.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"HEADERS\": [\n    {\n      \"NAME\": \"User-Agent\",\n      \"VALUE\": \"Mozilla/5.0 (X11; CrOS x86_64 14541.0.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"\n    },\n    {\n      \"NAME\": \"Accept\",\n      \"VALUE\": \"*/*\"\n    }\n  ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#http_response_headers","title":"HTTP_RESPONSE_HEADERS","text":"<p>Provides HTTP Response headers.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"HEADERS\": [\n    {\n      \"NAME\": \"content-length\",\n      \"VALUE\": \"859\"\n    },\n    {\n      \"NAME\": \"cache-control\",\n      \"VALUE\": \"max-age=3600\"\n    },\n    {\n      \"NAME\": \"content-encoding\",\n      \"VALUE\": \"br\"\n    },\n    {\n      \"NAME\": \"content-type\",\n      \"VALUE\": \"text/html; charset=utf-8\"\n    },\n    {\n      \"NAME\": \"etag\",\n      \"VALUE\": \"\\\"1540d7725dd15680377d45886baba56f620f7692faa530bc3597226ffadd77d1-br\\\"\"\n    },\n    {\n      \"NAME\": \"last-modified\",\n      \"VALUE\": \"Thu, 21 Dec 2023 23:59:32 GMT\"\n    },\n    {\n      \"NAME\": \"referrer-policy\",\n      \"VALUE\": \"sameorigin\"\n    },\n    {\n      \"NAME\": \"strict-transport-security\",\n      \"VALUE\": \"max-age=3600 ; includeSubDomains\"\n    },\n    {\n      \"NAME\": \"x-content-type-options\",\n      \"VALUE\": \"nosniff\"\n    },\n    {\n      \"NAME\": \"x-frame-options\",\n      \"VALUE\": \"sameorigin\"\n    },\n    {\n      \"NAME\": \"accept-ranges\",\n      \"VALUE\": \"bytes\"\n    },\n    {\n      \"NAME\": \"date\",\n      \"VALUE\": \"Fri, 22 Dec 2023 19:10:58 GMT\"\n    },\n    {\n      \"NAME\": \"x-served-by\",\n      \"VALUE\": \"cache-dub4332-DUB\"\n    },\n    {\n      \"NAME\": \"x-cache\",\n      \"VALUE\": \"HIT\"\n    },\n    {\n      \"NAME\": \"x-cache-hits\",\n      \"VALUE\": \"1\"\n    },\n    {\n      \"NAME\": \"x-timer\",\n      \"VALUE\": \"S1703272259.579745,VS0,VE1\"\n    },\n    {\n      \"NAME\": \"vary\",\n      \"VALUE\": \"x-fh-requested-host, accept-encoding\"\n    },\n    {\n      \"NAME\": \"alt-svc\",\n      \"VALUE\": \"h3=\\\":443\\\";ma=86400,h3-29=\\\":443\\\";ma=86400,h3-27=\\\":443\\\";ma=86400\"\n    }\n  ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#log_get_rep","title":"LOG_GET_REP","text":"<p>Response from a <code>log_get</code> request.</p>"},{"location":"8-reference/edr-events/#log_list_rep","title":"LOG_LIST_REP","text":"<p>Response from a <code>log_list</code> request.</p>"},{"location":"8-reference/edr-events/#mem_find_handles_rep","title":"MEM_FIND_HANDLES_REP","text":"<p>Response event for the <code>mem_find_handle</code> sensor command.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#mem_find_string_rep","title":"MEM_FIND_STRING_REP","text":"<p>Response event for the <code>mem_find_string</code> sensor command.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#mem_handles_rep","title":"MEM_HANDLES_REP","text":"<p>Response event for the <code>mem_handles</code> sensor command. This event will contain an array of handles identified in memory.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n    \"HANDLES\": [\n      {\n        \"HANDLE_NAME\": \"\\\\REGISTRY\\\\MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\Image File Execution Options\",\n        \"HANDLE_TYPE\": \"Key\",\n        \"HANDLE_VALUE\": 4,\n        \"PROCESS_ID\": 908\n      },\n      {\n        \"HANDLE_NAME\": \"\\\\KnownDlls\",\n        \"HANDLE_TYPE\": \"Directory\",\n        \"HANDLE_VALUE\": 48,\n        \"PROCESS_ID\": 908\n      },\n      \"...\"]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#mem_map_rep","title":"MEM_MAP_REP","text":"<p>Response event for the <code>mem_map</code> sensor command. This event will contain an array of arrays, representing processes and their associated memory data.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n    \"MEMORY_MAP\": [\n      {\n        \"BASE_ADDRESS\": 94100802174976,\n        \"MEMORY_ACCESS\": 6,\n        \"MEMORY_SIZE\": 4096,\n        \"MEMORY_TYPE\": 3\n      }\n    ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#mem_read_rep","title":"MEM_READ_REP","text":"<p>Response event for the <code>mem_read</code> sensor command.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"MEMORY_DUMP\": \"TGltYU...\",\n  \"PROCESS_ID\": 745\n}\n</code></pre>"},{"location":"8-reference/edr-events/#mem_strings_rep","title":"MEM_STRINGS_REP","text":"<p>Response event for the <code>mem_strings</code> sensor command. The response will contain two arrays of arrays, <code>STRINGSA</code> and <code>STRINGSW</code>.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n    \"PROCESS_ID\" : 745,\n    \"STRINGSA\" : [\n        [\n            0 : \"/lib64/ld-linux-x86-64.so.2\",\n            1 : \"__gmon_start__\"\n        ]\n    ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#module_load","title":"MODULE_LOAD","text":"<p>Generated when a module (like DLL on Windows) is loaded in a process.</p> <p>Platforms:</p> <pre><code>{\n  \"MEMORY_SIZE\": 241664,\n  \"PROCESS_ID\": 2904,\n  \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\imm32.dll\",\n  \"MODULE_NAME\": \"imm32.dll\",\n  \"TIMESTAMP\": 1468335264989,\n  \"BASE_ADDRESS\": 140715814092800\n}\n</code></pre>"},{"location":"8-reference/edr-events/#netstat_rep","title":"NETSTAT_REP","text":"<p>Response from a  <code>netstat</code> command to list active network sockets.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"FRIENDLY\": 0,\n  \"NETWORK_ACTIVITY\": [\n    {\n      \"DESTINATION\": {\n        \"IP_ADDRESS\": \"0.0.0.0\",\n        \"PORT\": 0\n      },\n      \"PROCESS_ID\": 856,\n      \"PROTOCOL\": \"tcp4\",\n      \"SOURCE\": {\n        \"IP_ADDRESS\": \"0.0.0.0\",\n        \"PORT\": 135\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#network_connections","title":"NETWORK_CONNECTIONS","text":"<p>List of recent network connections performed by a process.</p> <p>Platforms:</p> <pre><code>{\n  \"NETWORK_ACTIVITY\": [\n    {\n      \"SOURCE\": {\n        \"IP_ADDRESS\": \"172.16.223.138\",\n        \"PORT\": 50396\n      },\n      \"IS_OUTGOING\": 1,\n      \"DESTINATION\": {\n        \"IP_ADDRESS\": \"23.214.49.56\",\n        \"PORT\": 80\n      }\n    },\n    {\n      \"SOURCE\": {\n        \"IP_ADDRESS\": \"172.16.223.138\",\n        \"PORT\": 50397\n      },\n      \"IS_OUTGOING\": 1,\n      \"DESTINATION\": {\n        \"IP_ADDRESS\": \"189.247.166.18\",\n        \"PORT\": 80\n      }\n    },\n    {\n      \"SOURCE\": {\n        \"IP_ADDRESS\": \"172.16.223.138\",\n        \"PORT\": 50398\n      },\n      \"IS_OUTGOING\": 1,\n      \"DESTINATION\": {\n        \"IP_ADDRESS\": \"23.217.70.67\",\n        \"PORT\": 80\n      }\n    },\n    {\n      \"SOURCE\": {\n        \"IP_ADDRESS\": \"172.16.223.138\",\n        \"PORT\": 50399\n      },\n      \"IS_OUTGOING\": 1,\n      \"DESTINATION\": {\n        \"IP_ADDRESS\": \"104.110.238.53\",\n        \"PORT\": 80\n      }\n    },\n    {\n      \"SOURCE\": {\n        \"IP_ADDRESS\": \"172.16.223.138\",\n        \"PORT\": 50400\n      },\n      \"IS_OUTGOING\": 1,\n      \"DESTINATION\": {\n        \"IP_ADDRESS\": \"23.214.49.56\",\n        \"PORT\": 80\n      }\n    },\n    {\n      \"SOURCE\": {\n        \"IP_ADDRESS\": \"172.16.223.138\",\n        \"PORT\": 50401\n      },\n      \"IS_OUTGOING\": 1,\n      \"DESTINATION\": {\n        \"IP_ADDRESS\": \"204.79.197.203\",\n        \"PORT\": 80\n      }\n    }\n  ],\n  \"HASH\": \"2de228cad2e542b2af2554d61fab5463ecbba3ff8349ba88c3e48637ed8086e9\",\n  \"COMMAND_LINE\": \"C:\\\\WINDOWS\\\\system32\\\\msfeedssync.exe sync\",\n  \"PROCESS_ID\": 6968,\n  \"FILE_IS_SIGNED\": 1,\n  \"USER_NAME\": \"WIN-5KC7E0NG1OD\\\\dev\",\n  \"FILE_PATH\": \"C:\\\\WINDOWS\\\\system32\\\\msfeedssync.exe\",\n  \"PARENT_PROCESS_ID\": 1892\n}\n</code></pre>"},{"location":"8-reference/edr-events/#new_document","title":"NEW_DOCUMENT","text":"<p>Generated when a file is created that matches a set list of locations and extensions. It indicates the file has been cached in memory and can be retrieved using the <code>doc_cache_get</code> task.</p> <p>The following file patterns are considered \"documents\":</p> <ul> <li><code>.bat</code></li> <li><code>.js</code></li> <li><code>.ps1</code></li> <li><code>.sh</code></li> <li><code>.py</code></li> <li><code>.exe</code></li> <li><code>.scr</code></li> <li><code>.pdf</code></li> <li><code>.doc</code></li> <li><code>.docm</code></li> <li><code>.docx</code></li> <li><code>.ppt</code></li> <li><code>.pptm</code></li> <li><code>.pptx</code></li> <li><code>.xlt</code></li> <li><code>.xlsm</code></li> <li><code>.xlsx</code></li> <li><code>.vbs</code></li> <li><code>.rtf</code></li> <li><code>.hta</code></li> <li><code>.lnk</code></li> <li><code>.xsl</code></li> <li><code>.com</code></li> <li><code>.png</code></li> <li><code>.jpg</code></li> <li><code>.asp</code></li> <li><code>.aspx</code></li> <li><code>.php</code></li> <li><code>\\windows\\system32\\</code></li> </ul> <p>Platforms:</p> <pre><code>{\n  \"FILE_PATH\": \"C:\\\\Users\\\\dev\\\\Desktop\\\\evil.exe\",\n  \"TIMESTAMP\": 1468335816308,\n  \"HASH\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#new_named_pipe","title":"NEW_NAMED_PIPE","text":"<p>This event is emitted when a new Named Pipe is created by a process.</p> <p>Platforms:</p> <pre><code>{\n  \"FILE_PATH\": \"\\\\Device\\\\NamedPipe\\\\LOCAL\\\\mojo.6380.1072.2134013463507075011\",\n  \"PROCESS_ID\": 6380\n}\n</code></pre>"},{"location":"8-reference/edr-events/#new_process","title":"NEW_PROCESS","text":"<p>Generated when a new process starts.</p> <p>Platforms:</p> <pre><code>{\n  \"PARENT\": {\n    \"PARENT_PROCESS_ID\": 7076,\n    \"COMMAND_LINE\": \"\\\"C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 12.0\\\\Common7\\\\IDE\\\\devenv.exe\\\"  \",\n    \"MEMORY_USAGE\": 438730752,\n    \"PROCESS_ID\": 5820,\n    \"THREADS\": 39,\n    \"FILE_PATH\": \"C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 12.0\\\\Common7\\\\IDE\\\\devenv.exe\",\n    \"BASE_ADDRESS\": 798949376\n  },\n  \"PARENT_PROCESS_ID\": 5820,\n  \"COMMAND_LINE\": \"-q  -s {0257E42D-7F05-42C4-B402-34C1CC2F2EAD} -p 5820\",\n  \"FILE_PATH\": \"C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 12.0\\\\VC\\\\vcpackages\\\\VCPkgSrv.exe\",\n  \"PROCESS_ID\": 1080,\n  \"THREADS\": 9,\n  \"MEMORY_USAGE\": 8282112,\n  \"TIMESTAMP\": 1456285660,\n  \"BASE_ADDRESS\": 4194304\n}\n</code></pre>"},{"location":"8-reference/edr-events/#new_remote_thread","title":"NEW_REMOTE_THREAD","text":"<p>Generated when a thread is created by a process in another process. This is often used by malware during various forms of code injection.</p> <p>In this case, the process id <code>492</code> created a thread (with id <code>9012</code>) in the process id <code>7944</code>. The parent process is also globally uniquely identified by the <code>routing/parent</code> and the process where the thread was started is globally uniquely identified by the <code>routing/target</code> (not visible here).</p> <p>Platforms:</p> <pre><code>{\n  \"THREAD_ID\": 9012,\n  \"PROCESS_ID\": 7944,\n  \"PARENT_PROCESS_ID\": 492\n}\n</code></pre>"},{"location":"8-reference/edr-events/#new_tcp4_connection","title":"NEW_TCP4_CONNECTION","text":"<p>Generated when a new TCPv4 connection is established, either inbound or outbound.</p> <p>Platforms:</p> <pre><code>{\n  \"PROCESS_ID\": 6788,\n  \"DESTINATION\": {\n    \"IP_ADDRESS\": \"172.16.223.219\",\n    \"PORT\": 80\n  },\n  \"STATE\": 5,\n  \"TIMESTAMP\": 1468335512047,\n  \"SOURCE\": {\n    \"IP_ADDRESS\": \"172.16.223.163\",\n    \"PORT\": 63581\n  }\n}\n</code></pre>"},{"location":"8-reference/edr-events/#new_tcp6_connection","title":"NEW_TCP6_CONNECTION","text":"<p>Generated when a new TCPv6 connection is established, either inbound or outbound.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#new_udp4_connection","title":"NEW_UDP4_CONNECTION","text":"<p>Generated when a new UDPv4 socket \"connection\" is established, either inbound or outbound.</p> <p>Platforms:</p> <pre><code>{\n  \"TIMESTAMP\": 1468335452828,\n  \"PROCESS_ID\": 924,\n  \"IP_ADDRESS\": \"172.16.223.163\",\n  \"PORT\": 63057\n}\n</code></pre>"},{"location":"8-reference/edr-events/#new_udp6_connection","title":"NEW_UDP6_CONNECTION","text":"<p>Generated when a new UDPv6 socket \"connection\" is established, either inbound or outbound.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#open_named_pipe","title":"OPEN_NAMED_PIPE","text":"<p>This event is emitted when an existing Named Pipe is opened by a process.</p> <p>Platforms:</p> <pre><code>{\n  \"FILE_PATH\": \"\\\\Device\\\\NamedPipe\\\\lsass\",\n  \"PROCESS_ID\": 2232\n}\n</code></pre>"},{"location":"8-reference/edr-events/#os_autoruns_rep","title":"OS_AUTORUNS_REP","text":"<p>Response from an <code>os_autoruns</code> request.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"TIMESTAMP\": 1456194620,\n  \"AUTORUNS\": [\n    {\n      \"REGISTRY_KEY\": \"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\\\\VMware User Process\",\n      \"FILE_PATH\": \"\\\"C:\\\\Program Files\\\\VMware\\\\VMware Tools\\\\vmtoolsd.exe\\\" -n vmusr\",\n      \"HASH\": \"036608644e3c282efaac49792a2bb2534df95e859e2ddc727cd5d2e764133d14\"\n    }\n  ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#os_drivers_rep","title":"OS_DRIVERS_REP","text":"<p>Response from an <code>os_drivers</code> request.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"SVCS\": [\n    {\n      \"PROCESS_ID\": 0,\n      \"SVC_TYPE\": 1,\n      \"SVC_NAME\": \"1394ohci\",\n      \"SVC_STATE\": 1,\n      \"HASH\": \"9ecf6211ccd30273a23247e87c31b3a2acda623133cef6e9b3243463c0609c5f\",\n      \"SVC_DISPLAY_NAME\": \"1394 OHCI Compliant Host Controller\",\n      \"EXECUTABLE\": \"\\\\SystemRoot\\\\System32\\\\drivers\\\\1394ohci.sys\"\n    }\n  ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#os_kill_process_rep","title":"OS_KILL_PROCESS_REP","text":"<p>Response from an <code>os_kill_process</code> request.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"ERROR\": 0,\n  \"PROCESS_ID\": 579\n}\n</code></pre>"},{"location":"8-reference/edr-events/#os_packages_rep","title":"OS_PACKAGES_REP","text":"<p>List of packages installed on the system. This is currently Windows only but will be expanded to MacOS and Linux in the future.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>\"PACKAGES\": [\n  {\n    \"PACKAGE_NAME\": \"Microsoft Windows Driver Development Kit Uninstall\"\n  }\n]\n</code></pre>"},{"location":"8-reference/edr-events/#os_processes_rep","title":"OS_PROCESSES_REP","text":"<p>Response from an <code>os_process</code> request.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"PROCESSES\": [\n    {\n      \"COMMAND_LINE\": \"/sbin/init\",\n      \"FILE_PATH\": \"/usr/lib/systemd/systemd\",\n      \"HASH\": \"477209848fabcaf52c060d98287f880845cb07fc9696216dbcfe9b6ea8e72bcd\"\n    }\n  ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#os_resume_rep","title":"OS_RESUME_REP","text":"<p>Response from an <code>os_resume</code> request.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#os_services_rep","title":"OS_SERVICES_REP","text":"<p>Response from an <code>os_services</code> request.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"SVCS\": [\n    {\n      \"PROCESS_ID\": 0,\n      \"SVC_TYPE\": 32,\n      \"DLL\": \"%SystemRoot%\\\\System32\\\\AJRouter.dll\",\n      \"SVC_NAME\": \"AJRouter\"\n    }\n  ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#os_suspend_rep","title":"OS_SUSPEND_REP","text":"<p>Response from an <code>os_suspend</code> request.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#os_users_rep","title":"OS_USERS_REP","text":"<p>Response from an <code>os_users</code> request.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"USERS\": [\n    {\n      \"USER_NAME\": \"Administrator\"\n    }\n  ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#os_version_rep","title":"OS_VERSION_REP","text":"<p>Response from an <code>os_version</code> request.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"BUILD_NUMBER\": 20348\n}\n</code></pre>"},{"location":"8-reference/edr-events/#pcap_list_interfaces_rep","title":"PCAP_LIST_INTERFACES_REP","text":"<p>Response from a <code>pcap_ifaces</code> request.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"INTERFACE\": [\n    {\n      \"NAME\": \"ens4\",\n      \"IPV4\": [\"10.128.15.198\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#process_environment","title":"PROCESS_ENVIRONMENT","text":"<p>Generated when a process starts. It lists all environment variables associated with that new process.</p> <p>Platforms:</p> <pre><code>{\n  \"ENVIRONMENT_VARIABLES\": [\n    \"LANG=en_US.UTF-8\",\n    \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n    \"NOTIFY_SOCKET=/run/systemd/notify\",\n    \"LISTEN_PID=18950\",\n    \"LISTEN_FDS=2\"\n  ],\n  \"PROCESS_ID\": 13463\n}\n</code></pre>"},{"location":"8-reference/edr-events/#receipt","title":"RECEIPT","text":"<p>This event is used as a generic response to some commands. The contents of a <code>RECEIPT</code> event usually contain an <code>ERROR</code> code that you can use to determine if the command was successful (<code>ERROR</code> codes can be explored here). It's often a good idea to issue the original command with an <code>investigation_id</code> which will get echoed in the <code>RECEIPT</code> related to that command to make it easier to track.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#registry_create","title":"REGISTRY_CREATE","text":"<p>This event is generated whenever a registry key / value is created on a Windows OS.</p> <p>Platforms:</p> <pre><code>{\n  \"PROCESS_ID\":  764,\n  \"REGISTRY_KEY\":   \"\\\\REGISTRY\\\\A\\\\{fddf4643-a007-4086-903e-be998801d0f7}\\\\Events\\\\{8fb5d848-23dc-498f-ac61-84b93aac1c33}\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#registry_delete","title":"REGISTRY_DELETE","text":"<p>This event is generated whenever a registry key / value is deleted on a Windows OS.</p> <p>Platforms:</p> <pre><code>{\n  \"PROCESS_ID\":  764,\n  \"REGISTRY_KEY\":   \"\\\\REGISTRY\\\\A\\\\{fddf4643-a007-4086-903e-be998801d0f7}\\\\Events\\\\{8fb5d848-23dc-498f-ac61-84b93aac1c33}\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#registry_list_rep","title":"REGISTRY_LIST_REP","text":"<p>This event is generated in response to the <code>reg_list</code> command to list keys and values in a registry key.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n    \"REGISTRY_KEY\": [\n      \"ActiveState\"\n    ],\n    \"ROOT\": \"hklm\\\\software\",\n    \"REGISTRY_VALUE\": [\n      {\n        \"TYPE\": 4,\n        \"NAME\": \"Order\"\n      }\n    ],\n    \"ERROR\": 0\n}\n</code></pre>"},{"location":"8-reference/edr-events/#registry_write","title":"REGISTRY_WRITE","text":"<p>This event is generated whenever a registry value is written to on a Windows OS.</p> <p>The <code>REGISTRY_VALUE</code> contains the first 16 bytes of the value written to the registry. If this value is a valid ASCII or Unicode string, the value will be as-is. On the other hand if the value is binary data, it will be a base64 encoded string, see examples below.</p> <p>The <code>SIZE</code> is the size value used in the original registry write call. The <code>TYPE</code> is the Windows data type of the entry written as per Microsoft's definition.</p> <p>Platforms:</p> <p>Valid string payload:</p> <pre><code>{\n  \"PROCESS_ID\":1820,\n  \"REGISTRY_KEY\":\"\\\\REGISTRY\\\\MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Windows Defender\\\\Diagnostics\\\\LastKnownGoodPlatformLocation\",\n  \"REGISTRY_VALUE\":\"C:\\\\Progr\",\n  \"SIZE\":1,\n  \"TYPE\":1,\n}\n</code></pre> <p>Binary payload:</p> <pre><code>{\n  \"PROCESS_ID\": 1700,\n  \"REGISTRY_KEY\": \"\\\\REGISTRY\\\\MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Diagnostics\\\\DiagTrack\\\\HeartBeats\\\\Default\\\\LastHeartBeatTime\",\n  \"REGISTRY_VALUE\": \"bMPGjjDM1wE=\",\"SIZE\": 11,\n  \"TYPE\": 11\n}\n</code></pre>"},{"location":"8-reference/edr-events/#rejoin_network","title":"REJOIN_NETWORK","text":"<p>Emitted after a sensor is allowed network connectivity again (after it was previously segregated). An error code of 0 indicates success.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"ERROR\": 0\n}\n</code></pre>"},{"location":"8-reference/edr-events/#remote_process_handle","title":"REMOTE_PROCESS_HANDLE","text":"<p>Generated whenever a process opens a handle to another process with access flags like <code>VM_READ</code>, <code>VM_WRITE</code>, or <code>PROCESS_CREATE_THREAD</code>.</p> <p>The <code>ACCESS_FLAGS</code> is the access mask as defined here.</p> <p>Platforms:</p> <pre><code>{\n  \"ACCESS_FLAGS\": 136208,\n  \"PARENT_PROCESS_ID\": 6492,\n  \"PROCESS_ID\": 2516\n}\n</code></pre>"},{"location":"8-reference/edr-events/#segregate_network","title":"SEGREGATE_NETWORK","text":"<p>Emitted when a sensor is segregated (isolated) from the network using the <code>segregate_network</code> command. An error code of 0 indicates success.</p> <p>Platforms:</p> <p>Sample Event:</p> <pre><code>{\n  \"ERROR\": 0\n}\n</code></pre>"},{"location":"8-reference/edr-events/#sensitive_process_access","title":"SENSITIVE_PROCESS_ACCESS","text":"<p>Generated when a process gains sensitive access to operating system processes like <code>lsass.exe</code> on Windows.</p> <p>Note</p> <p>SENSITIVE_PROCESS_ACCESS currently is only emitted for processes accessing <code>lsass.exe</code> on Windows.</p> <p>Platforms:</p> <pre><code>{\n  \"EVENTS\": [\n    {\n      \"event\": {\n        \"COMMAND_LINE\": \"C:\\\\WINDOWS\\\\system32\\\\lsass.exe\",\n        \"FILE_PATH\": \"C:\\\\WINDOWS\\\\system32\\\\lsass.exe\",\n        \"PARENT_PROCESS_ID\": 484,\n        \"PROCESS_ID\": 636,\n        \"THREADS\": 12,\n        \"USER_NAME\": \"BUILTIN\\\\Administrators\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"8-reference/edr-events/#service_change","title":"SERVICE_CHANGE","text":"<p>Generated when a Service is changed.</p> <p>Platforms:</p> <pre><code>{\n  \"PROCESS_ID\": 0,\n  \"SVC_TYPE\": 32,\n  \"DLL\": \"%SystemRoot%\\\\system32\\\\wlidsvc.dll\",\n  \"SVC_NAME\": \"wlidsvc\",\n  \"SVC_STATE\": 1,\n  \"HASH\": \"b37199495115ed423ba99b7317377ce865bb482d4e847861e871480ac49d4a84\",\n  \"SVC_DISPLAY_NAME\": \"Microsoft Account Sign-in Assistant\",\n  \"TIMESTAMP\": 1467942600540,\n  \"EXECUTABLE\": \"%SystemRoot%\\\\system32\\\\svchost.exe -k netsvcs\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#ssh_login","title":"SSH_LOGIN","text":"<p>Generated when a user logs in via SSH.</p> <p>Platforms:</p> <pre><code>{\n  \"USER_NAME\": \"root\",\n  \"TIMESTAMP\": 1468335816308\n}\n</code></pre>"},{"location":"8-reference/edr-events/#self_test","title":"SELF_TEST","text":"<p>Internal event to manually request a power-on-self-test (POST) from the sensor.</p>"},{"location":"8-reference/edr-events/#shutting_down","title":"SHUTTING_DOWN","text":"<p>Event generated when the sensor shuts down. Note: this event may not be observed if the host shuts down abruptly or too quickly.</p> <p>Platforms:</p> <p>Event Data</p> Field Type Notes ts Epoch timestamp <p>Sample Event:</p> <pre><code>{\n  \"SHUTTING_DOWN\": {\n    \"ts\": 1455674775\n  }\n}\n</code></pre>"},{"location":"8-reference/edr-events/#ssh_logout","title":"SSH_LOGOUT","text":"<p>Generated when a user logs out via SSH.</p> <p>Platforms:</p> <pre><code>{\n  \"USER_NAME\": \"root\",\n  \"TIMESTAMP\": 1468335916308\n}\n</code></pre>"},{"location":"8-reference/edr-events/#starting_up","title":"STARTING_UP","text":"<p>Event generated when the sensor starts.</p> <p>Platforms:</p> <p>Event Data</p> Field Type Notes ts Epoch timestamp <p>Sample Event:</p> <pre><code>{\n  \"STARTING_UP\": {\n    \"ts\": 1455674775\n  }\n}\n</code></pre>"},{"location":"8-reference/edr-events/#terminate_process","title":"TERMINATE_PROCESS","text":"<p>Generated when a process exits.</p> <p>Platforms:</p> <pre><code>{\n  \"PARENT_PROCESS_ID\": 5820,\n  \"TIMESTAMP\": 1456285661,\n  \"PROCESS_ID\": 6072\n}\n</code></pre>"},{"location":"8-reference/edr-events/#terminate_tcp4_connection","title":"TERMINATE_TCP4_CONNECTION","text":"<p>Generated when a TCPv4 connection terminates.</p> <pre><code>{\n  \"DESTINATION\": {\n    \"IP_ADDRESS\": \"61.55.252.93\",\n    \"PORT\": 443\n  },\n  \"PROCESS_ID\": 4784,\n  \"SOURCE\": {\n    \"IP_ADDRESS\": \"172.16.223.138\",\n    \"PORT\": 50145\n  }\n}\n</code></pre>"},{"location":"8-reference/edr-events/#terminate_tcp6_connection","title":"TERMINATE_TCP6_CONNECTION","text":"<p>Generated when a TCPv6 connection terminates.</p>"},{"location":"8-reference/edr-events/#terminate_udp4_connection","title":"TERMINATE_UDP4_CONNECTION","text":"<p>Generated when a UDPv4 socket terminates.</p>"},{"location":"8-reference/edr-events/#terminate_udp6_connection","title":"TERMINATE_UDP6_CONNECTION","text":"<p>Generated when a UDPv6 socket terminates.</p>"},{"location":"8-reference/edr-events/#thread_injection","title":"THREAD_INJECTION","text":"<p>This event is generated when the sensor detects what looks like a thread injection into a remote process.</p> <p>Platforms:</p> <pre><code>{\n  \"event\": {\n    \"EVENTS\": [\n      {\n        \"event\": {\n          \"ACCESS_FLAGS\": 2097151,\n          \"PARENT_PROCESS_ID\": 5380,\n          \"PROCESS_ID\": 4276,\n          \"SOURCE\": {\n            \"BASE_ADDRESS\": 140701160243200,\n            \"COMMAND_LINE\": \"\\\"C:\\\\Program Files (x86)\\\\Microsoft\\\\Edge\\\\Application\\\\msedge.exe\\\" --continue-active-setup\",\n            \"FILE_IS_SIGNED\": 1,\n            \"FILE_PATH\": \"C:\\\\Program Files (x86)\\\\Microsoft\\\\Edge\\\\Application\\\\msedge.exe\",\n            \"HASH\": \"c47fc20231ffc1e3befef952478363bff96cf3af1f36da4bd1129c8ed0e17fdb\",\n            \"MEMORY_USAGE\": 5881856,\n            \"PARENT_ATOM\": \"df4e951a09e365cb46c36c11659ee556\",\n            \"PARENT_PROCESS_ID\": 5972,\n            \"PROCESS_ID\": 5380,\n            \"THIS_ATOM\": \"37b57d228af708b25d097f32659ee557\",\n            \"THREADS\": 3,\n            \"TIMESTAMP\": 1704912214704,\n            \"USER_NAME\": \"WINDOWS-SERVER-\\\\whitney\"\n          },\n          \"TARGET\": {\n            \"COMMAND_LINE\": \"C:\\\\Windows\\\\system32\\\\sppsvc.exe\",\n            \"FILE_IS_SIGNED\": 1,\n            \"FILE_PATH\": \"C:\\\\Windows\\\\system32\\\\sppsvc.exe\",\n            \"HASH\": \"1ca5b9745872748575c452e456966b8ed1c4153757e9f4faf6f86c78c53d4ae8\",\n            \"MEMORY_USAGE\": 6156288,\n            \"PARENT_ATOM\": \"74be005ef68f6edb8682d972659ee024\",\n            \"PARENT_PROCESS_ID\": 628,\n            \"PROCESS_ID\": 4276,\n            \"THIS_ATOM\": \"fe1dee93442392ea97becdad659ee516\",\n            \"THREADS\": 3,\n            \"TIMESTAMP\": 1704912150174,\n            \"USER_NAME\": \"NT AUTHORITY\\\\NETWORK SERVICE\"\n          }\n        },\n        \"routing\": {\n          \"arch\": 2,\n          \"did\": \"\",\n          \"event_id\": \"d61caa47-225a-4f6a-9f3a-6094cdb3c383\",\n          \"event_time\": 1704912219717,\n          \"event_type\": \"REMOTE_PROCESS_HANDLE\",\n          \"ext_ip\": \"104.198.223.172\",\n          \"hostname\": \"windows-server-2022-bc76d608-9d83-4c6c-bdd5-f86bbd385a94-0.c.lc-demo-infra.internal.\",\n          \"iid\": \"3c5c33e6-daaf-4029-be0b-94f50b86777e\",\n          \"int_ip\": \"10.128.15.197\",\n          \"moduleid\": 2,\n          \"oid\": \"bc76d608-9d83-4c6c-bdd5-f86bbd385a94\",\n          \"parent\": \"37b57d228af708b25d097f32659ee557\",\n          \"plat\": 268435456,\n          \"sid\": \"ccd0c386-88c1-4f8d-954c-581a95a1cc34\",\n          \"tags\": [\n            \"windows\"\n          ],\n          \"target\": \"fe1dee93442392ea97becdad659ee516\",\n          \"this\": \"87509849fc608bce8a236f49659ee55b\"\n        }\n      },\n      {\n        \"event\": {\n          \"PARENT_PROCESS_ID\": 5380,\n          \"PROCESS_ID\": 4276,\n          \"SOURCE\": {\n            \"BASE_ADDRESS\": 140701160243200,\n            \"COMMAND_LINE\": \"\\\"C:\\\\Program Files (x86)\\\\Microsoft\\\\Edge\\\\Application\\\\msedge.exe\\\" --continue-active-setup\",\n            \"FILE_IS_SIGNED\": 1,\n            \"FILE_PATH\": \"C:\\\\Program Files (x86)\\\\Microsoft\\\\Edge\\\\Application\\\\msedge.exe\",\n            \"HASH\": \"c47fc20231ffc1e3befef952478363bff96cf3af1f36da4bd1129c8ed0e17fdb\",\n            \"MEMORY_USAGE\": 5881856,\n            \"PARENT_ATOM\": \"df4e951a09e365cb46c36c11659ee556\",\n            \"PARENT_PROCESS_ID\": 5972,\n            \"PROCESS_ID\": 5380,\n            \"THIS_ATOM\": \"37b57d228af708b25d097f32659ee557\",\n            \"THREADS\": 3,\n            \"TIMESTAMP\": 1704912214704,\n            \"USER_NAME\": \"WINDOWS-SERVER-\\\\whitney\"\n          },\n          \"TARGET\": {\n            \"COMMAND_LINE\": \"C:\\\\Windows\\\\system32\\\\sppsvc.exe\",\n            \"FILE_IS_SIGNED\": 1,\n            \"FILE_PATH\": \"C:\\\\Windows\\\\system32\\\\sppsvc.exe\",\n            \"HASH\": \"1ca5b9745872748575c452e456966b8ed1c4153757e9f4faf6f86c78c53d4ae8\",\n            \"MEMORY_USAGE\": 6156288,\n            \"PARENT_ATOM\": \"74be005ef68f6edb8682d972659ee024\",\n            \"PARENT_PROCESS_ID\": 628,\n            \"PROCESS_ID\": 4276,\n            \"THIS_ATOM\": \"fe1dee93442392ea97becdad659ee516\",\n            \"THREADS\": 3,\n            \"TIMESTAMP\": 1704912150174,\n            \"USER_NAME\": \"NT AUTHORITY\\\\NETWORK SERVICE\"\n          },\n          \"THREAD_ID\": 3672\n        },\n        \"routing\": {\n          \"arch\": 2,\n          \"did\": \"\",\n          \"event_id\": \"ece7d85e-a43c-49d3-bc9a-28ace6dc1b02\",\n          \"event_time\": 1704912219967,\n          \"event_type\": \"NEW_REMOTE_THREAD\",\n          \"ext_ip\": \"104.198.223.172\",\n          \"hostname\": \"windows-server-2022-bc76d608-9d83-4c6c-bdd5-f86bbd385a94-0.c.lc-demo-infra.internal.\",\n          \"iid\": \"3c5c33e6-daaf-4029-be0b-94f50b86777e\",\n          \"int_ip\": \"10.128.15.197\",\n          \"moduleid\": 2,\n          \"oid\": \"bc76d608-9d83-4c6c-bdd5-f86bbd385a94\",\n          \"parent\": \"37b57d228af708b25d097f32659ee557\",\n          \"plat\": 268435456,\n          \"sid\": \"ccd0c386-88c1-4f8d-954c-581a95a1cc34\",\n          \"tags\": [\n            \"windows\"\n          ],\n          \"target\": \"fe1dee93442392ea97becdad659ee516\",\n          \"this\": \"b30a499edf9ec2e424b07d20659ee55b\"\n        }\n      }\n    ]\n  }\n  \"ts\": \"2024-01-10 18:43:39\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#user_login","title":"USER_LOGIN","text":"<p>Generated when a user logs in to the operating system.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#user_logout","title":"USER_LOGOUT","text":"<p>Generated when a user logs out of the operating system.</p> <p>Platforms:</p>"},{"location":"8-reference/edr-events/#user_observed","title":"USER_OBSERVED","text":"<p>Generated the first time a user is observed on a host.</p> <p>Platforms:</p> <pre><code>{\n  \"TIMESTAMP\": 1479241363009,\n  \"USER_NAME\": \"root\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#volume_mount","title":"VOLUME_MOUNT","text":"<p>This event is generated when a volume is mounted.</p> <p>Platforms:</p> <pre><code>{\n  \"VOLUME_PATH\": \"E:\",\n  \"DEVICE_NAME\": \"\\\\Device\\\\HarddiskVolume3\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#volume_unmount","title":"VOLUME_UNMOUNT","text":"<p>This event is generated when a volume is unmounted.</p> <p>Platforms:</p> <pre><code>{\n  \"VOLUME_PATH\": \"/Volumes/RECOVERY\",\n  \"VOLUME_NAME\": \"/dev/disk2s1\"\n}\n</code></pre>"},{"location":"8-reference/edr-events/#yara_detection","title":"YARA_DETECTION","text":"<p>Generated when a YARA scan finds a match.</p> <p>Platforms:</p> <pre><code>{\n  \"RULE_NAME\": \"malware_detection_rule\",\n  \"FILE_PATH\": \"C:\\\\malicious.exe\",\n  \"HASH\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n}\n</code></pre>"},{"location":"8-reference/endpoint-agent-commands/","title":"Reference: Endpoint Agent Commands","text":""},{"location":"8-reference/endpoint-agent-commands/#supported-commands-by-os","title":"Supported Commands by OS","text":"<p>For commands which emit a report/reply event type from the agent, the corresponding event type is provided.</p> Command Report/Reply Event macOS Windows Linux Chrome Edge artifact_get N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f deny_tree N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f dir_find_hash DIR_FINDHASH_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f dir_list DIR_LIST_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f dns_resolve DNS_REQUEST \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f doc_cache_get GET_DOCUMENT_REP \u2611\ufe0f \u2611\ufe0f get_debug_data DEBUG_DATA_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f exfil_add CLOUD_NOTIFICATION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f exfil_del CLOUD_NOTIFICATION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f exfil_get GET_EXFIL_EVENT_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f file_del FILE_DEL_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f file_get FILE_GET_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f file_hash FILE_HASH_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f file_info FILE_INFO_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f file_mov FILE_MOV_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f fim_add FIM_ADD \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f fim_del FIM_DEL \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f fim_get FIM_LIST_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f hidden_module_scan HIDDEN_MODULE_DETECTED \u2611\ufe0f \u2611\ufe0f history_dump HISTORY_DUMP_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f log_get N/A \u2611\ufe0f logoff N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f mem_find_handle MEM_FIND_HANDLES_REP \u2611\ufe0f mem_find_string MEM_FIND_STRING_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f mem_handles MEM_HANDLES_REP \u2611\ufe0f mem_map MEM_MAP_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f mem_read MEM_READ_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f mem_strings MEM_STRINGS_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f netstat NETSTAT_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_autoruns OS_AUTORUNS_REP \u2611\ufe0f \u2611\ufe0f os_drivers N/A \u2611\ufe0f os_kill_process OS_KILL_PROCESS_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_packages OS_PACKAGES_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_processes OS_PROCESSES_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_resume OS_RESUME_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_services OS_SERVICES_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_suspend OS_SUSPEND_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_users OS_USERS_REP \u2611\ufe0f os_version OS_VERSION_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f put RECEIPT \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f rejoin_network REJOIN_NETWORK \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f restart N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f run N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f seal \u2611\ufe0f segregate_network SEGREGATE_NETWORK \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f set_performance_mode N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f shutdown \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f uninstall N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f yara_scan YARA_DETECTION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f yara_update N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f epp_status [EPP_STATUS_REP] \u2611\ufe0f epp_scan [EPP_SCAN_REP] \u2611\ufe0f epp_list_exclusions [EPP_LIST_EXCLUSIONS_REP] \u2611\ufe0f epp_add_exclusion [EPP_ADD_EXCLUSION_REP] \u2611\ufe0f epp_rem_exclusion [EPP_REM_EXCLUSION_REP] \u2611\ufe0f epp_list_quarantine [EPP_LIST_QUARANTINE_REP] \u2611\ufe0f"},{"location":"8-reference/endpoint-agent-commands/#command-descriptions","title":"Command Descriptions","text":""},{"location":"8-reference/endpoint-agent-commands/#artifact_get","title":"artifact_get","text":"<p>Collect an artifact from a sensor by specifying a file path.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file</code> (required): File path to collect from the sensor - <code>type</code> (optional): Artifact type (e.g., \"pcap\") - <code>payload_id</code> (optional): Idempotent payload ID for the request (auto-generated if not provided) - <code>days_retention</code> (optional): Number of days the artifact should be retained (default: 30) - <code>is_ignore_cert</code> (optional): If set, the sensor will ignore SSL certificate mismatches during artifact upload</p> <p>Response Event: FILE_GET_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; artifact_get --file \"C:\\\\Windows\\\\System32\\\\drivers\\\\etc\\\\hosts\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#dir_list","title":"dir_list","text":"<p>List files and directories at a specified path on the endpoint.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>dir_path</code> (required): Directory path to list - <code>depth</code> (optional): Recursion depth (default: 0 = no recursion) - <code>file_pattern</code> (optional): File pattern filter (e.g., \"*.exe\")</p> <p>Response Event: DIR_LIST_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; dir_list --dir_path \"C:\\\\Windows\\\\System32\" --depth 1\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"DIRECTORY_LIST\": [\n      {\n        \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\cmd.exe\",\n        \"FILE_SIZE\": 289792,\n        \"LAST_MODIFIED\": 1579000000\n      }\n    ]\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#dir_findhash","title":"dir_findhash","text":"<p>Search for files matching a specific hash across a directory tree.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>dir_path</code> (required): Root directory to search - <code>hash</code> (required): Hash value to search for (MD5, SHA1, or SHA256) - <code>depth</code> (optional): Maximum recursion depth</p> <p>Response Event: DIR_FINDHASH_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; dir_findhash --dir_path \"/var\" --hash &lt;HASH_VALUE&gt;\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#dns_resolve","title":"dns_resolve","text":"<p>Perform DNS resolution on the endpoint to determine what DNS server responds.</p> <p>Platforms: macOS | Windows | Linux | Chrome | Edge</p> <p>Parameters: - <code>hostname</code> (required): Hostname to resolve</p> <p>Response Event: DNS_REQUEST</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; dns_resolve --hostname \"example.com\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#doc_cache_get","title":"doc_cache_get","text":"<p>Retrieve a previously cached document from the sensor's local cache.</p> <p>Platforms: macOS | Windows</p> <p>Parameters: - <code>hash</code> (required): Hash of the cached document</p> <p>Response Event: GET_DOCUMENT_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; doc_cache_get --hash &lt;DOC_HASH&gt;\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#exfil_add","title":"exfil_add","text":"<p>Add an exfiltration detection watch for specific event types and patterns.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>event</code> (required): Event type to monitor (e.g., \"DNS_REQUEST\", \"NEW_PROCESS\") - <code>operator</code> (required): Comparison operator (\"is\", \"contains\", \"matches\", etc.) - <code>path</code> (required): JSON path to the field to watch (e.g., \"event/DOMAIN_NAME\") - <code>value</code> (required): Value or pattern to match - <code>expire</code> (optional): TTL in seconds for the watch (default: permanent)</p> <p>Response Event: EXFIL_ADD_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; exfil_add --event \"DNS_REQUEST\" --operator \"contains\" --path \"event/DOMAIN_NAME\" --value \"malware\" --expire 3600\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#exfil_del","title":"exfil_del","text":"<p>Remove an exfiltration detection watch by its ID.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>id</code> (required): Watch ID to remove (from exfil_get response)</p> <p>Response Event: EXFIL_DEL_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; exfil_del --id &lt;WATCH_ID&gt;\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#exfil_get","title":"exfil_get","text":"<p>List all active exfiltration detection watches on the sensor.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: EXFIL_GET_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; exfil_get\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#file_del","title":"file_del","text":"<p>Delete a file from the endpoint filesystem.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path to the file to delete</p> <p>Response Event: FILE_DEL_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; file_del --file_path \"/tmp/suspicious_file\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#file_get","title":"file_get","text":"<p>Retrieve a file from the endpoint and upload it to LimaCharlie cloud storage.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path to the file to retrieve</p> <p>Response Event: FILE_GET_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; file_get --file_path \"C:\\\\Windows\\\\System32\\\\calc.exe\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#file_hash","title":"file_hash","text":"<p>Calculate cryptographic hashes (MD5, SHA1, SHA256) for a file.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path to the file to hash</p> <p>Response Event: FILE_HASH_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; file_hash --file_path \"/etc/passwd\"\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"FILE_PATH\": \"/etc/passwd\",\n    \"HASH\": \"abc123...\",\n    \"MD5\": \"def456...\",\n    \"SHA1\": \"ghi789...\",\n    \"SHA256\": \"jkl012...\"\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#file_info","title":"file_info","text":"<p>Get detailed metadata about a file without retrieving its contents.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path to the file</p> <p>Response Event: FILE_INFO_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; file_info --file_path \"C:\\\\Program Files\\\\app.exe\"\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"FILE_PATH\": \"C:\\\\Program Files\\\\app.exe\",\n    \"FILE_SIZE\": 1048576,\n    \"CREATED\": 1579000000,\n    \"MODIFIED\": 1580000000,\n    \"ACCESSED\": 1581000000\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#file_mov","title":"file_mov","text":"<p>Move or rename a file on the endpoint filesystem.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>src_path</code> (required): Source file path - <code>dst_path</code> (required): Destination file path</p> <p>Response Event: FILE_MOV_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; file_mov --src_path \"/tmp/file.txt\" --dst_path \"/tmp/renamed.txt\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#fim_add","title":"fim_add","text":"<p>Add a File Integrity Monitoring (FIM) watch for a specific path or pattern.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path or pattern to monitor (supports wildcards)</p> <p>Response Event: FIM_ADD_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; fim_add --file_path \"C:\\\\Windows\\\\System32\\\\*.dll\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#fim_del","title":"fim_del","text":"<p>Remove a File Integrity Monitoring watch.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path pattern to stop monitoring</p> <p>Response Event: FIM_REMOVE (note: event name is FIM_REMOVE, not FIM_DEL_REP)</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; fim_del --file_path \"C:\\\\Windows\\\\System32\\\\*.dll\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#fim_get","title":"fim_get","text":"<p>List all active File Integrity Monitoring watches on the sensor.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: FIM_LIST_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; fim_get\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#get_debug_data","title":"get_debug_data","text":"<p>Retrieve internal sensor debug data for troubleshooting.</p> <p>Platforms: Windows</p> <p>Parameters: None</p> <p>Response Event: DEBUG_DATA_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; get_debug_data\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#hidden_module_scan","title":"hidden_module_scan","text":"<p>Scan for hidden or stealthy modules loaded in process memory that may not appear in normal module lists.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>pid</code> (optional): Specific process ID to scan (default: all processes)</p> <p>Response Event: HIDDEN_MODULE_DETECTED</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; hidden_module_scan --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#history_dump","title":"history_dump","text":"<p>Export a dump of recent events from the sensor's local event cache.</p> <p>Platforms: macOS | Windows | Linux | Chrome | Edge</p> <p>Parameters: None</p> <p>Response Event: HISTORY_DUMP_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; history_dump\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#log_get","title":"log_get","text":"<p>Retrieve Windows Event Logs or macOS Unified Logs from the endpoint.</p> <p>Platforms: Windows (Event Logs) | macOS (Unified Logs)</p> <p>Parameters: - <code>source</code> (Windows required): Event log source name (e.g., \"Security\", \"System\") - <code>predicate</code> (macOS optional): Unified log filter predicate</p> <p>Response Event: LOG_GET_REP</p> <p>Usage Example: <pre><code># Windows\nlimacharlie sensor task &lt;SID&gt; log_get --source \"Security\"\n\n# macOS\nlimacharlie sensor task &lt;SID&gt; log_get --predicate \"eventType == logEvent\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#mem_find_string","title":"mem_find_string","text":"<p>Search process memory for specific string patterns.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to scan - <code>strings</code> (required): String or list of strings to search for</p> <p>Response Event: MEM_FIND_STRING_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; mem_find_string --pid 1234 --strings \"password\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#mem_find_handle","title":"mem_find_handle","text":"<p>Find handles (file, registry, process) held by a process on Windows.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>pid</code> (optional): Specific process ID (default: all processes) - <code>needle</code> (optional): Handle name pattern to search for</p> <p>Response Event: MEM_FIND_HANDLE_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; mem_find_handle --pid 1234 --needle \"malware.exe\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#mem_map","title":"mem_map","text":"<p>Get memory map of a process showing loaded modules and memory regions.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to map</p> <p>Response Event: MEM_MAP_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; mem_map --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#mem_read","title":"mem_read","text":"<p>Read raw memory from a process at a specific address.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID - <code>base_address</code> (required): Memory address to read from (hex format) - <code>size</code> (required): Number of bytes to read</p> <p>Response Event: MEM_READ_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; mem_read --pid 1234 --base_address 0x00400000 --size 1024\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#mem_strings","title":"mem_strings","text":"<p>Extract all readable strings from a process's memory.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to scan</p> <p>Response Event: MEM_STRINGS_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; mem_strings --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#netstat","title":"netstat","text":"<p>Get current network connections on the endpoint (similar to netstat command).</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: NETWORK_CONNECTIONS</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; netstat\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"NETWORK_ACTIVITY\": [\n      {\n        \"STATE\": \"ESTABLISHED\",\n        \"LOCAL_ADDRESS\": \"192.168.1.100\",\n        \"LOCAL_PORT\": 50234,\n        \"REMOTE_ADDRESS\": \"93.184.216.34\",\n        \"REMOTE_PORT\": 443,\n        \"PID\": 1234,\n        \"PROCESS\": \"chrome.exe\"\n      }\n    ]\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#network_summary","title":"network_summary","text":"<p>Get aggregated network statistics and active connections summary.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: NETWORK_SUMMARY</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; network_summary\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#os_kill_process","title":"os_kill_process","text":"<p>Terminate a running process.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to terminate</p> <p>Response Event: OS_KILL_PROCESS_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_kill_process --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#os_packages","title":"os_packages","text":"<p>List installed software packages on the endpoint.</p> <p>Platforms: Windows (via registry) | macOS (future) | Linux (future)</p> <p>Response Event: OS_PACKAGES_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_packages\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"PACKAGES\": [\n      {\n        \"NAME\": \"Google Chrome\",\n        \"VERSION\": \"120.0.6099.130\",\n        \"PUBLISHER\": \"Google LLC\"\n      }\n    ]\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#os_processes","title":"os_processes","text":"<p>Get a list of all running processes with detailed information.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: EXISTING_PROCESS (multiple events, one per process)</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_processes\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"PROCESS_ID\": 1234,\n    \"PARENT_PROCESS_ID\": 5678,\n    \"COMMAND_LINE\": \"C:\\\\Windows\\\\System32\\\\notepad.exe\",\n    \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\notepad.exe\",\n    \"USER_NAME\": \"DOMAIN\\\\user\"\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#os_resume","title":"os_resume","text":"<p>Resume a suspended process.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to resume</p> <p>Response Event: OS_RESUME_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_resume --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#os_services","title":"os_services","text":"<p>List all services/daemons running on the endpoint.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: OS_SERVICES_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_services\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#os_suspend","title":"os_suspend","text":"<p>Suspend (pause) a running process.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to suspend</p> <p>Response Event: OS_SUSPEND_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_suspend --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#os_autoruns","title":"os_autoruns","text":"<p>List programs configured to run automatically at system startup.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: OS_AUTORUNS_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_autoruns\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#os_drivers","title":"os_drivers","text":"<p>List all loaded kernel drivers/modules.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: OS_DRIVERS_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_drivers\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#os_version","title":"os_version","text":"<p>Get detailed operating system version information.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: OS_VERSION_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_version\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"OS_NAME\": \"Windows 11\",\n    \"OS_VERSION\": \"10.0.22631\",\n    \"ARCHITECTURE\": \"x64\"\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#rejoin_network","title":"rejoin_network","text":"<p>Re-enable network connectivity for a sensor that was previously isolated.</p> <p>Platforms: macOS | Windows | Linux | Chrome | Edge</p> <p>Parameters: None</p> <p>Response Event: None (sensor reconnects)</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; rejoin_network\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#run","title":"run","text":"<p>Execute a command or script on the endpoint (out-of-band execution).</p> <p>Platforms: macOS | Linux</p> <p>Parameters: - <code>command</code> (required): Command line to execute</p> <p>Response Event: EXEC_OOB</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; run --command \"ps aux | grep chrome\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#segregate_network","title":"segregate_network","text":"<p>Isolate a sensor from the network (except LimaCharlie cloud connectivity).</p> <p>Platforms: macOS | Windows | Linux | Chrome | Edge</p> <p>Parameters: None</p> <p>Response Event: None (sensor becomes isolated)</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; segregate_network\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#yara_scan","title":"yara_scan","text":"<p>Scan files or process memory with YARA rules.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>rule</code> (required): YARA rule content - <code>file_path</code> (optional): Specific file to scan - <code>pid</code> (optional): Specific process to scan - <code>process_expr</code> (optional): Process name pattern to scan</p> <p>Response Event: YARA_DETECTION</p> <p>Usage Example: <pre><code># Scan a file\nlimacharlie sensor task &lt;SID&gt; yara_scan --file_path \"C:\\\\suspicious.exe\" --rule \"rule test { strings: $a = \\\"malware\\\" condition: $a }\"\n\n# Scan process memory\nlimacharlie sensor task &lt;SID&gt; yara_scan --pid 1234 --rule \"rule test { strings: $a = \\\"malware\\\" condition: $a }\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#pcap_ifaces","title":"pcap_ifaces","text":"<p>List available network interfaces for packet capture.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: PCAP_INTERFACES_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; pcap_ifaces\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#pcap_start","title":"pcap_start","text":"<p>Start capturing network packets on a specified interface.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>iface</code> (required): Network interface ID or name - <code>max_size</code> (optional): Maximum capture size in MB</p> <p>Response Event: PCAP_START_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; pcap_start --iface eth0 --max_size 100\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#pcap_stop","title":"pcap_stop","text":"<p>Stop an active packet capture and upload the PCAP file.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>iface</code> (optional): Specific interface to stop (default: all)</p> <p>Response Event: PCAP_STOP_REP, followed by EXPORT_COMPLETE</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; pcap_stop\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#reg_list","title":"reg_list","text":"<p>List Windows registry keys and values.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>reg_path</code> (required): Registry path to list (e.g., \"HKEY_LOCAL_MACHINE\\SOFTWARE\")</p> <p>Response Event: REG_LIST_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; reg_list --reg_path \"HKEY_LOCAL_MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#epp_scan","title":"epp_scan","text":"<p>Trigger an Endpoint Protection (EPP) scan on a file or directory.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>file_path</code> (required): Path to scan</p> <p>Response Event: EPP_SCAN_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; epp_scan --file_path \"C:\\\\Users\\\\Public\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#epp_list_exclusions","title":"epp_list_exclusions","text":"<p>List EPP scan exclusions currently configured on the sensor.</p> <p>Platforms: Windows</p> <p>Parameters: None</p> <p>Response Event: EPP_LIST_EXCLUSIONS_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; epp_list_exclusions\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#epp_add_exclusion","title":"epp_add_exclusion","text":"<p>Add a path or process to EPP scan exclusions.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>file_path</code> (optional): File/directory path to exclude - <code>process</code> (optional): Process name to exclude</p> <p>Response Event: EPP_ADD_EXCLUSION_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; epp_add_exclusion --file_path \"C:\\\\safe_app\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#epp_rem_exclusion","title":"epp_rem_exclusion","text":"<p>Remove a path or process from EPP scan exclusions.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>file_path</code> (optional): File/directory path to remove from exclusions - <code>process</code> (optional): Process name to remove from exclusions</p> <p>Response Event: EPP_REM_EXCLUSION_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; epp_rem_exclusion --file_path \"C:\\\\safe_app\"\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#epp_list_quarantine","title":"epp_list_quarantine","text":"<p>List files currently in EPP quarantine.</p> <p>Platforms: Windows</p> <p>Parameters: None</p> <p>Response Event: EPP_LIST_QUARANTINE_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; epp_list_quarantine\n</code></pre></p>"},{"location":"8-reference/endpoint-agent-commands/#command-usage-notes","title":"Command Usage Notes","text":"<p>General Syntax: <pre><code>limacharlie sensor task &lt;SENSOR_ID&gt; &lt;COMMAND_NAME&gt; [--param value ...]\n</code></pre></p> <p>Platform Abbreviations: - macOS: Apple macOS and OS X - Windows: Microsoft Windows (7, 8, 10, 11, Server editions) - Linux: Linux distributions (Ubuntu, CentOS, Debian, etc.) - Chrome: Chrome browser extension sensor - Edge: Microsoft Edge browser extension sensor</p> <p>Response Events: Most commands generate a response event (typically ending in <code>_REP</code>) that can be: - Viewed in the LimaCharlie web interface under Sensor &gt; Timeline - Retrieved via API - Triggered on with D&amp;R rules</p> <p>Error Handling: Response events typically include an <code>ERROR</code> field: - <code>ERROR: 0</code> indicates success - Non-zero ERROR values indicate specific error conditions</p> <p>Permissions: Some commands require elevated privileges (root/administrator) on the endpoint to execute successfully.</p> <p>Timeouts: Commands have default timeouts (typically 30-60 seconds). Long-running operations may timeout and can be made persistent using the Reliable Tasking extension.</p>"},{"location":"8-reference/endpoint-commands/","title":"Reference: Endpoint Agent Commands","text":""},{"location":"8-reference/endpoint-commands/#supported-commands-by-os","title":"Supported Commands by OS","text":"<p>For commands which emit a report/reply event type from the agent, the corresponding event type is provided.</p> Command Report/Reply Event macOS Windows Linux Chrome Edge artifact_get N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f deny_tree N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f dir_find_hash DIR_FINDHASH_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f dir_list DIR_LIST_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f dns_resolve DNS_REQUEST \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f doc_cache_get GET_DOCUMENT_REP \u2611\ufe0f \u2611\ufe0f get_debug_data DEBUG_DATA_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f exfil_add CLOUD_NOTIFICATION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f exfil_del CLOUD_NOTIFICATION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f exfil_get GET_EXFIL_EVENT_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f file_del FILE_DEL_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f file_get FILE_GET_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f file_hash FILE_HASH_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f file_info FILE_INFO_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f file_mov FILE_MOV_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f fim_add FIM_ADD \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f fim_del FIM_DEL \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f fim_get FIM_LIST_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f hidden_module_scan HIDDEN_MODULE_DETECTED \u2611\ufe0f \u2611\ufe0f history_dump HISTORY_DUMP_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f log_get N/A \u2611\ufe0f logoff N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f mem_find_handle MEM_FIND_HANDLES_REP \u2611\ufe0f mem_find_string MEM_FIND_STRING_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f mem_handles MEM_HANDLES_REP \u2611\ufe0f mem_map MEM_MAP_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f mem_read MEM_READ_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f mem_strings MEM_STRINGS_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f netstat NETSTAT_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_autoruns OS_AUTORUNS_REP \u2611\ufe0f \u2611\ufe0f os_drivers N/A \u2611\ufe0f os_kill_process OS_KILL_PROCESS_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_packages OS_PACKAGES_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_processes OS_PROCESSES_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_resume OS_RESUME_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_services OS_SERVICES_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_suspend OS_SUSPEND_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f os_users OS_USERS_REP \u2611\ufe0f os_version OS_VERSION_REP \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f put RECEIPT \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f rejoin_network REJOIN_NETWORK \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f restart N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f run N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f seal \u2611\ufe0f segregate_network SEGREGATE_NETWORK \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f set_performance_mode N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f shutdown \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f uninstall N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f yara_scan YARA_DETECTION \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f yara_update N/A \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f epp_status [EPP_STATUS_REP] \u2611\ufe0f epp_scan [EPP_SCAN_REP] \u2611\ufe0f epp_list_exclusions [EPP_LIST_EXCLUSIONS_REP] \u2611\ufe0f epp_add_exclusion [EPP_ADD_EXCLUSION_REP] \u2611\ufe0f epp_rem_exclusion [EPP_REM_EXCLUSION_REP] \u2611\ufe0f epp_list_quarantine [EPP_LIST_QUARANTINE_REP] \u2611\ufe0f"},{"location":"8-reference/endpoint-commands/#command-descriptions","title":"Command Descriptions","text":""},{"location":"8-reference/endpoint-commands/#artifact_get","title":"artifact_get","text":"<p>Collect an artifact from a sensor by specifying a file path.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file</code> (required): File path to collect from the sensor - <code>type</code> (optional): Artifact type (e.g., \"pcap\") - <code>payload_id</code> (optional): Idempotent payload ID for the request (auto-generated if not provided) - <code>days_retention</code> (optional): Number of days the artifact should be retained (default: 30) - <code>is_ignore_cert</code> (optional): If set, the sensor will ignore SSL certificate mismatches during artifact upload</p> <p>Response Event: FILE_GET_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; artifact_get --file \"C:\\\\Windows\\\\System32\\\\drivers\\\\etc\\\\hosts\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#dir_list","title":"dir_list","text":"<p>List files and directories at a specified path on the endpoint.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>dir_path</code> (required): Directory path to list - <code>depth</code> (optional): Recursion depth (default: 0 = no recursion) - <code>file_pattern</code> (optional): File pattern filter (e.g., \"*.exe\")</p> <p>Response Event: DIR_LIST_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; dir_list --dir_path \"C:\\\\Windows\\\\System32\" --depth 1\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"DIRECTORY_LIST\": [\n      {\n        \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\cmd.exe\",\n        \"FILE_SIZE\": 289792,\n        \"LAST_MODIFIED\": 1579000000\n      }\n    ]\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#dir_findhash","title":"dir_findhash","text":"<p>Search for files matching a specific hash across a directory tree.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>dir_path</code> (required): Root directory to search - <code>hash</code> (required): Hash value to search for (MD5, SHA1, or SHA256) - <code>depth</code> (optional): Maximum recursion depth</p> <p>Response Event: DIR_FINDHASH_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; dir_findhash --dir_path \"/var\" --hash &lt;HASH_VALUE&gt;\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#dns_resolve","title":"dns_resolve","text":"<p>Perform DNS resolution on the endpoint to determine what DNS server responds.</p> <p>Platforms: macOS | Windows | Linux | Chrome | Edge</p> <p>Parameters: - <code>hostname</code> (required): Hostname to resolve</p> <p>Response Event: DNS_REQUEST</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; dns_resolve --hostname \"example.com\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#doc_cache_get","title":"doc_cache_get","text":"<p>Retrieve a previously cached document from the sensor's local cache.</p> <p>Platforms: macOS | Windows</p> <p>Parameters: - <code>hash</code> (required): Hash of the cached document</p> <p>Response Event: GET_DOCUMENT_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; doc_cache_get --hash &lt;DOC_HASH&gt;\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#exfil_add","title":"exfil_add","text":"<p>Add an exfiltration detection watch for specific event types and patterns.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>event</code> (required): Event type to monitor (e.g., \"DNS_REQUEST\", \"NEW_PROCESS\") - <code>operator</code> (required): Comparison operator (\"is\", \"contains\", \"matches\", etc.) - <code>path</code> (required): JSON path to the field to watch (e.g., \"event/DOMAIN_NAME\") - <code>value</code> (required): Value or pattern to match - <code>expire</code> (optional): TTL in seconds for the watch (default: permanent)</p> <p>Response Event: EXFIL_ADD_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; exfil_add --event \"DNS_REQUEST\" --operator \"contains\" --path \"event/DOMAIN_NAME\" --value \"malware\" --expire 3600\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#exfil_del","title":"exfil_del","text":"<p>Remove an exfiltration detection watch by its ID.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>id</code> (required): Watch ID to remove (from exfil_get response)</p> <p>Response Event: EXFIL_DEL_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; exfil_del --id &lt;WATCH_ID&gt;\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#exfil_get","title":"exfil_get","text":"<p>List all active exfiltration detection watches on the sensor.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: EXFIL_GET_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; exfil_get\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#file_del","title":"file_del","text":"<p>Delete a file from the endpoint filesystem.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path to the file to delete</p> <p>Response Event: FILE_DEL_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; file_del --file_path \"/tmp/suspicious_file\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#file_get","title":"file_get","text":"<p>Retrieve a file from the endpoint and upload it to LimaCharlie cloud storage.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path to the file to retrieve</p> <p>Response Event: FILE_GET_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; file_get --file_path \"C:\\\\Windows\\\\System32\\\\calc.exe\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#file_hash","title":"file_hash","text":"<p>Calculate cryptographic hashes (MD5, SHA1, SHA256) for a file.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path to the file to hash</p> <p>Response Event: FILE_HASH_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; file_hash --file_path \"/etc/passwd\"\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"FILE_PATH\": \"/etc/passwd\",\n    \"HASH\": \"abc123...\",\n    \"MD5\": \"def456...\",\n    \"SHA1\": \"ghi789...\",\n    \"SHA256\": \"jkl012...\"\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#file_info","title":"file_info","text":"<p>Get detailed metadata about a file without retrieving its contents.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path to the file</p> <p>Response Event: FILE_INFO_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; file_info --file_path \"C:\\\\Program Files\\\\app.exe\"\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"FILE_PATH\": \"C:\\\\Program Files\\\\app.exe\",\n    \"FILE_SIZE\": 1048576,\n    \"CREATED\": 1579000000,\n    \"MODIFIED\": 1580000000,\n    \"ACCESSED\": 1581000000\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#file_mov","title":"file_mov","text":"<p>Move or rename a file on the endpoint filesystem.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>src_path</code> (required): Source file path - <code>dst_path</code> (required): Destination file path</p> <p>Response Event: FILE_MOV_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; file_mov --src_path \"/tmp/file.txt\" --dst_path \"/tmp/renamed.txt\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#fim_add","title":"fim_add","text":"<p>Add a File Integrity Monitoring (FIM) watch for a specific path or pattern.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path or pattern to monitor (supports wildcards)</p> <p>Response Event: FIM_ADD_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; fim_add --file_path \"C:\\\\Windows\\\\System32\\\\*.dll\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#fim_del","title":"fim_del","text":"<p>Remove a File Integrity Monitoring watch.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>file_path</code> (required): Path pattern to stop monitoring</p> <p>Response Event: FIM_REMOVE (note: event name is FIM_REMOVE, not FIM_DEL_REP)</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; fim_del --file_path \"C:\\\\Windows\\\\System32\\\\*.dll\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#fim_get","title":"fim_get","text":"<p>List all active File Integrity Monitoring watches on the sensor.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: FIM_LIST_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; fim_get\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#get_debug_data","title":"get_debug_data","text":"<p>Retrieve internal sensor debug data for troubleshooting.</p> <p>Platforms: Windows</p> <p>Parameters: None</p> <p>Response Event: DEBUG_DATA_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; get_debug_data\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#hidden_module_scan","title":"hidden_module_scan","text":"<p>Scan for hidden or stealthy modules loaded in process memory that may not appear in normal module lists.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>pid</code> (optional): Specific process ID to scan (default: all processes)</p> <p>Response Event: HIDDEN_MODULE_DETECTED</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; hidden_module_scan --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#history_dump","title":"history_dump","text":"<p>Export a dump of recent events from the sensor's local event cache.</p> <p>Platforms: macOS | Windows | Linux | Chrome | Edge</p> <p>Parameters: None</p> <p>Response Event: HISTORY_DUMP_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; history_dump\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#log_get","title":"log_get","text":"<p>Retrieve Windows Event Logs or macOS Unified Logs from the endpoint.</p> <p>Platforms: Windows (Event Logs) | macOS (Unified Logs)</p> <p>Parameters: - <code>source</code> (Windows required): Event log source name (e.g., \"Security\", \"System\") - <code>predicate</code> (macOS optional): Unified log filter predicate</p> <p>Response Event: LOG_GET_REP</p> <p>Usage Example: <pre><code># Windows\nlimacharlie sensor task &lt;SID&gt; log_get --source \"Security\"\n\n# macOS\nlimacharlie sensor task &lt;SID&gt; log_get --predicate \"eventType == logEvent\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#mem_find_string","title":"mem_find_string","text":"<p>Search process memory for specific string patterns.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to scan - <code>strings</code> (required): String or list of strings to search for</p> <p>Response Event: MEM_FIND_STRING_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; mem_find_string --pid 1234 --strings \"password\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#mem_find_handle","title":"mem_find_handle","text":"<p>Find handles (file, registry, process) held by a process on Windows.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>pid</code> (optional): Specific process ID (default: all processes) - <code>needle</code> (optional): Handle name pattern to search for</p> <p>Response Event: MEM_FIND_HANDLE_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; mem_find_handle --pid 1234 --needle \"malware.exe\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#mem_map","title":"mem_map","text":"<p>Get memory map of a process showing loaded modules and memory regions.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to map</p> <p>Response Event: MEM_MAP_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; mem_map --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#mem_read","title":"mem_read","text":"<p>Read raw memory from a process at a specific address.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID - <code>base_address</code> (required): Memory address to read from (hex format) - <code>size</code> (required): Number of bytes to read</p> <p>Response Event: MEM_READ_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; mem_read --pid 1234 --base_address 0x00400000 --size 1024\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#mem_strings","title":"mem_strings","text":"<p>Extract all readable strings from a process's memory.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to scan</p> <p>Response Event: MEM_STRINGS_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; mem_strings --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#netstat","title":"netstat","text":"<p>Get current network connections on the endpoint (similar to netstat command).</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: NETWORK_CONNECTIONS</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; netstat\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"NETWORK_ACTIVITY\": [\n      {\n        \"STATE\": \"ESTABLISHED\",\n        \"LOCAL_ADDRESS\": \"192.168.1.100\",\n        \"LOCAL_PORT\": 50234,\n        \"REMOTE_ADDRESS\": \"93.184.216.34\",\n        \"REMOTE_PORT\": 443,\n        \"PID\": 1234,\n        \"PROCESS\": \"chrome.exe\"\n      }\n    ]\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#network_summary","title":"network_summary","text":"<p>Get aggregated network statistics and active connections summary.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: NETWORK_SUMMARY</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; network_summary\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#os_kill_process","title":"os_kill_process","text":"<p>Terminate a running process.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to terminate</p> <p>Response Event: OS_KILL_PROCESS_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_kill_process --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#os_packages","title":"os_packages","text":"<p>List installed software packages on the endpoint.</p> <p>Platforms: Windows (via registry) | macOS (future) | Linux (future)</p> <p>Response Event: OS_PACKAGES_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_packages\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"PACKAGES\": [\n      {\n        \"NAME\": \"Google Chrome\",\n        \"VERSION\": \"120.0.6099.130\",\n        \"PUBLISHER\": \"Google LLC\"\n      }\n    ]\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#os_processes","title":"os_processes","text":"<p>Get a list of all running processes with detailed information.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: EXISTING_PROCESS (multiple events, one per process)</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_processes\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"PROCESS_ID\": 1234,\n    \"PARENT_PROCESS_ID\": 5678,\n    \"COMMAND_LINE\": \"C:\\\\Windows\\\\System32\\\\notepad.exe\",\n    \"FILE_PATH\": \"C:\\\\Windows\\\\System32\\\\notepad.exe\",\n    \"USER_NAME\": \"DOMAIN\\\\user\"\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#os_resume","title":"os_resume","text":"<p>Resume a suspended process.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to resume</p> <p>Response Event: OS_RESUME_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_resume --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#os_services","title":"os_services","text":"<p>List all services/daemons running on the endpoint.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: OS_SERVICES_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_services\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#os_suspend","title":"os_suspend","text":"<p>Suspend (pause) a running process.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>pid</code> (required): Process ID to suspend</p> <p>Response Event: OS_SUSPEND_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_suspend --pid 1234\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#os_autoruns","title":"os_autoruns","text":"<p>List programs configured to run automatically at system startup.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: OS_AUTORUNS_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_autoruns\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#os_drivers","title":"os_drivers","text":"<p>List all loaded kernel drivers/modules.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: OS_DRIVERS_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_drivers\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#os_version","title":"os_version","text":"<p>Get detailed operating system version information.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: OS_VERSION_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; os_version\n</code></pre></p> <p>Sample Response: <pre><code>{\n  \"event\": {\n    \"OS_NAME\": \"Windows 11\",\n    \"OS_VERSION\": \"10.0.22631\",\n    \"ARCHITECTURE\": \"x64\"\n  }\n}\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#rejoin_network","title":"rejoin_network","text":"<p>Re-enable network connectivity for a sensor that was previously isolated.</p> <p>Platforms: macOS | Windows | Linux | Chrome | Edge</p> <p>Parameters: None</p> <p>Response Event: None (sensor reconnects)</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; rejoin_network\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#run","title":"run","text":"<p>Execute a command or script on the endpoint (out-of-band execution).</p> <p>Platforms: macOS | Linux</p> <p>Parameters: - <code>command</code> (required): Command line to execute</p> <p>Response Event: EXEC_OOB</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; run --command \"ps aux | grep chrome\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#segregate_network","title":"segregate_network","text":"<p>Isolate a sensor from the network (except LimaCharlie cloud connectivity).</p> <p>Platforms: macOS | Windows | Linux | Chrome | Edge</p> <p>Parameters: None</p> <p>Response Event: None (sensor becomes isolated)</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; segregate_network\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#yara_scan","title":"yara_scan","text":"<p>Scan files or process memory with YARA rules.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>rule</code> (required): YARA rule content - <code>file_path</code> (optional): Specific file to scan - <code>pid</code> (optional): Specific process to scan - <code>process_expr</code> (optional): Process name pattern to scan</p> <p>Response Event: YARA_DETECTION</p> <p>Usage Example: <pre><code># Scan a file\nlimacharlie sensor task &lt;SID&gt; yara_scan --file_path \"C:\\\\suspicious.exe\" --rule \"rule test { strings: $a = \\\"malware\\\" condition: $a }\"\n\n# Scan process memory\nlimacharlie sensor task &lt;SID&gt; yara_scan --pid 1234 --rule \"rule test { strings: $a = \\\"malware\\\" condition: $a }\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#pcap_ifaces","title":"pcap_ifaces","text":"<p>List available network interfaces for packet capture.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: None</p> <p>Response Event: PCAP_INTERFACES_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; pcap_ifaces\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#pcap_start","title":"pcap_start","text":"<p>Start capturing network packets on a specified interface.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>iface</code> (required): Network interface ID or name - <code>max_size</code> (optional): Maximum capture size in MB</p> <p>Response Event: PCAP_START_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; pcap_start --iface eth0 --max_size 100\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#pcap_stop","title":"pcap_stop","text":"<p>Stop an active packet capture and upload the PCAP file.</p> <p>Platforms: macOS | Windows | Linux</p> <p>Parameters: - <code>iface</code> (optional): Specific interface to stop (default: all)</p> <p>Response Event: PCAP_STOP_REP, followed by EXPORT_COMPLETE</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; pcap_stop\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#reg_list","title":"reg_list","text":"<p>List Windows registry keys and values.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>reg_path</code> (required): Registry path to list (e.g., \"HKEY_LOCAL_MACHINE\\SOFTWARE\")</p> <p>Response Event: REG_LIST_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; reg_list --reg_path \"HKEY_LOCAL_MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#epp_scan","title":"epp_scan","text":"<p>Trigger an Endpoint Protection (EPP) scan on a file or directory.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>file_path</code> (required): Path to scan</p> <p>Response Event: EPP_SCAN_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; epp_scan --file_path \"C:\\\\Users\\\\Public\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#epp_list_exclusions","title":"epp_list_exclusions","text":"<p>List EPP scan exclusions currently configured on the sensor.</p> <p>Platforms: Windows</p> <p>Parameters: None</p> <p>Response Event: EPP_LIST_EXCLUSIONS_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; epp_list_exclusions\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#epp_add_exclusion","title":"epp_add_exclusion","text":"<p>Add a path or process to EPP scan exclusions.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>file_path</code> (optional): File/directory path to exclude - <code>process</code> (optional): Process name to exclude</p> <p>Response Event: EPP_ADD_EXCLUSION_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; epp_add_exclusion --file_path \"C:\\\\safe_app\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#epp_rem_exclusion","title":"epp_rem_exclusion","text":"<p>Remove a path or process from EPP scan exclusions.</p> <p>Platforms: Windows</p> <p>Parameters: - <code>file_path</code> (optional): File/directory path to remove from exclusions - <code>process</code> (optional): Process name to remove from exclusions</p> <p>Response Event: EPP_REM_EXCLUSION_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; epp_rem_exclusion --file_path \"C:\\\\safe_app\"\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#epp_list_quarantine","title":"epp_list_quarantine","text":"<p>List files currently in EPP quarantine.</p> <p>Platforms: Windows</p> <p>Parameters: None</p> <p>Response Event: EPP_LIST_QUARANTINE_REP</p> <p>Usage Example: <pre><code>limacharlie sensor task &lt;SID&gt; epp_list_quarantine\n</code></pre></p>"},{"location":"8-reference/endpoint-commands/#command-usage-notes","title":"Command Usage Notes","text":"<p>General Syntax: <pre><code>limacharlie sensor task &lt;SENSOR_ID&gt; &lt;COMMAND_NAME&gt; [--param value ...]\n</code></pre></p> <p>Platform Abbreviations: - macOS: Apple macOS and OS X - Windows: Microsoft Windows (7, 8, 10, 11, Server editions) - Linux: Linux distributions (Ubuntu, CentOS, Debian, etc.) - Chrome: Chrome browser extension sensor - Edge: Microsoft Edge browser extension sensor</p> <p>Response Events: Most commands generate a response event (typically ending in <code>_REP</code>) that can be: - Viewed in the LimaCharlie web interface under Sensor &gt; Timeline - Retrieved via API - Triggered on with D&amp;R rules</p> <p>Error Handling: Response events typically include an <code>ERROR</code> field: - <code>ERROR: 0</code> indicates success - Non-zero ERROR values indicate specific error conditions</p> <p>Permissions: Some commands require elevated privileges (root/administrator) on the endpoint to execute successfully.</p> <p>Timeouts: Commands have default timeouts (typically 30-60 seconds). Long-running operations may timeout and can be made persistent using the Reliable Tasking extension.</p>"},{"location":"8-reference/error-codes/","title":"Reference: Error Codes","text":"<p>The follow error codes are found within various Report (<code>*_REP</code>) events found within the EDR Events, often in response to an endpoint agent command.</p> Error Code Value ERROR_SUCCESS 0, 200 ERROR_INVALID_FUNCTION 1 ERROR_FILE_NOT_FOUND 2 ERROR_PATH_NOT_FOUND 3 ERROR_ACCESS_DENIED 5 ERROR_INVALID_HANDLE 6 ERROR_NOT_ENOUGH_MEMORY 8 ERROR_INVALID_DRIVE 15 ERROR_CURRENT_DIRECTORY 16 ERROR_WRITE_PROTECT 19 ERROR_CRC 23 ERROR_SEEK 25 ERROR_WRITE_FAULT 29 ERROR_READ_FAULT 30 ERROR_SHARING_VIOLATION 32 ERROR_LOCK_VIOLATION 33 ERROR_HANDLE_EOF 38 ERROR_HANDLE_DISK_FULL 39 ERROR_NOT_SUPPORTED 50 ERROR_BAD_NETPATH 53 ERROR_NETWORK_BUSY 54 ERROR_NETWORK_ACCESS_DENIED 65 ERROR_BAD_NET_NAME 67 ERROR_FILE_EXISTS 80 ERROR_INVALID_PASSWORD 86 ERROR_INVALID_PARAMETER 87 ERROR_BROKEN_PIPE 109 ERROR_OPEN_FAILED 110 ERROR_BUFFER_OVERFLOW 111 ERROR_DISK_FULL 112 ERROR_INVALID_NAME 123 ERROR_NEGATIVE_SEEK 131 ERROR_DIR_NOT_EMPTY 145 ERROR_BUSY 170 ERROR_BAD_EXE_FORMAT 193 ERROR_FILENAME_EXCED_RANGE 206 ERROR_FILE_TOO_LARGE 223 ERROR_DIRECTORY 267 ERROR_INVALID_ADDRESS 487 ERROR_TIMEOUT 1460"},{"location":"8-reference/error-codes/#payload-specific","title":"Payload Specific","text":"<p>When dealing with Payloads or Artifact collection, you may receive HTTP specific error codes: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status</p>"},{"location":"8-reference/error-codes/#yara-specific","title":"Yara Specific","text":"<p>When doing Yara scanning operations, you may receive Yara specific error codes.</p> <p>These are documented here: https://github.com/VirusTotal/yara/blob/master/libyara/include/yara/error.h</p>"},{"location":"8-reference/event-schemas/","title":"Event Schemas","text":"<p>Since LimaCharlie standardizes on JSON, including arbitrary sources of data, it means that Schema in LimaCharlie is generally dynamic.</p> <p>To enable users to create schemas in external systems that expect more strictly typed data, LimaCharlie makes a Schema API available.</p> <p>This Schema API exposes the \"learned\" schema from specific event types. As data comes into LimaCharlie, the Schema API will accumulate the list of fields and types observed for those specific events. In turn, the API allows you to retrieve this learned schema.</p>"},{"location":"8-reference/event-schemas/#api","title":"API","text":""},{"location":"8-reference/event-schemas/#listing-schemas","title":"Listing Schemas","text":"<p>The list of all available schemas can get retrieved by doing a <code>GET</code> to <code>api.limacharlie.io/v1/orgs/YOUR-OID/schema</code>.</p> <p>The returned data looks like:</p> <pre><code>{\n  \"event_types\": [\n    \"evt:New-ExchangeAssistanceConfig\",\n    \"det:00285-WIN-RDP_Connection_From_Non-RFC-1918_Address\",\n    \"det:VirusTotal hit on DNS request\",\n    \"evt:WEL\",\n    \"evt:SHUTTING_DOWN\",\n    \"evt:NETSTAT_REP\",\n    \"evt:AdvancedHunting-DeviceEvents\",\n    \"evt:NEW_DOCUMENT\",\n    \"sched:12h_per_cloud_adapter\",\n    \"sched:1h_per_sensor\",\n    \"sched:3h_per_sensor\",\n    ...\n}\n</code></pre> <p>Each element in the list of schema is composed of a prefix and a value.</p> <p>Prefixes can be:</p> <ul> <li><code>evt</code> for an Event.</li> <li><code>dep</code> for a Deployment Event.</li> <li><code>det</code> for a Detection.</li> <li><code>art</code> for an Artifact Event.</li> <li><code>sched</code> for Scheduling Events.</li> </ul> <p>The value is generally the Event Type except for Detections where it is the <code>cat</code> (detection name).</p>"},{"location":"8-reference/event-schemas/#retrieveing-schema-definition","title":"Retrieveing Schema Definition","text":"<p>Retrieving a specific schema definition can be done by doing a <code>GET</code> on <code>api.limacharlie.io/v1/orgs/YOUR-OID/schema/EVENT-TYPE</code>, where the <code>EVENT-TYPE</code> is one of the exact keys returned by the listing API above.</p> <p>The returned data looks like:</p> <pre><code>{\n  \"schema\": {\n    \"elements\": [\n      \"i:routing/event_time\",\n      \"s:routing/sid\",\n      \"i:routing/moduleid\",\n      \"i:event/PROCESS_ID\",\n      \"s:routing/this\",\n      \"i:event/DNS_TYPE\",\n      \"s:routing/iid\",\n      \"s:routing/did\",\n      \"i:event/DNS_FLAGS\",\n      \"i:routing/tags\",\n      \"s:event/IP_ADDRESS\",\n      \"s:routing/event_type\",\n      \"i:event/MESSAGE_ID\",\n      \"s:event/CNAME\",\n      \"s:event/DOMAIN_NAME\",\n      \"s:routing/ext_ip\",\n      \"s:routing/parent\",\n      \"s:routing/hostname\",\n      \"s:routing/int_ip\",\n      \"i:routing/plat\",\n      \"s:routing/oid\",\n      \"i:routing/arch\",\n      \"s:routing/event_id\"\n    ],\n    \"event_type\": \"evt:DNS_REQUEST\"\n  }\n}\n</code></pre> <p>The <code>schema.elements</code> data returned is composed of a prefix and a value.</p> <p>The prefix is one of:</p> <ul> <li><code>i</code> indicating the element is an Integer.</li> <li><code>s</code> indicating the element is a String.</li> <li><code>b</code> indicating the element is a Boolean.</li> </ul> <p>The value is a path within the JSON. For example, the schema above would represent the following event:</p> <pre><code>{\n  \"event\": {\n    \"CNAME\": \"cs9.wac.phicdn.net\",\n    \"DNS_TYPE\": 5,\n    \"DOMAIN_NAME\": \"ocsp.digicert.com\",\n    \"MESSAGE_ID\": 19099,\n    \"PROCESS_ID\": 1224\n  },\n  \"routing\": {\n    \"arch\": 2,\n    \"did\": \"b97e9d00-aaaa-aaaa-aaaa-27c3468d5901\",\n    \"event_id\": \"8cec565d-14bd-4639-a1af-4fc8d5420b0c\",\n    \"event_time\": 1656959942437,\n    \"event_type\": \"DNS_REQUEST\",\n    \"ext_ip\": \"35.1.1.1\",\n    \"hostname\": \"demo-win-2016.c.lc-demo-infra.internal\",\n    \"iid\": \"7d23bee6-aaaa-aaaa-aaaa-c8e8cca132a1\",\n    \"int_ip\": \"10.1.1.1\",\n    \"moduleid\": 2,\n    \"oid\": \"8cbe27f4-aaaa-aaaa-aaaa-138cd51389cd\",\n    \"parent\": \"42217cb0326ca254999554a862c3298e\",\n    \"plat\": 268435456,\n    \"sid\": \"bb4b30af-aaaa-aaaa-aaaa-f014ada33345\",\n    \"tags\": [\n      \"edr\"\n    ],\n    \"this\": \"a443f9c48bef700740ef27e062c333c6\"\n  }\n}\n</code></pre>"},{"location":"8-reference/event-schemas/#event-structure-reference","title":"Event Structure Reference","text":"<p>All events in LimaCharlie follow a canonical structure with two top-level objects: <code>routing</code> and <code>event</code>. Understanding this structure is essential for writing D&amp;R rules, LCQL queries, and configuring outputs.</p>"},{"location":"8-reference/event-schemas/#top-level-structure","title":"Top-Level Structure","text":"<pre><code>{\n  \"routing\": { /* metadata about the event */ },\n  \"event\": { /* event-specific data */ }\n}\n</code></pre>"},{"location":"8-reference/event-schemas/#the-routing-object","title":"The <code>routing</code> Object","text":"<p>The <code>routing</code> object contains metadata about the event - information about where it came from, when it occurred, and how it relates to other events. This metadata is consistent across all event types, making it useful for correlation, filtering, and investigation.</p>"},{"location":"8-reference/event-schemas/#core-routing-fields","title":"Core Routing Fields","text":"Field Type Description Use Cases <code>oid</code> string (UUID) Organization ID Multi-tenant filtering, audit trails <code>sid</code> string (UUID) Sensor ID - uniquely identifies the endpoint Host-based correlation, sensor management <code>event_type</code> string Type of event (e.g., <code>NEW_PROCESS</code>, <code>DNS_REQUEST</code>) Event filtering in D&amp;R rules, LCQL queries <code>event_time</code> integer Unix timestamp in milliseconds Timeline analysis, temporal correlation <code>event_id</code> string (UUID) Unique identifier for this specific event Deduplication, event tracking <code>hostname</code> string Hostname of the sensor Host-based investigations <code>iid</code> string (UUID) Installation Key ID used to install the sensor Deployment tracking, sensor grouping <code>did</code> string (UUID) Device ID - hardware identifier Device tracking across reinstalls"},{"location":"8-reference/event-schemas/#network-information","title":"Network Information","text":"Field Type Description Use Cases <code>ext_ip</code> string External IP address of the sensor Geolocation, network-based correlation <code>int_ip</code> string Internal IP address of the sensor Network segmentation analysis"},{"location":"8-reference/event-schemas/#platform-information","title":"Platform Information","text":"Field Type Description Use Cases <code>plat</code> integer Platform identifier (Windows, Linux, macOS, etc.) Platform-specific rules <code>arch</code> integer Architecture (x86, x64, ARM, etc.) Architecture-specific analysis <code>moduleid</code> integer Sensor module that generated the event Module-specific filtering"},{"location":"8-reference/event-schemas/#process-correlation-fields","title":"Process Correlation Fields","text":"Field Type Description Use Cases <code>this</code> string (hash) Hash representing the current process or object Process tracking across events <code>parent</code> string (hash) Hash of the parent process Process tree reconstruction <code>target</code> string (hash) Hash of the target object (in actions on other objects) Object tracking, lateral movement detection"},{"location":"8-reference/event-schemas/#other-routing-fields","title":"Other Routing Fields","text":"Field Type Description Use Cases <code>tags</code> array[string] Sensor tags applied at event time Tag-based filtering, dynamic grouping"},{"location":"8-reference/event-schemas/#the-event-object","title":"The <code>event</code> Object","text":"<p>The <code>event</code> object contains event-specific data that varies by event type. For example:</p> <ul> <li>NEW_PROCESS events contain: <code>FILE_PATH</code>, <code>COMMAND_LINE</code>, <code>PROCESS_ID</code>, <code>PARENT</code> (full parent process info)</li> <li>DNS_REQUEST events contain: <code>DOMAIN_NAME</code>, <code>IP_ADDRESS</code>, <code>DNS_TYPE</code>, <code>DNS_FLAGS</code></li> <li>NETWORK_CONNECTIONS events contain: <code>NETWORK_ACTIVITY</code> array with connection details</li> <li>WEL (Windows Event Log) events contain: <code>EVENT</code> object with nested Windows event structure</li> </ul>"},{"location":"8-reference/event-schemas/#event-structure-in-practice","title":"Event Structure in Practice","text":""},{"location":"8-reference/event-schemas/#accessing-fields-in-dr-rules","title":"Accessing Fields in D&amp;R Rules","text":"<p>In Detection &amp; Response rules, you access fields using the <code>event/</code> and <code>routing/</code> path prefixes:</p> <pre><code>detect:\n  event: NEW_PROCESS\n  op: and\n  rules:\n    - op: is\n      path: routing/plat\n      value: 0x10000000  # Windows\n    - op: contains\n      path: event/COMMAND_LINE\n      value: powershell\n      case sensitive: false\n</code></pre>"},{"location":"8-reference/event-schemas/#event-correlation-using-routing","title":"Event Correlation Using Routing","text":"<p>The <code>routing/this</code>, <code>routing/parent</code>, and <code>routing/target</code> hashes enable powerful event correlation:</p> <pre><code># Track all events from a specific process\ndetect:\n  op: is\n  path: routing/this\n  value: \"a443f9c48bef700740ef27e062c333c6\"\n</code></pre>"},{"location":"8-reference/event-schemas/#relationship-to-other-structures","title":"Relationship to Other Structures","text":"<p>Events \u2192 Detections: When a D&amp;R rule matches an event, a Detection is created. The Detection inherits the <code>routing</code> object from the triggering event and adds detection-specific metadata.</p> <p>Events \u2192 Outputs: Events can be routed to external systems via the \"event\" output stream. The full event structure (both <code>routing</code> and <code>event</code>) is sent.</p> <p>Events \u2192 Audit: Audit logs track platform actions and have a different structure. See the Output Stream Structures documentation for details.</p>"},{"location":"8-reference/event-schemas/#platform-specific-considerations","title":"Platform-Specific Considerations","text":""},{"location":"8-reference/event-schemas/#windows-events","title":"Windows Events","text":"<ul> <li>Often include nested structures like <code>event/EVENT/System/EventID</code> for Windows Event Logs</li> <li>Process events include detailed parent information in <code>event/PARENT</code></li> </ul>"},{"location":"8-reference/event-schemas/#linux-events","title":"Linux Events","text":"<ul> <li>File paths use forward slashes</li> <li>Process events may include user/group information</li> </ul>"},{"location":"8-reference/event-schemas/#cloud-adapter-events","title":"Cloud Adapter Events","text":"<ul> <li>May have custom <code>event</code> structures based on the source system</li> <li><code>routing/event_type</code> reflects the adapter and event type (e.g., <code>WEL</code>, <code>AdvancedHunting-DeviceEvents</code>)</li> </ul>"},{"location":"8-reference/event-schemas/#best-practices","title":"Best Practices","text":"<ol> <li>Use routing fields for correlation: <code>sid</code>, <code>hostname</code>, <code>this</code>, <code>parent</code> are consistent across all events</li> <li>Filter by event_type early: Most D&amp;R rules should specify <code>event:</code> at the top level for performance</li> <li>Leverage platform and architecture: Use <code>routing/plat</code> and <code>routing/arch</code> for OS-specific logic</li> <li>Understand timestamp format: <code>routing/event_time</code> is Unix milliseconds (not seconds)</li> <li>Hash consistency: <code>routing/this</code> and <code>routing/parent</code> use the same hashing algorithm, enabling cross-event tracking</li> </ol>"},{"location":"8-reference/id-schema/","title":"Reference: ID Schema","text":""},{"location":"8-reference/id-schema/#agent-ids","title":"Agent IDs","text":"<p>An AgentID is a 5-tuple that completely describes a Sensor, while a Sensor ID is the smallest single unique identifier that can identify a sensor.</p> <p>The AgentID's components look like this: <code>OID.IID.SID.PLATFORM.ARCHITECTURE</code>.</p> <p>For all components, a value of <code>0</code> indicates a wildcard that matches any value when comparing AgentIDs as masks.</p>"},{"location":"8-reference/id-schema/#architecture","title":"Architecture","text":"<p>The architecture is an 8 bit integer that identifies the exact architecture the sensor runs on. The important values are:</p> <ul> <li><code>1</code>: 32 bit (<code>x86</code>)</li> <li><code>2</code>: 64 bit (<code>x64</code>)</li> <li><code>3</code>: ARM (<code>arm</code>)</li> <li><code>4</code>: ARM64 (<code>arm64</code>)</li> <li><code>5</code>: Alpine 64 (<code>alpine64</code>)</li> <li><code>6</code>: Chrome (<code>chromium</code>)</li> <li><code>7</code>: Wireguard (<code>wireguard</code>)</li> <li><code>8</code>: ARML (<code>arml</code>)</li> <li><code>9</code>: lc-adapter (<code>usp_adapter</code>)</li> </ul> <p>Operating System Specifics</p> <p>Looking for more detailed version information on a specific operating system? Check out these vendor guides:</p> <ul> <li>Microsoft Windows</li> <li>RHEL</li> <li>Ubuntu</li> </ul>"},{"location":"8-reference/id-schema/#device-ids","title":"Device IDs","text":"<p>Given the breadth of platforms supported by LimaCharlie, it is not unusual for one \"device\" (laptop, server, mobile etc) to be visible from multiple sensors. A basic example of this might be:</p> <ul> <li>We have a laptop, running macOS as its operating system and running a macOS sensor</li> <li>The laptop is also running a Windows Virtual Machine, running a Windows sensor</li> </ul> <p>In this example, we're dealing with one piece of hardware, but two different sensors.</p> <p>To help provide a holistic view of activity, LimaCharlie introduces the concept of a Device ID. This ID is mostly visible in the sensor's basic info and in the <code>routing</code> component of sensor events under the name <code>did</code> (Device ID).</p> <p>This Device ID is automatically generated and assigned by LimaCharlie using correlation of specific low level events common to all the sensors. This means that if two sensors share a <code>did: 1234-5678...</code> ID, it means they are either on the same device or at least share the same visibility (they see the same activity from two angles).</p>"},{"location":"8-reference/id-schema/#installer-id","title":"Installer ID","text":"<p>The Installer ID (IID) is a UUID that identifies a unique Installation Key. This allows us to cycle installation keys and repudiate old keys, in the event the key gets leaked.</p>"},{"location":"8-reference/id-schema/#organization-id","title":"Organization ID","text":"<p>The Organization ID (OID) is a UUID which identifies a unique organization.</p>"},{"location":"8-reference/id-schema/#platform","title":"Platform","text":"<p>The platform is a 32-bit integer (in its hex format) which identifies the exact platform the sensor runs on. Sensor telemetry will display the <code>plat</code> value in decimal format. Although it is structured with a major and minor platform, the important values are:</p> Hex ID Decimal API Name Platform Name 0x01000000 16777216 crowdstrike CrowdStrike 0x02000000 33554432 xml XML 0x03000000 50331648 wel Windows Event Logs 0x04000000 67108864 msdefender Microsoft Defender 0x05000000 83886080 duo Duo 0x06000000 100663296 okta Okta 0x07000000 117440512 sentinel_one SentinelOne 0x08000000 134217728 github GitHub 0x09000000 150994944 slack Slack 0x0A000000 167772160 cef Common Event Format (CEF) 0x0B000000 184549376 lc_event LimaCharlie Events 0x0C000000 201326592 azure_ad Azure Active Directory 0x0D000000 218103808 azure_monitor Azure Monitor 0x0E000000 234881024 canary_token Canary Token 0x0F000000 251658240 guard_duty Guard Duty 0x11000000 285212672 itglue IT Glue 0x12000000 301989888 k8s_pods Kubernetes Pods 0x13000000 318767104 zeek Zeek 0x14000000 335544320 mac_unified_logging Macos Unified Logging 0x15000000 352321536 azure_event_hub_namespace Azure Event Hub Namespace 0x16000000 369098752 azure_key_vault Azure Key Vault 0x17000000 385875968 azure_kubernetes_service Azure Kubernetes Service 0x18000000 402653184 azure_network_security_group Azure Network Security Group 0x19000000 419430400 azure_sql_audit Azure SQL Audit 0x1A000000 436207616 email Email 0x21000000 553648128 hubspot HubSpot 0x22000000 570425344 zendesk Zendesk 0x23000000 587202560 pandadoc PandaDoc 0x24000000 603979776 falconcloud FalconCloud 0x25000000 620756992 mimecast Mimecast 0x26000000 637534208 sublime Sublime 0x27000000 654311424 box Box 0x28000000 671088640 cylance Cylance 0x29000000 687865856 proofpoint Proofpoint 0x2A000000 704643072 entraid EntraID 0x2B000000 721420288 wiz Wiz 0x10000000 268435456 windows Windows 0x20000000 536870912 linux Linux 0x30000000 805306368 macos MacOS 0x40000000 1073741824 ios iOS 0x50000000 1342177280 android Android 0x60000000 1610612736 chrome ChromeOS 0x70000000 1879048192 vpn VPN 0x80000000 2147483648 text Text (external telemetry) 0x90000000 2415919104 json JSON (external telemetry) 0xA0000000 2684354560 gcp GCP (external telemetry) 0xB0000000 2952790016 aws AWS (external telemetry) 0xC0000000 3221225472 carbon_black VMWare Carbon Black 0xD0000000 3489660928 1password 1Password 0xE0000000 3758096384 office365 Microsoft/Office 365 0xF0000000 4026531840 sophos Sophos <p>Tip: If you're writing a  rule to target a specific platform, consider using the <code>is platform</code> operator instead of the decimal value for easier readability.</p>"},{"location":"8-reference/id-schema/#sensor-id","title":"Sensor ID","text":"<p>The Sensor ID (SID) is a UUID that identifies a unique sensor.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p> <p>In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.</p> <p>Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.</p> <p>In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>In LimaCharlie, an Organization ID (OID) is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.</p> <p>In LimaCharlie, a Sensor ID (SID) is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.</p>"},{"location":"8-reference/permissions/","title":"Reference: Permissions","text":""},{"location":"8-reference/permissions/#overview","title":"Overview","text":"<p>LimaCharlie uses a granular permission system that controls access to all platform functionality. Permissions are applied through User accounts, API Keys, or Groups and follow a hierarchical naming convention: <code>category</code>.<code>action</code></p>"},{"location":"8-reference/permissions/#permission-structure","title":"Permission Structure","text":""},{"location":"8-reference/permissions/#naming-convention","title":"Naming Convention","text":"<ul> <li>Category: Functional area (e.g. sensor, org, dr)</li> <li>Action: Operation type (e.g. get, list, set, del, ctrl)</li> </ul>"},{"location":"8-reference/permissions/#core-permissions","title":"Core Permissions","text":""},{"location":"8-reference/permissions/#organization-management","title":"Organization Management","text":"Permission Description org.get View organization information org.del Delete organization org.set_quota Manage organization quotas org.conf.get View organization configuration org.conf.set Modify organization configuration"},{"location":"8-reference/permissions/#user-access-control","title":"User &amp; Access Control","text":"Permission Description apikey.ctrl Create, delete, and modify API keys user.ctrl Manage user accounts and permissions billing.ctrl Access and modify billing information"},{"location":"8-reference/permissions/#sensor-management","title":"Sensor Management","text":"Permission Description sensor.list List all sensors in organization sensor.get View detailed sensor information sensor.task Send commands and tasks to sensors sensor.del Delete sensors sensor.tag Manage sensor tags and labels"},{"location":"8-reference/permissions/#installation-keys","title":"Installation Keys","text":"Permission Description ikey.list List installation keys ikey.set Create new installation keys ikey.del Delete installation keys"},{"location":"8-reference/permissions/#detection-response-dr","title":"Detection &amp; Response (D&amp;R)","text":""},{"location":"8-reference/permissions/#general-dr-rules","title":"General D&amp;R Rules","text":"Permission Description dr.list List general detection rules dr.set Create and modify general detection rules dr.del Delete general detection rules"},{"location":"8-reference/permissions/#managed-dr-rules","title":"Managed D&amp;R Rules","text":"Permission Description dr.list.managed List managed detection rules dr.set.managed Create and modify managed detection rules dr.del.managed Delete managed detection rules"},{"location":"8-reference/permissions/#service-dr-rules","title":"Service D&amp;R Rules","text":"Permission Description dr.list.service List service detection rules dr.set.service Create and modify service detection rules dr.del.service Delete service detection rules"},{"location":"8-reference/permissions/#false-positives","title":"False Positives","text":"Permission Description fp.ctrl Manage false positive suppressions"},{"location":"8-reference/permissions/#configuration-management-hive","title":"Configuration Management (Hive)","text":""},{"location":"8-reference/permissions/#secrets","title":"Secrets","text":"Permission Description secret.get Access secret values secret.set Create and modify secrets secret.del Delete secrets secret.get.mtd View secret metadata only secret.set.mtd Modify secret metadata only"},{"location":"8-reference/permissions/#lookups","title":"Lookups","text":"Permission Description lookup.get Access lookup tables lookup.set Create and modify lookup tables lookup.del Delete lookup tables lookup.get.mtd View lookup metadata only lookup.set.mtd Modify lookup metadata only"},{"location":"8-reference/permissions/#models","title":"Models","text":"Permission Description model.get Access behavioral models model.set Create and modify behavioral models model.del Delete behavioral models model.get.mtd View model metadata only model.set.mtd Modify model metadata only"},{"location":"8-reference/permissions/#queries","title":"Queries","text":"Permission Description query.get Access saved queries query.set Create and modify saved queries query.del Delete saved queries query.get.mtd View query metadata only query.set.mtd Modify query metadata only"},{"location":"8-reference/permissions/#yara-rules","title":"YARA Rules","text":"Permission Description yara.get Access YARA rules yara.set Create and modify YARA rules yara.del Delete YARA rules yara.get.mtd View YARA rule metadata only yara.set.mtd Modify YARA rule metadata only"},{"location":"8-reference/permissions/#ai-agents","title":"AI Agents","text":"Permission Description ai_agent.get Access AI agent configurations ai_agent.set Create and modify AI agents ai_agent.del Delete AI agents ai_agent.get.mtd View AI agent metadata only ai_agent.set.mtd Modify AI agent metadata only"},{"location":"8-reference/permissions/#cloud-sensors","title":"Cloud Sensors","text":"Permission Description cloudsensor.get Access cloud sensor configurations cloudsensor.set Create and modify cloud sensor configurations cloudsensor.del Delete cloud sensor configurations cloudsensor.get.mtd View cloud sensor metadata only cloudsensor.set.mtd Modify cloud sensor metadata only"},{"location":"8-reference/permissions/#playbooks","title":"Playbooks","text":"Permission Description playbook.get Access playbooks playbook.set Create and modify playbooks playbook.del Delete playbooks playbook.get.mtd View playbook metadata only playbook.set.mtd Modify playbook metadata only"},{"location":"8-reference/permissions/#external-adapters","title":"External Adapters","text":"Permission Description externaladapter.get Access external adapter configurations externaladapter.set Create and modify external adapters externaladapter.del Delete external adapter configurations externaladapter.get.mtd View external adapter metadata only externaladapter.set.mtd Modify external adapter metadata only"},{"location":"8-reference/permissions/#extensions-services","title":"Extensions &amp; Services","text":""},{"location":"8-reference/permissions/#extensions","title":"Extensions","text":"Permission Description ext.request Request extension actions ext.conf.get View extension configurations ext.conf.set Modify extension configurations ext.conf.del Delete extension configurations ext.conf.get.mtd View extension metadata only ext.conf.set.mtd Modify extension metadata only ext.sub Subscribe to extension services ext.sub.mtd Manage extension subscription metadata"},{"location":"8-reference/permissions/#replicant-services","title":"Replicant Services","text":"Permission Description replicant.get View replicant service status replicant.ctrl Control replicant services"},{"location":"8-reference/permissions/#data-access-analytics","title":"Data Access &amp; Analytics","text":""},{"location":"8-reference/permissions/#insight-detections","title":"Insight &amp; Detections","text":"Permission Description insight.list List available insights insight.ctrl Control insight generation insight.del Delete insights insight.evt.get Access detailed event data insight.evt.get.simple Access simplified event data insight.det.get Access detection details insight.stat Access insight statistics"},{"location":"8-reference/permissions/#audit-logging","title":"Audit &amp; Logging","text":"Permission Description audit.get Access audit logs and error messages audit.set Create audit logs entries"},{"location":"8-reference/permissions/#operations-management","title":"Operations Management","text":""},{"location":"8-reference/permissions/#jobs","title":"Jobs","text":"Permission Description job.get View job status and results job.ctrl Create and schedule jobs"},{"location":"8-reference/permissions/#outputs","title":"Outputs","text":"Permission Description output.list List output configurations output.set Create and modify output configurations output.del Delete output configurations"},{"location":"8-reference/permissions/#payloads","title":"Payloads","text":"Permission Description payload.ctrl Manage sensor payloads"},{"location":"8-reference/permissions/#module-management","title":"Module Management","text":"Permission Description module.update Update sensor modules"},{"location":"8-reference/permissions/#ingestion","title":"Ingestion","text":"Permission Description ingestkey.ctrl Manage data ingestion keys"},{"location":"8-reference/permissions/#permission-application","title":"Permission Application","text":"<p>Permissions can be applied through:</p> <ol> <li>User Accounts: Direct assignment to individual users</li> <li>API Keys: Embedded in API key configurations for programmatic access</li> <li>Groups: Assigned to groups, then inherited by group members</li> </ol>"},{"location":"8-reference/permissions/#best-practices","title":"Best Practices","text":"<ol> <li>Principle of Least Privilege: Grant only the minimum permissions required</li> <li>Use Groups: Manage permissions through groups rather than individual assignments</li> <li>Regular Auditing: Periodically review and audit permission assignments</li> <li>Separate Environments: Use different permission sets for development, staging, and production</li> <li>API Key Management: Rotate API keys regularly and scope them appropriately</li> </ol>"},{"location":"8-reference/platform-events/","title":"Reference: Platform Events","text":""},{"location":"8-reference/platform-events/#event-details","title":"Event Details","text":""},{"location":"8-reference/platform-events/#ack_messages","title":"ACK_MESSAGES","text":"<p>Acknowledge messages event is used by some LimaCharlie Sensors (e.g. USP). It is not used by the EDR.</p>"},{"location":"8-reference/platform-events/#backoff","title":"BACKOFF","text":"<p>Used for flow control. Provides a number of seconds that the Sensor should wait before sending events to the cloud.</p>"},{"location":"8-reference/platform-events/#billing_record","title":"billing_record","text":"<p>This event is emitted for all kinds of billable records for the Organization.</p> <p>Sample Event:</p> <pre><code>{\n  \"record\": {\n    \"cat\": \"extension\",\n    \"k\": \"ext-strelka:bytes_scanned\",\n    \"oid\": \"8cbe27f4-aaaa-bbbb-cccc-138cd51389cd\",\n    \"record_id\": \"3bbbe4d9-925b-4538-bcad-e2e1ba2be923-0\",\n    \"ts\": \"2024-05-30 00:44:37\",\n    \"v\": 2797\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#cloud_adapter_disabled","title":"CLOUD_ADAPTER_DISABLED","text":"<p>This event is emitted when a Cloud Adapter gets disabled because it has been erroring for a long period of time.</p> <p>Sample Event:</p> <pre><code>{\n  \"event\":{\n    \"error\": \"invalid api key\"\n  },\n  \"routing\": {\n    \"event_time\": 1644444297696,\n    \"event_type\": \"cloud_adapter_disabled\",\n    \"oid\": \"8cbe27f4-aaaa-cccc-bbbb-138cd51389cd\"\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#data_dropped","title":"DATA_DROPPED","text":"<p>This event is generated by the Sensor when it has been offline and the events generated overflowed its internal buffer before they could be sent to the cloud, resulting in dropped events.</p>"},{"location":"8-reference/platform-events/#deleted_sensor","title":"DELETED_SENSOR","text":"<p>Deleted Sensor deployment events are produced when a sensor that was previously deleted from an Org attempts to connect to the LimaCharlie cloud.</p> <p>Sample Event:</p> <pre><code>{\n  \"routing\": {\n    \"oid\": \"d9ae5c17-d519-4ef5-a4ac-c454a95d31ca\",\n    \"iid\": \"ca812425-5a36-4c73-a0a0-935a8ace6451\",\n    \"sid\": \"a75cc927-bf28-4178-a42d-25ecc8a6be81\",\n    \"plat\": 536870912,\n    \"arch\": 2,\n    \"ext_ip\": \"104.196.34.101\",\n    \"int_ip\": \"172.17.0.2\",\n    \"hostname\": \"linux-server-1\",\n    \"event_type\": \"deleted_sensor\",\n    \"event_time\": 1561741553230\n  },\n  \"event\": {\n    \"denied_for\": \"720h0m0s\"\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#disconnected","title":"DISCONNECTED","text":"<p>This platform event is generated by the LimaCharlie backend when a sensor disconnects from the cloud. This event applies to all sensor types (Windows, macOS, Linux, Chrome, Edge) and is generated server-side, not by the endpoint itself.</p> <p>Sample Event:</p> <pre><code>{\n  \"routing\": {\n    \"oid\": \"d9ae5c17-d519-4ef5-a4ac-c454a95d31ca\",\n    \"sid\": \"a75cc927-bf28-4178-a42d-25ecc8a6be81\",\n    \"event_type\": \"disconnected\",\n    \"event_time\": 1561741553230\n  },\n  \"event\": {}\n}\n</code></pre>"},{"location":"8-reference/platform-events/#enrollment","title":"ENROLLMENT","text":"<p>Enrollment deployment events are produced when a sensor enrolls into the Organization for the first time.</p> <p>Sample Event:</p> <pre><code>{\n  \"routing\": {\n    \"oid\": \"d9ae5c17-d519-4ef5-a4ac-c454a95d31ca\",\n    \"iid\": \"ca812425-5a36-4c73-a0a0-935a8ace6451\",\n    \"sid\": \"a75cc927-bf28-4178-a42d-25ecc8a6be81\",\n    \"plat\": 536870912,\n    \"arch\": 2,\n    \"event_type\": \"enrollment\",\n    \"event_time\": 1561741553230\n  },\n  \"event\": {\n    \"public_ip\": \"104.196.34.101\",\n    \"internal_ip\": \"172.17.0.2\",\n    \"host_name\": \"linux-server-1\"\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#export_complete","title":"EXPORT_COMPLETE","text":"<p>An export of artifact data is completed and ready for download.</p> <p>Sample Event:</p> <pre><code>{\n  \"routing\" : {\n    \"log_id\" : \"ca812425-5a36-4c73-a0a0-935a8ace6451\",\n    \"event_type\" : \"export_complete\",\n    \"log_type\" : \"pcap\",\n    \"oid\" : \"ca812425-5a36-4c73-a0a0-935a8ace6451\",\n    \"event_time\" : 1561741553230\n  },\n  \"event\" : {\n    \"size\" : 2048,\n    \"source\" : \"a75cc927-bf28-4178-a42d-25ecc8a6be81\",\n    \"original_path\" : \"/data/pcap/dat.pcap\",\n    \"export_id\" : \"d9ae5c17-d519-4ef5-a4ac-c454a95d31ca\"\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#ingest","title":"INGEST","text":"<p>A new artifact has been ingested.</p> <p>Sample Event:</p> <pre><code>{\n  \"routing\" : {\n    \"log_id\" : \"ca812425-5a36-4c73-a0a0-935a8ace6451\",\n    \"event_type\" : \"ingest\",\n    \"log_type\" : \"pcap\",\n    \"oid\" : \"ca812425-5a36-4c73-a0a0-935a8ace6451\",\n    \"event_time\" : 1561741553230\n  },\n  \"event\" : {\n    \"size\" : 2048,\n    \"source\" : \"a75cc927-bf28-4178-a42d-25ecc8a6be81\",\n    \"original_path\" : \"/data/pcap/dat.pcap\",\n    \"original_md5\" : \"adjfnwonefowrnfowef\"\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#quota_changed","title":"QUOTA_CHANGED","text":"<p>Quota changed events are emitted when the quota for an Organization changes.</p> <p>Sample Event:</p> <pre><code>{\n  \"event\":{\n    \"new_quota\": 30,\n    \"old_quota\": 25\n  },\n  \"routing\": {\n    \"event_time\": 1644444297696,\n    \"event_type\": \"quota_changed\",\n    \"oid\": \"8cbe27f4-aaaa-cccc-bbbb-138cd51389cd\"\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#run","title":"RUN","text":"<p>Emitted after a run command has been issued (e.g. to run a payload, shell command, etc.).</p>"},{"location":"8-reference/platform-events/#self_test_result","title":"SELF_TEST_RESULT","text":"<p>Internal event used during a power-on-self-test (POST) of the sensor.</p>"},{"location":"8-reference/platform-events/#sensor_clone","title":"SENSOR_CLONE","text":"<p>Sensor clone events are generated when the LimaCharlie Cloud detects that a specific Sensor ID may have been cloned.</p> <p>Sample Event:</p> <pre><code>{\n  \"routing\": {\n    \"oid\": \"d9ae5c17-d519-4ef5-a4ac-c454a95d31ca\",\n    \"iid\": \"ca812425-5a36-4c73-a0a0-935a8ace6451\",\n    \"sid\": \"a75cc927-bf28-4178-a42d-25ecc8a6be81\",\n    \"plat\": 536870912,\n    \"arch\": 2,\n    \"event_type\": \"sensor_clone\",\n    \"event_time\": 1561741553230\n  },\n  \"event\": {\n    \"previous_hostname\" : \"server-1\",\n    \"new_hostname\" : \"server-2\"\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#sensor_crash","title":"SENSOR_CRASH","text":"<p>This event is generated when a Sensor has crashed. It will include some telemetry useful to help LimaCharlie troubleshoot the crash.</p> <p>Sample Event:</p> <pre><code>{\n  \"routing\": {\n    \"arch\": 2,\n    \"event_time\": 1670861698000,\n    \"event_type\": \"sensor_crash\",\n    \"hostname\": \"linux-server-1\",\n    \"ext_ip\": \"104.196.34.101\",\n    \"int_ip\": \"172.17.0.2\",\n    \"oid\": \"8cbe27f4-aaaa-cccc-bbbb-138cd51389cd\",\n    \"plat\": 268435456,\n    \"iid\": \"ca812425-5a36-4c73-a0a0-935a8ace6451\",\n    \"sid\": \"a75cc927-bf28-4178-a42d-25ecc8a6be81\"\n  },\n  \"event\": {\n    \"crash_context\": {\n      \"FILE_ID\": 63,\n      \"LINE_NUMBER\": 1216,\n      \"THREAD_ID\": 7808\n    }\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#sensor_over_quota","title":"SENSOR_OVER_QUOTA","text":"<p>Over quota deployment events are produced when a Sensor tries to connect but the Organization quota is already reached.</p> <p>Sample Event:</p> <pre><code>{\n  \"routing\": {\n    \"oid\": \"d9ae5c17-d519-4ef5-a4ac-c454a95d31ca\",\n    \"iid\": \"ca812425-5a36-4c73-a0a0-935a8ace6451\",\n    \"sid\": \"a75cc927-bf28-4178-a42d-25ecc8a6be81\",\n    \"plat\": 536870912,\n    \"arch\": 2,\n    \"event_type\": \"sensor_over_quota\",\n    \"event_time\": 1561741553230\n  },\n  \"event\": {\n    \"public_ip\": \"104.196.34.101\",\n    \"internal_ip\": \"172.17.0.2\",\n    \"host_name\": \"linux-server-1\"\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#set_performance_mode","title":"SET_PERFORMANCE_MODE","text":"<p>Enables performance mode in the kernel (e.g., disables file tracking on Windows).</p>"},{"location":"8-reference/platform-events/#sync","title":"SYNC","text":"<p>Internal event used as a heartbeat to the cloud. Sent by default every 10 minutes.</p>"},{"location":"8-reference/platform-events/#unload_kernel","title":"UNLOAD_KERNEL","text":"<p>Allows manual unloading of kernel component.</p>"},{"location":"8-reference/platform-events/#update","title":"UPDATE","text":"<p>Internal event used to update the configuration of a specific collector within the endpoint.</p>"},{"location":"8-reference/platform-events/#_per_cloud_adapter","title":"*_per_cloud_adapter","text":"<p>Events that are emitted once per period per cloud adapter. See Schedule Events Reference for more details.</p> <p>Sample Event:</p> <pre><code>{\n  \"event\": {\n    \"frequency\": 1800,\n    \"adapter_name\": \"office-audit\",\n    \"runtime_mtd\": {\n      \"entity_name\": \"81c72a07-9540-4341-9c35-66f6cfe1b9d7\",\n      \"entity_type\": \"adapter\",\n      \"mtd\": {\n        \"platform\": \"office365\",\n        \"hostname\": \"office-365-audit\",\n        \"adapter_type\": \"office365\"\n      },\n      \"published_at\": 1689858693935\n    }\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#_per_org","title":"*_per_org","text":"<p>Events that are emitted once per period per org. See Schedule Events Reference for more details.</p> <p>Sample Event:</p> <pre><code>{\n  \"event\": {\n    \"frequency\": 86400\n  },\n  \"routing\": {\n    \"event_id\": \"0f236fbb-31df-4d11-b6ab-c6b71a63a072\",\n    \"event_time\": 1673298756512,\n    \"event_type\": \"1h_per_org\",\n    \"oid\": \"8cbe27f4-bfa1-4afb-ba19-138cd51389cd\",\n    \"sid\": \"00000000-0000-0000-0000-000000000000\",\n    \"tags\": []\n  }\n}\n</code></pre>"},{"location":"8-reference/platform-events/#_per_sensor","title":"*_per_sensor","text":"<p>Events that are emitted once per period per Sensor. See Schedule Events Reference for more details.</p> <p>Sample Event:</p> <pre><code>{\n  \"event\": {\n    \"frequency\": 1800,\n    \"runtime_mtd\": {\n      \"entity_name\": \"81c72a07-9540-4341-9c35-66f6cfe1b9d7\",\n      \"entity_type\": \"sensor\",\n      \"mtd\": {\n        \"bytes_recv\": 6202524,\n        \"conn_at\": 1689819872,\n        \"eps_in\": 1,\n        \"eps_out\": 0,\n        \"q_size\": 0\n      },\n      \"published_at\": 1689858693935\n    }\n  }\n}\n</code></pre> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p> <p>Endpoint Detection &amp; Response</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.</p> <p>In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.</p>"},{"location":"8-reference/response-actions/","title":"Response Actions","text":""},{"location":"8-reference/response-actions/#overview","title":"Overview","text":"<p>Actions in LimaCharlie Detection &amp; Response () rules define what happens after a detection is triggered. Common actions include generating reports, tagging sensors, isolating networks, and the frequently used <code>task</code> action, which sends commands to an Endpoint Agent to interrogate or take action on the endpoint. This is useful for tasks like gathering system information or isolating a compromised endpoint. Suppression settings manage repetitive alerts by limiting action frequency, ensuring efficient automation and response workflows.</p> <p>For more information on how to use Actions, read Detection &amp; Response rules.</p>"},{"location":"8-reference/response-actions/#suppression","title":"Suppression","text":"<p>Suppression is valuable to help manage repetitive or noisy alerts.</p>"},{"location":"8-reference/response-actions/#reduce-frequency","title":"Reduce Frequency","text":"<p>In some cases, you may want to limit the number of times a specific Action is executed over a certain period of time. You can achieve this through <code>suppression</code>. This feature is supported in every Actions.</p> <p>A suppression descriptor can be added to an Action like:</p> <pre><code>- action: report\n  name: evil-process-detected\n  suppression:\n    max_count: 1\n    period: 1h\n    is_global: true\n    keys:\n      - '{{ .event.FILE_PATH }}'\n      - 'evil-process-detected'\n</code></pre> <p>The above example means that the <code>evil-process-detected</code> detection will be generated up to once per hour per <code>FILE_PATH</code>. Beyond the first <code>report</code> with a given <code>FILE_PATH</code>, during the one hour period, new <code>report</code> actions from this rule will be skipped.</p> <p>The <code>is_global: true</code> means that the suppression should operate globally within the Org (tenant), if the value was <code>false</code>, the suppression would be scoped per-Sensor.</p> <p>The <code>keys</code> parameter is a list of strings that support templating. Together, the unique combination of values of all those strings (ANDed) will be the uniqueness key this suppression rule uses. By adding to the keys the <code>{{ .event.FILE_PATH }}</code> template, we indicate that the <code>FILE_PATH</code> of the event generating this <code>report</code> is part of the key, while the constant string <code>evil process-detected</code> is just a convenient way for us to specify a value related to this specific detection. If the <code>evil process-detected</code> component of the key was not specified, then all actions that also just specify the <code>{{ .event.FILE_PATH }}</code> would be contained in this suppression. This means that using <code>is_global: true</code> and a complex key set, it is possible to suppress some actions across multiple Actions across multiple D&amp;R rules.</p> <p>Supported Time Period Formats</p> <p>LimaCharlie supports the following formats for time periods: ns, us (or \u00b5s, both are accepted), ms, s, m, h (nanoseconds, microseconds, milliseconds, seconds, minutes, and hours, respectively)</p>"},{"location":"8-reference/response-actions/#threshold-activation","title":"Threshold Activation","text":"<p>The other way to use suppression is using the <code>min_count</code> parameter. When set, the specific action will be suppressed until <code>min_count</code> number of activations have been received in that period.</p> <p>Here's an example of this:</p> <pre><code>- action: report\n  name: high-alerts\n  suppression:\n    min_count: 3\n    max_count: 3\n    period: 24h\n</code></pre> <p>The above example means the <code>high-alerts</code> detection will be generated once per hour but only after the rule the action belongs to has matched 3 times within that period.</p> <p>This could be useful if you wanted to create higher order alerts that trigger a different type of detection, or send a page alert to a SOC, when more than X alerts occurred on a single host per period.</p> <p>Note: Both <code>min_count</code> and <code>max_count</code> must be specified when setting a threshold.</p>"},{"location":"8-reference/response-actions/#variable-count","title":"Variable Count","text":"<p>It is also possible to increment a suppression by a value that's not one (<code>1</code>). This is achieved using the <code>count_path</code> parameter, which is a path (like <code>event/record/v</code>) pointing to an integer that should be used to increment the suppression counter.</p> <p>This is useful for things like billing alerts, where we set a threshold activation (meaning \"alert me if above X\") where the threshold is reached by increments of billable values.</p> <p>Here's an example of this:</p> <pre><code>detect:\n    event: billing_record\n    op: is\n    path: event/record/k\n    target: billing\n    value: ext-strelka:bytes_scanned\n\nrespond:\n    - action: report\n      name: strelka-bytes-reached\n      suppression:\n        count_path: event/record/v\n        is_global: true\n        keys:\n          - strelka-bytes-usage\n        max_count: 1048576\n        min_count: 1048576\n        period: 24h\n</code></pre> <p>The above will alert (generate a detection in this case) when 1MB (1024 x 1024 x 1) of bytes have been billed by the Strelka Extension based on the <code>bytes_scanned</code> SKU, per 24h.</p> <p>It does so by incrementing the suppression counter by the billed value (found in <code>event/record/v</code>), resetting after 24h, and if the value of 1MB is reached, alert once and only once.</p>"},{"location":"8-reference/response-actions/#available-actions","title":"Available Actions","text":"<p>Actions allow you to specify \"what\" happens after a detection is found.</p>"},{"location":"8-reference/response-actions/#add-tag-remove-tag","title":"add tag, remove tag","text":"<pre><code>- action: add tag\n  tag: vip\n  entire_device: false # defaults to false\n  ttl: 30 # optional\n</code></pre> <p>Adds or removes Tags on the sensor.</p>"},{"location":"8-reference/response-actions/#optional-parameters","title":"Optional Parameters","text":"<p>The <code>add tag</code> action can optionally take a <code>ttl</code> parameter that is a number of seconds the tag should remain applied to the sensor.</p> <p>The <code>add tag</code> action can optionally have the <code>entire_device</code> parameter set to <code>true</code>. When enabled, the new tag will apply to the entire Device ID, meaning that every sensor that shares this Device ID will have the tag applied (and relevant TTL). If a Device ID is unavailable for the sensor, it will still be tagged.</p> <p>This can be used as a mechanism to synchronize and operate changes across an entire device. A D&amp;R rule could detect a behavior and then tag all sensors on the device so they may act accordingly, like start doing full pcap.</p> <p>For example, this would apply the <code>full_pcap</code> to all sensors on the device for 5 minutes:</p> <pre><code>- action: add tag\n  tag: full_pcap\n  ttl: 300\n  entire_device: true\n</code></pre>"},{"location":"8-reference/response-actions/#add-var-del-var","title":"add var, del var","text":"<p>Add or remove a value from the variables associated with a sensor.</p> <pre><code>- action: add var\n  name: my-variable\n  value: &lt;&lt;event/VOLUME_PATH&gt;&gt;\n  ttl: 30 # optional\n</code></pre> <p>The <code>add var</code> action can optionally take a <code>ttl</code> parameter that is a number of seconds the variable should remain in state for the sensor.</p>"},{"location":"8-reference/response-actions/#extension-request","title":"extension request","text":"<p>Perform an asynchronous request to an extension the Organization is subscribed to.</p> <pre><code>- action: extension request\n  extension name: dumper # name of the extension\n  extension action: dump # action to trigger\n  extension request:     # request parameters\n    sid: '{{ .routing.sid }}'\n    pid: event.PROCESS_ID\n</code></pre> <p>The <code>extension request</code> parameters will vary depending on the extension (see the relevant extension's schema). The <code>extension request</code> parameter is a transform.</p> <p>You can also specify a <code>based on report: true</code> parameter. When true (defaults to false), the transform for the <code>extension request</code> will be based on the latest <code>report</code> action's report instead of the original event. This means you MUST have a <code>report</code> action before the <code>extension request</code>.</p>"},{"location":"8-reference/response-actions/#isolate-network","title":"isolate network","text":"<p>Isolates the sensor from the network in a persistent fashion (if the sensor/host reboots, it will remain isolated). Only works on platforms supporting the <code>segregate_network</code> sensor command.</p> <pre><code>- action: isolate network\n</code></pre> <p>When the network isolation feature is used, LimaCharlie will block connections to all destinations other than the LimaCharlie cloud (so that you can perform an investigation, take remediation actions, and then ultimately remove the isolation to resume normal network operation). The host will maintain internet connectivity to allow for you to perform those actions.</p> <p>The <code>segregate_network</code> command is stateless, so if the endpoint reboots, it will not be in effect. The isolate network command in D&amp;R rules is stateful, so it sets a flag in the cloud to make sure the endpoint remains isolated even after reboots.</p>"},{"location":"8-reference/response-actions/#seal","title":"seal","text":"<p>Seals the sensor in a persistent fashion (if the sensor/host reboots, it will remain sealed). Only works on platforms supporting the <code>seal</code> sensor command.</p> <pre><code>- action: seal\n</code></pre> <p>Sealing a sensor enables tamper resistance, preventing direct modifications to the installed EDR.</p> <p>The <code>seal</code> command is stateless, so if the endpoint reboots, it will not be in effect. The seal command in D&amp;R rules is stateful, so it sets a flag in the cloud to make sure the endpoint remains sealed even after reboots.</p>"},{"location":"8-reference/response-actions/#unseal","title":"unseal","text":"<p>Removes the seal status of a sensor that had it set using <code>seal</code>.</p> <pre><code>- action: unseal\n</code></pre>"},{"location":"8-reference/response-actions/#output","title":"output","text":"<p>Forwards the matched event to an Output identified by <code>name</code> in the <code>tailored</code> stream.</p> <p>This allows you to create highly granular Outputs for specific events.</p> <p>The <code>name</code> parameter is the name of the Output.</p> <p>Example:</p> <pre><code>- action: output\n  name: my-output\n</code></pre>"},{"location":"8-reference/response-actions/#rejoin-network","title":"rejoin network","text":"<p>Removes the isolation status of a sensor that had it set using <code>isolate network</code>.</p> <pre><code>- action: rejoin network\n</code></pre>"},{"location":"8-reference/response-actions/#report","title":"report","text":"<pre><code>- action: report\n  name: my-detection-name\n  publish: true # defaults to true\n  priority: 3   # optional\n  metadata:     # optional &amp; free-form\n    author: Alice (alice@wonderland.com)\n  detect_data:  # additional free-form field that can be used for extraction of specific elements\n</code></pre> <p>Reports the match as a detection. Think of it as an alert. Detections go a few places:</p> <ul> <li>The <code>detection</code> Output stream</li> <li>The organization's Detections page (if <code>insight</code> is enabled)</li> <li>The D&amp;R rule engine, for chaining detections</li> </ul> <p>The <code>name</code>, <code>metadata</code> and <code>detect_data</code> parameters support string templates like <code>detected {{ .cat }} on {{ .routing.hostname }}</code>, note that the context of the transform is the detection itself and not the original event, so you would refer to <code>.detect.event.USER_NAME</code> and not <code>.event.USER_NAME</code> for example.</p> <p>The <code>metadata</code> is generally used to populate information about the rule, its author, remediation etc.</p> <p>The <code>detect_data</code> is generally used to extract specific parts of the detected event into a known format that can be common across multiple detection, like extracting the <code>domain</code> or <code>hash</code> field for example.</p>"},{"location":"8-reference/response-actions/#limiting-scope","title":"Limiting Scope","text":"<p>There is a mechanism for limiting scope of a <code>report</code>, prefixing <code>name</code> with <code>__</code> (double underscore). This will cause the detection generated to be visible to chained D&amp;R rules and Services, but the detection will not be sent to the Outputs for storage.</p> <p>This is a useful mechanism to automate behavior using D&amp;R rules without generating extra traffic that is not useful.</p>"},{"location":"8-reference/response-actions/#optional-parameters_1","title":"Optional Parameters","text":"<p>The <code>priority</code> parameter, if set, should be an integer. It will be added to the root of the detection report as <code>priority</code>.</p> <p>The <code>metadata</code> parameter, if set, can include any data. It will be added to the root of the detection report as <code>detect_mtd</code>. This can be used to include information for internal use like reference numbers or URLs.</p>"},{"location":"8-reference/response-actions/#task","title":"task","text":"<pre><code>- action: task\n  command: history_dump\n  investigation: susp-process-inv\n</code></pre> <p>Sends a task in the <code>command</code> parameter to the sensor that the event under evaluation is from.</p> <p>An optional <code>investigation</code> parameter can be given to create a unique identifier for the task and any events emitted from the sensor as a result of the task.</p> <p>The <code>command</code> parameter supports string templates like <code>artifact_get {{ .event.FILE_PATH }}</code>.</p> <p>To view all possible commands, see Endpoint Agent Commands</p>"},{"location":"8-reference/response-actions/#undelete-sensor","title":"undelete sensor","text":"<p>Un-deletes a sensor that was previously deleted.</p> <pre><code>detect:\n    target: deployment\n    event: deleted_sensor\n    op: is\n    path: routing/event_type\n    value: deleted_sensor\nrespond:\n    - action: undelete sensor\n</code></pre> <p>This can be used in conjunction with the <code>deleted_sensor</code> event to allow sensors to rejoin the fleet.</p>"},{"location":"8-reference/response-actions/#wait","title":"wait","text":"<p>Adds a delay (up to 1 minute) before running the next response action.</p> <p>This can be useful if a previous response action needs to finish running (i.e. a command or payload run via <code>task</code>) before you can execute the next action.</p> <p>The <code>wait</code> action will block processing any events from that sensor for the specified duration of time. This is because D&amp;R rules are run at wire-speed and in-order.</p> <p>The <code>duration</code> parameter supports two types of values:</p> <ul> <li>A string describing a duration, like <code>5s</code> for 5 seconds or <code>10ms</code> for 10 milliseconds, as defined by this function call.</li> <li>An integer representing a number of seconds.</li> </ul> <p>Example:</p> <pre><code>- action: wait\n  duration: 10s\n</code></pre> <p>and</p> <pre><code>- action: wait\n  duration: 5\n</code></pre>"},{"location":"8-reference/response-actions/#add-hive-tag","title":"add hive tag","text":"<p>Adds a tag to a Hive record. This can be used to mark some Hive records like D&amp;R rules automatically.</p> <pre><code>- action: add hive tag\n  hive name: dr-general\n  record name: my-rule\n  tag: high-hit\n</code></pre> <p>Unless the rule is not expected to hit often, you likely want to couple this with a <code>suppression</code> statement to avoid doing a lot of tagging of the same rules like:</p> <pre><code>- action: add hive tag\n  hive name: dr-general\n  record name: my-rule\n  tag: high-hit\n  suppression:\n    max_count: 1\n    period: 1h\n    is_global: true\n    keys:\n      - 'high-hit'\n      - 'hive-tag'\n</code></pre>"},{"location":"8-reference/response-actions/#remove-hive-tag","title":"remove hive tag","text":"<p>Removes a tag from a Hive record.</p> <pre><code>- action: remove hive tag\n  hive name: dr-general\n  record name: my-rule\n  tag: high-hit\n</code></pre>"},{"location":"8-reference/response-actions/#see-also","title":"See Also","text":"<ul> <li>D&amp;R Rules Overview</li> <li>Detection Operators</li> <li>Endpoint Commands</li> </ul>"},{"location":"8-reference/schedule-events/","title":"Reference: Schedule Events","text":"<p>Schedule events are triggered automatically at various intervals per Organization or per Sensor, observable in rules via the <code>schedule</code> target.</p> <p>Scheduling events have a very similar structure whether they are per-sensor or per-org.</p> <p>The <code>event</code> component contains a single key, <code>frequency</code> which is the number of seconds frequency this scheduling event is for. The event type also contains the human readable version of the frequency.</p> <p>The following frequencies are currently emitted:</p> <ul> <li><code>30m</code>: <code>30m_per_org</code> and <code>30m_per_sensor</code></li> <li><code>1h</code>: <code>1h_per_org</code> and <code>1h_per_sensor</code></li> <li><code>3h</code>: <code>3h_per_org</code> and <code>3h_per_sensor</code></li> <li><code>6h</code>: <code>6h_per_org</code> and <code>6h_per_sensor</code></li> <li><code>12h</code>: <code>12h_per_org</code> and <code>12h_per_sensor</code></li> <li><code>24h</code>: <code>24h_per_org</code> and <code>24h_per_sensor</code></li> <li><code>168h</code> (7 days): <code>168h_per_org</code> and <code>168h_per_sensor</code></li> </ul> <p>Scheduling events are generated for each org that meets the following criteria:</p> <ul> <li>Has had at least 1 sensor online in the last 7 days.</li> </ul> <p>Scheduling events are generated for each sensor that meets the following criteria:</p> <ul> <li>Has been online at least once in the last 30 days.</li> </ul> <p>Scheduling events are not retained as part of the year retention in LimaCharlie. To leverage them, create D&amp;R rules that target the <code>schedule</code> target and take the relevant <code>action</code> when matched. For example to issue an <code>os_packages</code> once per week on Windows hosts:</p> <pre><code>detect:\n  target: schedule\n  event: 168h_per_sensor\n  op: is platform\n  name: windows\nrespond:\n  - action: task\n    command: os_packages\n    investigation: weekly-package-list\n</code></pre> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p>"},{"location":"8-reference/schedule-events/#related-articles","title":"Related articles","text":"<ul> <li>Detection on Alternate Targets</li> <li>Detection and Response Examples</li> <li>Reference: Platform Events</li> </ul>"},{"location":"8-reference/sensor-selector-expressions/","title":"Reference: Sensor Selector Expressions","text":"<p>Many components in LimaCharlie require selecting a set of Sensors based on some characteristics. The selector expression is a text field that describe what matching characteristics the selector is looking for.</p> <p>The following fields are available in this evaluation:</p> <ul> <li><code>sid</code>: the Sensor ID</li> <li><code>oid</code>: the Organization ID</li> <li><code>iid</code>: the Installation Key ID</li> <li><code>plat</code>: the Platform name (see platforms)</li> <li><code>ext_plat</code>: the Extended Platform name (see platforms)</li> <li><code>arch</code>: the Architecture name (see architectures)</li> <li><code>enroll</code>: the Enrollment as a second epoch timestamp</li> <li><code>hostname</code>: the hostname</li> <li><code>mac_addr</code>: the latest MAC address</li> <li><code>alive</code>: second epoch timestamp of the last time the Sensor connected to the cloud</li> <li><code>ext_ip</code>: the last external IP</li> <li><code>int_ip</code> the last internal IP</li> <li><code>isolated</code>: a boolean True if the sensor's network is isolated</li> <li><code>should_isolate</code>: a boolean True if the sensor is marked to be isolated</li> <li><code>kernel</code>: a boolean True if the sensor has some sort of \"kernel\" enhanced visibility</li> <li><code>did</code>: the Device ID the sensor belongs to</li> <li><code>tags</code>: the list of tags the sensor currently has</li> </ul> <p>The following are the available operators:</p> <ul> <li><code>==</code>: equals</li> <li><code>!=</code>: not equal</li> <li><code>in</code>: element in list, or substring in string</li> <li><code>not in</code>: element not in list, or substring not in string</li> <li><code>matches</code>: element matches regular expression</li> <li><code>not matches</code>: element does not match regular expression</li> <li><code>contains</code>: string is contained within element</li> </ul> <p>Here are some examples:</p> <ul> <li>all sensors with the test tag: <code>test in tags</code></li> <li>all windows boxes with an internal IP starting in 10.3.x.x: <code>plat == windows and int_ip matches `^10\\.3\\..*`</code></li> <li>all 1password sensors, strings starting with a number need to be quoted with a backtick: <code>plat == `1password`</code></li> <li>all linux with network isolation or evil tag: <code>plat == linux or (isolated == true or evil in tags)</code></li> <li>all azure related platforms: <code>plat contains \"azure\"</code></li> </ul> <p>In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.</p> <p>In LimaCharlie, an Organization ID is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.</p> <p>Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p>"},{"location":"8-reference/faq/","title":"Frequently Asked Questions","text":"<p>Common questions about LimaCharlie.</p>"},{"location":"8-reference/faq/#documentation","title":"Documentation","text":"<ul> <li>Account Management</li> <li>Billing</li> <li>General</li> <li>Invoices</li> <li>Privacy</li> <li>Sensor Installation</li> <li>Troubleshooting</li> <li>Sensor Removal</li> <li>Detect and Respond Rules</li> </ul>"},{"location":"8-reference/faq/account-management/","title":"FAQ - Account Management","text":""},{"location":"8-reference/faq/account-management/#how-can-i-create-more-than-two-organizations","title":"How Can I Create More Than Two Organizations?","text":"<p>By default, LimaCharlie has a limit of two organizations. If you need to create more organizations, please reach out to the support team and we will change this limit.</p>"},{"location":"8-reference/faq/account-management/#how-do-i-delete-an-organization","title":"How Do I Delete an Organization?","text":"<p>Please navigate to the bottom of the Billing &amp; Usage section of the organization you want to delete, and click Delete Organization button. Note that this action is final and cannot be undone.</p> <p></p>"},{"location":"8-reference/faq/account-management/#is-there-a-way-to-wipe-an-organization","title":"Is There a Way to Wipe an Organization?","text":"<p>You can wipe the data retention by disabling the <code>Insight</code> add on on the marketplace and re-enabling it again. Please note that unsubscribing from <code>Insight</code> will delete all telemetry stored for a selected organization, and this action cannot be undone.</p> <p>To wipe the configuration, you can use Templates / Infrastructure as Code functionality with the <code>is_force</code> flag to remove everything. To learn more about the infrastructure as code, visit Infrastructure Extension.</p>"},{"location":"8-reference/faq/account-management/#can-i-transfer-ownership-of-an-organization","title":"Can I Transfer Ownership of an Organization?","text":"<p>You can transfer ownership of an organization to any other entity. The request needs to be initiated by the current owner (billing or legal contact) of the organization. To do so, contact support@limacharlie.io.</p>"},{"location":"8-reference/faq/account-management/#i-created-an-account-and-have-been-given-access-but-i-do-not-seem-to-have-access-to-other-organizations","title":"I Created an Account and Have Been Given Access, but I Do Not Seem to Have Access to Other Organizations.","text":"<p>With LimaCharlie's granular role-based access control you can be granted access in one of two ways:</p> <ul> <li>On a per-organization basis</li> <li>To a set of organizations using Organization Groups</li> </ul> <p>You'll want to ask the person who granted access if they added you to the individual organizations, or if they'd set up an organization group.  Either method works, but they'll have to ensure that either you're added to each organization individually, or that they set up a group.</p>"},{"location":"8-reference/faq/account-management/#how-can-i-update-my-time-zone","title":"How Can I Update My Time Zone?","text":"<p>All dates and times displayed in the web app follow the user preferred time zone.</p> <p>To set your time zone, navigate to the settings icon in the right hand corner and select <code>Manage User Settings</code>.</p> <p></p> <p>You can set your preferred time zone under <code>Display</code> section of the <code>User Settings</code>; all changes are saved automatically.</p> <p></p>"},{"location":"8-reference/faq/account-management/#how-can-i-unsubscribecanceldelete-my-limacharlie-account","title":"How Can I Unsubscribe/Cancel/Delete My Limacharlie Account?","text":"<p>You can unsubscribe / cancel your subscription from app.limacharlie.io by logging in and going to the Billing &amp; Usage under the Billing section. Click the Delete Organization button at the bottom of the page and follow the instructions on screen.</p> <p></p>"},{"location":"8-reference/faq/account-management/#why-didnt-i-receive-my-account-activation-email","title":"Why Didn't I Receive My Account Activation Email?","text":"<p>Account activation emails are sent when you sign up for a new LimaCharlie account. If you do not see the activation email in your inbox, it can typically be found in a spam / junk folder. If you're a user of Microsoft Office 365, or similar service that has server-side filtering, you may wish to check your online Quarantine (or equivalent). See the Microsoft instructions for details.</p> <p>Please reach out to our support team and we can verify if a successful delivery response message was received from your mail server.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>Infrastructure as Code (IaC) automates the management and provisioning of IT infrastructure using code, making it easier to scale, maintain, and deploy resources consistently. In LimaCharlie, IaC allows security teams to deploy and manage sensors, rules, and other security infrastructure programmatically, ensuring streamlined, repeatable configurations and faster response times, while maintaining infrastructure-as-code best practices in cybersecurity operations.</p>"},{"location":"8-reference/faq/billing/","title":"FAQ - Billing","text":"<p>This page contains frequently asked questions about billing within LimaCharlie.</p> <p>Pricing Details</p> <p>Please note that our pricing is transparent, and is available via our Pricing webpage.</p>"},{"location":"8-reference/faq/billing/#how-can-i-change-my-quotaupgrade-to-the-paid-tier","title":"How Can I Change My Quota/Upgrade to the Paid Tier?","text":"<p>When you sign up for the LimaCharlie account, you will automatically be on a free tier, allowing you to create two organizations with two sensors each. All add-ons and additional services are free on this tier.</p> <p>To upgrade to paid tier, simply navigate to the Setup section of the Organization you are looking to upgrade and perform the following actions:</p> <ol> <li>Ensure you have a payment method on file by clicking the Billing &amp; Usage tab.</li> <li>In the Billing &amp; Usage tab, set the quota number you would like and click Update Quota. Quota is the number of sensors concurrently online you would like to support.</li> </ol> <p></p>"},{"location":"8-reference/faq/billing/#what-is-the-cost-of-deploying-payloads-via-limacharlie","title":"What is the Cost of Deploying Payloads via LimaCharlie?","text":"<p>Payload pricing is provided via our pricing page. For example, assume deploying Payloads via LimaCharlie costs $0.19 per 1 GB of data sent. A 1GB payload sent to 10 endpoints will cost $1.9 (10GBs x  $0.19).</p> <p>This only impacts organizations that leverage Payloads functionality, as well as Atomic Red Team and Dumper services (they are running as Payloads in LC).</p> <p>To understand the impact on your organization, check the Metered Usage section of the Billing page. You will notice the new Payload Data Sent metric along with the size of payloads deployed and price.</p> <p></p>"},{"location":"8-reference/faq/billing/#what-is-usage-based-billing","title":"What is Usage-Based Billing?","text":"<p>Along with our predictable per endpoint pricing model, LimaCharlie offers a pure usage-based billing model for our Endpoint Detection &amp; Response (EDR) capability. Pricing within this model is calculated solely on the time the Sensor is connected, events processed, and events stored. You can find more information about our billing options here.</p> <p>We acknowledge that some might not need the entirety of available components all the time, and might benefit from having access to an Endpoint Agent on an ad-hoc basis. This approach enables the following:</p> <ol> <li>Incident responders will now be able to offer pre-deployments to their customers at almost zero cost. That is, they can deploy across an organization's entire fleet and lay dormant in sleeper mode. With agents deployed ahead of an incident, responders can offer competitive SLA's.</li> <li>Product developers can take advantage of usage-based billing to leverage narrow bands of functionality at a low cost. This means getting the functionality they need without building it from the ground up or paying for a full EDR deployment.</li> </ol>"},{"location":"8-reference/faq/billing/#for-lc-adapters-billed-on-usage-what-does-block-of-data-mean-how-will-it-impact-the-price-i-pay","title":"For Lc Adapters Billed on Usage, What Does \"Block of Data\" Mean &amp; How Will It Impact the Price I Pay?","text":"<p>Some LimaCharlie Adapters are billed based on usage. Updated pricing details can be found on our pricing page.</p> <p>For example, assume $0.15 per block of data of 1 GB (on the organizational level). This means that 10 adapters with less than 1 GB (total) in the same organization will be $0.15 total for that month.</p>"},{"location":"8-reference/faq/billing/#how-do-i-determine-how-much-i-need-to-pay-for-an-org-if-it-was-in-usage-based-billing-mode","title":"How Do I Determine How Much I Need to Pay for an Org If It Was in Usage-Based Billing Mode?","text":"<p>If the organization you are trying to assess has 1-year telemetry retention enabled, you could use the stats API to see the number of events retained:</p> <p><code>https://api.limacharlie.io/v1/usage/OID</code>  or <code>https://api.limacharlie.io/static/swagger/#/Organizations/getOrgUsageStats</code></p> <p>You will want to check the <code>sensor_events</code> and <code>sensor_retained</code> values.</p>"},{"location":"8-reference/faq/billing/#how-is-the-price-of-sensors-add-ons-calculated-in-limacharlie","title":"How Is the Price of Sensors &amp; Add-Ons Calculated in LimaCharlie?","text":"<p>There are two categories of Sensors: sensors billed on Quota set by the user (vSensor basis) and sensors billed on usage basis.</p>"},{"location":"8-reference/faq/billing/#vsensors","title":"vSensors","text":"<p>LimaCharlie has the concept of a vSensor. A vSensor is a virtual sensor used for the purpose of setting up quota and billing of Endpoint Agents. vSensor pricing matches that listed on our pricing page, and includes a year of full telemetry storage.</p> <p>Our transparent pricing and quota-based approach allows you to easily mix and match deployments, while staying within a certain price point.</p> <p>If you set the quota to 100 vSensors, you can have concurrently:</p> <ul> <li>50 Windows Sensors + 50 Linux Sensors, OR</li> <li>20 Windows Sensors + 30 Linux Sensors + 50 macOS Sensors, OR</li> <li>100 macOS Sensors</li> <li>Or any other combination as long as the total number of sensors does not exceed the quota of 100 vSensors.</li> </ul>"},{"location":"8-reference/faq/billing/#sensors-over-quota","title":"Sensors Over Quota","text":"<p>If the quota is maxed out when a sensor attempts to come online, the sensor will be given a message to go away for a period of time and then they can check again. A <code>sensor_over_quota</code> event will be emitted in the deployments stream as well enabling users to set up alerts and be notified about this happening. The amount of time sensors are told to go away for increases if they connect again and the organization is still over quota.</p>"},{"location":"8-reference/faq/billing/#when-will-my-credit-card-be-charged","title":"When Will My Credit Card Be Charged?","text":"<p>Quota-based items are charged a month ahead, while usage items are billed the month following, similar to most cellphone invoices (or hosting).</p>"},{"location":"8-reference/faq/billing/#how-do-i-change-my-billing-credit-card","title":"How Do I Change My Billing Credit Card?","text":"<p>If you are using a credit card for payment and wish to change your address or card details, navigate to Billing &gt; Billing &amp; Usage within the web UI. From there, select Change Payment Details to update the appropriate details.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>Endpoint Detection &amp; Response</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p> <p>Endpoint Agents are lightweight software agents deployed directly on endpoints like workstations and servers. These sensors collect real-time data related to system activity, network traffic, file changes, process behavior, and much more.</p>"},{"location":"8-reference/faq/dr-rules/","title":"FAQ - Detect and Respond Rules","text":""},{"location":"8-reference/faq/dr-rules/#is-there-an-method-for-base64-decoding-and-inspection-within-detect-respond-rules","title":"Is there an method for base64 decoding and inspection within Detect &amp; Respond rules?","text":"<p>Base64 decoding is not currently supported directly within D&amp;R rules.</p> <p>You can have your D&amp;R rule detect base64 content and send it as an action to a Python playbook, where you can perform the necessary decoding and analysis.</p> <p>Why isn't this feature available? Base64 decoding in security contexts is rarely straightforward - it typically involves: - Extracting substrings rather than decoding entire fields - Handling special alphabets and custom encoding schemes - Managing different starting offsets</p> <p>While a basic full-field decoding parameter could potentially be added to operators, the complexity and variety of real-world base64 usage patterns make this a challenging feature to implement generically.</p>"},{"location":"8-reference/faq/general/","title":"FAQ - General","text":""},{"location":"8-reference/faq/general/#is-my-data-secure-with-limacharlie","title":"Is my data secure with LimaCharlie?","text":"<p>LimaCharlie data is secured starting at the endpoint all the way through your infrastructure. The LimaCharlie platform is hosted on the Google Cloud Platform, leveraging multiple capabilities from credentials management to compute isolation in order to limit the attack surface.</p> <p>Data access is managed through Google Cloud IAM which is used to isolate various components and customer data. Processing is done in Google Kubernetes Engine which provides an additional layer of container isolation.</p> <p>Each LimaCharlie data center uses independent cryptographic keys at all layers. Key management uses industry best practices such as key encryption at rest.</p> <p>LimaCharlie is SOC 2 Type 2 and PCI-DSS compliant. Our infrastructure is housed in ISO 27001 compliant data centres.</p>"},{"location":"8-reference/faq/general/#where-will-my-data-be-processed-and-stored","title":"Where will my data be processed and stored?","text":"<p>The LimaCharlie global infrastructure is built on the Google Cloud Platform (GCP). Currently, computing resources are available in the USA, Canada, Europe, India, and the United Kingdom. New data centers can be spun up anywhere GCP is available upon request.</p> <p>When you set up an Organization for the first time, you can select the Data Residency Region of your choice:</p> <p></p> <p>This provides you with the benefit of being able to select which GCP region you want your data in, and have assurance that it will always be processed in this location and never moved outside. This can be important for data residency requirements as it relates to regulatory compliance. For example, if you want to keep all of your information in the US, you can simply select the US region and know that your data will be both processed and stored there.</p> <p>Need to change the Data Residency Region?</p> <p>Please note that once a region has been selected for an organization, it cannot be changed later.</p>"},{"location":"8-reference/faq/general/#can-limacharlie-staff-access-my-data","title":"Can LimaCharlie staff access my data?","text":"<p>LimaCharlie staff only access your private data when you contact us and give us permission to do so. We will always ask for your permission before we access your private telemetry data.</p> <p>We consider your sensors and telemetry data to be private and confidential. We understand the tremendous power that is being entrusted to us while we have access to this data. We promise to only access your organization for the exclusive purpose of providing you with the assistance you request from us. We treat your private and confidential information with at least the same due care as we do with our own confidential information, as outlined in our privacy policy.</p>"},{"location":"8-reference/faq/general/#will-third-parties-get-access-to-my-data","title":"Will third parties get access to my data?","text":"<p>The only time we provide your data to a third party is with your explicit consent. (e.g. when you set up an Output in LimaCharlie, you're explicitly telling us to send your data to a 3<sup>rd</sup> party).</p>"},{"location":"8-reference/faq/general/#what-control-measures-do-you-have-in-place-to-ensure-that-my-data-wont-be-accessed-without-proper-authorizations","title":"What control measures do you have in place to ensure that my data won't be accessed without proper authorizations?","text":"<p>We use transparency as a mitigating control against insider threats. In particular, when we access your organization data, an entry is made to the audit log in your organization. You can access the audit log in the web interface and via the API. We also provide the ability for you to send audit log data out of LimaCharlie immediately to a write-only bucket that you control in your own environment.</p> <p>We use a break-glass system, meaning that LimaCharlie personnel do not have access to customer data by default. This requires an explicit programmatic action (internal to LimaCharlie) that includes its own audit trail that cannot be modified by LimaCharlie staff. This audit trail is regularly reviewed.</p> <p>LimaCharlie staff access to customer data is restricted to only those who need it to perform their official duties.</p> <p>LimaCharlie staff must explicitly request permission from the customer before granting access to any data or systems (other than in emergency cases where infrastructure is at risk).</p> <p>We use role-based access control systems to provide granular control over the type of data access granted.</p> <p>Access to customer organizations is granted programmatically as to provide a security control.</p> <p>We require that our staff undergo a background check and take training, including privacy training, prior to being allowed to access customer data.</p> <p>We are SOC 2 (Type 2) compliant and a copy of our audit report can be provided upon request.</p>"},{"location":"8-reference/faq/general/#what-is-detected-by-limacharlie-after-its-initially-installed","title":"What is detected by LimaCharlie after it's initially installed?","text":"<p>When the Sensor is installed, LimaCharlie will start recording the telemetry. It will not, however, generate detections or take actions to protect the endpoints automatically. As an infrastructure company, we recognize that each environment is different, and one size fits all approach rarely works well. By default, we take the AWS approach - any new organization starts empty, without any pre-configured settings, add-ons, or  rules.</p>"},{"location":"8-reference/faq/general/#can-limacharlie-be-deployed-on-premises","title":"Can LimaCharlie be deployed on-premises?","text":"<p>LimaCharlie is a cloud-based solution. The LimaCharlie platform is hosted on the Google Cloud Platform (GCP). There are no limits between AWS &amp; GCP but LimaCharlie is not available on premises; if you configure the sensor on the endpoint, it will connect to the cloud.</p>"},{"location":"8-reference/faq/general/#does-limacharlie-detect-variants-of-the-latest-malware","title":"Does LimaCharlie detect variants of the latest malware?","text":"<p>When the sensor is installed, LimaCharlie will start recording telemetry. It will not, however, generate detections or take actions to protect the endpoints automatically. As an infrastructure company, we recognize that each environment is different, and one size fits all approach rarely works well. By default, any new organization starts empty, without any pre-configured settings, add-ons, or D&amp;R rules.</p> <p>LimaCharlie makes it easy to add a detection &amp; response rule as soon as new variants of malware are discovered. This way, you are in a full control of your coverage and there is no need to wait for a vendor to come up with a new detection rule.</p>"},{"location":"8-reference/faq/general/#what-latency-can-i-expect-in-limacharlie","title":"What latency can I expect in LimaCharlie?","text":"<p>LimaCharlie Detection &amp; Response (D&amp;R) engine has very low latency and you can expect that responses are almost instantaneous (e.g. 100ms).</p> <p>You may notice some latency as it relates to outputs. Some of our outputs are done in batches, such as Amazon S3, SFTP, Google Cloud Storage. You can configure the maximum size and maximum time for these outputs. We also offer live outputs, such as Syslog.</p>"},{"location":"8-reference/faq/general/#how-can-i-integrate-limacharlie-with-my-existing-siem","title":"How can I integrate LimaCharlie with my existing SIEM?","text":"<p>The most common use case we see is sending detections and events data from LimaCharlie into the SIEM.</p> <p>To do it, you will need to configure outputs. Here are some examples for configuring outputs to go to an email or to Chronicle.</p> <p>Remember to select the type of data forwarded by this configuration (stream). The available options are as follows:</p> <ul> <li>event: Contains all events coming back from sensors (not cloud detections). It is very verbose.</li> <li>detect: Contains all detections reported from D&amp;R rules or subscriptions. This is the option you would choose if you want detections to generate emails (you would also need to ensure that D&amp;R rules are configured to generate detections).</li> <li>audit: Contains auditing events about activity around the management of the platform in the cloud.</li> <li>deployment: Contains all \"deployment\" events like sensor enrollment, cloned sensors etc.</li> <li>artifact: Contains all \"artifact\" events of files collected through the Artifact Collection mechanism.</li> </ul> <p>While sending detections and events data from LimaCharlie into the SIEM is the most common way we see our users set up the integration between these two systems, you can also bring in the data into LimaCharlie from SIEM or build other custom workflows. Contact our support team if you need help with your use case or if you have further questions.</p>"},{"location":"8-reference/faq/general/#what-is-the-retention-policy-for-managementaudit-logs","title":"What is the retention policy for management/audit logs?","text":"<p>LimaCharlie stores management/audit logs for one year.</p> <p>We suggest you set up an Output to send logs to an external destination if you are looking to have your logs stored for over one year.</p>"},{"location":"8-reference/faq/general/#does-limacharlie-offer-reporting-capabilities","title":"Does LimaCharlie offer reporting capabilities?","text":"<p>It is very common for users to bring different log, network and endpoint data into the LimaCharlie to leverage our detection and response, advanced correlation and storage. If you wish to leverage data visualization capabilities, we make it easy to send the data you need to Splunk, Tableau or any other solution of your choice via public API.</p> <p>In LimaCharlie web app, you can track information such as detections and events over time and number of sensors online.</p> <p></p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p>"},{"location":"8-reference/faq/invoices/","title":"FAQ - Invoices","text":"<p>This page contains frequently asked questions about invoices you receive for LimaCharlie service.</p> <p>Pricing Details</p> <p>Please note that our pricing is transparent and is available via our Pricing webpage.</p>"},{"location":"8-reference/faq/invoices/#limacharlie-invoices","title":"LimaCharlie Invoices","text":"<p>LimaCharlie offers two types of invoices:</p> <ul> <li>Individual Organization</li> <li>Unified billing</li> </ul> <p>We'll examine each in detail.</p>"},{"location":"8-reference/faq/invoices/#individual-organization-invoices","title":"Individual organization invoices","text":"<p>Your invoice will include a detailed breakdown of usage for your LimaCharlie tenant organization. You'll see individual line items for each LimaCharlie product utilized, along with your actual usage for the period. For example:</p> <ul> <li>Sensors</li> <li>Output usage</li> <li>Artifact ingestion</li> <li>Replay usage</li> </ul> <p>Invoices cover both lines for standard billable items like Sensor quota which are pre-paid for the following month, as well as consumption-based items (e.g. per-gigabyte costs incurred throughout the prior period) which are post-paid after the month has ended.</p> <p>Your monthly invoices include a detailed breakdown enable you to see the exact periods covered for each product listed.</p> <p>Because you are able to adjust your organization quota on demand, this will trigger proration of charges. You will see line items on your invoice which indicate \"Remaining time on ...\" or \"Unused time on ...\" that are related to the proration, which is done on a per-second basis.</p>"},{"location":"8-reference/faq/invoices/#unified-billing-invoices","title":"Unified Billing invoices","text":"<p>Customers who are set up on Unified Billing receive one invoice that contain a roll-up summary of all of their LimaCharlie organizations so that they can pay them all together. The Unified invoice includes one line item per tenant organization. Those tenant organizations include a reference to their sub-invoice number; you can refer to those for detailed line-level information related to each organization.</p> <p>Example Unified invoice</p> <p>Your browser does not support PDF. Click here to download.</p> <p>Example individual Tenant invoice</p> <p>Your browser does not support PDF. Click here to download.</p> <p>In addition to the Unified Billing invoice, customers are also provided with a LimaCharlie Global Billing email. This email contains:</p> <ol> <li>A table showing all organizations included in the period, along with a link to each individual organization's detailed invoice which shows breakdown of charges. Note that these individual invoices have a zero-dollar balance as the amounts are reflected on the Unified Invoice; this is reflected with a line item called \"UNIFIED-BILLING\" that shows the invoice total was moved to the unified invoice.</li> <li>A summary report (attachment) in CSV format that contains a list of the organizations included on the global billing invoice. The fields included in the CSV are as follows:     A - Org Name     B - Org ID     C - Payment     D - Sub-total     E - Total Due     F - Total Paid</li> </ol> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p> <p>In LimaCharlie, an Organization ID (OID) is a unique identifier assigned to each tenant or customer account. It distinguishes different organizations within the platform, enabling LimaCharlie to manage resources, permissions, and data segregation securely. The Organization ID ensures that all telemetry, configurations, and operations are kept isolated and specific to each organization, allowing for multi-tenant support and clear separation between different customer environments.</p>"},{"location":"8-reference/faq/privacy/","title":"FAQ - Privacy","text":"<p>LimaCharlie is a highly configurable security infrastructure-as-a-service platform. It allows users to control which data they ingest into the platform from various locations, including endpoints and cloud services.</p>"},{"location":"8-reference/faq/privacy/#collection-of-personally-identifiable-information-pii","title":"Collection of personally identifiable information (PII)","text":"<p>The LimaCharlie platform focuses on the collection of machine telemetry. This type of telemetry does not generally contain personally identifiable information. The LimaCharlie Sensor does not typically monitor PII-heavy areas such as the contents of email messages or documents. Consequently, manually stripping PII generally is not necessary. Users may choose to ingest their own sources of information. In those cases where LimaCharlie does not have knowledge of the nature of the ingested data, configuration mechanisms are available to users to specify fields they wish to drop or transform in order to better preserve privacy.</p> <p>We urge users to take a thoughtful approach to the types of data they collect, as they play a crucial role in preserving the privacy of their users. This sense of responsibility is key to maintaining a secure environment.</p>"},{"location":"8-reference/faq/privacy/#types-of-data-limacharlie-collects","title":"Types of data LimaCharlie collects","text":"<p>The LimaCharlie Sensor gathers telemetry from endpoints. The type of data collected is user-configurable and controlled behind role-based access controls. This telemetry contains basic details about endpoints, such as IP address, platform name, OS &amp; package version numbers, IP addresses, etc.</p> <p>Core sensor telemetry is collected and presented in JSON format.</p> <p>Example telemetry:</p> <pre><code>{\n  \"event\": {\n    \"COMMAND_LINE\": \"C:\\\\WINDOWS\\\\system32\\\\svchost.exe -k NetworkService -p\",\n    \"CREATION_TIME\": 1726927583937,\n    \"FILE_IS_SIGNED\": 1,\n    \"FILE_PATH\": \"C:\\\\WINDOWS\\\\system32\\\\svchost.exe\",\n    \"HASH\": \"0ad27dc6b692903c4e129b1ad75ee8188da4b9ce34c309fed34a25fe86fb176d\",\n    \"NETWORK_ACTIVITY\": [\n      {\n        \"DESTINATION\": {\n          \"IP_ADDRESS\": \"ff02::fb\",\n          \"PORT\": 5353\n        },\n        \"IS_OUTGOING\": 1,\n        \"PROTOCOL\": \"udp6\",\n        \"SOURCE\": {\n          \"IP_ADDRESS\": \"fe80::77d6:f691:a738:9c7d\",\n          \"PORT\": 5353\n        },\n        \"TIMESTAMP\": 1727414615732\n      },\n      {\n        \"DESTINATION\": {\n          \"IP_ADDRESS\": \"192.168.3.1\",\n          \"PORT\": 53\n        },\n        \"IS_OUTGOING\": 1,\n        \"PROTOCOL\": \"udp4\",\n        \"SOURCE\": {\n          \"IP_ADDRESS\": \"192.168.3.40\",\n          \"PORT\": 62283\n        },\n        \"TIMESTAMP\": 1727414631067\n      }\n    ],\n    \"PARENT_PROCESS_ID\": 888,\n    \"PROCESS_ID\": 2384,\n    \"USER_NAME\": \"NT AUTHORITY\\\\NETWORK SERVICE\"\n  },\n  \"routing\": {\n    \"arch\": 2,\n    \"did\": \"\",\n    \"event_id\": \"68ff82ba-c580-4a19-990e-4455effb7255\",\n    \"event_time\": 1727414635585,\n    \"event_type\": \"NETWORK_CONNECTIONS\",\n    \"ext_ip\": \"172.16.162.191\",\n    \"hostname\": \"workstation\",\n    \"iid\": \"c4cd7ab1-630d-40b4-b46c-2b817183117d\",\n    \"int_ip\": \"192.168.3.40\",\n    \"moduleid\": 2,\n    \"oid\": \"e946c975-2f02-4044-be5f-945b9c43d061\",\n    \"parent\": \"55f56dc5e19c460042d8179f66eed2f2\",\n    \"plat\": 268435456,\n    \"sid\": \"a8f8ca97-8614-438d-qb26-19100e8c90e3\",\n    \"tags\": [\n      \"workstations\"\n    ],\n    \"this\": \"4fef24a89ce77af24365721066f6416b\"\n  },\n  \"ts\": \"2024-09-27 05:23:55\"\n}\n</code></pre> <p>By default, the following types of telemetry are collected on Windows-based systems:</p> <p>AUTORUN_CHANGE  CODE_IDENTITY  CONNECTED  DIR_FINDHASH_REP  DIR_LIST_REP  DNS_REQUEST  DRIVER_CHANGE  EXEC_OOB  EXISTING_PROCESS  FILE_DEL_REP  FILE_GET_REP  FILELHASHLREP  FILE_INFO_REP  FILE_MOV_REP  FILE_TYPE_ACCESSED  FIM_HIT  FIM_LIST_REP  GET_DOCUMENT_REP  GET_EXFIL_EVENT_REP  HIDDEN_MODULE_DETECTED  HISTORY_DUMP_REP  LOG_GET_REP  LOG_LIST_REP  MEM_FIND_HANDLE_REP  MEM_FIND_STRING_REP  MEM_HANDLES_REP  MEM_MAP_REP  MEM_READ_REP  MEM_STRINGS_REP  MODULE_MEM_DISK_MISMATCH  NETSTAT_REP  NETWORK_CONNECTIONS  NEW_DOCUMENT  NEW_PROCESS  OS_AUTORUNS_REP  OS_DRIVERS_REP  OS_KILL_PROCESS_REP  OS_PACKAGES_REP  0S_PROCESSES_REP  0S_RESUME_REP  OS_SERVICES_REP  OS_SUSPEND_REP  OS_USERS_REP  OS_VERSION_REP  POSSIBLE_DOC_EXPLOIT  RECEIPT  RECON_BURST  REGISTRY_LIST_REP  SELF_TEST_RESULT  SENSITIVE_PROCESS_ACCESS  SERVICE_CHANGE  TERMINATE_PROCESS  THREAD_INJECTION  USER_OBSERVED  VOLUME_MOUNT  VOLUME_UNMOUNT  WEL  YARA_DETECTION</p> <p>Users can opt in / out of collection of event types on a per-platform basis. The default list varies based on OS platform and may change over time. For a full list of events, along with descriptions and samples, please see Events.</p>"},{"location":"8-reference/faq/privacy/#examples-of-limacharlie-sensor-data","title":"Examples of LimaCharlie Sensor Data","text":"<ol> <li>Sensor Overview    </li> <li>Artifacts    </li> <li>Autoruns    </li> <li>Console    </li> <li>Detections    </li> <li>Drivers    </li> <li>File System    </li> <li>File Integrity Monitoring    </li> <li>Network Connections    </li> <li>Packages     </li> <li>Processes     </li> <li>Services     </li> <li>Timeline with Event Details     </li> <li>Users     </li> </ol> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p>"},{"location":"8-reference/faq/sensor-installation/","title":"FAQ - Sensor Installation","text":""},{"location":"8-reference/faq/sensor-installation/#how-can-i-add-limacharlie-traffic-to-an-allow-list","title":"How can I add LimaCharlie traffic to an allow list?","text":"<p>The tables below show the hostnames and IPs used to connect to LimaCharlie. All connections use TCP port 443 and TLS 1.2+</p>"},{"location":"8-reference/faq/sensor-installation/#what-hostnames-and-ips-does-limacharlie-use-for-each-region","title":"What Hostnames and IPs does LimaCharlie use for each region?","text":""},{"location":"8-reference/faq/sensor-installation/#canada-quebec","title":"Canada (Quebec)","text":"Hostname IP Use aae67d7e76570ec1.lc.limacharlie.io 35.203.33.203 Windows, Mac, &amp; Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) aae67d7e76570ec1.edr.limacharlie.io 35.201.82.57 Windows, Mac, &amp; Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) aae67d7e76570ec1.wss.limacharlie.io 35.201.96.199 Chrome, Edge and Adapters aae67d7e76570ec1.ingest.limacharlie.io 34.149.216.238 Logs and Artifacts aae67d7e76570ec1.replay.limacharlie.io 142.250.115.121 Replay aae67d7e76570ec1.live.limacharlie.io 34.120.175.14 Live feed aae67d7e76570ec1.hook.limacharlie.io 142.250.115.121 Webhooks"},{"location":"8-reference/faq/sensor-installation/#us-iowa","title":"US (Iowa)","text":"Hostname IP Use 9157798c50af372c.lc.limacharlie.io 35.194.62.236 Windows, Mac, &amp; Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) 9157798c50af372c.edr.limacharlie.io 34.149.165.165 Windows, Mac, &amp; Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) 9157798c50af372c.wss.limacharlie.io 34.102.223.182 Chrome, Edge and Adapters 9157798c50af372c.ingest.limacharlie.io 34.120.157.194 Logs and Artifacts 9157798c50af372c.replay.limacharlie.io 142.250.115.121 Replay 9157798c50af372c.live.limacharlie.io 34.120.123.4 Live feed 9157798c50af372c.hook.limacharlie.io 142.250.115.121 Webhooks"},{"location":"8-reference/faq/sensor-installation/#india-mumbai","title":"India (Mumbai)","text":"Hostname IP Use 4d897015b0815621.lc.limacharlie.io 35.200.151.24 Windows, Mac, &amp; Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) 4d897015b0815621.edr.limacharlie.io 34.102.207.18 Windows, Mac, &amp; Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) 4d897015b0815621.wss.limacharlie.io 34.98.108.101 Chrome, Edge and Adapters 4d897015b0815621.ingest.limacharlie.io 34.149.161.19 Logs and Artifacts 4d897015b0815621.replay.limacharlie.io 142.250.115.121 Replay 4d897015b0815621.live.limacharlie.io 35.244.221.119 Live feed 4d897015b0815621.hook.limacharlie.io 142.250.115.121 Webhooks"},{"location":"8-reference/faq/sensor-installation/#uk-london","title":"UK (London)","text":"Hostname IP Use 70182cf634c346bd.lc.limacharlie.io 35.242.152.114 Windows, Mac, &amp; Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) 70182cf634c346bd.edr.limacharlie.io 34.107.134.233 Windows, Mac, &amp; Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) 70182cf634c346bd.wss.limacharlie.io 35.244.147.201 Chrome, Edge and Adapters 70182cf634c346bd.ingest.limacharlie.io 34.149.56.238 Logs and Artifacts 70182cf634c346bd.replay.limacharlie.io 142.250.115.121 Replay 70182cf634c346bd.live.limacharlie.io 35.244.146.102 Live feed 70182cf634c346bd.hook.limacharlie.io 142.250.115.121 Webhooks"},{"location":"8-reference/faq/sensor-installation/#europe-emshaven","title":"Europe (Emshaven)","text":"Hostname IP Use b76093c3662d5b4f.lc.limacharlie.io 35.204.142.125 Windows, Mac, &amp; Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) b76093c3662d5b4f.edr.limacharlie.io 34.111.194.87 Windows, Mac, &amp; Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) b76093c3662d5b4f.wss.limacharlie.io 130.211.22.248 Chrome, Edge and Adapters b76093c3662d5b4f.ingest.limacharlie.io 34.120.5.160 Logs and Artifacts b76093c3662d5b4f.replay.limacharlie.io 142.250.115.121 Replay b76093c3662d5b4f.live.limacharlie.io 34.120.64.23 Live feed b76093c3662d5b4f.hook.limacharlie.io 142.250.115.121 Webhooks"},{"location":"8-reference/faq/sensor-installation/#australia-sydney","title":"Australia (Sydney)","text":"Hostname IP Use abc32764762fce67.lc.limacharlie.io 34.151.84.52 Windows, Mac, &amp; Linux EDR Agent  Note: Pinned SSL certificates (SSL interception unsupported) abc32764762fce67.edr.limacharlie.io 34.54.253.51 Windows, Mac, &amp; Linux EDR Agent  Note: Non-Pinned SSL certificates (SSL interception supported) abc32764762fce67.wss.limacharlie.io 34.96.104.54 Chrome, Edge and Adapters abc32764762fce67.ingest.limacharlie.io 35.241.63.128 Logs and Artifacts abc32764762fce67.replay.limacharlie.io 34.49.249.16 Replay abc32764762fce67.live.limacharlie.io 34.8.102.215 Live feed abc32764762fce67.hook.limacharlie.io 34.49.185.177 Webhooks"},{"location":"8-reference/faq/sensor-installation/#how-much-data-does-the-limacharlie-sensor-produce-per-day","title":"How much data does the LimaCharlie Sensor produce per day?","text":"<p>The amount of data that is produced by the sensor is dependent on how much, and what kind of activity is taking place on the endpoint. That being said, the average data produced per endpoint across thousands of deployments is approximately 1MB per day.</p>"},{"location":"8-reference/faq/sensor-installation/#what-resources-does-the-limacharlie-agent-consume","title":"What resources does the LimaCharlie agent consume?","text":"<p>The total footprint of the agent on disk combined with what is in memory is approximately 50MB. The agent typically runs under 1% CPU.</p> <p>Depending on what actions you may be performing it may increase (e.g. if you're doing a full YARA scan it's expected that the CPU usage will increase). When you use our YARA trickle scan, that also keeps CPU usage within reasonable bounds. You'll only see YARA scans spike CPU when you do a full manual scan.</p> <p>Depending on the configuration of the agent (it's fully customizable), the network bandwidth will vary, but we typically see approximately 2MB per day on Windows hosts.</p>"},{"location":"8-reference/faq/sensor-installation/#why-does-my-sensor-initially-connect-successfully-but-then-disappear","title":"Why does my sensor initially connect successfully but then disappear?","text":"<p>Sometimes we see the agent connect to the LimaCharlie cloud, enrolls, then disconnects (which is normal the first time after enrollment) and never connects again, or it doesn't show that kernel has been acquired.</p> <p>This behavior is typical with SSL interception. Sometimes it's a network device, but at other times some security products on the host can do that without being very obvious.</p> <p>You can confirm if there is SSL interception by performing the following steps to check the SSL fingerprint of the LimaCharlie cloud from the host.</p> <p>Confirm the region of your Organization</p> <p>If you already know where your organization's region is located, you can move to the next step. To verify the organization's region where the data is processed and stored, click <code>Add Sensor</code> from the <code>Sensors</code> view. You will then see the region listed under <code>Sensor Connectivity</code>.</p> <p>Open the test URL Via web browser, navigate to one of the below test URLs that corresponds to the correct region:</p> <p>Test URL - US Region Test URL - UK Region Test URL - India Region Test URL - Europe Region Test URL - Canada Region</p> <p>No website will open; you should get a \"Your connection is not private\" type of message instead.</p> <p>Display the SSL Certificate</p> <p>By clicking near the URL bar on the exclamation mark, you will open a small menu and you can click \"Certificate status\"/\"Certificate validity\"/\"Certificate is not valid\" which will display the certificate information.</p> <p>Confirm the SHA-1 and SHA-256 fingerprints</p> <p>The SHA-1 and SHA-256 fingerprints should match the values below that correspond to the region your organization is in.</p> <p>If the SHA-1 and SHA-256 fingerprints you are seeing do not match what's listed below, that's an indicator of the SSL interception.</p> Region SHA-256 Fingerprint SHA-1 Fingerprint US 14 44 8C B6 A1 19 A5 BE 18 AE 28 07 E3 D6 BD 55 B8 7A 5E 0C 3F 2D 78 03 6E 7C 6A 2A AA 45 8F 60 1A 72 67 08 D0 83 7D A9 62 85 39 55 A1 12 1B 10 B0 F4 56 1A UK 49 49 B0 41 D6 14 F3 3B 86 BF DF 14 24 F8 BD 2F E1 98 39 41 5A 99 E6 F1 C7 A2 C8 AB 34 0C FE 1D 2E 49 00 DB F8 3A 2A 88 E0 15 76 D5 C5 4F 8F F3 7D 27 77 DD India 68 6F 08 3D 53 3F 08 E0 22 EB F6 67 0C 3C 41 08 75 D6 0E 67 03 88 D9 B6 E1 F8 19 6B DA 54 5A A3 37 57 DD 4E CF 2B 25 0B CA EA E2 E6 E3 B2 98 48 29 19 F3 6B Europe EF B3 FA A7 78 AB F0 B0 41 00 CF A3 5F 44 3F 9A 4D 16 28 B9 83 22 85 E3 36 44 D5 DC F9 5C 78 5B 07 72 B3 31 1A 89 D6 54 1D 71 C3 07 AD B5 8A 26 FD 30 7E 5D Canada D3 40 8B 59 AE 5A 28 75 D1 65 71 50 52 2E 6F 45 26 EE E8 19 3A 9A 74 39 C1 64 60 B8 6A 92 15 47 E3 EF AE 6A 0E 7F 18 83 15 FE F2 02 6C F3 2D 4E 59 95 4D 0A"},{"location":"8-reference/faq/sensor-installation/#what-happens-if-a-host-is-offline","title":"What happens if a host is offline?","text":"<p>When the host is offline, the Sensor will keep collecting telemetry and store it locally in a \"ring buffer\" (which limits the total possible size). The buffer is ~60mb, so the amount of time it will cover will vary based on how much telemetry the individual endpoint generates. e.g. A domain controller will likely be generating many more events than a regular end user workstation.</p> <p>When the host is back online, the content of this buffer will be flushed to the cloud where detection and response rules will apply as usual.</p> <p>The same ring buffer is used when the Sensor runs normally, even if data is not sent to the cloud in real-time. The cloud can then retroactively request the full or partial content of the ring buffer, bringing your telemetry current.</p>"},{"location":"8-reference/faq/sensor-installation/#how-can-i-tell-which-installation-key-was-used-to-enroll-a-sensor","title":"How can I tell which Installation Key was used to enroll a sensor?","text":"<p>On occasion you may need to check which installation key was used to enroll a sensor. You can do so by comparing the sensors <code>Installer ID</code> with the Installation Key's <code>Adapter Key</code> value.</p> <ol> <li>Go to the Sensors section and click into the sensor in question to view its details page. Take note of the <code>Installer ID</code>.</li> <li>Go to the Install Sensors section.  Click the copy icon under the <code>Adapter Key</code>.</li> <li>Compare these two values; the Installer ID on a sensor should be the same as the Adapter Key of the installation key used.</li> </ol> <p>If you need to check a large list of sensors, you can perform an export of all sensors from the main sensors list page, or use the LimaCharlie API.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.</p> <p>Adapters serve as flexible data ingestion mechanisms for both on-premise and cloud environments.</p>"},{"location":"8-reference/faq/sensor-removal/","title":"FAQ - Sensor Removal","text":""},{"location":"8-reference/faq/sensor-removal/#how-do-i-verify-the-limacharlie-agent-was-uninstalled-from-macos-systems","title":"How do I verify the LimaCharlie agent was uninstalled from macOS systems?","text":"<p>After performing an uninstallation of the LimaCharlie Sensor for macOS, you can verify that the process was successful by manually checking several items on the endpoint, as described below.</p>"},{"location":"8-reference/faq/sensor-removal/#verify-the-limacharlie-processes-are-not-running","title":"Verify the LimaCharlie processes are not running","text":"<ol> <li>Open Activity Monitor (<code>/Applications/Utilities/Activity Monitor.app</code>).</li> <li>From the View menu, ensure \"All Processes\" is selected.</li> <li>In the Search box, type: <code>rphcp</code></li> <li>Ensure that neither of the following processes appear:</li> </ol> <p><code>rphcp</code></p> <p><code>com.refractionpoint.rphcp.extension</code></p> <p>If either appear, the uninstallation likely did not complete successfully and it should be re-attempted.</p>"},{"location":"8-reference/faq/sensor-removal/#verify-all-files-on-disk-were-removed","title":"Verify all files on disk were removed","text":"<p>The following LimaCharlie sensor-related files should no longer exist on disk:</p> <p>/Applications/RPHCP.app</p> <p>/usr/local/bin/rphcp</p> <p>/usr/local/hcp</p> <p>/usr/local/hcp_conf</p> <p>/usr/local/hcp_hbs</p> <p>You may optionally remove the log file located at: /usr/local/hcp.log</p>"},{"location":"8-reference/faq/sensor-removal/#verify-limacharlie-network-extension-was-removed","title":"Verify LimaCharlie Network Extension was removed","text":"<ol> <li>Open System Settings</li> <li>Navigate to Network</li> <li>Select VPN &amp; Filters</li> <li>Check if. \"RPHCP\" appears in the list.</li> </ol> <p>\u2705 If it does not appear, the Network Extension was successfully removed.</p> <p>\u274c If you see RPHCP in the list, the Network Extension was not properly removed and you should perform uninstallation again.</p>"},{"location":"8-reference/faq/sensor-removal/#verify-limacharlie-security-extension-was-removed","title":"Verify LimaCharlie Security Extension was removed","text":"<p>Open the Terminal and run the following commands</p> <p>Run Command #1</p> <p><code>sudo systemextensionsctl list | grep rphcp</code></p> <p>\u2705 No result would indicate that the uninstall was successful.</p> <p>\u274c The following result would indicate that the uninstall was not successful:</p> <pre><code>*   *   N7N82884NH  com.refractionpoint.rphcp.extension (1.0.241204/1.0.241204) RPHCP   [activated enabled]\n</code></pre> <p>Run Command #2</p> <p><code>sudo cat /Library/SystemExtensions/db.plist | grep rphcp</code></p> <p>\u2705 If no result is returned, the security extension was successfully removed.</p> <p>\u274c If instead you see something similar to the below, the extension was not properly removed and you may need to take some additional measures to do so (i.e. manual removal after booting into Recovery mode).</p>"},{"location":"8-reference/faq/troubleshooting/","title":"FAQ - Sensor Troubleshooting","text":""},{"location":"8-reference/faq/troubleshooting/#why-is-there-no-output-in-the-console","title":"Why is there no output in the console?","text":"<p>When running Sensor console commands, you may encounter a \"spinning wheel\" or no output back from the Sensor. Oftentimes, this is due to the response event not enabled in Event Collection. You will need to configure the response event in order to receive feedback in the console.</p> <p>For example, the <code>os_users</code> Sensor command has two components:</p> <ul> <li><code>OS_USERS_REQ</code> is the request event sent to the Sensor to collect OS user information.</li> <li><code>OS_USERS_REP</code> is the response event sent back by the Sensor containing the information of interest.</li> </ul> <p>Please ensure that you are collecting the <code>*_REP</code> events in order to display output in the console.</p>"},{"location":"8-reference/faq/troubleshooting/#sensor-not-showing-as-online","title":"Sensor Not Showing as Online","text":""},{"location":"8-reference/faq/troubleshooting/#determining-online-status","title":"Determining Online Status","text":"<p>It is important to note that the online marker in the Web UI does not display real-time information. Instead it refreshes its status between every 30 seconds to every few minutes, depending on the page in question.</p> <p>This means that an icon showing a sensor as not online may be lagging behind the actual status. If you need to get a positive feedback on whether the sensor is online or not, go to the \"Sensors\" page which refreshes status more often. Moving to the \"Sensors\" page also triggers a refresh of the status right away.</p>"},{"location":"8-reference/faq/troubleshooting/#reasons-for-temporary-disconnect","title":"Reasons for Temporary Disconnect","text":"<p>Sensors connect to the cloud via a semi-persistent SSL connection. In general, if a host has connectivity to the internet, the sensor should be online. There are, however, a few situations that result in the sensor temporarily disconnecting from the cloud for a few seconds. This means that if you notice a sensor is offline when you expect it to be online, give it 30 seconds, and in most situations it will come back online within 5 seconds.</p>"},{"location":"8-reference/faq/troubleshooting/#sensor-not-connecting","title":"Sensor Not Connecting","text":"<p>Sensors connect to the LimaCharlie.io cloud via an SSL connection on port 443. Make sure your network allows such a connection. It is a very common port typically used for HTTPS so an issue is highly unlikely.</p> <p>The sensor uses a pinned SSL certificate to talk to the cloud. This means that if you are in a network that enforces SSL inspection (a man-in-the-middle of the SSL connections sometimes used in large corporate environments), this may prevent the sensor from connecting. LimaCharlie uses a pinned certificate to ensure the highest level of security possible, as usage of off-the-shelf certificates can be leveraged by state-sponsored (or advanced) attackers.</p> <p>If your network uses SSL inspection, we recommend you setup an exception for the LimaCharlie cloud domain relevant to you. Get in touch with us and we can provide you with the necessary information.</p> <p>Sensors since version 4.21.2 also generate a local log file able to be used to help pinpoint the level at which the connectivity fails. This log file is located:</p> <ul> <li>Windows: <code>c:\\windows\\system32\\hcp.log</code></li> <li>MacOS: <code>/usr/local/hcp.log</code></li> <li>Linux: <code>./hcp.log</code></li> </ul> <p>This log provides a simple line for each basic step of connectivity to the cloud. It only logs the first connection attempted to the cloud and rolls over every time the sensor starts. A successful connection should look like:</p> <pre><code>hcp launched\nconfigs applied\nconn started\nconnecting\nssl connected\nheaders sent\nchannel up\n</code></pre> <p>If you are having trouble getting your sensor connected to the cloud, we recommend that you attempt the following on the host:</p> <ol> <li>Restart the LimaCharlie service.</li> <li> <p>Check that the service is running.</p> </li> <li> <p>The service process should be called <code>rphcp</code>.</p> </li> <li> <p>If the sensor still shows as not online, check the <code>hcp.log</code> file mentioned above:</p> </li> <li> <p>Check that the \"configs applied\" step is reached. If not, it may indicate the Installation Key provided is wrong or has a typo.</p> </li> <li>Check that the proxy is mentioned in the log if you are using a proxy configuration.</li> <li>Check that the \"ssl connected\" step is reached. If not, this indicates a network configuration issue connecting to the cloud.</li> <li> <p>Check that the \"channel up\" step is reached. If not, this could indicate one of a few things:</p> <ul> <li>Your sensor was deleted (through API or Web interface) from the org. If so, reinstall to get a new identity.</li> <li>Your Organization may be out-of-quota if more sensors than the maximum number you've set in the Billing section are trying to connect at once. Increase your quota and wait a few minutes to fix it.</li> <li>If this is a brand new sensor install, make sure the Installation Key you're using still exists in your Org. Once deleted, an Installation Key cannot be used for NEW sensors, but old sensors that were installed using it will still work fine.</li> </ul> </li> </ol>"},{"location":"8-reference/faq/troubleshooting/#sensor-not-responding","title":"Sensor Not Responding","text":"<p>Your sensor shows up as \"online\", but does not respond to interactive tasking.</p> <p>The most common cause of this problem is a partial uninstall and reinstall of the sensor on the host. The sensor, when installed, creates local files that record the identity the sensor has with the cloud.</p> <p>When uninstalling, the <code>-r</code> mode leaves these identification files behind, so that if you reinstall a new version of the sensor which talks to the same Org in LimaCharlie, the Sensor ID will be the same. On the other hand, the <code>-c</code> mode will remove all the identity files as well.</p> <p>If you uninstall with <code>-r</code> and re-enroll the sensor to a different Org, as can often happen during testing, the files on disk that include some cryptographic material will not match with what the cloud expects. This may result in taskings being refused by the sensor.</p> <p>To make sure this is not what's happening, uninstall the sensor with <code>-c</code>. Double-check that the local files <code>hcp</code>, <code>hcp_hbs</code> and <code>hcp_conf</code> are deleted before reinstalling. On Windows these should be in <code>c:\\windows\\system32</code> while on macOS they should be in <code>/usr/local</code>.</p>"},{"location":"8-reference/faq/troubleshooting/#sensor-duplication","title":"Sensor Duplication","text":"<p>Sensor duplication can occur during certain types of installation or deployments, e.g. creation of virtual systems via a \"gold image\" that has LimaCharlie pre-installed.</p> <p>However, in niche cases we have seen examples of:</p> <ol> <li>LimaCharlie unable to write it's own identity files to disk, causing a constant \"new\" sensor connection.</li> <li>Third-party security software on the system incorrectly categorizing LimaCharlie as malware, and killing the process before it can start.</li> </ol> <p>One method to troubleshoot and determine root cause is to utilize Sysinternals' DebugView to investigate the error caused during Sensor installaton/start-up.</p> <p>Another quick troubleshooting technique may be to determine whether the Sensor process <code>rphcp.exe</code></p>"},{"location":"8-reference/faq/troubleshooting/#upgrading-sensors","title":"Upgrading Sensors","text":"<p>To ensure the sensor version is up-to-date, open the \"Install Sensors\" page in the web app (under \"Setup\") and navigate to the \"Upgrading Sensors\" section.</p> <p>Upgrading sensors is done transparently for you once you click the button in the web app interface. You do not need to re download installers (in fact the installer stays the same). The new version should be in effect across the organization within about 20 minutes.</p>"},{"location":"8-reference/faq/troubleshooting/#how-can-i-tell-which-version-of-the-sensor-is-running-locally","title":"How can I tell which version of the sensor is running locally?","text":"<p>The LimaCharlie sensor outputs a status file on the endpoint which allows you to see the:</p> <ul> <li>Sensor ID,</li> <li>Organization ID,</li> <li>Sensor version, and</li> <li>the agent's service uptime.</li> </ul> <p>You can find this log data at the following location, based on your platform:</p> Platform File Path Linux <code>/opt/limacharlie/hcp_hbs_status.json</code> macOS <code>/Library/Application Support/limacharlie/hcp_hbs_status.json</code> Windows <code>c:\\programdata\\limacharlie\\hcp_hbs_status.json</code> <p>The log data is formatted similarly to the example below:</p> <pre><code>{\n      \"version\": \"4.33.0\",\n      \"sid\": \"be8bc53b-36b2-469d-a914-716d629cb2d8\",\n      \"oid\": \"d02c08e4-aedc-45eb-88aa-98b09b7d92df\",\n      \"last_update\": 1738872790,\n      \"uptime\": 127\n}\n</code></pre>"},{"location":"8-reference/faq/troubleshooting/#sensor-troubleshooting-utility","title":"Sensor Troubleshooting Utility","text":"<p>In some cases we may ask you for sensor health information from an endpoint that is having issues. To get this information, run the LC sensor interactively in the terminal with the -H flag.</p> <p>On macOS run the command: <code>sudo /usr/local/bin/rphcp -H</code></p> <p>The diagnostic information will be displayed on screen, and saved to a file. The location of the output file will be shown at the bottom of the message shown on screen (on macOS, typically at `/Library/Application Support/limacharlie/``).</p> <p>Note that the Sensor Troubleshooting Utility requires sensor version 4.33.6 or newer to be installed on disk on the impacted endpoint.</p> <p>You can find the output file at the following location, based on your platform:</p> Platform File Path Linux <code>/opt/limacharlie/sensor_health_YYYY_MM_DD_HH_MM.json</code> macOS <code>/Library/Application Support/limacharlie/sensor_health_YYYY_MM_DD_HH_MM.json</code> Windows <code>c:\\programdata\\limacharlie\\sensor_health_YYYY_MM_DD_HH_MM.json</code> <p>The log data is formatted similarly to the example below:</p> <pre><code>{\n  \"system\": {\n    \"memory_total\": 25769803776,\n    \"memory_used\": 13423722496,\n    \"name\": \"Darwin\",\n    \"kernel\": \"24.4.0\",\n    \"version\": \"15.4.1\",\n    \"hostname\": \"Mac\",\n    \"cpu_count\": 8,\n    \"process_list\": [\n\n    ]\n  },\n  \"agent\": {\n    \"agent_info\": {\n      \"MacOS\": {\n        \"process\": {\n          \"Ok\": {\n            \"pid\": 2024,\n            \"ppid\": 2023,\n            \"cpu_usage\": 0.0,\n            \"cwd\": \"/Users/username/Downloads\",\n            \"exe\": \"/usr/local/bin/rphcp\",\n            \"start_time\": 1745890277,\n            \"run_time\": 1,\n            \"memory\": 10125312,\n            \"virtual_memory\": 420875878400,\n            \"command_line\": [\n              \"/usr/local/bin/rphcp\",\n              \"-H\"\n            ]\n          }\n        },\n        \"agent_service\": {\n          \"Ok\": {\n            \"name\": \"com.refractionpoint.rphcp\",\n            \"pid\": 1521,\n            \"state\": \"running\",\n            \"service_type\": null,\n            \"launchd_config\": \"/Library/LaunchDaemons/com.refractionpoint.rphcp.plist\",\n            \"launchd_type\": \"LaunchDaemon\",\n            \"program\": \"/usr/local/bin/rphcp\",\n            \"restart_count\": 1,\n            \"last_signal\": null\n          }\n        },\n        \"system_extension_process\": {\n          \"Ok\": {\n            \"pid\": 1638,\n            \"ppid\": 1,\n            \"cpu_usage\": 0.0,\n            \"cwd\": \"/\",\n            \"exe\": \"/Library/SystemExtensions/3C420533-7D6B-409C-A2B4-BB9D526AB7E2/com.refractionpoint.rphcp.extension.systemextension/Contents/MacOS/com.refractionpoint.rphcp.extension\",\n            \"start_time\": 1745889761,\n            \"run_time\": 517,\n            \"memory\": 15450112,\n            \"virtual_memory\": 423440154624,\n            \"command_line\": [\n              \"/Library/SystemExtensions/3C420533-7D6B-409C-A2B4-BB9D526AB7E2/com.refractionpoint.rphcp.extension.systemextension/Contents/MacOS/com.refractionpoint.rphcp.extension\"\n            ]\n          }\n        },\n        \"system_extension\": {\n          \"Ok\": {\n            \"name\": \"N7N82884NH.com.refractionpoint.rphcp.extension\",\n            \"pid\": 1638,\n            \"state\": \"running\",\n            \"service_type\": null,\n            \"launchd_config\": \"(submitted by smd[323])\",\n            \"launchd_type\": \"Submitted\",\n            \"program\": \"/Library/SystemExtensions/3C420533-7D6B-409C-A2B4-BB9D526AB7E2/com.refractionpoint.rphcp.extension.systemextension/Contents/MacOS/com.refractionpoint.rphcp.extension\",\n            \"restart_count\": 1,\n            \"last_signal\": null\n          }\n        },\n        \"config\": {\n          \"Ok\": {\n            \"launchd_file_hash\": {\n              \"Ok\": \"01049276aaa1708885f24788230fe9a4c2316e43aadef42354e4061b0aac906c\"\n            },\n            \"launchd_file\": \"ABC+\",\n            \"mdm_silent_file_hash\": {\n              \"Err\": \"No such file or directory (os error 2)\\n\"\n            },\n            \"mdm_silent_file\": null,\n            \"system_extensions\": {\n              \"Ok\": [\n                {\n                  \"enabled\": true,\n                  \"active\": true,\n                  \"team_id\": \"N7N82884NH\",\n                  \"bundle_id\": \"com.refractionpoint.rphcp.extension\",\n                  \"version\": \"(1.0.250416/1.0.250416)\",\n                  \"name\": \"RPHCP\",\n                  \"state\": \"[activated enabled]\"\n                }\n              ]\n            },\n            \"network_extension\": {\n              \"Ok\": {\n                \"name\": \"com.refractionpoint.rphcp.client\",\n                \"enabled\": true\n              }\n            },\n            \"profiles\": {\n              \"Ok\": [\n\n              ]\n            }\n          }\n        }\n      }\n    },\n    \"hbs_status\": {\n      \"Ok\": {\n        \"version\": \"4.33.6\",\n        \"sid\": \"da1020f7-c247-4749-b7d7-d05f282e6ca2\",\n        \"oid\": \"0bb86406-b1f3-4d3b-af5c-118cc5291972\",\n        \"last_update\": 1745890057,\n        \"uptime\": 300\n      }\n    },\n    \"logs\": {\n      \"Ok\": {\n        \"file\": \"/usr/local/hcp.log\",\n        \"oid\": null,\n        \"sid\": null,\n        \"data\": \"MMGgMTq5NTg4OTczNzogaGNwIGxhdW5amGVkClRTIDE3NDU4ODk3Mzc6IGJvb3RzdHJhcCB1c2VkClRTIDE3NDU4ODk3Mzc6IGNvbm4gl3RhcnRlZApUUyAxNzQ1ODg5NzM3OiBjb25uZWN0bW5nClRTIDE3NMU4ODk3Mzg6IHNzbCBjb25uZWN0ZWQKVFMgMTc0UTg4OTczODogaGVhZGVycyBzZW50ClRTIDM3NDU4ODk3Mzg6IGNoYW5uZWwgdXAKVFMgMTc0NTg4OTczODogY29tbXMgd2l0aCBjbG91ZCBkb3duClRTIDE3NDU4ODk3NDM6IGNvbm5lY3RpbmcKVFMgMTc0NTg4OTc0NDogc3NsIGNvbm5lY3RlZApUUyAxNzQ1ODg5NzQ0OiBoZWFkZXJzIHNlbnQKVFMgMTc0NTg4OTc0NDogY2hhbm5lbCB1cApUUyAxNzQ1ODg5NzYyOiBkaXNjb25uZWN0aW5nIGZyb20gYmFkIHNlbmQKVFMgMTc0NTg4OTc2MzogZZJyb3IgcmVjZWl2aW5nIGZyYW1lOgpUUyAxNzQ1ODg5NzYzOiBTU0wgLSBCYWQgaW5wdXQgcGFyYW1ldGVycyB0byBmdW5jdGlvblRTIDE3NDU4ODk3NjM6IApUUyAxNzQ1ODg5NzYzOiBjb21tcyBqaXRoIGNsb3VkIGRvd24KVFMgMTc0NTg4OTc2ODogY29ubmVjdGluZwpUUyAxNzQ1ODg5NzY4OiBzc2wgY29ubmVjdGVkClRTIDE3NDU4ODk3Njg6IGhlYWRlcnMgc2VudApMUyAbNyQ1OEg4NzY58iBjaGGubmVbIHVwUd==\"\n      }\n    }\n  },\n  \"network\": {\n    \"Ok\": {\n      \"endpoint_server\": \"0651b4f82df0a29c.edr.limacharlie.io\",\n      \"addresses\": [\n        \"34.160.14.29:443\"\n      ],\n      \"tcp_connect\": true,\n      \"proxy\": {\n        \"Ok\": {\n          \"proxy_server\": null,\n          \"tcp_connect\": false\n        }\n      },\n      \"cert_chain\": [\n        {\n          \"common_name\": \"0651b4f82df0a29c.edr.limacharlie.io\",\n          \"issuer\": \"C = Google Trust Services, O = US, CN = WR3\",\n          \"serial\": \"00:b3:f6:29:5a:3e:78:03:10:18:38:fd:4c:df:54:c5\",\n          \"not_before\": 1742383890,\n          \"not_after\": 1750163165,\n          \"is_ca\": false\n        },\n        {\n          \"common_name\": \"WR3\",\n          \"issuer\": \"C = Google Trust Services LLC, O = US, CN = GTS Root R1\",\n          \"serial\": \"7f:f0:05:a9:15:68:d6:3a:bc:22:86:16:84:aa:4b:5a\",\n          \"not_before\": 1702458000,\n          \"not_after\": 1866290400,\n          \"is_ca\": true\n        },\n        {\n          \"common_name\": \"GTS Root R1\",\n          \"issuer\": \"C = GlobalSign nv-sa, O = BE, CN = GlobalSign Root CA\",\n          \"serial\": \"77:bd:0d:6c:db:36:f9:1a:ea:21:0f:c4:f0:58:d3:0d\",\n          \"not_before\": 1592524842,\n          \"not_after\": 1832630442,\n          \"is_ca\": true\n        }\n      ]\n    }\n  },\n  \"verifier\": {\n    \"Ok\": {\n      \"pid\": 2024,\n      \"ppid\": 2023,\n      \"cpu_usage\": 0.0,\n      \"cwd\": \"/Users/username/Downloads\",\n      \"exe\": \"/usr/local/bin/rphcp\",\n      \"start_time\": 1745890277,\n      \"run_time\": 1,\n      \"memory\": 10125312,\n      \"virtual_memory\": 420875878400,\n      \"command_line\": [\n        \"/usr/local/bin/rphcp\",\n        \"-H\"\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"8-reference/faq/troubleshooting/#additional-help","title":"Additional Help","text":"<p>If these steps do not help, get in touch with us, and we will help you figure out the issue. The best way of contacting us is via our Community Site, followed by <code>support@limacharlie.io</code>.</p> <p>Similar to agents, Sensors send telemetry to the LimaCharlie platform in the form of EDR telemetry or forwarded logs. Sensors are offered as a scalable, serverless solution for securely connecting endpoints of an organization to the cloud.</p> <p>Installation keys are Base64-encoded strings provided to Sensors and Adapters in order to associate them with the correct Organization. Installation keys are created per-organization and offer a way to label and control your deployment population.</p> <p>In LimaCharlie, an Organization represents a tenant within the SecOps Cloud Platform, providing a self-contained environment to manage security data, configurations, and assets independently. Each Organization has its own sensors, detection rules, data sources, and outputs, offering complete control over security operations. This structure enables flexible, multi-tenant setups, ideal for managed security providers or enterprises managing multiple departments or clients.</p> <p>In LimaCharlie, a Sensor ID is a unique identifier assigned to each deployed endpoint agent (sensor). It distinguishes individual sensors across an organization's infrastructure, allowing LimaCharlie to track, manage, and communicate with each endpoint. The Sensor ID is critical for operations such as sending commands, collecting telemetry, and monitoring activity, ensuring that actions and data are accurately linked to specific devices or endpoints.</p>"},{"location":"assets/images/","title":"Logo and Image Assets","text":""},{"location":"assets/images/#required-assets","title":"Required Assets","text":"<p>This directory should contain the official LimaCharlie branding assets:</p>"},{"location":"assets/images/#logo-files","title":"Logo Files","text":"<ol> <li>logo.svg - Main logo for dark backgrounds</li> <li>Download from: https://brandfetch.com/limacharlie.io</li> <li>Or use the official logo from LimaCharlie marketing assets</li> <li> <p>Current file is a placeholder - replace with official logo</p> </li> <li> <p>logo-dark.svg (optional) - Logo variant for light backgrounds</p> </li> <li> <p>Use if you have a specific light background variant</p> </li> <li> <p>favicon.png - Site favicon</p> </li> <li>Recommended size: 512x512px or 256x256px</li> <li>Format: PNG with transparency</li> <li>Download icon from: https://brandfetch.com/limacharlie.io</li> <li>Current file is a placeholder - replace with official favicon</li> </ol>"},{"location":"assets/images/#getting-official-assets","title":"Getting Official Assets","text":"<p>Official LimaCharlie brand assets can be obtained from:</p> <ol> <li>Brandfetch: https://brandfetch.com/limacharlie.io</li> <li>Logos in SVG and PNG formats</li> <li>Official brand colors</li> <li> <p>Typography information</p> </li> <li> <p>LimaCharlie Marketing Team</p> </li> <li>Contact marketing@limacharlie.io for official brand assets</li> <li> <p>Request high-resolution logos and brand guidelines</p> </li> <li> <p>Website Assets</p> </li> <li>Some assets may be available on https://limacharlie.io</li> </ol>"},{"location":"assets/images/#brand-guidelines","title":"Brand Guidelines","text":"<p>When replacing the placeholder assets, ensure they match:</p> <ul> <li>Primary Color: Midnight (#00183c)</li> <li>Accent Color: Maroon Flush (#c32152)</li> <li>Fonts: Syne (headings), Rubik (body text)</li> </ul>"},{"location":"assets/images/#file-requirements","title":"File Requirements","text":"<ul> <li>Format: SVG preferred for logo (scales perfectly at any size)</li> <li>Background: Transparent or appropriate for dark theme</li> <li>Size: Logo should be recognizable at small sizes (navbar display)</li> <li>Colors: Should work with the dark theme (#00183c background)</li> </ul>"},{"location":"includes/glossary/","title":"Glossary","text":""}]}